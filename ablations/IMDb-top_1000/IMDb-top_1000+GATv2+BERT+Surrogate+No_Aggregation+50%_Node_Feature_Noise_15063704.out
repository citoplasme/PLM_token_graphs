[I 2025-02-28 10:55:22,401] Using an existing study with name 'IMDb-top_1000-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-No_Ablation-1.0-0.5' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 512). Running this sequence through the model will result in indexing errors
[I 2025-02-28 11:09:02,539] Trial 230 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9710082684115899, 'batch_size': 27, 'attention_heads': 5, 'hidden_dimension': 152, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4972217784969765, 'global_pooling': 'mean', 'learning_rate': 0.0005976465465352218, 'weight_decay': 1.5355603210575615e-06, 'beta_0': 0.8057565874711053, 'beta_1': 0.9905217739196919, 'epsilon': 8.12957171463165e-07, 'balanced_loss': False, 'epochs': 70, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 44.56 GiB of which 58.69 MiB is free. Including non-PyTorch memory, this process has 44.50 GiB memory in use. Of the allocated memory 40.19 GiB is allocated by PyTorch, and 3.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 11:21:24,663] Trial 231 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9033582526345979, 'batch_size': 35, 'attention_heads': 4, 'hidden_dimension': 139, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4849766637581832, 'global_pooling': 'mean', 'learning_rate': 7.264634936264252e-05, 'weight_decay': 1.135559277299532e-06, 'beta_0': 0.8093288739060949, 'beta_1': 0.9913223096046898, 'epsilon': 3.754461740551718e-06, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 24, 'plateau_patience': 19, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 11:37:21,585] Trial 232 finished with value: 0.8545454545454545 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9635743127429004, 'batch_size': 18, 'attention_heads': 5, 'hidden_dimension': 191, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5101271334960875, 'global_pooling': 'mean', 'learning_rate': 0.0005019617444117071, 'weight_decay': 1.0015363852279694e-06, 'beta_0': 0.8076508313443197, 'beta_1': 0.9810492563422132, 'epsilon': 7.836496053872597e-06, 'balanced_loss': False, 'epochs': 193, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 11:48:11,190] Trial 233 finished with value: 0.8787878787878788 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.958309363405209, 'batch_size': 17, 'attention_heads': 5, 'hidden_dimension': 41, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3792665854082426, 'global_pooling': 'mean', 'learning_rate': 0.0003331707738924708, 'weight_decay': 1.0022528692311802e-06, 'beta_0': 0.8062367360868606, 'beta_1': 0.990902753272346, 'epsilon': 2.745788493331817e-07, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 24, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 11:57:41,001] Trial 234 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9581116109609853, 'batch_size': 16, 'attention_heads': 5, 'hidden_dimension': 40, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37779254121012606, 'global_pooling': 'mean', 'learning_rate': 0.0008271232895583681, 'weight_decay': 1.1972191701740058e-06, 'beta_0': 0.8042940913876765, 'beta_1': 0.9907859240483294, 'epsilon': 2.5475706255836933e-07, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 22, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 12:08:04,150] Trial 235 finished with value: 0.8666666666666667 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9969507903338728, 'batch_size': 20, 'attention_heads': 5, 'hidden_dimension': 178, 'number_of_hidden_layers': 2, 'dropout_rate': 0.47185782847023977, 'global_pooling': 'mean', 'learning_rate': 0.0006487938134103502, 'weight_decay': 2.2520546267019047e-05, 'beta_0': 0.8190351319151254, 'beta_1': 0.9915867980188708, 'epsilon': 4.4108792756834824e-07, 'balanced_loss': False, 'epochs': 187, 'early_stopping_patience': 24, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 12:18:49,899] Trial 236 finished with value: 0.8424242424242424 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9601951910389849, 'batch_size': 48, 'attention_heads': 5, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4957080148494875, 'global_pooling': 'mean', 'learning_rate': 0.0003242612555182996, 'weight_decay': 1.338690848085415e-06, 'beta_0': 0.8061626535024659, 'beta_1': 0.9901495381473655, 'epsilon': 3.066535189514699e-07, 'balanced_loss': False, 'epochs': 196, 'early_stopping_patience': 23, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 12:28:18,451] Trial 237 finished with value: 0.8606060606060606 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9502710566760861, 'batch_size': 17, 'attention_heads': 4, 'hidden_dimension': 42, 'number_of_hidden_layers': 0, 'dropout_rate': 0.38961958321550916, 'global_pooling': 'mean', 'learning_rate': 0.0004229877524247271, 'weight_decay': 1.1287249837318322e-06, 'beta_0': 0.810819900742743, 'beta_1': 0.9908748370710854, 'epsilon': 1.5662639860929306e-07, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 24, 'plateau_patience': 20, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 12:41:42,372] Trial 238 finished with value: 0.5878787878787879 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9616099117680664, 'batch_size': 29, 'attention_heads': 5, 'hidden_dimension': 67, 'number_of_hidden_layers': 3, 'dropout_rate': 0.37294757305139287, 'global_pooling': 'mean', 'learning_rate': 0.014780080015112867, 'weight_decay': 1.320350649277698e-06, 'beta_0': 0.8023851560325586, 'beta_1': 0.9918765788706804, 'epsilon': 3.507557790148065e-07, 'balanced_loss': False, 'epochs': 105, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 12:53:39,194] Trial 239 finished with value: 0.8727272727272727 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.957362643141935, 'batch_size': 27, 'attention_heads': 4, 'hidden_dimension': 89, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4886760711231697, 'global_pooling': 'mean', 'learning_rate': 0.0010870325047311331, 'weight_decay': 0.00022087599816932382, 'beta_0': 0.806393611896369, 'beta_1': 0.9911597871530884, 'epsilon': 4.914493571876412e-06, 'balanced_loss': False, 'epochs': 184, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 13:05:05,632] Trial 240 finished with value: 0.5333333333333333 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9549755234696603, 'batch_size': 18, 'attention_heads': 4, 'hidden_dimension': 57, 'number_of_hidden_layers': 2, 'dropout_rate': 0.49182898386702867, 'global_pooling': 'mean', 'learning_rate': 0.09285939748894982, 'weight_decay': 1.6907266025556766e-06, 'beta_0': 0.8062922233189788, 'beta_1': 0.9915736311726501, 'epsilon': 5.314513446547295e-06, 'balanced_loss': False, 'epochs': 182, 'early_stopping_patience': 23, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 13:19:27,988] Trial 241 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9564300495550331, 'batch_size': 24, 'attention_heads': 4, 'hidden_dimension': 79, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4808430681213234, 'global_pooling': 'sum', 'learning_rate': 0.00010491956249537472, 'weight_decay': 0.000170518341783039, 'beta_0': 0.8091112540532056, 'beta_1': 0.9910737110589952, 'epsilon': 4.5725375114801636e-06, 'balanced_loss': False, 'epochs': 184, 'early_stopping_patience': 22, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 13:30:02,670] Trial 242 finished with value: 0.8545454545454545 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9595224880034153, 'batch_size': 27, 'attention_heads': 4, 'hidden_dimension': 47, 'number_of_hidden_layers': 2, 'dropout_rate': 0.49998448716005944, 'global_pooling': 'mean', 'learning_rate': 0.0009012026605691961, 'weight_decay': 6.041795102218662e-05, 'beta_0': 0.8039309609235517, 'beta_1': 0.9911447220553284, 'epsilon': 4.1228086500747485e-06, 'balanced_loss': False, 'epochs': 186, 'early_stopping_patience': 23, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 13:41:57,546] Trial 243 finished with value: 0.8545454545454545 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9574544841488749, 'batch_size': 28, 'attention_heads': 5, 'hidden_dimension': 70, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4878225203836345, 'global_pooling': 'mean', 'learning_rate': 0.0005687241358698008, 'weight_decay': 0.00020611948432641746, 'beta_0': 0.8074452606481651, 'beta_1': 0.9904610395678524, 'epsilon': 2.9778405567939274e-07, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 23, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 13:52:30,267] Trial 244 finished with value: 0.8545454545454545 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9617839928399524, 'batch_size': 30, 'attention_heads': 4, 'hidden_dimension': 88, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3818255765717524, 'global_pooling': 'mean', 'learning_rate': 0.000740099130439257, 'weight_decay': 0.00023731230361255813, 'beta_0': 0.8126994644315384, 'beta_1': 0.9802997520838471, 'epsilon': 6.719271427830091e-06, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 14, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 44.56 GiB of which 512.69 MiB is free. Including non-PyTorch memory, this process has 44.05 GiB memory in use. Of the allocated memory 40.07 GiB is allocated by PyTorch, and 2.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 14:01:18,166] Trial 245 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9589080892256486, 'batch_size': 26, 'attention_heads': 4, 'hidden_dimension': 184, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3851737415937841, 'global_pooling': 'mean', 'learning_rate': 0.0011075016276389563, 'weight_decay': 0.00013864396417622395, 'beta_0': 0.8164299154173505, 'beta_1': 0.9896945347766253, 'epsilon': 9.912910694274863e-07, 'balanced_loss': False, 'epochs': 180, 'early_stopping_patience': 22, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.93 GiB is free. Including non-PyTorch memory, this process has 42.63 GiB memory in use. Of the allocated memory 40.01 GiB is allocated by PyTorch, and 1.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 14:10:25,048] Trial 246 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9650886225435129, 'batch_size': 28, 'attention_heads': 5, 'hidden_dimension': 146, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3435888712245616, 'global_pooling': 'mean', 'learning_rate': 0.0010889357884567316, 'weight_decay': 0.00043437684435414, 'beta_0': 0.8048959534419592, 'beta_1': 0.9910676124935205, 'epsilon': 4.753861461950263e-06, 'balanced_loss': False, 'epochs': 186, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 14:20:29,106] Trial 247 finished with value: 0.8666666666666667 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9666668431629101, 'batch_size': 19, 'attention_heads': 5, 'hidden_dimension': 33, 'number_of_hidden_layers': 2, 'dropout_rate': 0.36636937023733207, 'global_pooling': 'mean', 'learning_rate': 0.0006391397363222902, 'weight_decay': 9.702144973747968e-06, 'beta_0': 0.8094328102149387, 'beta_1': 0.9903147036079735, 'epsilon': 8.928800535918204e-08, 'balanced_loss': True, 'epochs': 197, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 14:29:48,043] Trial 248 finished with value: 0.8424242424242424 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.962735473998257, 'batch_size': 44, 'attention_heads': 4, 'hidden_dimension': 39, 'number_of_hidden_layers': 0, 'dropout_rate': 0.39341093795083154, 'global_pooling': 'mean', 'learning_rate': 0.0004558796965957247, 'weight_decay': 4.988561480233551e-05, 'beta_0': 0.8205345711497323, 'beta_1': 0.9906965091999825, 'epsilon': 1.8192290507916254e-07, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 14:39:03,756] Trial 249 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9872388245049224, 'batch_size': 17, 'attention_heads': 5, 'hidden_dimension': 46, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5230192802005315, 'global_pooling': 'mean', 'learning_rate': 0.0005156616308894743, 'weight_decay': 1.0939379838981705e-06, 'beta_0': 0.8066137244432153, 'beta_1': 0.9805525434744277, 'epsilon': 3.47780121033917e-06, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 3.40 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.56 GiB is free. Including non-PyTorch memory, this process has 42.00 GiB memory in use. Of the allocated memory 39.08 GiB is allocated by PyTorch, and 1.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 14:47:51,500] Trial 250 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.953517826970648, 'batch_size': 26, 'attention_heads': 5, 'hidden_dimension': 225, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3763011626813048, 'global_pooling': 'mean', 'learning_rate': 0.0013591831460157873, 'weight_decay': 2.5407586371849213e-06, 'beta_0': 0.8555654649929542, 'beta_1': 0.9921194293099713, 'epsilon': 5.961966680526663e-06, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 22, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 5.95 GiB. GPU 0 has a total capacity of 44.56 GiB of which 5.07 GiB is free. Including non-PyTorch memory, this process has 39.49 GiB memory in use. Of the allocated memory 37.09 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 14:56:25,513] Trial 251 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9609340854622375, 'batch_size': 38, 'attention_heads': 9, 'hidden_dimension': 188, 'number_of_hidden_layers': 2, 'dropout_rate': 0.38900951086559354, 'global_pooling': 'mean', 'learning_rate': 0.0008345593175814986, 'weight_decay': 0.0006816431221463635, 'beta_0': 0.8112354015762602, 'beta_1': 0.9912170113285158, 'epsilon': 2.4606214715770433e-07, 'balanced_loss': False, 'epochs': 198, 'early_stopping_patience': 25, 'plateau_patience': 20, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 15:06:20,093] Trial 252 finished with value: 0.8545454545454545 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9745830807378062, 'batch_size': 27, 'attention_heads': 4, 'hidden_dimension': 32, 'number_of_hidden_layers': 0, 'dropout_rate': 0.44634775888358635, 'global_pooling': 'mean', 'learning_rate': 0.0002530272758291785, 'weight_decay': 1.2428843378424482e-06, 'beta_0': 0.8021411390391755, 'beta_1': 0.9905596462093756, 'epsilon': 5.679188564315414e-07, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.46 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.03 GiB is free. Including non-PyTorch memory, this process has 43.52 GiB memory in use. Of the allocated memory 38.13 GiB is allocated by PyTorch, and 4.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 15:22:53,110] Trial 253 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9643073351625226, 'batch_size': 29, 'attention_heads': 4, 'hidden_dimension': 104, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3798147802771736, 'global_pooling': 'mean', 'learning_rate': 0.00011680375578614993, 'weight_decay': 1.0897799875106216e-06, 'beta_0': 0.8355987836990553, 'beta_1': 0.9882580290304565, 'epsilon': 1.2414195068541145e-06, 'balanced_loss': False, 'epochs': 184, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 15:32:53,667] Trial 254 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9840779704291225, 'batch_size': 21, 'attention_heads': 5, 'hidden_dimension': 183, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3373753624974462, 'global_pooling': 'mean', 'learning_rate': 0.0004105058945022317, 'weight_decay': 1.4322206146009646e-06, 'beta_0': 0.8396705408190452, 'beta_1': 0.9900147498585598, 'epsilon': 2.0947552919081434e-06, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 22, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 15:44:19,881] Trial 255 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9927074017629357, 'batch_size': 18, 'attention_heads': 4, 'hidden_dimension': 178, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3988412106732372, 'global_pooling': 'mean', 'learning_rate': 0.00015120092121455013, 'weight_decay': 1.2839497212775311e-06, 'beta_0': 0.8179788157366968, 'beta_1': 0.9800284780045976, 'epsilon': 7.190902196290617e-06, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 16, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 15:55:23,039] Trial 256 finished with value: 0.8424242424242424 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9581852529679609, 'batch_size': 19, 'attention_heads': 5, 'hidden_dimension': 174, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4925783582381488, 'global_pooling': 'mean', 'learning_rate': 0.0006977588417671949, 'weight_decay': 1.0094113168481373e-06, 'beta_0': 0.8141472564135958, 'beta_1': 0.9916781799805124, 'epsilon': 8.329685238117576e-07, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 23, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 16:10:59,035] Trial 257 finished with value: 0.8727272727272727 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.968626885255377, 'batch_size': 16, 'attention_heads': 5, 'hidden_dimension': 192, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3700080348915507, 'global_pooling': 'mean', 'learning_rate': 8.9906197393151e-05, 'weight_decay': 1.0110442059052714e-06, 'beta_0': 0.8091758221767923, 'beta_1': 0.9808906331305004, 'epsilon': 5.653888849025738e-06, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 21, 'plateau_patience': 22, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 16:30:41,187] Trial 258 finished with value: 0.8363636363636363 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9704684516644624, 'batch_size': 16, 'attention_heads': 4, 'hidden_dimension': 219, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3660971377098415, 'global_pooling': 'sum', 'learning_rate': 0.0001119121139465914, 'weight_decay': 0.00020483568087003068, 'beta_0': 0.8091331807711112, 'beta_1': 0.9810001373659728, 'epsilon': 5.113676987117326e-06, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 16:43:20,040] Trial 259 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9673248635296159, 'batch_size': 16, 'attention_heads': 5, 'hidden_dimension': 88, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3474365339647954, 'global_pooling': 'mean', 'learning_rate': 9.540213616297317e-05, 'weight_decay': 3.311984408818364e-06, 'beta_0': 0.8075591556877181, 'beta_1': 0.9815232819773013, 'epsilon': 6.788694618645194e-06, 'balanced_loss': False, 'epochs': 198, 'early_stopping_patience': 21, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 16:56:53,777] Trial 260 finished with value: 0.8545454545454545 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9686959171005802, 'batch_size': 17, 'attention_heads': 4, 'hidden_dimension': 203, 'number_of_hidden_layers': 2, 'dropout_rate': 0.356833684808446, 'global_pooling': 'max', 'learning_rate': 0.000336779259907197, 'weight_decay': 1.0000224052042192e-06, 'beta_0': 0.8043641056082694, 'beta_1': 0.980585934990683, 'epsilon': 5.795653414882604e-06, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 21, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 17:11:53,806] Trial 261 finished with value: 0.8666666666666667 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9479724782524062, 'batch_size': 16, 'attention_heads': 8, 'hidden_dimension': 57, 'number_of_hidden_layers': 2, 'dropout_rate': 0.37379268738495147, 'global_pooling': 'mean', 'learning_rate': 8.521662136376382e-05, 'weight_decay': 1.2228048877621096e-06, 'beta_0': 0.8109981956232778, 'beta_1': 0.9812075592202708, 'epsilon': 9.141102338562618e-06, 'balanced_loss': False, 'epochs': 196, 'early_stopping_patience': 21, 'plateau_patience': 22, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 17:26:30,779] Trial 262 finished with value: 0.8666666666666667 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9723236412702995, 'batch_size': 18, 'attention_heads': 5, 'hidden_dimension': 150, 'number_of_hidden_layers': 2, 'dropout_rate': 0.36242451616879445, 'global_pooling': 'mean', 'learning_rate': 6.368809431743246e-05, 'weight_decay': 1.5115179640274523e-06, 'beta_0': 0.8067510017936967, 'beta_1': 0.980825720005343, 'epsilon': 4.733803728309267e-06, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 22, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.03 GiB is free. Including non-PyTorch memory, this process has 43.53 GiB memory in use. Of the allocated memory 40.89 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 17:36:01,570] Trial 263 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.960099223467073, 'batch_size': 20, 'attention_heads': 4, 'hidden_dimension': 196, 'number_of_hidden_layers': 2, 'dropout_rate': 0.47281214539901917, 'global_pooling': 'mean', 'learning_rate': 0.00012891146493629817, 'weight_decay': 1.8860658005563495e-06, 'beta_0': 0.8088777263253386, 'beta_1': 0.9805043703876751, 'epsilon': 7.976395208672674e-06, 'balanced_loss': False, 'epochs': 181, 'early_stopping_patience': 22, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 17:53:10,090] Trial 264 finished with value: 0.8606060606060606 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9658692076970917, 'batch_size': 17, 'attention_heads': 5, 'hidden_dimension': 185, 'number_of_hidden_layers': 2, 'dropout_rate': 0.37069403660922845, 'global_pooling': 'mean', 'learning_rate': 7.571999060193228e-05, 'weight_decay': 1.1427282101997009e-06, 'beta_0': 0.8054866256900733, 'beta_1': 0.985169400733532, 'epsilon': 9.293478915032775e-05, 'balanced_loss': False, 'epochs': 177, 'early_stopping_patience': 23, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.05 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.86 GiB is free. Including non-PyTorch memory, this process has 42.69 GiB memory in use. Of the allocated memory 39.36 GiB is allocated by PyTorch, and 2.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 18:07:32,713] Trial 265 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9694556863578306, 'batch_size': 25, 'attention_heads': 6, 'hidden_dimension': 160, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5128094002206773, 'global_pooling': 'mean', 'learning_rate': 0.0005756393256208084, 'weight_decay': 1.0002927138729362e-06, 'beta_0': 0.8126361491437566, 'beta_1': 0.9813090695520013, 'epsilon': 2.666410596972451e-07, 'balanced_loss': False, 'epochs': 82, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.74 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.54 GiB is free. Including non-PyTorch memory, this process has 43.02 GiB memory in use. Of the allocated memory 40.24 GiB is allocated by PyTorch, and 1.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 18:16:23,554] Trial 266 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9566286517878257, 'batch_size': 17, 'attention_heads': 5, 'hidden_dimension': 171, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3790016450837391, 'global_pooling': 'mean', 'learning_rate': 0.000490219896052282, 'weight_decay': 1.3565897569889296e-06, 'beta_0': 0.8037477987520854, 'beta_1': 0.980967681992413, 'epsilon': 6.702940060859331e-07, 'balanced_loss': False, 'epochs': 193, 'early_stopping_patience': 21, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 18:31:49,940] Trial 267 finished with value: 0.8666666666666667 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9623697420071359, 'batch_size': 19, 'attention_heads': 4, 'hidden_dimension': 190, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5021832361354486, 'global_pooling': 'mean', 'learning_rate': 9.356385053564179e-05, 'weight_decay': 1.6746081885883068e-06, 'beta_0': 0.8101755108159676, 'beta_1': 0.9910298636353514, 'epsilon': 4.070684321933942e-07, 'balanced_loss': False, 'epochs': 185, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 18:45:26,759] Trial 268 finished with value: 0.8545454545454545 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9811726209608315, 'batch_size': 18, 'attention_heads': 6, 'hidden_dimension': 138, 'number_of_hidden_layers': 2, 'dropout_rate': 0.350447719451019, 'global_pooling': 'mean', 'learning_rate': 4.952122438244981e-05, 'weight_decay': 1.5498603409542598e-05, 'beta_0': 0.895622674091819, 'beta_1': 0.9924364618393563, 'epsilon': 4.080347122598643e-06, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 13, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 18:58:19,508] Trial 269 finished with value: 0.8727272727272727 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9734796451268263, 'batch_size': 16, 'attention_heads': 4, 'hidden_dimension': 178, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4873322444776939, 'global_pooling': 'mean', 'learning_rate': 0.00021513645510430588, 'weight_decay': 0.00034578952343180104, 'beta_0': 0.8001818795251745, 'beta_1': 0.9974504929626943, 'epsilon': 1.0673437478450876e-06, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 22, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 19:12:20,258] Trial 270 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9738446379704828, 'batch_size': 16, 'attention_heads': 4, 'hidden_dimension': 179, 'number_of_hidden_layers': 2, 'dropout_rate': 0.48547650074447873, 'global_pooling': 'mean', 'learning_rate': 0.00020048305290332552, 'weight_decay': 0.00032425926254142705, 'beta_0': 0.8006453265052721, 'beta_1': 0.9943532790154133, 'epsilon': 1.1215245579655418e-06, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 22, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 19:29:59,864] Trial 271 finished with value: 0.8363636363636363 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9710175492294735, 'batch_size': 16, 'attention_heads': 4, 'hidden_dimension': 175, 'number_of_hidden_layers': 2, 'dropout_rate': 0.47831650845233303, 'global_pooling': 'sum', 'learning_rate': 0.00019215968841574996, 'weight_decay': 0.00031683866389101666, 'beta_0': 0.8021111329594776, 'beta_1': 0.9983096819346565, 'epsilon': 1.5348422124270252e-06, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 22, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 19:42:24,132] Trial 272 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9759975343761448, 'batch_size': 18, 'attention_heads': 4, 'hidden_dimension': 182, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4873684482839448, 'global_pooling': 'mean', 'learning_rate': 0.00014378019135372435, 'weight_decay': 2.217972438774902e-06, 'beta_0': 0.8010258092133427, 'beta_1': 0.995449113922868, 'epsilon': 1.0037236067777947e-06, 'balanced_loss': True, 'epochs': 197, 'early_stopping_patience': 22, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacity of 44.56 GiB of which 380.69 MiB is free. Including non-PyTorch memory, this process has 44.18 GiB memory in use. Of the allocated memory 41.29 GiB is allocated by PyTorch, and 1.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 19:50:58,530] Trial 273 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9722225197942129, 'batch_size': 23, 'attention_heads': 11, 'hidden_dimension': 169, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4912746204935217, 'global_pooling': 'mean', 'learning_rate': 0.00027506486070001527, 'weight_decay': 0.00039536686656314207, 'beta_0': 0.8034664187597681, 'beta_1': 0.9935260304924075, 'epsilon': 1.2746290092092154e-06, 'balanced_loss': True, 'epochs': 187, 'early_stopping_patience': 21, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 20:02:26,695] Trial 274 finished with value: 0.8363636363636363 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9789610238966336, 'batch_size': 51, 'attention_heads': 4, 'hidden_dimension': 187, 'number_of_hidden_layers': 0, 'dropout_rate': 0.49807048431301243, 'global_pooling': 'mean', 'learning_rate': 0.00015054905789997413, 'weight_decay': 0.00025102358871035104, 'beta_0': 0.8755104216883577, 'beta_1': 0.9974532189646418, 'epsilon': 2.1007145239973925e-07, 'balanced_loss': True, 'epochs': 192, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 5.46 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.47 GiB is free. Including non-PyTorch memory, this process has 41.09 GiB memory in use. Of the allocated memory 38.61 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 20:11:01,064] Trial 275 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9514248346778502, 'batch_size': 24, 'attention_heads': 10, 'hidden_dimension': 195, 'number_of_hidden_layers': 2, 'dropout_rate': 0.38446014222900354, 'global_pooling': 'mean', 'learning_rate': 0.0002263063026622308, 'weight_decay': 2.771044797373724e-06, 'beta_0': 0.8448955442241146, 'beta_1': 0.9963194446476251, 'epsilon': 1.7669444210668098e-06, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 23, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.23 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.59 GiB is free. Including non-PyTorch memory, this process has 42.97 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 3.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 20:19:25,805] Trial 276 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9682536634006317, 'batch_size': 27, 'attention_heads': 5, 'hidden_dimension': 214, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3752994045478563, 'global_pooling': 'mean', 'learning_rate': 0.00011928611643279034, 'weight_decay': 1.2626841079414662e-06, 'beta_0': 0.8147221879976394, 'beta_1': 0.9801791571876749, 'epsilon': 7.398841707883783e-07, 'balanced_loss': False, 'epochs': 182, 'early_stopping_patience': 22, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 20:33:16,129] Trial 277 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9772938236352667, 'batch_size': 19, 'attention_heads': 16, 'hidden_dimension': 180, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4796443934666653, 'global_pooling': 'mean', 'learning_rate': 0.00016461117729759696, 'weight_decay': 1.53984668473294e-06, 'beta_0': 0.8085886287390244, 'beta_1': 0.9894740729661945, 'epsilon': 8.991022729722497e-07, 'balanced_loss': False, 'epochs': 196, 'early_stopping_patience': 12, 'plateau_patience': 20, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 20:55:00,647] Trial 278 finished with value: 0.8666666666666667 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.973043265524447, 'batch_size': 16, 'attention_heads': 5, 'hidden_dimension': 78, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5054788408772568, 'global_pooling': 'mean', 'learning_rate': 0.0006118768021888546, 'weight_decay': 0.0006376309337024393, 'beta_0': 0.8004384813207606, 'beta_1': 0.9887222908056579, 'epsilon': 1.1122869087388248e-06, 'balanced_loss': False, 'epochs': 189, 'early_stopping_patience': 22, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.93 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.58 GiB is free. Including non-PyTorch memory, this process has 42.98 GiB memory in use. Of the allocated memory 39.12 GiB is allocated by PyTorch, and 2.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 21:06:27,345] Trial 279 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9585856738491061, 'batch_size': 21, 'attention_heads': 4, 'hidden_dimension': 165, 'number_of_hidden_layers': 2, 'dropout_rate': 0.33288953493337725, 'global_pooling': 'mean', 'learning_rate': 0.0004290002133257959, 'weight_decay': 1.1664795640309336e-06, 'beta_0': 0.8059396707595603, 'beta_1': 0.9942036757050514, 'epsilon': 2.4801717466500258e-05, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 23, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 21:16:06,746] Trial 280 finished with value: 0.8545454545454545 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9543986632747786, 'batch_size': 17, 'attention_heads': 4, 'hidden_dimension': 52, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3635896788390159, 'global_pooling': 'mean', 'learning_rate': 0.0007263474637624403, 'weight_decay': 3.535248126889864e-05, 'beta_0': 0.8114202600390885, 'beta_1': 0.9804930020191194, 'epsilon': 5.260977755650394e-07, 'balanced_loss': True, 'epochs': 92, 'early_stopping_patience': 25, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 21:30:33,572] Trial 281 finished with value: 0.793939393939394 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.974826829678209, 'batch_size': 20, 'attention_heads': 5, 'hidden_dimension': 37, 'number_of_hidden_layers': 2, 'dropout_rate': 0.37192735419448375, 'global_pooling': 'mean', 'learning_rate': 1.0942290680543605e-05, 'weight_decay': 1.3722177078408315e-06, 'beta_0': 0.8040383753687382, 'beta_1': 0.9906743487021437, 'epsilon': 5.616794318597402e-06, 'balanced_loss': False, 'epochs': 160, 'early_stopping_patience': 22, 'plateau_patience': 13, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 21:42:46,920] Trial 282 finished with value: 0.8545454545454545 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9659110833195925, 'batch_size': 29, 'attention_heads': 4, 'hidden_dimension': 193, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4560386077977618, 'global_pooling': 'max', 'learning_rate': 0.0005600509393604217, 'weight_decay': 2.5979611467119657e-05, 'beta_0': 0.8077815198973775, 'beta_1': 0.9869065889493699, 'epsilon': 3.76807407689411e-07, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.18 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 43.49 GiB memory in use. Of the allocated memory 40.90 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 21:51:20,925] Trial 283 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9610481280081477, 'batch_size': 25, 'attention_heads': 5, 'hidden_dimension': 187, 'number_of_hidden_layers': 2, 'dropout_rate': 0.34196260054215616, 'global_pooling': 'mean', 'learning_rate': 0.0010097211833343803, 'weight_decay': 5.372681953450297e-06, 'beta_0': 0.8131333440301924, 'beta_1': 0.9915314672405828, 'epsilon': 1.499752403496477e-06, 'balanced_loss': False, 'epochs': 88, 'early_stopping_patience': 22, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 22:05:55,358] Trial 284 finished with value: 0.8606060606060606 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9702732393404134, 'batch_size': 27, 'attention_heads': 4, 'hidden_dimension': 176, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3892770439612979, 'global_pooling': 'sum', 'learning_rate': 0.0003137356162118232, 'weight_decay': 1.8946142340011422e-06, 'beta_0': 0.8095029381558242, 'beta_1': 0.9879090554152852, 'epsilon': 3.7418842094213107e-06, 'balanced_loss': False, 'epochs': 185, 'early_stopping_patience': 21, 'plateau_patience': 20, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 22:24:51,578] Trial 285 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9641036961617088, 'batch_size': 18, 'attention_heads': 5, 'hidden_dimension': 200, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4685019076688296, 'global_pooling': 'mean', 'learning_rate': 7.775793440668042e-05, 'weight_decay': 4.362520323498244e-06, 'beta_0': 0.805665531738424, 'beta_1': 0.9891768426301888, 'epsilon': 5.289054203452984e-08, 'balanced_loss': False, 'epochs': 53, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.54 GiB. GPU 0 has a total capacity of 44.56 GiB of which 874.69 MiB is free. Including non-PyTorch memory, this process has 43.70 GiB memory in use. Of the allocated memory 41.24 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 22:33:44,488] Trial 286 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9572670839130711, 'batch_size': 26, 'attention_heads': 5, 'hidden_dimension': 183, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3838124788283429, 'global_pooling': 'mean', 'learning_rate': 0.0008293576651097606, 'weight_decay': 1.1576825060122208e-06, 'beta_0': 0.8641622850759201, 'beta_1': 0.9964257506593892, 'epsilon': 8.269626545409685e-07, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 22:44:39,641] Trial 287 finished with value: 0.8484848484848485 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9669778385912515, 'batch_size': 28, 'attention_heads': 4, 'hidden_dimension': 191, 'number_of_hidden_layers': 0, 'dropout_rate': 0.492425923474734, 'global_pooling': 'mean', 'learning_rate': 0.0005013087607365433, 'weight_decay': 1.428811260587767e-06, 'beta_0': 0.8022487248320256, 'beta_1': 0.9800333083759766, 'epsilon': 6.508640099151732e-07, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 4.54 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.68 GiB is free. Including non-PyTorch memory, this process has 40.87 GiB memory in use. Of the allocated memory 37.92 GiB is allocated by PyTorch, and 1.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 22:53:32,178] Trial 288 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9597971285605663, 'batch_size': 17, 'attention_heads': 12, 'hidden_dimension': 223, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3582748134623944, 'global_pooling': 'mean', 'learning_rate': 0.0007167285542744627, 'weight_decay': 1.6724498474076413e-06, 'beta_0': 0.821559111549976, 'beta_1': 0.9807632032385537, 'epsilon': 1.2877043485794784e-05, 'balanced_loss': False, 'epochs': 179, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 23:08:40,014] Trial 289 finished with value: 0.8545454545454545 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.96328043106397, 'batch_size': 18, 'attention_heads': 5, 'hidden_dimension': 180, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3933179140965924, 'global_pooling': 'mean', 'learning_rate': 0.00037183431455655705, 'weight_decay': 1.234321827606617e-06, 'beta_0': 0.8160359670896769, 'beta_1': 0.9909640258972567, 'epsilon': 4.469237113085726e-06, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 23, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 23:21:59,913] Trial 290 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9613237173905845, 'batch_size': 19, 'attention_heads': 4, 'hidden_dimension': 173, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3787539154343775, 'global_pooling': 'mean', 'learning_rate': 0.00010164674974081714, 'weight_decay': 2.347604835829392e-06, 'beta_0': 0.8267843852612402, 'beta_1': 0.9905502102219758, 'epsilon': 2.8831955196600705e-06, 'balanced_loss': True, 'epochs': 194, 'early_stopping_patience': 22, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 5.11 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.18 GiB is free. Including non-PyTorch memory, this process has 42.37 GiB memory in use. Of the allocated memory 39.86 GiB is allocated by PyTorch, and 1.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 23:35:34,301] Trial 291 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9337799432346271, 'batch_size': 30, 'attention_heads': 5, 'hidden_dimension': 208, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3676137918683965, 'global_pooling': 'mean', 'learning_rate': 0.0006396619990859032, 'weight_decay': 1.1513577542157454e-06, 'beta_0': 0.8103353922370398, 'beta_1': 0.9900448287610076, 'epsilon': 6.226065639489251e-06, 'balanced_loss': False, 'epochs': 183, 'early_stopping_patience': 15, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.61 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.00 GiB is free. Including non-PyTorch memory, this process has 43.55 GiB memory in use. Of the allocated memory 39.91 GiB is allocated by PyTorch, and 2.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 23:44:28,237] Trial 292 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.955717263620948, 'batch_size': 32, 'attention_heads': 4, 'hidden_dimension': 185, 'number_of_hidden_layers': 3, 'dropout_rate': 0.4223128704139327, 'global_pooling': 'mean', 'learning_rate': 0.0005006917321955552, 'weight_decay': 0.00042031221881116076, 'beta_0': 0.8072466639121954, 'beta_1': 0.9860060150670327, 'epsilon': 9.953676047355744e-06, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-02-28 23:56:52,799] Trial 293 finished with value: 0.8484848484848485 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.968154174076398, 'batch_size': 16, 'attention_heads': 5, 'hidden_dimension': 145, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4842853143366112, 'global_pooling': 'mean', 'learning_rate': 0.00017241419736064177, 'weight_decay': 0.00014717111196211908, 'beta_0': 0.8120248289947732, 'beta_1': 0.9803267595607856, 'epsilon': 1.36029857586026e-06, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 23, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 44.56 GiB of which 968.69 MiB is free. Including non-PyTorch memory, this process has 43.61 GiB memory in use. Of the allocated memory 39.94 GiB is allocated by PyTorch, and 2.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 00:06:09,058] Trial 294 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9647973103433252, 'batch_size': 22, 'attention_heads': 4, 'hidden_dimension': 218, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3495404350478145, 'global_pooling': 'mean', 'learning_rate': 0.00041777239270266407, 'weight_decay': 1.374258653115509e-06, 'beta_0': 0.8236159290535657, 'beta_1': 0.9919263077583629, 'epsilon': 5.074256632096764e-05, 'balanced_loss': False, 'epochs': 147, 'early_stopping_patience': 22, 'plateau_patience': 20, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 00:16:38,222] Trial 295 finished with value: 0.8363636363636363 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9862814568478137, 'batch_size': 17, 'attention_heads': 5, 'hidden_dimension': 72, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3795480788785311, 'global_pooling': 'mean', 'learning_rate': 6.133035410896806e-05, 'weight_decay': 1.0054175360923177e-06, 'beta_0': 0.8048672899196627, 'beta_1': 0.9912953835307745, 'epsilon': 3.4366022800821376e-07, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 00:28:55,767] Trial 296 finished with value: 0.8666666666666667 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9887967341026535, 'batch_size': 42, 'attention_heads': 4, 'hidden_dimension': 190, 'number_of_hidden_layers': 2, 'dropout_rate': 0.38685035048413563, 'global_pooling': 'sum', 'learning_rate': 0.0009791725577639747, 'weight_decay': 1.5823455300173227e-06, 'beta_0': 0.8305693456163692, 'beta_1': 0.9875760396786474, 'epsilon': 3.471242146394793e-05, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 00:39:04,483] Trial 297 finished with value: 0.8121212121212121 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9586701393778493, 'batch_size': 20, 'attention_heads': 5, 'hidden_dimension': 103, 'number_of_hidden_layers': 0, 'dropout_rate': 0.39987801310624743, 'global_pooling': 'mean', 'learning_rate': 0.04440540239698851, 'weight_decay': 1.280488054416829e-05, 'beta_0': 0.802749699314486, 'beta_1': 0.9807283608039898, 'epsilon': 5.3161810132890336e-06, 'balanced_loss': False, 'epochs': 174, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.70 GiB is free. Including non-PyTorch memory, this process has 42.85 GiB memory in use. Of the allocated memory 40.36 GiB is allocated by PyTorch, and 1.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 00:47:44,585] Trial 298 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9714635263502136, 'batch_size': 28, 'attention_heads': 7, 'hidden_dimension': 169, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4960973525835354, 'global_pooling': 'mean', 'learning_rate': 0.0002657274380089549, 'weight_decay': 1.181478038255929e-06, 'beta_0': 0.8088130160799604, 'beta_1': 0.9896872884803347, 'epsilon': 2.907767096470336e-07, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 01:04:13,578] Trial 299 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.962423968499594, 'batch_size': 18, 'attention_heads': 4, 'hidden_dimension': 228, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5216539145570858, 'global_pooling': 'mean', 'learning_rate': 0.00011767962272478266, 'weight_decay': 0.0003490619648645305, 'beta_0': 0.8132977907612907, 'beta_1': 0.9902556180807309, 'epsilon': 7.657627423818381e-06, 'balanced_loss': True, 'epochs': 190, 'early_stopping_patience': 23, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 01:18:19,419] Trial 300 finished with value: 0.8424242424242424 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9660668172065687, 'batch_size': 26, 'attention_heads': 5, 'hidden_dimension': 198, 'number_of_hidden_layers': 0, 'dropout_rate': 0.371668440160414, 'global_pooling': 'mean', 'learning_rate': 8.695002141375753e-05, 'weight_decay': 1.980956596554601e-06, 'beta_0': 0.8823507881694577, 'beta_1': 0.9811164471650154, 'epsilon': 1.0017882037944677e-06, 'balanced_loss': False, 'epochs': 185, 'early_stopping_patience': 24, 'plateau_patience': 20, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 01:34:43,889] Trial 301 finished with value: 0.8787878787878788 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9601266709496704, 'batch_size': 16, 'attention_heads': 5, 'hidden_dimension': 156, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5007813663422327, 'global_pooling': 'mean', 'learning_rate': 0.0006091378660163648, 'weight_decay': 0.00019488337222200127, 'beta_0': 0.8056811787136128, 'beta_1': 0.99094598106301, 'epsilon': 4.757265101073057e-07, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 24, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 01:49:03,715] Trial 302 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.95981378088013, 'batch_size': 16, 'attention_heads': 4, 'hidden_dimension': 155, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4977875802569052, 'global_pooling': 'mean', 'learning_rate': 0.0006442200486241544, 'weight_decay': 0.00018590903530723448, 'beta_0': 0.8052086058791209, 'beta_1': 0.9841174207343207, 'epsilon': 4.740276026545574e-07, 'balanced_loss': False, 'epochs': 193, 'early_stopping_patience': 25, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.62 GiB. GPU 0 has a total capacity of 44.56 GiB of which 216.69 MiB is free. Including non-PyTorch memory, this process has 44.34 GiB memory in use. Of the allocated memory 41.62 GiB is allocated by PyTorch, and 1.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 01:58:40,225] Trial 303 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9542928559032229, 'batch_size': 16, 'attention_heads': 5, 'hidden_dimension': 158, 'number_of_hidden_layers': 2, 'dropout_rate': 0.506471783256529, 'global_pooling': 'mean', 'learning_rate': 0.0008108910055278877, 'weight_decay': 0.0002348123522680212, 'beta_0': 0.8001655218694679, 'beta_1': 0.9855513986053364, 'epsilon': 7.257616206541592e-07, 'balanced_loss': False, 'epochs': 196, 'early_stopping_patience': 24, 'plateau_patience': 14, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 02:09:14,290] Trial 304 finished with value: 0.8424242424242424 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9612131439965097, 'batch_size': 17, 'attention_heads': 4, 'hidden_dimension': 145, 'number_of_hidden_layers': 0, 'dropout_rate': 0.49846894662883234, 'global_pooling': 'mean', 'learning_rate': 0.0005831282920239528, 'weight_decay': 1.1150470307440581e-06, 'beta_0': 0.806646480612275, 'beta_1': 0.9908204663341599, 'epsilon': 5.632960384863671e-07, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.74 GiB is free. Including non-PyTorch memory, this process has 42.81 GiB memory in use. Of the allocated memory 40.26 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 02:22:21,347] Trial 305 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9583422638429233, 'batch_size': 27, 'attention_heads': 6, 'hidden_dimension': 139, 'number_of_hidden_layers': 2, 'dropout_rate': 0.486407624783374, 'global_pooling': 'max', 'learning_rate': 0.00047731139821339754, 'weight_decay': 0.00022585338060529346, 'beta_0': 0.8609331991684549, 'beta_1': 0.9804061729699447, 'epsilon': 5.335802374023082e-07, 'balanced_loss': False, 'epochs': 198, 'early_stopping_patience': 18, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 02:33:36,673] Trial 306 finished with value: 0.8606060606060606 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9632211738114734, 'batch_size': 29, 'attention_heads': 5, 'hidden_dimension': 152, 'number_of_hidden_layers': 0, 'dropout_rate': 0.47582787652308806, 'global_pooling': 'mean', 'learning_rate': 0.0012208406462338708, 'weight_decay': 0.000262163846192297, 'beta_0': 0.8038435544118825, 'beta_1': 0.9948023464978163, 'epsilon': 4.666287790643979e-07, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacity of 44.56 GiB of which 242.69 MiB is free. Including non-PyTorch memory, this process has 44.32 GiB memory in use. Of the allocated memory 41.19 GiB is allocated by PyTorch, and 1.97 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 02:44:18,350] Trial 307 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9494226396058242, 'batch_size': 17, 'attention_heads': 4, 'hidden_dimension': 165, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32174962275663704, 'global_pooling': 'mean', 'learning_rate': 0.0007281457623036115, 'weight_decay': 0.00029908840981455516, 'beta_0': 0.8026690247715176, 'beta_1': 0.9914089841550773, 'epsilon': 6.650681599694124e-07, 'balanced_loss': False, 'epochs': 189, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.21 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.18 GiB is free. Including non-PyTorch memory, this process has 42.37 GiB memory in use. Of the allocated memory 39.81 GiB is allocated by PyTorch, and 1.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 02:53:10,772] Trial 308 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9606973282727301, 'batch_size': 25, 'attention_heads': 6, 'hidden_dimension': 150, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5121669527750429, 'global_pooling': 'mean', 'learning_rate': 0.0005498665398833419, 'weight_decay': 0.0009733153604421686, 'beta_0': 0.8107780477545025, 'beta_1': 0.9808753682187877, 'epsilon': 4.816212519318848e-06, 'balanced_loss': True, 'epochs': 165, 'early_stopping_patience': 25, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 03:04:52,310] Trial 309 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.952317497261711, 'batch_size': 19, 'attention_heads': 5, 'hidden_dimension': 211, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5036764601927795, 'global_pooling': 'mean', 'learning_rate': 0.0003641764135981552, 'weight_decay': 0.000535141631020011, 'beta_0': 0.8147297805540877, 'beta_1': 0.981344691937819, 'epsilon': 3.5414146924058377e-06, 'balanced_loss': False, 'epochs': 131, 'early_stopping_patience': 10, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 03:18:21,653] Trial 310 finished with value: 0.8545454545454545 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9560468688531156, 'batch_size': 16, 'attention_heads': 4, 'hidden_dimension': 44, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3544938215431075, 'global_pooling': 'sum', 'learning_rate': 0.00043743272006449747, 'weight_decay': 1.3105326143835362e-06, 'beta_0': 0.8473723648235206, 'beta_1': 0.993221368653856, 'epsilon': 2.3215641157160434e-06, 'balanced_loss': False, 'epochs': 198, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 03:29:39,899] Trial 311 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9650968137012413, 'batch_size': 28, 'attention_heads': 5, 'hidden_dimension': 204, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4915191375916503, 'global_pooling': 'mean', 'learning_rate': 0.0008630768002352444, 'weight_decay': 7.016517769251613e-06, 'beta_0': 0.8057902969000205, 'beta_1': 0.9903916560343295, 'epsilon': 8.401053586144154e-07, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 22, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 03:42:38,802] Trial 312 finished with value: 0.8606060606060606 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9945169131541546, 'batch_size': 16, 'attention_heads': 4, 'hidden_dimension': 235, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3376599319576095, 'global_pooling': 'mean', 'learning_rate': 0.0016301539276641814, 'weight_decay': 6.762037773008952e-05, 'beta_0': 0.8198980000807858, 'beta_1': 0.9800026159525305, 'epsilon': 6.363976448428673e-06, 'balanced_loss': False, 'epochs': 187, 'early_stopping_patience': 24, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 03:56:35,021] Trial 313 finished with value: 0.8666666666666667 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9631905806539987, 'batch_size': 22, 'attention_heads': 5, 'hidden_dimension': 142, 'number_of_hidden_layers': 1, 'dropout_rate': 0.36117804566031364, 'global_pooling': 'mean', 'learning_rate': 0.00022054329701556166, 'weight_decay': 0.0001818924813972444, 'beta_0': 0.8076709477317178, 'beta_1': 0.9905978156520955, 'epsilon': 3.959405195244352e-07, 'balanced_loss': False, 'epochs': 97, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 04:08:10,046] Trial 314 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.991248187655656, 'batch_size': 18, 'attention_heads': 5, 'hidden_dimension': 161, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3470615137542366, 'global_pooling': 'mean', 'learning_rate': 0.0006029239643794699, 'weight_decay': 0.00048138111340709287, 'beta_0': 0.8038467500017982, 'beta_1': 0.9805894679152178, 'epsilon': 9.012537275434904e-06, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 3.33 GiB. GPU 0 has a total capacity of 44.56 GiB of which 934.69 MiB is free. Including non-PyTorch memory, this process has 43.64 GiB memory in use. Of the allocated memory 37.25 GiB is allocated by PyTorch, and 5.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 04:16:55,119] Trial 315 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9577775147312185, 'batch_size': 31, 'attention_heads': 6, 'hidden_dimension': 172, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5421371425438426, 'global_pooling': 'mean', 'learning_rate': 0.0007180911021264388, 'weight_decay': 3.717133373622411e-06, 'beta_0': 0.8096209272222332, 'beta_1': 0.9913358600739459, 'epsilon': 6.357515221195143e-06, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 25, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 3.79 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.57 GiB is free. Including non-PyTorch memory, this process has 40.98 GiB memory in use. Of the allocated memory 37.79 GiB is allocated by PyTorch, and 2.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 04:25:25,657] Trial 316 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.962252136623235, 'batch_size': 54, 'attention_heads': 4, 'hidden_dimension': 195, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3821106281817491, 'global_pooling': 'mean', 'learning_rate': 0.0005033124175781434, 'weight_decay': 1.0116598403812713e-06, 'beta_0': 0.8159373487607361, 'beta_1': 0.9898831535161594, 'epsilon': 1.1615413364666695e-06, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 22, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 04:37:25,744] Trial 317 finished with value: 0.8666666666666667 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9599584970432664, 'batch_size': 17, 'attention_heads': 4, 'hidden_dimension': 179, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32956175828941175, 'global_pooling': 'mean', 'learning_rate': 0.0003148504574051958, 'weight_decay': 1.1306286770581236e-06, 'beta_0': 0.8122494516103327, 'beta_1': 0.990858785790488, 'epsilon': 1.855850120583935e-05, 'balanced_loss': False, 'epochs': 196, 'early_stopping_patience': 12, 'plateau_patience': 11, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 04:47:43,227] Trial 318 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9827132476466967, 'batch_size': 40, 'attention_heads': 5, 'hidden_dimension': 188, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37472547508601667, 'global_pooling': 'mean', 'learning_rate': 0.0010228325731045933, 'weight_decay': 1.321807445078618e-06, 'beta_0': 0.8065379111579382, 'beta_1': 0.9820728618980323, 'epsilon': 1.1416416535292022e-05, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 21, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 05:07:41,734] Trial 319 finished with value: 0.8666666666666667 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9676556070176968, 'batch_size': 24, 'attention_heads': 5, 'hidden_dimension': 135, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5167187969386853, 'global_pooling': 'mean', 'learning_rate': 0.00041334992237918445, 'weight_decay': 4.8873136711160544e-05, 'beta_0': 0.8175917445142676, 'beta_1': 0.9893139575490175, 'epsilon': 7.96599000642493e-06, 'balanced_loss': False, 'epochs': 187, 'early_stopping_patience': 22, 'plateau_patience': 21, 'plateau_divider': 5}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 05:25:03,964] Trial 320 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9642337657671629, 'batch_size': 27, 'attention_heads': 4, 'hidden_dimension': 147, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5011685936785708, 'global_pooling': 'mean', 'learning_rate': 0.0073812678126336, 'weight_decay': 1.0000353832448697e-06, 'beta_0': 0.8082487145302037, 'beta_1': 0.991707725927176, 'epsilon': 4.017721926983543e-06, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 7.90 GiB. GPU 0 has a total capacity of 44.56 GiB of which 6.09 GiB is free. Including non-PyTorch memory, this process has 38.47 GiB memory in use. Of the allocated memory 35.15 GiB is allocated by PyTorch, and 2.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 05:33:51,407] Trial 321 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9429690074802267, 'batch_size': 60, 'attention_heads': 6, 'hidden_dimension': 155, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4841531876581207, 'global_pooling': 'mean', 'learning_rate': 0.00065089735651698, 'weight_decay': 2.9228348791477884e-06, 'beta_0': 0.842553168291026, 'beta_1': 0.9888309992698603, 'epsilon': 9.104404102062047e-07, 'balanced_loss': False, 'epochs': 182, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 6}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 05:48:26,190] Trial 322 finished with value: 0.8666666666666667 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9579065147582797, 'batch_size': 19, 'attention_heads': 5, 'hidden_dimension': 92, 'number_of_hidden_layers': 0, 'dropout_rate': 0.393931222404847, 'global_pooling': 'sum', 'learning_rate': 0.0005354378071411971, 'weight_decay': 0.00020179013144055967, 'beta_0': 0.8337363874045575, 'beta_1': 0.9808714825645244, 'epsilon': 2.736877569605409e-06, 'balanced_loss': False, 'epochs': 198, 'early_stopping_patience': 11, 'plateau_patience': 22, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 05:59:39,554] Trial 323 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.968947872517657, 'batch_size': 36, 'attention_heads': 4, 'hidden_dimension': 36, 'number_of_hidden_layers': 4, 'dropout_rate': 0.36860269616370483, 'global_pooling': 'mean', 'learning_rate': 0.000817413531602154, 'weight_decay': 1.2319367274698688e-06, 'beta_0': 0.868438258984897, 'beta_1': 0.9864489982719423, 'epsilon': 5.33486537232725e-06, 'balanced_loss': False, 'epochs': 136, 'early_stopping_patience': 23, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 06:13:34,855] Trial 324 finished with value: 0.8727272727272727 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9615580138441041, 'batch_size': 20, 'attention_heads': 4, 'hidden_dimension': 183, 'number_of_hidden_layers': 2, 'dropout_rate': 0.34337482934337965, 'global_pooling': 'mean', 'learning_rate': 0.00038264953019588854, 'weight_decay': 1.1261376591069538e-06, 'beta_0': 0.8019596163854185, 'beta_1': 0.9911963142724064, 'epsilon': 1.7759665211693496e-06, 'balanced_loss': True, 'epochs': 189, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.70 GiB is free. Including non-PyTorch memory, this process has 40.85 GiB memory in use. Of the allocated memory 37.71 GiB is allocated by PyTorch, and 1.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 06:22:07,191] Trial 325 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9597759912837963, 'batch_size': 20, 'attention_heads': 13, 'hidden_dimension': 185, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3356609916054942, 'global_pooling': 'mean', 'learning_rate': 0.0003427025759538773, 'weight_decay': 0.00015001215524644985, 'beta_0': 0.8010885949354083, 'beta_1': 0.9910648041158241, 'epsilon': 1.7492387820803984e-06, 'balanced_loss': True, 'epochs': 77, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 06:33:57,562] Trial 326 finished with value: 0.8545454545454545 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9617050748086732, 'batch_size': 26, 'attention_heads': 4, 'hidden_dimension': 193, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3445270148074345, 'global_pooling': 'mean', 'learning_rate': 0.00026128475716337884, 'weight_decay': 0.00010802204870618438, 'beta_0': 0.8028479222409979, 'beta_1': 0.981616682673122, 'epsilon': 1.9110987828934747e-06, 'balanced_loss': True, 'epochs': 66, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.54 GiB is free. Including non-PyTorch memory, this process has 43.01 GiB memory in use. Of the allocated memory 39.56 GiB is allocated by PyTorch, and 2.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 06:42:32,038] Trial 327 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9562546581945572, 'batch_size': 21, 'attention_heads': 4, 'hidden_dimension': 182, 'number_of_hidden_layers': 2, 'dropout_rate': 0.35494488065557694, 'global_pooling': 'mean', 'learning_rate': 0.00019930156884551603, 'weight_decay': 1.5286249251437618e-06, 'beta_0': 0.8002698352136819, 'beta_1': 0.9901568870001889, 'epsilon': 1.4243939369737102e-06, 'balanced_loss': True, 'epochs': 190, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.00 GiB is free. Including non-PyTorch memory, this process has 42.56 GiB memory in use. Of the allocated memory 40.22 GiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 06:50:50,142] Trial 328 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9593361561828099, 'batch_size': 29, 'attention_heads': 7, 'hidden_dimension': 188, 'number_of_hidden_layers': 2, 'dropout_rate': 0.49110188305818686, 'global_pooling': 'max', 'learning_rate': 0.0006927265071755634, 'weight_decay': 1.7435426256828803e-06, 'beta_0': 0.8051632793431522, 'beta_1': 0.9811976347476263, 'epsilon': 1.7279781656677185e-06, 'balanced_loss': True, 'epochs': 186, 'early_stopping_patience': 25, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 6.79 GiB. GPU 0 has a total capacity of 44.56 GiB of which 6.32 GiB is free. Including non-PyTorch memory, this process has 38.24 GiB memory in use. Of the allocated memory 35.09 GiB is allocated by PyTorch, and 2.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 06:59:20,424] Trial 329 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9535646672151545, 'batch_size': 23, 'attention_heads': 15, 'hidden_dimension': 177, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5282498862802496, 'global_pooling': 'mean', 'learning_rate': 0.00013325185088553033, 'weight_decay': 1.0809213985597541e-05, 'beta_0': 0.8137473731936743, 'beta_1': 0.9904800971230355, 'epsilon': 2.0431844427443957e-06, 'balanced_loss': True, 'epochs': 193, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.93 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.09 GiB is free. Including non-PyTorch memory, this process has 43.47 GiB memory in use. Of the allocated memory 39.51 GiB is allocated by PyTorch, and 2.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 07:12:32,523] Trial 330 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9632234854470717, 'batch_size': 21, 'attention_heads': 4, 'hidden_dimension': 217, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3449585457097402, 'global_pooling': 'mean', 'learning_rate': 0.0011220517459919683, 'weight_decay': 2.5698385180297073e-06, 'beta_0': 0.8102265961617157, 'beta_1': 0.9804243659540206, 'epsilon': 1.2362394530442293e-06, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 07:23:12,863] Trial 331 finished with value: 0.8545454545454545 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9612460547484915, 'batch_size': 27, 'attention_heads': 4, 'hidden_dimension': 190, 'number_of_hidden_layers': 0, 'dropout_rate': 0.46338735847035695, 'global_pooling': 'mean', 'learning_rate': 0.000876465744460699, 'weight_decay': 1.1515235939454392e-06, 'beta_0': 0.8382989318515536, 'beta_1': 0.9906788174088096, 'epsilon': 1.1504824006198403e-08, 'balanced_loss': True, 'epochs': 196, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 07:36:42,243] Trial 332 finished with value: 0.8545454545454545 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9569970345674952, 'batch_size': 19, 'attention_heads': 4, 'hidden_dimension': 112, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3388063207878358, 'global_pooling': 'mean', 'learning_rate': 0.0004553783223728996, 'weight_decay': 1.3464949551040802e-06, 'beta_0': 0.8220790108670145, 'beta_1': 0.9831198606665341, 'epsilon': 2.2633269342174275e-06, 'balanced_loss': False, 'epochs': 189, 'early_stopping_patience': 25, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.84 GiB. GPU 0 has a total capacity of 44.56 GiB of which 916.69 MiB is free. Including non-PyTorch memory, this process has 43.66 GiB memory in use. Of the allocated memory 40.91 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 07:46:42,496] Trial 333 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9650074671093473, 'batch_size': 20, 'attention_heads': 4, 'hidden_dimension': 200, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5634887442381761, 'global_pooling': 'mean', 'learning_rate': 0.0005718738336651561, 'weight_decay': 1.1105539361058401e-06, 'beta_0': 0.8026096717294045, 'beta_1': 0.9898264567258763, 'epsilon': 1.3501514779609494e-06, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 07:58:10,368] Trial 334 finished with value: 0.8545454545454545 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9596033170647242, 'batch_size': 18, 'attention_heads': 4, 'hidden_dimension': 50, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5080448998497717, 'global_pooling': 'mean', 'learning_rate': 0.0003340304473997864, 'weight_decay': 0.00012257891905056705, 'beta_0': 0.8286943046674936, 'beta_1': 0.9978474651406638, 'epsilon': 3.189026361537483e-06, 'balanced_loss': False, 'epochs': 184, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 3.41 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.05 GiB is free. Including non-PyTorch memory, this process has 42.50 GiB memory in use. Of the allocated memory 36.30 GiB is allocated by PyTorch, and 5.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 08:06:57,115] Trial 335 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9613906581875574, 'batch_size': 26, 'attention_heads': 7, 'hidden_dimension': 185, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35140106884059136, 'global_pooling': 'sum', 'learning_rate': 0.00039348905836761685, 'weight_decay': 2.2138083800452373e-06, 'beta_0': 0.824310286420941, 'beta_1': 0.9911521676372319, 'epsilon': 9.373281371703349e-07, 'balanced_loss': False, 'epochs': 180, 'early_stopping_patience': 25, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.71 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.38 GiB is free. Including non-PyTorch memory, this process has 43.17 GiB memory in use. Of the allocated memory 38.84 GiB is allocated by PyTorch, and 3.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 08:15:28,770] Trial 336 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9583085171497632, 'batch_size': 30, 'attention_heads': 4, 'hidden_dimension': 142, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3621693420260151, 'global_pooling': 'mean', 'learning_rate': 0.0007477881432261642, 'weight_decay': 8.471625966247675e-06, 'beta_0': 0.8115786556761742, 'beta_1': 0.9807620192103148, 'epsilon': 3.300600747371484e-07, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 23, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 08:27:11,877] Trial 337 finished with value: 0.8545454545454545 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9749979137419419, 'batch_size': 28, 'attention_heads': 5, 'hidden_dimension': 179, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5487766098465079, 'global_pooling': 'mean', 'learning_rate': 0.0001596915740815318, 'weight_decay': 1.43422045255149e-06, 'beta_0': 0.8067858694868979, 'beta_1': 0.9802593903555854, 'epsilon': 2.6192330917281554e-06, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacity of 44.56 GiB of which 180.69 MiB is free. Including non-PyTorch memory, this process has 44.38 GiB memory in use. Of the allocated memory 41.92 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 08:37:37,544] Trial 338 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9471766073200297, 'batch_size': 25, 'attention_heads': 4, 'hidden_dimension': 194, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4733316866539843, 'global_pooling': 'mean', 'learning_rate': 0.0006023848997029185, 'weight_decay': 1.0049803896825936e-06, 'beta_0': 0.8524995868833396, 'beta_1': 0.9813805200180968, 'epsilon': 1.1092383814351667e-06, 'balanced_loss': False, 'epochs': 187, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 08:47:55,808] Trial 339 finished with value: 0.8666666666666667 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9551131238921268, 'batch_size': 18, 'attention_heads': 6, 'hidden_dimension': 64, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34097233810775024, 'global_pooling': 'mean', 'learning_rate': 0.0009673063808265671, 'weight_decay': 1.244801764344202e-06, 'beta_0': 0.8049552468139536, 'beta_1': 0.9922097083337839, 'epsilon': 6.512797257664613e-07, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 25, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 09:00:04,991] Trial 340 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9791678666564944, 'batch_size': 21, 'attention_heads': 5, 'hidden_dimension': 182, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4936711941049436, 'global_pooling': 'mean', 'learning_rate': 0.001439766253303042, 'weight_decay': 1.591195700023226e-06, 'beta_0': 0.808545023232257, 'beta_1': 0.9987775184163925, 'epsilon': 4.084245875453106e-07, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 16, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 09:14:35,643] Trial 341 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9629475767839507, 'batch_size': 16, 'attention_heads': 4, 'hidden_dimension': 190, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5348723076928393, 'global_pooling': 'mean', 'learning_rate': 0.0005055295250596848, 'weight_decay': 0.00036717778250756753, 'beta_0': 0.8014573331477889, 'beta_1': 0.9902332942241693, 'epsilon': 1.4417150971376769e-06, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 22, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 09:29:39,683] Trial 342 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9659750382382462, 'batch_size': 17, 'attention_heads': 5, 'hidden_dimension': 175, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4986917175817452, 'global_pooling': 'mean', 'learning_rate': 0.000714504919629788, 'weight_decay': 1.1462152407850385e-06, 'beta_0': 0.818301919139052, 'beta_1': 0.9927494964358886, 'epsilon': 9.864292791057212e-06, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 14, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.19 GiB. GPU 0 has a total capacity of 44.56 GiB of which 44.69 MiB is free. Including non-PyTorch memory, this process has 44.51 GiB memory in use. Of the allocated memory 40.41 GiB is allocated by PyTorch, and 2.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 09:38:54,004] Trial 343 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9612655186781025, 'batch_size': 19, 'attention_heads': 5, 'hidden_dimension': 222, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4832953777490797, 'global_pooling': 'mean', 'learning_rate': 0.0004351829295247507, 'weight_decay': 1.2648005026992673e-06, 'beta_0': 0.8718175615716707, 'beta_1': 0.9810209296379435, 'epsilon': 1.5932115929342314e-05, 'balanced_loss': False, 'epochs': 184, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 09:52:21,600] Trial 344 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9766498803236487, 'batch_size': 20, 'attention_heads': 6, 'hidden_dimension': 150, 'number_of_hidden_layers': 2, 'dropout_rate': 0.37686588148999567, 'global_pooling': 'mean', 'learning_rate': 0.00028648789321296836, 'weight_decay': 1.9109600116964604e-06, 'beta_0': 0.8143198460485584, 'beta_1': 0.990924591274763, 'epsilon': 7.96969028084892e-07, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 10:01:55,776] Trial 345 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9579993680366182, 'batch_size': 34, 'attention_heads': 4, 'hidden_dimension': 32, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3003780642313021, 'global_pooling': 'mean', 'learning_rate': 0.0006175284109212761, 'weight_decay': 1.0001018877721636e-06, 'beta_0': 0.810902509876455, 'beta_1': 0.9914137331066388, 'epsilon': 5.255577841258361e-07, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 10:16:00,463] Trial 346 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9644742290563149, 'batch_size': 18, 'attention_heads': 4, 'hidden_dimension': 185, 'number_of_hidden_layers': 1, 'dropout_rate': 0.43187965758828223, 'global_pooling': 'mean', 'learning_rate': 7.227519406560877e-05, 'weight_decay': 1.394756434994847e-06, 'beta_0': 0.8038729861697566, 'beta_1': 0.980518031420445, 'epsilon': 7.7903021588054e-06, 'balanced_loss': False, 'epochs': 187, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.87 GiB is free. Including non-PyTorch memory, this process has 42.68 GiB memory in use. Of the allocated memory 40.32 GiB is allocated by PyTorch, and 1.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 10:24:49,203] Trial 347 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9598217244326969, 'batch_size': 22, 'attention_heads': 5, 'hidden_dimension': 205, 'number_of_hidden_layers': 2, 'dropout_rate': 0.38753406848743044, 'global_pooling': 'sum', 'learning_rate': 0.0008651981781644637, 'weight_decay': 1.1130188072648182e-06, 'beta_0': 0.8080745146896059, 'beta_1': 0.9896192377182936, 'epsilon': 1.6518375850010913e-06, 'balanced_loss': False, 'epochs': 106, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 10:42:32,845] Trial 348 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9695796064486546, 'batch_size': 17, 'attention_heads': 5, 'hidden_dimension': 177, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5697526103197262, 'global_pooling': 'mean', 'learning_rate': 0.001970190135756966, 'weight_decay': 1.7000655664653689e-06, 'beta_0': 0.8057444493716206, 'beta_1': 0.9918966247456282, 'epsilon': 2.8276735363802234e-07, 'balanced_loss': True, 'epochs': 190, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 10:56:52,181] Trial 349 finished with value: 0.8727272727272727 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9635919877126181, 'batch_size': 16, 'attention_heads': 4, 'hidden_dimension': 198, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32945421853906054, 'global_pooling': 'mean', 'learning_rate': 0.0002234003736446412, 'weight_decay': 1.2555045384781002e-06, 'beta_0': 0.8169435598662776, 'beta_1': 0.9826387037377907, 'epsilon': 3.748823367180932e-06, 'balanced_loss': False, 'epochs': 198, 'early_stopping_patience': 22, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 43.45 GiB memory in use. Of the allocated memory 41.02 GiB is allocated by PyTorch, and 1.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 11:05:34,346] Trial 350 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9625341706556114, 'batch_size': 29, 'attention_heads': 4, 'hidden_dimension': 198, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3428338486528275, 'global_pooling': 'mean', 'learning_rate': 0.00021762354953493935, 'weight_decay': 4.1299451122453235e-05, 'beta_0': 0.8163299676792298, 'beta_1': 0.9969008129684724, 'epsilon': 2.3767412460617626e-06, 'balanced_loss': False, 'epochs': 198, 'early_stopping_patience': 17, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 11:20:27,662] Trial 351 finished with value: 0.806060606060606 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9660351422202862, 'batch_size': 16, 'attention_heads': 4, 'hidden_dimension': 214, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31630027786037795, 'global_pooling': 'max', 'learning_rate': 4.032247636167806e-05, 'weight_decay': 1.461486913966456e-06, 'beta_0': 0.818348068714445, 'beta_1': 0.9816947312781402, 'epsilon': 1.0108736101493265e-06, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 21, 'plateau_patience': 23, 'plateau_divider': 8}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 4.69 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.67 GiB is free. Including non-PyTorch memory, this process has 40.88 GiB memory in use. Of the allocated memory 38.36 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 11:29:52,898] Trial 352 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9639089547636687, 'batch_size': 27, 'attention_heads': 9, 'hidden_dimension': 197, 'number_of_hidden_layers': 2, 'dropout_rate': 0.45007781270507746, 'global_pooling': 'mean', 'learning_rate': 0.00026214145109572064, 'weight_decay': 1.2871073880892913e-06, 'beta_0': 0.8203582312582903, 'beta_1': 0.9822572324996381, 'epsilon': 3.243705242161839e-06, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 11:42:08,224] Trial 353 finished with value: 0.8606060606060606 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9613916385581452, 'batch_size': 25, 'attention_heads': 4, 'hidden_dimension': 194, 'number_of_hidden_layers': 0, 'dropout_rate': 0.330237737424186, 'global_pooling': 'mean', 'learning_rate': 0.00019278348695300833, 'weight_decay': 2.060354959234007e-06, 'beta_0': 0.8161801722158076, 'beta_1': 0.9820120452419676, 'epsilon': 4.545603670859442e-06, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 11:56:52,541] Trial 354 finished with value: 0.8666666666666667 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9627567228475507, 'batch_size': 16, 'attention_heads': 4, 'hidden_dimension': 202, 'number_of_hidden_layers': 2, 'dropout_rate': 0.34906346269564614, 'global_pooling': 'mean', 'learning_rate': 0.0002246124665849978, 'weight_decay': 1.137590792399652e-06, 'beta_0': 0.8126068581199059, 'beta_1': 0.9829482850606858, 'epsilon': 6.177186029073534e-05, 'balanced_loss': True, 'epochs': 194, 'early_stopping_patience': 22, 'plateau_patience': 24, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacity of 44.56 GiB of which 562.69 MiB is free. Including non-PyTorch memory, this process has 44.00 GiB memory in use. Of the allocated memory 41.53 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 12:05:34,465] Trial 355 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9510258379120183, 'batch_size': 28, 'attention_heads': 4, 'hidden_dimension': 133, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32657626493029573, 'global_pooling': 'mean', 'learning_rate': 0.00030904276200274876, 'weight_decay': 1.0056652579448458e-06, 'beta_0': 0.8145337832683243, 'beta_1': 0.980920302056121, 'epsilon': 6.137510679951826e-07, 'balanced_loss': False, 'epochs': 177, 'early_stopping_patience': 12, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 12:21:41,015] Trial 356 finished with value: 0.8484848484848485 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9563262907692831, 'batch_size': 17, 'attention_heads': 4, 'hidden_dimension': 209, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3232018011856415, 'global_pooling': 'mean', 'learning_rate': 0.00039641300613182083, 'weight_decay': 2.439516707332984e-06, 'beta_0': 0.8203436938839392, 'beta_1': 0.9825902469905442, 'epsilon': 4.3171185341791567e-07, 'balanced_loss': False, 'epochs': 198, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 12:31:56,599] Trial 357 finished with value: 0.8424242424242424 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9593796235807488, 'batch_size': 26, 'attention_heads': 4, 'hidden_dimension': 147, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3334577735935332, 'global_pooling': 'mean', 'learning_rate': 0.0004881529467698209, 'weight_decay': 1.5748026577607262e-06, 'beta_0': 0.8101940215381548, 'beta_1': 0.9940232446361851, 'epsilon': 3.7881495355087576e-06, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 10, 'plateau_patience': 14, 'plateau_divider': 8}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.65 GiB. GPU 0 has a total capacity of 44.56 GiB of which 520.69 MiB is free. Including non-PyTorch memory, this process has 44.04 GiB memory in use. Of the allocated memory 41.49 GiB is allocated by PyTorch, and 1.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 12:40:24,122] Trial 358 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9664285424054841, 'batch_size': 63, 'attention_heads': 4, 'hidden_dimension': 138, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4895304638694551, 'global_pooling': 'mean', 'learning_rate': 0.0005853997454150118, 'weight_decay': 1.2574750311672998e-06, 'beta_0': 0.8125617309121618, 'beta_1': 0.9838749991989032, 'epsilon': 7.176488250066864e-06, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 13, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 12:54:56,365] Trial 359 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.964093357394458, 'batch_size': 20, 'attention_heads': 6, 'hidden_dimension': 190, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31126678472022173, 'global_pooling': 'mean', 'learning_rate': 0.0003761782872270231, 'weight_decay': 3.002868734801169e-05, 'beta_0': 0.8173177558502044, 'beta_1': 0.9847275210973099, 'epsilon': 1.0888261461284467e-05, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 25, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.84 GiB is free. Including non-PyTorch memory, this process has 41.71 GiB memory in use. Of the allocated memory 38.69 GiB is allocated by PyTorch, and 1.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 13:04:34,635] Trial 360 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9537343692104159, 'batch_size': 28, 'attention_heads': 4, 'hidden_dimension': 201, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3561955192800128, 'global_pooling': 'mean', 'learning_rate': 5.5207024340554395e-05, 'weight_decay': 1.3964391693128736e-06, 'beta_0': 0.8156924189173, 'beta_1': 0.9813182097384457, 'epsilon': 1.1549341503032144e-06, 'balanced_loss': False, 'epochs': 171, 'early_stopping_patience': 22, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 13:19:20,097] Trial 361 finished with value: 0.8727272727272727 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.98517778497463, 'batch_size': 19, 'attention_heads': 5, 'hidden_dimension': 158, 'number_of_hidden_layers': 2, 'dropout_rate': 0.33567511094083413, 'global_pooling': 'sum', 'learning_rate': 0.00017964238730790709, 'weight_decay': 1.7495865132770757e-06, 'beta_0': 0.808901703232794, 'beta_1': 0.9805959972797449, 'epsilon': 2.9082351131562155e-06, 'balanced_loss': True, 'epochs': 155, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 13:34:08,030] Trial 362 finished with value: 0.8424242424242424 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9858130223722568, 'batch_size': 19, 'attention_heads': 5, 'hidden_dimension': 156, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3353049420859015, 'global_pooling': 'sum', 'learning_rate': 0.00015168249508653922, 'weight_decay': 0.00016418696279989269, 'beta_0': 0.8076392977837902, 'beta_1': 0.9802986582781067, 'epsilon': 3.235828730275602e-06, 'balanced_loss': True, 'epochs': 168, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 5.42 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.09 GiB is free. Including non-PyTorch memory, this process has 40.47 GiB memory in use. Of the allocated memory 37.13 GiB is allocated by PyTorch, and 2.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 13:42:47,541] Trial 363 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9100093167594749, 'batch_size': 32, 'attention_heads': 5, 'hidden_dimension': 158, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32688257687702876, 'global_pooling': 'sum', 'learning_rate': 0.00018509653731108017, 'weight_decay': 2.118622780834253e-05, 'beta_0': 0.8216727242488837, 'beta_1': 0.9800003167218657, 'epsilon': 2.4793750464023168e-06, 'balanced_loss': True, 'epochs': 151, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 13:56:49,764] Trial 364 finished with value: 0.8303030303030303 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9653603357083024, 'batch_size': 18, 'attention_heads': 5, 'hidden_dimension': 153, 'number_of_hidden_layers': 2, 'dropout_rate': 0.33838088410238226, 'global_pooling': 'sum', 'learning_rate': 0.00025283900844495517, 'weight_decay': 8.555991940933348e-05, 'beta_0': 0.8259749548497095, 'beta_1': 0.9884954835757379, 'epsilon': 2.069040836551613e-06, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 11, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 14:13:21,754] Trial 365 finished with value: 0.8727272727272727 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9908645213971853, 'batch_size': 38, 'attention_heads': 6, 'hidden_dimension': 162, 'number_of_hidden_layers': 2, 'dropout_rate': 0.33345975887150126, 'global_pooling': 'sum', 'learning_rate': 0.00027198709939873714, 'weight_decay': 3.1766383709594963e-06, 'beta_0': 0.8089325919835341, 'beta_1': 0.9834619125139161, 'epsilon': 3.795394795461697e-06, 'balanced_loss': True, 'epochs': 197, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 14:26:03,972] Trial 366 finished with value: 0.8727272727272727 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9949788835100339, 'batch_size': 19, 'attention_heads': 6, 'hidden_dimension': 163, 'number_of_hidden_layers': 2, 'dropout_rate': 0.33621699987191195, 'global_pooling': 'sum', 'learning_rate': 0.00023266030849166048, 'weight_decay': 3.228784026089764e-06, 'beta_0': 0.8066709994205323, 'beta_1': 0.982675635033908, 'epsilon': 2.8119371489938333e-06, 'balanced_loss': True, 'epochs': 198, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 14:43:05,972] Trial 367 finished with value: 0.8545454545454545 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9967725402549955, 'batch_size': 38, 'attention_heads': 6, 'hidden_dimension': 158, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3284232228100876, 'global_pooling': 'sum', 'learning_rate': 0.00022660247071925024, 'weight_decay': 2.831641857474657e-06, 'beta_0': 0.80953599082517, 'beta_1': 0.983460866768936, 'epsilon': 2.8537089924822013e-06, 'balanced_loss': True, 'epochs': 197, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 14:57:22,987] Trial 368 finished with value: 0.8666666666666667 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9890491822223909, 'batch_size': 19, 'attention_heads': 6, 'hidden_dimension': 163, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3176795318243988, 'global_pooling': 'sum', 'learning_rate': 0.0002784512378197985, 'weight_decay': 3.0701768988293614e-06, 'beta_0': 0.8069172628751025, 'beta_1': 0.9827958663873058, 'epsilon': 3.385612377234693e-06, 'balanced_loss': True, 'epochs': 197, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 9}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 15:14:11,516] Trial 369 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9926371169154409, 'batch_size': 40, 'attention_heads': 6, 'hidden_dimension': 163, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3371937537600517, 'global_pooling': 'sum', 'learning_rate': 0.00018815796634717456, 'weight_decay': 3.431193290329547e-06, 'beta_0': 0.8090273721200445, 'beta_1': 0.9825956284510919, 'epsilon': 2.7933696802996844e-06, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 15:38:31,904] Trial 370 finished with value: 0.8727272727272727 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9875680565695213, 'batch_size': 41, 'attention_heads': 7, 'hidden_dimension': 166, 'number_of_hidden_layers': 2, 'dropout_rate': 0.33089202870530765, 'global_pooling': 'sum', 'learning_rate': 0.00022814178898534674, 'weight_decay': 3.1027209381367754e-06, 'beta_0': 0.8063933979862332, 'beta_1': 0.9832228079789292, 'epsilon': 3.8804338842842505e-06, 'balanced_loss': True, 'epochs': 142, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 16:00:54,432] Trial 371 finished with value: 0.8666666666666667 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9876548048879923, 'batch_size': 40, 'attention_heads': 7, 'hidden_dimension': 161, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3307074510269382, 'global_pooling': 'sum', 'learning_rate': 0.0002486082214951292, 'weight_decay': 3.6143599009266315e-06, 'beta_0': 0.8066618964153038, 'beta_1': 0.9831739980993329, 'epsilon': 4.166756541318834e-06, 'balanced_loss': True, 'epochs': 154, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
CUDA out of memory. Tried to allocate 2.42 GiB. GPU 0 has a total capacity of 44.56 GiB of which 406.69 MiB is free. Including non-PyTorch memory, this process has 44.16 GiB memory in use. Of the allocated memory 39.75 GiB is allocated by PyTorch, and 3.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 16:15:52,210] Trial 372 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.984037625798019, 'batch_size': 41, 'attention_heads': 8, 'hidden_dimension': 166, 'number_of_hidden_layers': 2, 'dropout_rate': 0.340603337315777, 'global_pooling': 'sum', 'learning_rate': 0.00021962613463537268, 'weight_decay': 3.896519193645462e-06, 'beta_0': 0.8088700393639232, 'beta_1': 0.9836550362345895, 'epsilon': 3.637396406845842e-06, 'balanced_loss': True, 'epochs': 195, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 16:36:08,655] Trial 373 finished with value: 0.8727272727272727 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9950283702786019, 'batch_size': 39, 'attention_heads': 6, 'hidden_dimension': 166, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32909019582355065, 'global_pooling': 'sum', 'learning_rate': 0.00031195223035854387, 'weight_decay': 4.645176374157741e-06, 'beta_0': 0.8108026960267694, 'beta_1': 0.9833416439580891, 'epsilon': 3.1092084483809335e-06, 'balanced_loss': True, 'epochs': 163, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 4}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 16:56:11,148] Trial 374 finished with value: 0.8484848484848485 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9892101148614975, 'batch_size': 43, 'attention_heads': 7, 'hidden_dimension': 165, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3327249971098771, 'global_pooling': 'sum', 'learning_rate': 0.00029955420015336556, 'weight_decay': 5.910111702609246e-06, 'beta_0': 0.8111788586928335, 'beta_1': 0.9839797169969695, 'epsilon': 4.4150226071315896e-06, 'balanced_loss': True, 'epochs': 162, 'early_stopping_patience': 25, 'plateau_patience': 22, 'plateau_divider': 5}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 17:14:22,139] Trial 375 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9950994062506106, 'batch_size': 37, 'attention_heads': 6, 'hidden_dimension': 168, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32371261548729935, 'global_pooling': 'sum', 'learning_rate': 0.0002972910547550197, 'weight_decay': 4.1082301891934895e-06, 'beta_0': 0.8101134996650751, 'beta_1': 0.9832736006503112, 'epsilon': 3.6034542569853547e-06, 'balanced_loss': True, 'epochs': 161, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 17:36:17,774] Trial 376 finished with value: 0.8606060606060606 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9900251874618241, 'batch_size': 42, 'attention_heads': 6, 'hidden_dimension': 159, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3318024082412649, 'global_pooling': 'sum', 'learning_rate': 0.0002486327906536183, 'weight_decay': 4.376846871932291e-06, 'beta_0': 0.8074318791716164, 'beta_1': 0.982903175601649, 'epsilon': 3.0134122634036526e-06, 'balanced_loss': True, 'epochs': 148, 'early_stopping_patience': 25, 'plateau_patience': 22, 'plateau_divider': 4}. Best is trial 126 with value: 0.8787878787878788.
[I 2025-03-01 17:57:32,995] Trial 377 finished with value: 0.896969696969697 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9931812160243588, 'batch_size': 39, 'attention_heads': 8, 'hidden_dimension': 162, 'number_of_hidden_layers': 2, 'dropout_rate': 0.320182512670764, 'global_pooling': 'sum', 'learning_rate': 0.000341054673379974, 'weight_decay': 3.05925605973374e-06, 'beta_0': 0.812888899225744, 'beta_1': 0.982549152413063, 'epsilon': 5.133426011957278e-06, 'balanced_loss': True, 'epochs': 156, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 377 with value: 0.896969696969697.
[I 2025-03-01 18:17:00,059] Trial 378 finished with value: 0.8848484848484849 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9941375232144157, 'batch_size': 39, 'attention_heads': 8, 'hidden_dimension': 162, 'number_of_hidden_layers': 2, 'dropout_rate': 0.321743644758477, 'global_pooling': 'sum', 'learning_rate': 0.0003376932275117118, 'weight_decay': 3.26171977514083e-06, 'beta_0': 0.8132539583666029, 'beta_1': 0.9826553802446002, 'epsilon': 5.079881879440778e-06, 'balanced_loss': True, 'epochs': 151, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 4}. Best is trial 377 with value: 0.896969696969697.
[I 2025-03-01 18:39:00,944] Trial 379 finished with value: 0.8606060606060606 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9918439946463896, 'batch_size': 39, 'attention_heads': 8, 'hidden_dimension': 162, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3255635646704033, 'global_pooling': 'sum', 'learning_rate': 0.0003281721060857319, 'weight_decay': 4.996406542729242e-06, 'beta_0': 0.8131540791785944, 'beta_1': 0.983027509803816, 'epsilon': 3.8205220255095384e-06, 'balanced_loss': True, 'epochs': 157, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 4}. Best is trial 377 with value: 0.896969696969697.
[I 2025-03-01 18:59:11,561] Trial 380 finished with value: 0.8848484848484849 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9935952056412076, 'batch_size': 38, 'attention_heads': 8, 'hidden_dimension': 155, 'number_of_hidden_layers': 2, 'dropout_rate': 0.31100013187527653, 'global_pooling': 'sum', 'learning_rate': 0.00031766405914438324, 'weight_decay': 3.2718435261655436e-06, 'beta_0': 0.8130160468554776, 'beta_1': 0.9835041638188785, 'epsilon': 4.9296846643155975e-06, 'balanced_loss': True, 'epochs': 154, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 377 with value: 0.896969696969697.
[I 2025-03-01 19:18:04,503] Trial 381 finished with value: 0.8666666666666667 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9939131939582669, 'batch_size': 39, 'attention_heads': 8, 'hidden_dimension': 157, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3081340401405233, 'global_pooling': 'sum', 'learning_rate': 0.00033330974291756254, 'weight_decay': 3.2926049390612475e-06, 'beta_0': 0.8138766762311804, 'beta_1': 0.983471417756817, 'epsilon': 5.039673801097931e-06, 'balanced_loss': True, 'epochs': 154, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 6}. Best is trial 377 with value: 0.896969696969697.
[I 2025-03-01 19:34:59,354] Trial 382 finished with value: 0.7818181818181819 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9959745938683897, 'batch_size': 39, 'attention_heads': 8, 'hidden_dimension': 154, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3100588656018685, 'global_pooling': 'sum', 'learning_rate': 2.852153136721949e-05, 'weight_decay': 3.5907493618463117e-06, 'beta_0': 0.8114777626090082, 'beta_1': 0.9825607928864417, 'epsilon': 5.621594410161825e-06, 'balanced_loss': True, 'epochs': 154, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 4}. Best is trial 377 with value: 0.896969696969697.
[I 2025-03-01 19:56:25,544] Trial 383 finished with value: 0.8848484848484849 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9926986179406853, 'batch_size': 38, 'attention_heads': 8, 'hidden_dimension': 162, 'number_of_hidden_layers': 2, 'dropout_rate': 0.31572881027068694, 'global_pooling': 'sum', 'learning_rate': 0.00028516469887898227, 'weight_decay': 2.765062390021382e-06, 'beta_0': 0.8134560268728235, 'beta_1': 0.9832527589155272, 'epsilon': 5.065982628578313e-06, 'balanced_loss': True, 'epochs': 144, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 4}. Best is trial 377 with value: 0.896969696969697.
[I 2025-03-01 20:14:12,994] Trial 384 finished with value: 0.8424242424242424 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9976336565695623, 'batch_size': 38, 'attention_heads': 8, 'hidden_dimension': 160, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3142217361610789, 'global_pooling': 'sum', 'learning_rate': 0.00027060616681526885, 'weight_decay': 3.1439954102886404e-06, 'beta_0': 0.8149834261457314, 'beta_1': 0.9842202484829176, 'epsilon': 5.103150273831166e-06, 'balanced_loss': True, 'epochs': 141, 'early_stopping_patience': 25, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 377 with value: 0.896969696969697.
[I 2025-03-01 20:38:15,008] Trial 385 finished with value: 0.8787878787878788 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9938373573473971, 'batch_size': 37, 'attention_heads': 9, 'hidden_dimension': 152, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3063984489794821, 'global_pooling': 'sum', 'learning_rate': 0.00023678534754629553, 'weight_decay': 2.7974785933065904e-06, 'beta_0': 0.8152665459578039, 'beta_1': 0.9824635650287725, 'epsilon': 5.09020811099038e-06, 'balanced_loss': True, 'epochs': 145, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 377 with value: 0.896969696969697.

[TRIAL] 377 [VALIDATION PERFORMANCE] 0.896969696969697 [TRAINING LOSS] 0.004514993674372538 [VALIDATION LOSS] 0.4549689039122313 

number                                     377
value                                  0.89697
params_threshold                      0.993181
params_attention_heads                       8
params_balanced_loss                      True
params_embedding_pooling_operation        mean
params_attention_pooling_operation        mean
params_batch_size                           39
params_dropout_rate                   0.320183
params_early_stopping_patience              24
params_epochs                              156
params_global_pooling                      sum
params_hidden_dimension                    162
params_learning_rate                  0.000341
params_number_of_hidden_layers               2
params_plateau_divider                      10
params_plateau_patience                     22
params_weight_decay                   0.000003
params_beta_0                         0.812889
params_beta_1                         0.982549
params_epsilon                        0.000005
user_attrs_epoch                          60.0
user_attrs_training_loss              0.004515
user_attrs_validation_loss            0.454969
params_left_stride                          32
params_right_stride                        128
Name: 377, dtype: object
37 Val: 0.8606060606060606 Test: 0.8835820895522388
38 Val: 0.8787878787878788 Test: 0.8985074626865671
39 Val: 0.8727272727272727 Test: 0.8626865671641791
40 Val: 0.8666666666666667 Test: 0.8716417910447761
41 Val: 0.8666666666666667 Test: 0.8955223880597015
42 Val: 0.8787878787878788 Test: 0.8895522388059701
43 Val: 0.8787878787878788 Test: 0.8895522388059701
44 Val: 0.8727272727272727 Test: 0.9014925373134328
45 Val: 0.8848484848484849 Test: 0.9044776119402985
46 Val: 0.8666666666666667 Test: 0.9044776119402985
Validation performance: 86.06 & 87.27  0.76 & 88.48
Testing performance: 86.27 & 89.01  1.41 & 90.45

[TRIAL] 378 [VALIDATION PERFORMANCE] 0.8848484848484849 [TRAINING LOSS] 0.008350762816217657 [VALIDATION LOSS] 0.43765646517276763 

number                                     378
value                                 0.884848
params_threshold                      0.994138
params_attention_heads                       8
params_balanced_loss                      True
params_embedding_pooling_operation        mean
params_attention_pooling_operation        mean
params_batch_size                           39
params_dropout_rate                   0.321744
params_early_stopping_patience              24
params_epochs                              151
params_global_pooling                      sum
params_hidden_dimension                    162
params_learning_rate                  0.000338
params_number_of_hidden_layers               2
params_plateau_divider                       4
params_plateau_patience                     22
params_weight_decay                   0.000003
params_beta_0                         0.813254
params_beta_1                         0.982655
params_epsilon                        0.000005
user_attrs_epoch                          53.0
user_attrs_training_loss              0.008351
user_attrs_validation_loss            0.437656
params_left_stride                          32
params_right_stride                        128
Name: 378, dtype: object
37 Val: 0.8606060606060606 Test: 0.8746268656716418
38 Val: 0.8848484848484849 Test: 0.9044776119402985
39 Val: 0.8787878787878788 Test: 0.8895522388059701
40 Val: 0.8727272727272727 Test: 0.8865671641791045
41 Val: 0.8606060606060606 Test: 0.9134328358208955
42 Val: 0.8848484848484849 Test: 0.8895522388059701
43 Val: 0.8666666666666667 Test: 0.9044776119402985
44 Val: 0.8727272727272727 Test: 0.8716417910447761
45 Val: 0.8727272727272727 Test: 0.9074626865671642
46 Val: 0.8727272727272727 Test: 0.9104477611940298
Validation performance: 86.06 & 87.27  0.86 & 88.48
Testing performance: 87.16 & 89.52  1.49 & 91.34

[TRIAL] 383 [VALIDATION PERFORMANCE] 0.8848484848484849 [TRAINING LOSS] 0.0017405781025965033 [VALIDATION LOSS] 0.4619026601314545 

number                                     383
value                                 0.884848
params_threshold                      0.992699
params_attention_heads                       8
params_balanced_loss                      True
params_embedding_pooling_operation        mean
params_attention_pooling_operation        mean
params_batch_size                           38
params_dropout_rate                   0.315729
params_early_stopping_patience              24
params_epochs                              144
params_global_pooling                      sum
params_hidden_dimension                    162
params_learning_rate                  0.000285
params_number_of_hidden_layers               2
params_plateau_divider                       4
params_plateau_patience                     22
params_weight_decay                   0.000003
params_beta_0                         0.813456
params_beta_1                         0.983253
params_epsilon                        0.000005
user_attrs_epoch                          64.0
user_attrs_training_loss              0.001741
user_attrs_validation_loss            0.461903
params_left_stride                          32
params_right_stride                        128
Name: 383, dtype: object
37 Val: 0.8727272727272727 Test: 0.8567164179104477
38 Val: 0.8787878787878788 Test: 0.8776119402985074
39 Val: 0.8727272727272727 Test: 0.8746268656716418
40 Val: 0.8606060606060606 Test: 0.9014925373134328
41 Val: 0.8666666666666667 Test: 0.8805970149253731
42 Val: 0.8727272727272727 Test: 0.9104477611940298
43 Val: 0.8848484848484849 Test: 0.8746268656716418
44 Val: 0.8848484848484849 Test: 0.8865671641791045
45 Val: 0.8666666666666667 Test: 0.9074626865671642
46 Val: 0.8606060606060606 Test: 0.8895522388059701
Validation performance: 86.06 & 87.21  0.88 & 88.48
Testing performance: 85.67 & 88.6  1.68 & 91.04

[TRIAL] 380 [VALIDATION PERFORMANCE] 0.8848484848484849 [TRAINING LOSS] 0.001924380881973775 [VALIDATION LOSS] 0.5909836620092392 

number                                     380
value                                 0.884848
params_threshold                      0.993595
params_attention_heads                       8
params_balanced_loss                      True
params_embedding_pooling_operation        mean
params_attention_pooling_operation        mean
params_batch_size                           38
params_dropout_rate                      0.311
params_early_stopping_patience              24
params_epochs                              154
params_global_pooling                      sum
params_hidden_dimension                    155
params_learning_rate                  0.000318
params_number_of_hidden_layers               2
params_plateau_divider                       7
params_plateau_patience                     22
params_weight_decay                   0.000003
params_beta_0                         0.813016
params_beta_1                         0.983504
params_epsilon                        0.000005
user_attrs_epoch                          54.0
user_attrs_training_loss              0.001924
user_attrs_validation_loss            0.590984
params_left_stride                          32
params_right_stride                        128
Name: 380, dtype: object
37 Val: 0.8727272727272727 Test: 0.8686567164179104
38 Val: 0.8848484848484849 Test: 0.9044776119402985
39 Val: 0.8787878787878788 Test: 0.8895522388059701
40 Val: 0.8666666666666667 Test: 0.8895522388059701
41 Val: 0.8727272727272727 Test: 0.8805970149253731
42 Val: 0.8727272727272727 Test: 0.8955223880597015
43 Val: 0.8787878787878788 Test: 0.8925373134328358
44 Val: 0.8909090909090909 Test: 0.8925373134328358
45 Val: 0.8727272727272727 Test: 0.9044776119402985
46 Val: 0.8727272727272727 Test: 0.8686567164179104
Validation performance: 86.67 & 87.64  0.71 & 89.09
Testing performance: 86.87 & 88.87  1.27 & 90.45

[TRIAL] 301 [VALIDATION PERFORMANCE] 0.8787878787878788 [TRAINING LOSS] 0.013952072114989278 [VALIDATION LOSS] 0.3964057508856058 

number                                     301
value                                 0.878788
params_threshold                      0.960127
params_attention_heads                       5
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           16
params_dropout_rate                   0.500781
params_early_stopping_patience              24
params_epochs                              192
params_global_pooling                     mean
params_hidden_dimension                    156
params_learning_rate                  0.000609
params_number_of_hidden_layers               2
params_plateau_divider                      10
params_plateau_patience                     14
params_weight_decay                   0.000195
params_beta_0                         0.805681
params_beta_1                         0.990946
params_epsilon                             0.0
user_attrs_epoch                          26.0
user_attrs_training_loss              0.013952
user_attrs_validation_loss            0.396406
params_left_stride                          64
params_right_stride                         32
Name: 301, dtype: object
37 Val: 0.8787878787878788 Test: 0.8985074626865671
38 Val: 0.8848484848484849 Test: 0.9164179104477612
39 Val: 0.8727272727272727 Test: 0.8805970149253731
slurmstepd: error: *** JOB 15063704 ON gpu050 CANCELLED AT 2025-03-02T10:55:25 DUE TO TIME LIMIT ***
