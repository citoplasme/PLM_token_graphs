[I 2025-02-20 10:41:36,627] Using an existing study with name 'IMDb-top_1000-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-Unitary_Weights-0.0-0.0' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 512). Running this sequence through the model will result in indexing errors
[I 2025-02-20 10:54:29,340] Trial 230 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9840207216410704, 'batch_size': 40, 'attention_heads': 11, 'hidden_dimension': 50, 'number_of_hidden_layers': 1, 'dropout_rate': 0.518233294182879, 'global_pooling': 'mean', 'learning_rate': 0.0005289754809335043, 'weight_decay': 4.306312515301923e-06, 'beta_0': 0.8787952235609576, 'beta_1': 0.9884576885724488, 'epsilon': 2.1986324831312343e-05, 'balanced_loss': False, 'epochs': 85, 'early_stopping_patience': 19, 'plateau_patience': 20, 'plateau_divider': 4}. Best is trial 180 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 418.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 286.69 MiB is free. Including non-PyTorch memory, this process has 44.27 GiB memory in use. Of the allocated memory 41.24 GiB is allocated by PyTorch, and 1.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 11:04:13,210] Trial 231 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9033582526345979, 'batch_size': 39, 'attention_heads': 10, 'hidden_dimension': 222, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5558240663686789, 'global_pooling': 'mean', 'learning_rate': 0.00034786230835882594, 'weight_decay': 2.2483616904664616e-06, 'beta_0': 0.8736632151493249, 'beta_1': 0.9870080073633264, 'epsilon': 3.133878671509694e-05, 'balanced_loss': False, 'epochs': 130, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 11:16:21,648] Trial 232 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9826727619334832, 'batch_size': 28, 'attention_heads': 10, 'hidden_dimension': 44, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4477900625987228, 'global_pooling': 'mean', 'learning_rate': 0.00044094417379299044, 'weight_decay': 1.963812020040981e-06, 'beta_0': 0.8781325250910266, 'beta_1': 0.9876485536676981, 'epsilon': 3.031388994185259e-05, 'balanced_loss': False, 'epochs': 88, 'early_stopping_patience': 25, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 11:29:13,315] Trial 233 finished with value: 0.9212121212121213 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9801509452980146, 'batch_size': 32, 'attention_heads': 10, 'hidden_dimension': 45, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5009425121474488, 'global_pooling': 'mean', 'learning_rate': 0.0007888599137234405, 'weight_decay': 1.1752003418812842e-05, 'beta_0': 0.880763789253601, 'beta_1': 0.9874188275885557, 'epsilon': 2.757869783650214e-05, 'balanced_loss': False, 'epochs': 110, 'early_stopping_patience': 24, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 11:42:22,630] Trial 234 finished with value: 0.9212121212121213 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9802561540162267, 'batch_size': 32, 'attention_heads': 10, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5083183043358298, 'global_pooling': 'mean', 'learning_rate': 0.0007966375428499385, 'weight_decay': 1.0903015198948705e-05, 'beta_0': 0.8802683192846836, 'beta_1': 0.9866197365804209, 'epsilon': 2.6480768413738998e-05, 'balanced_loss': False, 'epochs': 108, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 11:54:33,669] Trial 235 finished with value: 0.896969696969697 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9798557396771451, 'batch_size': 32, 'attention_heads': 12, 'hidden_dimension': 36, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5072476678518327, 'global_pooling': 'mean', 'learning_rate': 0.001381921702438411, 'weight_decay': 1.1599903020349476e-05, 'beta_0': 0.8803157732145018, 'beta_1': 0.9840413516469363, 'epsilon': 2.4686727142406004e-05, 'balanced_loss': False, 'epochs': 86, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 12:08:17,942] Trial 236 finished with value: 0.9212121212121213 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.981389194420896, 'batch_size': 33, 'attention_heads': 10, 'hidden_dimension': 57, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5108226911424262, 'global_pooling': 'mean', 'learning_rate': 0.0008207050516702451, 'weight_decay': 8.021418366879524e-06, 'beta_0': 0.8756626831793781, 'beta_1': 0.9866950342051917, 'epsilon': 1.9293071084017897e-05, 'balanced_loss': False, 'epochs': 107, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 12:21:00,950] Trial 237 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9851799058743518, 'batch_size': 32, 'attention_heads': 11, 'hidden_dimension': 54, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4977207172400013, 'global_pooling': 'mean', 'learning_rate': 0.0012169981240574633, 'weight_decay': 1.0403712820100962e-05, 'beta_0': 0.8761880649820074, 'beta_1': 0.9866397547504182, 'epsilon': 1.9506385327920568e-05, 'balanced_loss': False, 'epochs': 108, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 12:33:18,459] Trial 238 finished with value: 0.8909090909090909 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9786377629768795, 'batch_size': 34, 'attention_heads': 10, 'hidden_dimension': 48, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5099739345232668, 'global_pooling': 'mean', 'learning_rate': 0.000901285079288091, 'weight_decay': 1.1712227678057027e-05, 'beta_0': 0.868687780276532, 'beta_1': 0.9872405189191956, 'epsilon': 1.6858752732470705e-05, 'balanced_loss': False, 'epochs': 109, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 12:44:28,197] Trial 239 finished with value: 0.8848484848484849 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9818166830157617, 'batch_size': 23, 'attention_heads': 10, 'hidden_dimension': 43, 'number_of_hidden_layers': 0, 'dropout_rate': 0.49450806514569934, 'global_pooling': 'mean', 'learning_rate': 0.0008214686855752443, 'weight_decay': 8.804957867292847e-06, 'beta_0': 0.8951832753173348, 'beta_1': 0.9867725573560095, 'epsilon': 2.6454552722146024e-05, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 12:58:23,920] Trial 240 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.977230320000214, 'batch_size': 31, 'attention_heads': 11, 'hidden_dimension': 56, 'number_of_hidden_layers': 2, 'dropout_rate': 0.48534088946771625, 'global_pooling': 'mean', 'learning_rate': 0.0010813628014475348, 'weight_decay': 1.4952595679342412e-05, 'beta_0': 0.8752714685299443, 'beta_1': 0.9864638528054771, 'epsilon': 2.1816923397030205e-05, 'balanced_loss': False, 'epochs': 103, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 44.56 GiB of which 364.69 MiB is free. Including non-PyTorch memory, this process has 44.20 GiB memory in use. Of the allocated memory 40.92 GiB is allocated by PyTorch, and 2.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 13:08:25,546] Trial 241 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9482401883167458, 'batch_size': 33, 'attention_heads': 11, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5128316835887656, 'global_pooling': 'mean', 'learning_rate': 0.00030706106126732614, 'weight_decay': 1.87446827416465e-05, 'beta_0': 0.8810404368445346, 'beta_1': 0.9870326438328892, 'epsilon': 3.637852740835065e-05, 'balanced_loss': False, 'epochs': 119, 'early_stopping_patience': 24, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 13:21:38,709] Trial 242 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9793051960256698, 'batch_size': 33, 'attention_heads': 10, 'hidden_dimension': 50, 'number_of_hidden_layers': 2, 'dropout_rate': 0.48798392076587216, 'global_pooling': 'mean', 'learning_rate': 0.0005632363365401671, 'weight_decay': 9.730535444768305e-06, 'beta_0': 0.8771923908813977, 'beta_1': 0.9878457693503926, 'epsilon': 2.8570462044020458e-05, 'balanced_loss': False, 'epochs': 96, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 13:35:14,295] Trial 243 finished with value: 0.9212121212121213 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9809169322103246, 'batch_size': 32, 'attention_heads': 10, 'hidden_dimension': 60, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4989558630645596, 'global_pooling': 'mean', 'learning_rate': 0.0007833402946954845, 'weight_decay': 7.723134265623244e-06, 'beta_0': 0.898753375442671, 'beta_1': 0.987413702237617, 'epsilon': 3.568469963752142e-05, 'balanced_loss': False, 'epochs': 111, 'early_stopping_patience': 25, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 13:47:17,670] Trial 244 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.981302426111049, 'batch_size': 32, 'attention_heads': 10, 'hidden_dimension': 35, 'number_of_hidden_layers': 2, 'dropout_rate': 0.517918080425066, 'global_pooling': 'mean', 'learning_rate': 0.0007956469555940353, 'weight_decay': 7.97800335763661e-06, 'beta_0': 0.8991160373838003, 'beta_1': 0.9874272286847564, 'epsilon': 3.5650825270128296e-05, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 25, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 13:58:44,314] Trial 245 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9835948044428329, 'batch_size': 30, 'attention_heads': 9, 'hidden_dimension': 45, 'number_of_hidden_layers': 2, 'dropout_rate': 0.49577795178334627, 'global_pooling': 'mean', 'learning_rate': 0.001009007398076004, 'weight_decay': 7.061428782159829e-06, 'beta_0': 0.896788849905065, 'beta_1': 0.9844211750529598, 'epsilon': 2.3556436980934686e-05, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 24, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 14:12:21,330] Trial 246 finished with value: 0.896969696969697 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9765280283356882, 'batch_size': 35, 'attention_heads': 10, 'hidden_dimension': 57, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5022069572625435, 'global_pooling': 'mean', 'learning_rate': 0.0007848438019627176, 'weight_decay': 1.2727175747967715e-05, 'beta_0': 0.893703327677759, 'beta_1': 0.9887687815788594, 'epsilon': 1.836660541811008e-05, 'balanced_loss': False, 'epochs': 105, 'early_stopping_patience': 24, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 14:24:24,459] Trial 247 finished with value: 0.9272727272727272 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9800570221613393, 'batch_size': 36, 'attention_heads': 9, 'hidden_dimension': 41, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4984987836127241, 'global_pooling': 'mean', 'learning_rate': 0.0004321050351660455, 'weight_decay': 8.389049792607458e-06, 'beta_0': 0.8995269911531264, 'beta_1': 0.9870197853718112, 'epsilon': 3.0362517706136554e-05, 'balanced_loss': False, 'epochs': 74, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 14:36:35,968] Trial 248 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.979037709365613, 'batch_size': 36, 'attention_heads': 9, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5023919659475904, 'global_pooling': 'mean', 'learning_rate': 0.0003892742495638549, 'weight_decay': 8.580676659978172e-06, 'beta_0': 0.8998368632483278, 'beta_1': 0.9865793018553873, 'epsilon': 3.3420537632501386e-05, 'balanced_loss': False, 'epochs': 76, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 14:52:22,260] Trial 249 finished with value: 0.9090909090909091 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9742509940471679, 'batch_size': 35, 'attention_heads': 8, 'hidden_dimension': 44, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5356188943612867, 'global_pooling': 'mean', 'learning_rate': 0.00026435179966931554, 'weight_decay': 1.0429121647139798e-05, 'beta_0': 0.8993496595018866, 'beta_1': 0.9869999007777142, 'epsilon': 4.2527497857927737e-05, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 15:04:08,956] Trial 250 finished with value: 0.8909090909090909 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9797390259998549, 'batch_size': 32, 'attention_heads': 9, 'hidden_dimension': 36, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4799764907116122, 'global_pooling': 'mean', 'learning_rate': 0.00044852624036011694, 'weight_decay': 8.924738456472759e-06, 'beta_0': 0.8958910481671172, 'beta_1': 0.9881030702619817, 'epsilon': 2.9318759596966713e-05, 'balanced_loss': False, 'epochs': 111, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 15:17:07,538] Trial 251 finished with value: 0.8727272727272727 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9764584619544584, 'batch_size': 34, 'attention_heads': 9, 'hidden_dimension': 48, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5022931111344443, 'global_pooling': 'sum', 'learning_rate': 0.0015557372160793729, 'weight_decay': 2.6688523971922354e-06, 'beta_0': 0.8978914132296223, 'beta_1': 0.9868414056899423, 'epsilon': 1.5388097319504474e-05, 'balanced_loss': False, 'epochs': 123, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 15:28:49,973] Trial 252 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9812783619715263, 'batch_size': 36, 'attention_heads': 10, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5085207479856831, 'global_pooling': 'mean', 'learning_rate': 0.0005012156189989109, 'weight_decay': 7.487891012959604e-06, 'beta_0': 0.897351564964127, 'beta_1': 0.9891638117664269, 'epsilon': 2.1367047160572933e-05, 'balanced_loss': False, 'epochs': 72, 'early_stopping_patience': 19, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 15:42:19,211] Trial 253 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9749388822910688, 'batch_size': 31, 'attention_heads': 9, 'hidden_dimension': 41, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5134101735505202, 'global_pooling': 'mean', 'learning_rate': 0.0003573422964091448, 'weight_decay': 1.1252267188563604e-05, 'beta_0': 0.8931009933318973, 'beta_1': 0.9849184804488889, 'epsilon': 3.2762274556560134e-05, 'balanced_loss': False, 'epochs': 110, 'early_stopping_patience': 18, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 15:57:34,956] Trial 254 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9776569111150071, 'batch_size': 33, 'attention_heads': 10, 'hidden_dimension': 51, 'number_of_hidden_layers': 2, 'dropout_rate': 0.49683053993318427, 'global_pooling': 'mean', 'learning_rate': 0.0002236817688772604, 'weight_decay': 3.2516132920596115e-06, 'beta_0': 0.8953265782924272, 'beta_1': 0.9854035328283707, 'epsilon': 2.5798690690375383e-05, 'balanced_loss': False, 'epochs': 96, 'early_stopping_patience': 24, 'plateau_patience': 17, 'plateau_divider': 4}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 16:09:37,644] Trial 255 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9726480996375656, 'batch_size': 41, 'attention_heads': 8, 'hidden_dimension': 45, 'number_of_hidden_layers': 2, 'dropout_rate': 0.49949416335792857, 'global_pooling': 'mean', 'learning_rate': 0.00121535673101074, 'weight_decay': 9.785963580129536e-06, 'beta_0': 0.8911511227316375, 'beta_1': 0.9873382918988436, 'epsilon': 3.869235713258373e-05, 'balanced_loss': False, 'epochs': 106, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 4}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 16:24:15,152] Trial 256 finished with value: 0.8909090909090909 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.980301430990269, 'batch_size': 34, 'attention_heads': 10, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.492483813299463, 'global_pooling': 'mean', 'learning_rate': 0.0002991562792006547, 'weight_decay': 2.4425862237278417e-06, 'beta_0': 0.8791930637401031, 'beta_1': 0.9862528125860331, 'epsilon': 1.8686350426327713e-05, 'balanced_loss': False, 'epochs': 118, 'early_stopping_patience': 21, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 16:34:56,247] Trial 257 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9784866929415839, 'batch_size': 25, 'attention_heads': 7, 'hidden_dimension': 42, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5210840658385633, 'global_pooling': 'mean', 'learning_rate': 0.0009436611288764964, 'weight_decay': 2.8033357396486875e-06, 'beta_0': 0.8888306773519921, 'beta_1': 0.9884982109474132, 'epsilon': 2.7046201146833732e-05, 'balanced_loss': False, 'epochs': 62, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 16:46:05,677] Trial 258 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9863130134080144, 'batch_size': 29, 'attention_heads': 9, 'hidden_dimension': 39, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3113568420092509, 'global_pooling': 'mean', 'learning_rate': 0.00041824607815723946, 'weight_decay': 7.582551964357593e-06, 'beta_0': 0.8845253508082591, 'beta_1': 0.9868298432846406, 'epsilon': 2.1719891047731442e-05, 'balanced_loss': False, 'epochs': 79, 'early_stopping_patience': 24, 'plateau_patience': 17, 'plateau_divider': 7}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 16:58:15,950] Trial 259 finished with value: 0.9030303030303031 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9758527197936028, 'batch_size': 35, 'attention_heads': 10, 'hidden_dimension': 49, 'number_of_hidden_layers': 2, 'dropout_rate': 0.48689586114292976, 'global_pooling': 'mean', 'learning_rate': 0.0005372779415774253, 'weight_decay': 6.5131790376711015e-06, 'beta_0': 0.8979377905995658, 'beta_1': 0.9879362566022162, 'epsilon': 5.3734771832249776e-05, 'balanced_loss': False, 'epochs': 101, 'early_stopping_patience': 18, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.22 GiB. GPU 0 has a total capacity of 44.56 GiB of which 376.69 MiB is free. Including non-PyTorch memory, this process has 44.19 GiB memory in use. Of the allocated memory 41.70 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 17:07:58,810] Trial 260 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9736376738380386, 'batch_size': 31, 'attention_heads': 14, 'hidden_dimension': 176, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5266282459419068, 'global_pooling': 'mean', 'learning_rate': 0.0007493079534136612, 'weight_decay': 3.348973698082226e-06, 'beta_0': 0.8815631924371122, 'beta_1': 0.9873654649852843, 'epsilon': 3.185541220619507e-05, 'balanced_loss': False, 'epochs': 72, 'early_stopping_patience': 20, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 17:20:05,277] Trial 261 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9825962083361507, 'batch_size': 36, 'attention_heads': 10, 'hidden_dimension': 45, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3042577994274022, 'global_pooling': 'mean', 'learning_rate': 0.00034348169803240746, 'weight_decay': 2.1427411353569165e-06, 'beta_0': 0.873392950390125, 'beta_1': 0.9862067985738509, 'epsilon': 1.2689013124012294e-05, 'balanced_loss': False, 'epochs': 167, 'early_stopping_patience': 21, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 17:38:14,858] Trial 262 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.971102930092516, 'batch_size': 41, 'attention_heads': 12, 'hidden_dimension': 54, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5060764030754085, 'global_pooling': 'mean', 'learning_rate': 0.0019356269924542461, 'weight_decay': 9.165416822978319e-06, 'beta_0': 0.875843487548554, 'beta_1': 0.9890010293964162, 'epsilon': 4.3196212107290395e-05, 'balanced_loss': False, 'epochs': 93, 'early_stopping_patience': 24, 'plateau_patience': 17, 'plateau_divider': 4}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 17:49:58,588] Trial 263 finished with value: 0.896969696969697 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.978029906592993, 'batch_size': 37, 'attention_heads': 13, 'hidden_dimension': 38, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5464121067306399, 'global_pooling': 'mean', 'learning_rate': 0.00046496734190834923, 'weight_decay': 1.5353629824323003e-06, 'beta_0': 0.8795486436147243, 'beta_1': 0.985762605284345, 'epsilon': 1.5743369954333747e-05, 'balanced_loss': False, 'epochs': 113, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 3.68 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.93 GiB is free. Including non-PyTorch memory, this process has 41.62 GiB memory in use. Of the allocated memory 39.29 GiB is allocated by PyTorch, and 1.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 17:59:21,629] Trial 264 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9807474049226321, 'batch_size': 33, 'attention_heads': 11, 'hidden_dimension': 202, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3150455887544431, 'global_pooling': 'mean', 'learning_rate': 0.0005558429589674438, 'weight_decay': 3.7965652814087696e-06, 'beta_0': 0.8722326839465334, 'beta_1': 0.986629815734552, 'epsilon': 3.705097425159219e-05, 'balanced_loss': False, 'epochs': 135, 'early_stopping_patience': 24, 'plateau_patience': 16, 'plateau_divider': 4}. Best is trial 180 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacity of 44.56 GiB of which 282.69 MiB is free. Including non-PyTorch memory, this process has 44.28 GiB memory in use. Of the allocated memory 39.39 GiB is allocated by PyTorch, and 3.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 18:08:37,293] Trial 265 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9757624379828569, 'batch_size': 40, 'attention_heads': 9, 'hidden_dimension': 132, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5319102007674992, 'global_pooling': 'mean', 'learning_rate': 0.0002804704301597014, 'weight_decay': 2.312031420396542e-05, 'beta_0': 0.8027911496925836, 'beta_1': 0.9845364852165379, 'epsilon': 2.3632929522640492e-05, 'balanced_loss': False, 'epochs': 64, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacity of 44.56 GiB of which 864.69 MiB is free. Including non-PyTorch memory, this process has 43.71 GiB memory in use. Of the allocated memory 40.89 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 18:17:53,523] Trial 266 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.942135278733363, 'batch_size': 44, 'attention_heads': 7, 'hidden_dimension': 47, 'number_of_hidden_layers': 1, 'dropout_rate': 0.32038108392917236, 'global_pooling': 'mean', 'learning_rate': 0.00039187412818263357, 'weight_decay': 1.3262130486748195e-05, 'beta_0': 0.8766979820705709, 'beta_1': 0.9875899068210015, 'epsilon': 1.9236427109791765e-05, 'balanced_loss': False, 'epochs': 165, 'early_stopping_patience': 18, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 18:29:56,283] Trial 267 finished with value: 0.9212121212121213 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9775779735310793, 'batch_size': 34, 'attention_heads': 10, 'hidden_dimension': 35, 'number_of_hidden_layers': 2, 'dropout_rate': 0.499285934899037, 'global_pooling': 'mean', 'learning_rate': 0.0006910948333549456, 'weight_decay': 2.94682121023161e-06, 'beta_0': 0.8838816996854095, 'beta_1': 0.9838405439354238, 'epsilon': 2.9295050198618428e-05, 'balanced_loss': True, 'epochs': 170, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 1.84 GiB. GPU 0 has a total capacity of 44.56 GiB of which 798.69 MiB is free. Including non-PyTorch memory, this process has 43.77 GiB memory in use. Of the allocated memory 39.54 GiB is allocated by PyTorch, and 3.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 18:39:05,089] Trial 268 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.932511393731147, 'batch_size': 34, 'attention_heads': 10, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4892782083020164, 'global_pooling': 'mean', 'learning_rate': 0.0009878460492690447, 'weight_decay': 3.0022996200579785e-06, 'beta_0': 0.8855932260589903, 'beta_1': 0.9842887975780089, 'epsilon': 3.0347684671783806e-05, 'balanced_loss': True, 'epochs': 168, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 18:51:52,874] Trial 269 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.977054138424028, 'batch_size': 32, 'attention_heads': 10, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4995273115465283, 'global_pooling': 'mean', 'learning_rate': 0.0007236970746310263, 'weight_decay': 2.4625026188685176e-06, 'beta_0': 0.8843826056848713, 'beta_1': 0.9838415566678742, 'epsilon': 4.387291391607903e-05, 'balanced_loss': True, 'epochs': 172, 'early_stopping_patience': 25, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 19:04:09,360] Trial 270 finished with value: 0.9272727272727272 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9737077603077308, 'batch_size': 35, 'attention_heads': 9, 'hidden_dimension': 41, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5069172214044202, 'global_pooling': 'mean', 'learning_rate': 0.0014078576649068863, 'weight_decay': 2.846545851340736e-06, 'beta_0': 0.8812132741674106, 'beta_1': 0.9849602106804047, 'epsilon': 3.602050429941657e-05, 'balanced_loss': False, 'epochs': 170, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 19:17:01,672] Trial 271 finished with value: 0.8666666666666667 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9730639654404528, 'batch_size': 35, 'attention_heads': 9, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5094076697903527, 'global_pooling': 'sum', 'learning_rate': 0.0014785334184418276, 'weight_decay': 3.0980826124998414e-06, 'beta_0': 0.883173819076657, 'beta_1': 0.9835178866864459, 'epsilon': 3.633490458887105e-05, 'balanced_loss': False, 'epochs': 166, 'early_stopping_patience': 24, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 19:28:26,457] Trial 272 finished with value: 0.896969696969697 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.970974745221293, 'batch_size': 33, 'attention_heads': 9, 'hidden_dimension': 37, 'number_of_hidden_layers': 1, 'dropout_rate': 0.47237682696936023, 'global_pooling': 'mean', 'learning_rate': 0.0012982054532904375, 'weight_decay': 2.738343924795716e-06, 'beta_0': 0.8807251900664256, 'beta_1': 0.9851502122267579, 'epsilon': 5.545580768234376e-05, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 22, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 19:39:54,581] Trial 273 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9746803543860362, 'batch_size': 34, 'attention_heads': 9, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5015118418324486, 'global_pooling': 'mean', 'learning_rate': 0.0011101905502563, 'weight_decay': 2.4877950573725872e-06, 'beta_0': 0.8826029213937046, 'beta_1': 0.9847455219799883, 'epsilon': 1.118948019425197e-06, 'balanced_loss': False, 'epochs': 98, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 2}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 19:58:20,737] Trial 274 finished with value: 0.8909090909090909 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9742440083224838, 'batch_size': 35, 'attention_heads': 8, 'hidden_dimension': 42, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5157668219281898, 'global_pooling': 'mean', 'learning_rate': 0.0016508656044242997, 'weight_decay': 3.894477442556414e-06, 'beta_0': 0.8877096094018823, 'beta_1': 0.9842085375358075, 'epsilon': 3.1652824980768786e-05, 'balanced_loss': False, 'epochs': 162, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 3.33 GiB. GPU 0 has a total capacity of 44.56 GiB of which 984.69 MiB is free. Including non-PyTorch memory, this process has 43.59 GiB memory in use. Of the allocated memory 39.91 GiB is allocated by PyTorch, and 2.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 20:09:49,068] Trial 275 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9765171146070611, 'batch_size': 28, 'attention_heads': 10, 'hidden_dimension': 160, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5043214247558989, 'global_pooling': 'mean', 'learning_rate': 0.000881016015127132, 'weight_decay': 2.139928124464237e-06, 'beta_0': 0.8996373896837011, 'beta_1': 0.9853304724458325, 'epsilon': 4.495203875036395e-05, 'balanced_loss': False, 'epochs': 82, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 20:22:25,664] Trial 276 finished with value: 0.9212121212121213 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9721833133535746, 'batch_size': 34, 'attention_heads': 10, 'hidden_dimension': 39, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5108911223957517, 'global_pooling': 'mean', 'learning_rate': 0.000736760905035663, 'weight_decay': 2.8751901909334267e-06, 'beta_0': 0.8804528699353955, 'beta_1': 0.9838548593645022, 'epsilon': 2.7440628244982074e-05, 'balanced_loss': False, 'epochs': 169, 'early_stopping_patience': 25, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 20:34:20,663] Trial 277 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9714889073493245, 'batch_size': 35, 'attention_heads': 8, 'hidden_dimension': 35, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5172633988044256, 'global_pooling': 'mean', 'learning_rate': 0.0009021847426608505, 'weight_decay': 2.8292961230018997e-06, 'beta_0': 0.8856174365057308, 'beta_1': 0.9837044609552464, 'epsilon': 3.6788043655399615e-05, 'balanced_loss': False, 'epochs': 170, 'early_stopping_patience': 25, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 20:46:08,732] Trial 278 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9783286307397606, 'batch_size': 32, 'attention_heads': 9, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5100194348135068, 'global_pooling': 'mean', 'learning_rate': 0.002346628029837359, 'weight_decay': 3.3218944166315634e-06, 'beta_0': 0.8806434459137416, 'beta_1': 0.9888236648304314, 'epsilon': 2.808096826792087e-05, 'balanced_loss': False, 'epochs': 165, 'early_stopping_patience': 24, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 20:58:50,021] Trial 279 finished with value: 0.9272727272727272 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9760484124419793, 'batch_size': 34, 'attention_heads': 10, 'hidden_dimension': 47, 'number_of_hidden_layers': 2, 'dropout_rate': 0.49319669688202006, 'global_pooling': 'mean', 'learning_rate': 0.0013156175335483453, 'weight_decay': 2.370361497013568e-06, 'beta_0': 0.890208473915056, 'beta_1': 0.982954911469417, 'epsilon': 2.7732787052613683e-05, 'balanced_loss': False, 'epochs': 173, 'early_stopping_patience': 25, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 21:12:13,684] Trial 280 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.975109234880435, 'batch_size': 34, 'attention_heads': 10, 'hidden_dimension': 50, 'number_of_hidden_layers': 2, 'dropout_rate': 0.49364438430653623, 'global_pooling': 'mean', 'learning_rate': 0.0012955538572739483, 'weight_decay': 2.428731580871425e-06, 'beta_0': 0.8915448198570805, 'beta_1': 0.9826937886345798, 'epsilon': 2.561452507382693e-05, 'balanced_loss': False, 'epochs': 169, 'early_stopping_patience': 25, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 21:25:21,394] Trial 281 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9724842229244208, 'batch_size': 34, 'attention_heads': 10, 'hidden_dimension': 47, 'number_of_hidden_layers': 2, 'dropout_rate': 0.49500966195394974, 'global_pooling': 'mean', 'learning_rate': 0.0014683327244772524, 'weight_decay': 2.9337344764029786e-06, 'beta_0': 0.8925580298043274, 'beta_1': 0.9844778085842834, 'epsilon': 7.825797917603526e-07, 'balanced_loss': False, 'epochs': 174, 'early_stopping_patience': 25, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 21:38:02,627] Trial 282 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9691809904117149, 'batch_size': 33, 'attention_heads': 10, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.485265539723027, 'global_pooling': 'mean', 'learning_rate': 0.0017078883756132003, 'weight_decay': 2.3801597436375027e-06, 'beta_0': 0.8943510722452909, 'beta_1': 0.98199192650368, 'epsilon': 3.086237664132547e-05, 'balanced_loss': False, 'epochs': 163, 'early_stopping_patience': 25, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 21:49:42,195] Trial 283 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9790209908998215, 'batch_size': 36, 'attention_heads': 9, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5073382898906943, 'global_pooling': 'mean', 'learning_rate': 0.001114904665324517, 'weight_decay': 3.532079135270033e-06, 'beta_0': 0.890425859087735, 'beta_1': 0.98225432982604, 'epsilon': 2.4594082006849335e-05, 'balanced_loss': False, 'epochs': 167, 'early_stopping_patience': 25, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 22:05:24,270] Trial 284 finished with value: 0.896969696969697 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9754245344971935, 'batch_size': 35, 'attention_heads': 10, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5022894803276967, 'global_pooling': 'mean', 'learning_rate': 0.00023464924383959516, 'weight_decay': 2.6985395050547854e-06, 'beta_0': 0.888650904941628, 'beta_1': 0.9833939582817792, 'epsilon': 2.9986772590269806e-05, 'balanced_loss': False, 'epochs': 108, 'early_stopping_patience': 25, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 22:17:01,894] Trial 285 finished with value: 0.8909090909090909 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9735794904021774, 'batch_size': 33, 'attention_heads': 9, 'hidden_dimension': 51, 'number_of_hidden_layers': 1, 'dropout_rate': 0.523077050695076, 'global_pooling': 'mean', 'learning_rate': 0.00048648508288342396, 'weight_decay': 2.0562775463543742e-06, 'beta_0': 0.8831916242654025, 'beta_1': 0.9833724057211957, 'epsilon': 3.880749228114353e-05, 'balanced_loss': False, 'epochs': 165, 'early_stopping_patience': 25, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 22:34:05,756] Trial 286 finished with value: 0.9090909090909091 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9768696723429621, 'batch_size': 30, 'attention_heads': 10, 'hidden_dimension': 45, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5128570578601301, 'global_pooling': 'mean', 'learning_rate': 0.001293081440150268, 'weight_decay': 3.084891265411532e-06, 'beta_0': 0.8949210989636044, 'beta_1': 0.9841662521845534, 'epsilon': 2.163449249664624e-05, 'balanced_loss': False, 'epochs': 170, 'early_stopping_patience': 25, 'plateau_patience': 17, 'plateau_divider': 2}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 22:45:59,156] Trial 287 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9798739528234555, 'batch_size': 36, 'attention_heads': 9, 'hidden_dimension': 39, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4980522414500765, 'global_pooling': 'mean', 'learning_rate': 0.0006293624435547217, 'weight_decay': 1.189937796762181e-06, 'beta_0': 0.8851173385751808, 'beta_1': 0.9837976551432723, 'epsilon': 2.6999145737169586e-05, 'balanced_loss': False, 'epochs': 161, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 23:00:41,074] Trial 288 finished with value: 0.896969696969697 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9699782342811059, 'batch_size': 34, 'attention_heads': 10, 'hidden_dimension': 54, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5685986401325939, 'global_pooling': 'mean', 'learning_rate': 0.00031760126487774076, 'weight_decay': 2.2327484796820064e-06, 'beta_0': 0.8816073585644267, 'beta_1': 0.9892574754223169, 'epsilon': 1.5881916509254665e-05, 'balanced_loss': False, 'epochs': 76, 'early_stopping_patience': 23, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 23:12:32,734] Trial 289 finished with value: 0.896969696969697 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9776322214718421, 'batch_size': 32, 'attention_heads': 8, 'hidden_dimension': 46, 'number_of_hidden_layers': 2, 'dropout_rate': 0.49152485921419153, 'global_pooling': 'mean', 'learning_rate': 0.002017920693839288, 'weight_decay': 1.846766795204796e-06, 'beta_0': 0.8186207976870615, 'beta_1': 0.9883748268337083, 'epsilon': 3.2798903794388464e-05, 'balanced_loss': False, 'epochs': 87, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 23:25:12,180] Trial 290 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9740960744771595, 'batch_size': 32, 'attention_heads': 10, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5783646399655912, 'global_pooling': 'mean', 'learning_rate': 0.0010598459470753364, 'weight_decay': 2.6772736842493394e-06, 'beta_0': 0.8971272848512, 'beta_1': 0.9899272299618471, 'epsilon': 4.7258987696812156e-05, 'balanced_loss': False, 'epochs': 166, 'early_stopping_patience': 25, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.38 GiB is free. Including non-PyTorch memory, this process has 43.17 GiB memory in use. Of the allocated memory 40.88 GiB is allocated by PyTorch, and 1.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 23:34:58,974] Trial 291 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9562187161670564, 'batch_size': 35, 'attention_heads': 10, 'hidden_dimension': 42, 'number_of_hidden_layers': 2, 'dropout_rate': 0.43320923960202595, 'global_pooling': 'mean', 'learning_rate': 0.0004530820881749145, 'weight_decay': 1.4235403893153276e-06, 'beta_0': 0.8792017186246497, 'beta_1': 0.9830608693472632, 'epsilon': 2.361763827691313e-05, 'balanced_loss': False, 'epochs': 173, 'early_stopping_patience': 24, 'plateau_patience': 15, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-20 23:48:20,845] Trial 292 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9756667559597366, 'batch_size': 34, 'attention_heads': 9, 'hidden_dimension': 48, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4774583588749146, 'global_pooling': 'mean', 'learning_rate': 0.00019559012041801122, 'weight_decay': 3.5514302381493347e-06, 'beta_0': 0.8872557953728454, 'beta_1': 0.9904204298638836, 'epsilon': 1.8019498127172643e-05, 'balanced_loss': False, 'epochs': 162, 'early_stopping_patience': 23, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-21 00:02:09,681] Trial 293 finished with value: 0.8545454545454545 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9723037482734919, 'batch_size': 33, 'attention_heads': 9, 'hidden_dimension': 43, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5953185367416308, 'global_pooling': 'sum', 'learning_rate': 0.0003800189191420819, 'weight_decay': 4.399703040084645e-06, 'beta_0': 0.8119163730532668, 'beta_1': 0.9839749590235617, 'epsilon': 3.475357339182955e-05, 'balanced_loss': False, 'epochs': 168, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-21 00:14:50,040] Trial 294 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9796793747871502, 'batch_size': 36, 'attention_heads': 10, 'hidden_dimension': 38, 'number_of_hidden_layers': 2, 'dropout_rate': 0.587908960126106, 'global_pooling': 'mean', 'learning_rate': 0.000568630390390136, 'weight_decay': 8.31480949975685e-05, 'beta_0': 0.8895119389443342, 'beta_1': 0.9829356821553239, 'epsilon': 2.7944535680248994e-05, 'balanced_loss': False, 'epochs': 91, 'early_stopping_patience': 25, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-21 00:28:31,763] Trial 295 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9776930634626815, 'batch_size': 31, 'attention_heads': 9, 'hidden_dimension': 52, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4655279174895018, 'global_pooling': 'mean', 'learning_rate': 0.0002677264564003869, 'weight_decay': 3.100737384572034e-06, 'beta_0': 0.8827680780005246, 'beta_1': 0.9881731559697959, 'epsilon': 1.35998540381132e-05, 'balanced_loss': False, 'epochs': 107, 'early_stopping_patience': 24, 'plateau_patience': 16, 'plateau_divider': 6}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-21 00:40:44,656] Trial 296 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9754351986203197, 'batch_size': 35, 'attention_heads': 10, 'hidden_dimension': 57, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5062423780648075, 'global_pooling': 'mean', 'learning_rate': 0.0008537138219810042, 'weight_decay': 2.318021634198397e-06, 'beta_0': 0.8955983144510685, 'beta_1': 0.9886953488833603, 'epsilon': 4.0473934134907756e-05, 'balanced_loss': False, 'epochs': 72, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-21 00:57:13,970] Trial 297 finished with value: 0.8848484848484849 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9803324417002667, 'batch_size': 37, 'attention_heads': 16, 'hidden_dimension': 32, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4828594085786525, 'global_pooling': 'mean', 'learning_rate': 0.000670907320673345, 'weight_decay': 1.8617765542972884e-06, 'beta_0': 0.8802604260868996, 'beta_1': 0.9893291824328904, 'epsilon': 2.25620755674159e-05, 'balanced_loss': False, 'epochs': 160, 'early_stopping_patience': 24, 'plateau_patience': 19, 'plateau_divider': 2}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-21 01:10:11,971] Trial 298 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9713321018488807, 'batch_size': 30, 'attention_heads': 9, 'hidden_dimension': 45, 'number_of_hidden_layers': 2, 'dropout_rate': 0.49641536941339237, 'global_pooling': 'mean', 'learning_rate': 0.00033431546042063013, 'weight_decay': 2.715544384436218e-06, 'beta_0': 0.8923759961045865, 'beta_1': 0.984712054094322, 'epsilon': 3.240245858107663e-05, 'balanced_loss': False, 'epochs': 117, 'early_stopping_patience': 22, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-21 01:22:24,316] Trial 299 finished with value: 0.9272727272727272 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9769529879881294, 'batch_size': 44, 'attention_heads': 8, 'hidden_dimension': 39, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5558147013977127, 'global_pooling': 'mean', 'learning_rate': 0.00041655278741223003, 'weight_decay': 2.147955903011925e-06, 'beta_0': 0.8982817404939993, 'beta_1': 0.9863330080972599, 'epsilon': 8.027215587601612e-06, 'balanced_loss': False, 'epochs': 103, 'early_stopping_patience': 25, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-21 01:34:20,773] Trial 300 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9735294077262135, 'batch_size': 44, 'attention_heads': 8, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.553631825412859, 'global_pooling': 'mean', 'learning_rate': 0.0005077441860291992, 'weight_decay': 2.4165834726867252e-06, 'beta_0': 0.8973784100460224, 'beta_1': 0.9860600215332831, 'epsilon': 8.923438705570738e-06, 'balanced_loss': False, 'epochs': 102, 'early_stopping_patience': 25, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-21 01:47:42,300] Trial 301 finished with value: 0.9090909090909091 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.984135899679965, 'batch_size': 33, 'attention_heads': 8, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5477082805501681, 'global_pooling': 'mean', 'learning_rate': 0.00042672599104085575, 'weight_decay': 3.6384759206675097e-06, 'beta_0': 0.8989310216904243, 'beta_1': 0.9864337388319032, 'epsilon': 7.063691886870312e-06, 'balanced_loss': False, 'epochs': 111, 'early_stopping_patience': 25, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-21 01:59:19,152] Trial 302 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9767944413153863, 'batch_size': 34, 'attention_heads': 8, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5624639449271679, 'global_pooling': 'mean', 'learning_rate': 0.0006285184288858399, 'weight_decay': 1.1644521566789267e-06, 'beta_0': 0.8945515150039343, 'beta_1': 0.9858757658902195, 'epsilon': 1.8662492984752167e-05, 'balanced_loss': False, 'epochs': 107, 'early_stopping_patience': 25, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.62 GiB is free. Including non-PyTorch memory, this process has 42.94 GiB memory in use. Of the allocated memory 38.72 GiB is allocated by PyTorch, and 3.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 02:09:03,749] Trial 303 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9814695607304139, 'batch_size': 45, 'attention_heads': 8, 'hidden_dimension': 119, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5410941039547787, 'global_pooling': 'mean', 'learning_rate': 0.0007780877130948166, 'weight_decay': 2.130858335437253e-06, 'beta_0': 0.8971914084099734, 'beta_1': 0.9808186058360886, 'epsilon': 1.0163017517147174e-05, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 25, 'plateau_patience': 18, 'plateau_divider': 10}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-21 02:20:53,431] Trial 304 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.979038014331365, 'batch_size': 35, 'attention_heads': 7, 'hidden_dimension': 42, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5718991412904573, 'global_pooling': 'mean', 'learning_rate': 0.00126470770924426, 'weight_decay': 2.9932308220974454e-06, 'beta_0': 0.8838226532345187, 'beta_1': 0.9863607244292775, 'epsilon': 1.119504551538037e-05, 'balanced_loss': False, 'epochs': 98, 'early_stopping_patience': 24, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.
[I 2025-02-21 02:32:19,575] Trial 305 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9748312161803023, 'batch_size': 32, 'attention_heads': 8, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5582669437006107, 'global_pooling': 'mean', 'learning_rate': 0.0009551969968944683, 'weight_decay': 1.699120476031944e-06, 'beta_0': 0.893912564512974, 'beta_1': 0.9869253873741826, 'epsilon': 8.956511035720418e-06, 'balanced_loss': False, 'epochs': 112, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 180 with value: 0.9333333333333333.

[TRIAL] 180 [VALIDATION PERFORMANCE] 0.9333333333333333 [TRAINING LOSS] 0.03655886383106311 [VALIDATION LOSS] 0.3166294425725937 

number                                     180
value                                 0.933333
params_threshold                      0.975077
params_attention_heads                       9
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           34
params_dropout_rate                     0.3593
params_early_stopping_patience              23
params_epochs                              163
params_global_pooling                     mean
params_hidden_dimension                     32
params_learning_rate                  0.000635
params_number_of_hidden_layers               2
params_plateau_divider                       4
params_plateau_patience                     19
params_weight_decay                   0.000002
params_beta_0                         0.882578
params_beta_1                         0.989285
params_epsilon                        0.000021
user_attrs_epoch                          24.0
user_attrs_training_loss              0.036559
user_attrs_validation_loss            0.316629
params_left_stride                          64
params_right_stride                         64
Name: 180, dtype: object
37 Val: 0.9151515151515152 Test: 0.9164179104477612
38 Val: 0.9090909090909091 Test: 0.9343283582089552
39 Val: 0.9151515151515152 Test: 0.9313432835820895
40 Val: 0.9151515151515152 Test: 0.9313432835820895
41 Val: 0.9030303030303031 Test: 0.9253731343283582
42 Val: 0.9272727272727272 Test: 0.9313432835820895
43 Val: 0.9030303030303031 Test: 0.9194029850746268
44 Val: 0.9090909090909091 Test: 0.9313432835820895
45 Val: 0.9090909090909091 Test: 0.9194029850746268
46 Val: 0.9151515151515152 Test: 0.9343283582089552
Validation performance: 90.3 & 91.21 ± 0.71 & 92.73
Testing performance: 91.64 & 92.75 ± 0.68 & 93.43

[TRIAL] 214 [VALIDATION PERFORMANCE] 0.9272727272727272 [TRAINING LOSS] 0.029598620873385745 [VALIDATION LOSS] 0.2153170369565487 

number                                     214
value                                 0.927273
params_threshold                      0.974589
params_attention_heads                      10
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           27
params_dropout_rate                   0.531134
params_early_stopping_patience              20
params_epochs                               86
params_global_pooling                     mean
params_hidden_dimension                     42
params_learning_rate                  0.000403
params_number_of_hidden_layers               2
params_plateau_divider                       3
params_plateau_patience                     21
params_weight_decay                   0.000003
params_beta_0                         0.874964
params_beta_1                         0.987434
params_epsilon                        0.000024
user_attrs_epoch                          38.0
user_attrs_training_loss              0.029599
user_attrs_validation_loss            0.215317
params_left_stride                          64
params_right_stride                         64
Name: 214, dtype: object
37 Val: 0.9212121212121213 Test: 0.9283582089552239
38 Val: 0.9212121212121213 Test: 0.9253731343283582
39 Val: 0.9030303030303031 Test: 0.9194029850746268
40 Val: 0.9151515151515152 Test: 0.9283582089552239
41 Val: 0.9090909090909091 Test: 0.9164179104477612
42 Val: 0.9333333333333333 Test: 0.9432835820895522
43 Val: 0.9090909090909091 Test: 0.9253731343283582
44 Val: 0.9090909090909091 Test: 0.9223880597014925
45 Val: 0.9151515151515152 Test: 0.9283582089552239
46 Val: 0.9272727272727272 Test: 0.9313432835820895
Validation performance: 90.3 & 91.64 ± 0.94 & 93.33
Testing performance: 91.64 & 92.69 ± 0.73 & 94.33

[TRIAL] 299 [VALIDATION PERFORMANCE] 0.9272727272727272 [TRAINING LOSS] 0.1515645575709641 [VALIDATION LOSS] 0.2563680000603199 

number                                     299
value                                 0.927273
params_threshold                      0.976953
params_attention_heads                       8
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           44
params_dropout_rate                   0.555815
params_early_stopping_patience              25
params_epochs                              103
params_global_pooling                     mean
params_hidden_dimension                     39
params_learning_rate                  0.000417
params_number_of_hidden_layers               2
params_plateau_divider                       3
params_plateau_patience                     18
params_weight_decay                   0.000002
params_beta_0                         0.898282
params_beta_1                         0.986333
params_epsilon                        0.000008
user_attrs_epoch                          42.0
user_attrs_training_loss              0.151565
user_attrs_validation_loss            0.256368
params_left_stride                          64
params_right_stride                         64
Name: 299, dtype: object
37 Val: 0.896969696969697 Test: 0.9283582089552239
38 Val: 0.9090909090909091 Test: 0.9283582089552239
39 Val: 0.9151515151515152 Test: 0.9402985074626866
40 Val: 0.9030303030303031 Test: 0.9194029850746268
41 Val: 0.9272727272727272 Test: 0.9373134328358209
42 Val: 0.9272727272727272 Test: 0.9283582089552239
43 Val: 0.9090909090909091 Test: 0.9313432835820895
44 Val: 0.9151515151515152 Test: 0.9283582089552239
45 Val: 0.9151515151515152 Test: 0.9194029850746268
46 Val: 0.9151515151515152 Test: 0.9313432835820895
Validation performance: 89.7 & 91.33 ± 0.95 & 92.73
Testing performance: 91.94 & 92.93 ± 0.66 & 94.03

[TRIAL] 218 [VALIDATION PERFORMANCE] 0.9272727272727272 [TRAINING LOSS] 0.06893248407037131 [VALIDATION LOSS] 0.28445375710725784 

number                                     218
value                                 0.927273
params_threshold                      0.980723
params_attention_heads                      11
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           38
params_dropout_rate                   0.541643
params_early_stopping_patience              20
params_epochs                               84
params_global_pooling                     mean
params_hidden_dimension                     41
params_learning_rate                  0.000336
params_number_of_hidden_layers               2
params_plateau_divider                       3
params_plateau_patience                     17
params_weight_decay                   0.000003
params_beta_0                          0.86983
params_beta_1                         0.986612
params_epsilon                        0.000015
user_attrs_epoch                          50.0
user_attrs_training_loss              0.068932
user_attrs_validation_loss            0.284454
params_left_stride                          64
params_right_stride                         64
Name: 218, dtype: object
37 Val: 0.896969696969697 Test: 0.9074626865671642
38 Val: 0.9151515151515152 Test: 0.9283582089552239
39 Val: 0.896969696969697 Test: 0.9194029850746268
40 Val: 0.9151515151515152 Test: 0.9343283582089552
41 Val: 0.9212121212121213 Test: 0.9283582089552239
42 Val: 0.9212121212121213 Test: 0.9313432835820895
43 Val: 0.9272727272727272 Test: 0.9313432835820895
44 Val: 0.9212121212121213 Test: 0.9283582089552239
45 Val: 0.9151515151515152 Test: 0.9223880597014925
46 Val: 0.9212121212121213 Test: 0.9223880597014925
Validation performance: 89.7 & 91.52 ± 1.03 & 92.73
Testing performance: 90.75 & 92.54 ± 0.78 & 93.43

[TRIAL] 279 [VALIDATION PERFORMANCE] 0.9272727272727272 [TRAINING LOSS] 0.0561572249357899 [VALIDATION LOSS] 0.28639640361070634 

number                                     279
value                                 0.927273
params_threshold                      0.976048
params_attention_heads                      10
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           34
params_dropout_rate                   0.493197
params_early_stopping_patience              25
params_epochs                              173
params_global_pooling                     mean
params_hidden_dimension                     47
params_learning_rate                  0.001316
params_number_of_hidden_layers               2
params_plateau_divider                       3
params_plateau_patience                     19
params_weight_decay                   0.000002
params_beta_0                         0.890208
params_beta_1                         0.982955
params_epsilon                        0.000028
user_attrs_epoch                          21.0
user_attrs_training_loss              0.056157
user_attrs_validation_loss            0.286396
params_left_stride                          64
params_right_stride                         64
Name: 279, dtype: object
37 Val: 0.9272727272727272 Test: 0.9343283582089552
38 Val: 0.9090909090909091 Test: 0.9343283582089552
39 Val: 0.9212121212121213 Test: 0.9373134328358209
40 Val: 0.9151515151515152 Test: 0.9194029850746268
41 Val: 0.9151515151515152 Test: 0.9343283582089552
42 Val: 0.9272727272727272 Test: 0.9343283582089552
43 Val: 0.9272727272727272 Test: 0.9313432835820895
44 Val: 0.9090909090909091 Test: 0.9253731343283582
45 Val: 0.9151515151515152 Test: 0.9223880597014925
46 Val: 0.9090909090909091 Test: 0.9283582089552239
Validation performance: 90.91 & 91.76 ± 0.77 & 92.73
Testing performance: 91.94 & 93.01 ± 0.6 & 93.73

[IMDb-top_1000] Elapsed time: 1579.0448544780413 minutes.
