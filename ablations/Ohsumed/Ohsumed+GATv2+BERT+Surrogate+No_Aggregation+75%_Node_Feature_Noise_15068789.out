[I 2025-03-02 22:24:21,284] Using an existing study with name 'Ohsumed-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-No_Ablation-1.0-0.75' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors
[I 2025-03-02 22:44:26,873] Trial 196 finished with value: 0.4759531216719192 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9797987917783552, 'batch_size': 58, 'attention_heads': 14, 'hidden_dimension': 130, 'number_of_hidden_layers': 1, 'dropout_rate': 0.53917031581843, 'global_pooling': 'max', 'learning_rate': 0.00032850908655470237, 'weight_decay': 4.460313850380817e-05, 'beta_0': 0.8438468129026884, 'beta_1': 0.9943476418214059, 'epsilon': 1.605596278503462e-07, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 16, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-02 23:03:50,095] Trial 197 finished with value: 0.4784460463444077 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9928655236515279, 'batch_size': 54, 'attention_heads': 14, 'hidden_dimension': 149, 'number_of_hidden_layers': 1, 'dropout_rate': 0.536467814986449, 'global_pooling': 'max', 'learning_rate': 0.0004343853572459847, 'weight_decay': 5.862812175037746e-05, 'beta_0': 0.8356101650281335, 'beta_1': 0.9934799876579614, 'epsilon': 3.575779045966615e-07, 'balanced_loss': True, 'epochs': 131, 'early_stopping_patience': 17, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-02 23:24:33,805] Trial 198 finished with value: 0.49813893628956374 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9844374982472391, 'batch_size': 56, 'attention_heads': 15, 'hidden_dimension': 135, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5292159197909602, 'global_pooling': 'max', 'learning_rate': 0.0008064821813828986, 'weight_decay': 3.315933616932401e-05, 'beta_0': 0.8392704957270485, 'beta_1': 0.993697439387198, 'epsilon': 4.969056077116172e-07, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 17, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-02 23:44:08,659] Trial 199 finished with value: 0.509774376941034 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9775255856607546, 'batch_size': 53, 'attention_heads': 14, 'hidden_dimension': 141, 'number_of_hidden_layers': 1, 'dropout_rate': 0.543838451838367, 'global_pooling': 'max', 'learning_rate': 0.0007230528397535142, 'weight_decay': 4.0980910511194074e-05, 'beta_0': 0.8431693238899418, 'beta_1': 0.9931387116186475, 'epsilon': 5.815527438091939e-07, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 16, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-03 00:09:28,006] Trial 200 finished with value: 0.5098802693423358 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9667215324557225, 'batch_size': 52, 'attention_heads': 14, 'hidden_dimension': 137, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5320997960861873, 'global_pooling': 'max', 'learning_rate': 0.0005141926505865804, 'weight_decay': 4.5058025330944015e-05, 'beta_0': 0.8420044621732313, 'beta_1': 0.9930738044310593, 'epsilon': 2.539417712842298e-07, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 17, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-03 00:30:32,686] Trial 201 finished with value: 0.5045166704901647 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9715743675639015, 'batch_size': 65, 'attention_heads': 14, 'hidden_dimension': 132, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5530586598848667, 'global_pooling': 'max', 'learning_rate': 0.0005100166661531232, 'weight_decay': 2.7903744709902334e-05, 'beta_0': 0.8453104005289523, 'beta_1': 0.9939069454299605, 'epsilon': 3.9394114118171366e-07, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-03 00:53:43,164] Trial 202 finished with value: 0.5264389414866365 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9658409462275421, 'batch_size': 56, 'attention_heads': 14, 'hidden_dimension': 143, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5414297489346149, 'global_pooling': 'max', 'learning_rate': 0.00040828271855433777, 'weight_decay': 5.3083219762189864e-05, 'beta_0': 0.8406709382648903, 'beta_1': 0.9929652074860504, 'epsilon': 8.38396457364451e-07, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-03 01:15:16,494] Trial 203 finished with value: 0.5265417692479408 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9660141557253348, 'batch_size': 56, 'attention_heads': 14, 'hidden_dimension': 144, 'number_of_hidden_layers': 1, 'dropout_rate': 0.539867729818207, 'global_pooling': 'max', 'learning_rate': 0.0003115146993250573, 'weight_decay': 5.609487899610507e-05, 'beta_0': 0.840068904243239, 'beta_1': 0.9934728067598805, 'epsilon': 8.682494152998879e-07, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-03 01:37:23,530] Trial 204 finished with value: 0.5229081699561867 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9657433160927641, 'batch_size': 60, 'attention_heads': 15, 'hidden_dimension': 144, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5418242841079208, 'global_pooling': 'max', 'learning_rate': 0.000295226870446981, 'weight_decay': 5.475867320526537e-05, 'beta_0': 0.8466285850062775, 'beta_1': 0.9944868699076989, 'epsilon': 8.349880524112304e-07, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.79 GiB is free. Including non-PyTorch memory, this process has 42.77 GiB memory in use. Of the allocated memory 40.10 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-03 01:49:46,681] Trial 205 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9636336636198308, 'batch_size': 59, 'attention_heads': 15, 'hidden_dimension': 159, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5236981230667861, 'global_pooling': 'max', 'learning_rate': 0.0002955515398563093, 'weight_decay': 5.511809093465608e-05, 'beta_0': 0.8399940627158654, 'beta_1': 0.994360501831405, 'epsilon': 7.850252303345529e-07, 'balanced_loss': True, 'epochs': 104, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-03 02:12:59,053] Trial 206 finished with value: 0.5107753829927201 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.977818137692871, 'batch_size': 61, 'attention_heads': 15, 'hidden_dimension': 147, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5632715995812669, 'global_pooling': 'max', 'learning_rate': 0.00035541965819243333, 'weight_decay': 7.768300200310722e-05, 'beta_0': 0.8373375358291245, 'beta_1': 0.9935767078089525, 'epsilon': 7.913314310071134e-07, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-03 02:34:52,921] Trial 207 finished with value: 0.5352470627703714 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9648829370736276, 'batch_size': 55, 'attention_heads': 14, 'hidden_dimension': 152, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5334767536831335, 'global_pooling': 'max', 'learning_rate': 0.00038572164937504983, 'weight_decay': 6.635202326740835e-05, 'beta_0': 0.8460223297369956, 'beta_1': 0.9945278967673951, 'epsilon': 1.353173009445922e-07, 'balanced_loss': True, 'epochs': 107, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.38 GiB is free. Including non-PyTorch memory, this process has 43.17 GiB memory in use. Of the allocated memory 38.61 GiB is allocated by PyTorch, and 3.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-03 02:47:35,982] Trial 208 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.964676870937323, 'batch_size': 57, 'attention_heads': 15, 'hidden_dimension': 152, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5320150004134266, 'global_pooling': 'max', 'learning_rate': 0.0003016267933523819, 'weight_decay': 6.89036004688156e-05, 'beta_0': 0.845264813381204, 'beta_1': 0.9945717027579893, 'epsilon': 1.096156618767067e-07, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-03 03:08:00,296] Trial 209 finished with value: 0.5038610113808373 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9680008474507662, 'batch_size': 55, 'attention_heads': 14, 'hidden_dimension': 143, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5442265181966903, 'global_pooling': 'max', 'learning_rate': 0.0003933629274254143, 'weight_decay': 6.173735691182778e-05, 'beta_0': 0.84605705712088, 'beta_1': 0.9940847391046518, 'epsilon': 1.7560181594379842e-07, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 17, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-03 03:29:47,861] Trial 210 finished with value: 0.5097362556819187 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9657283478049713, 'batch_size': 57, 'attention_heads': 14, 'hidden_dimension': 152, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5378031802153515, 'global_pooling': 'max', 'learning_rate': 0.0004134921704617492, 'weight_decay': 5.751144867801566e-05, 'beta_0': 0.843239704056347, 'beta_1': 0.9937363760536889, 'epsilon': 1.3066651571327266e-07, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-03 03:50:05,386] Trial 211 finished with value: 0.499091171403422 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.961925041040096, 'batch_size': 54, 'attention_heads': 13, 'hidden_dimension': 126, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5466088996755719, 'global_pooling': 'max', 'learning_rate': 0.00033289462200883547, 'weight_decay': 5.186003505702202e-05, 'beta_0': 0.8407773121602861, 'beta_1': 0.9930357541478427, 'epsilon': 7.073038205568242e-08, 'balanced_loss': True, 'epochs': 101, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 26.69 MiB is free. Including non-PyTorch memory, this process has 44.53 GiB memory in use. Of the allocated memory 42.77 GiB is allocated by PyTorch, and 619.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-03 03:59:14,445] Trial 212 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8730340044643164, 'batch_size': 51, 'attention_heads': 14, 'hidden_dimension': 145, 'number_of_hidden_layers': 1, 'dropout_rate': 0.533384624387922, 'global_pooling': 'max', 'learning_rate': 0.00028048038409998803, 'weight_decay': 3.553225944170134e-05, 'beta_0': 0.8469913834559643, 'beta_1': 0.9946811030741513, 'epsilon': 9.317490701548551e-07, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-03 04:21:27,375] Trial 213 finished with value: 0.5207129888396069 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9693281130472564, 'batch_size': 55, 'attention_heads': 14, 'hidden_dimension': 158, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5404550859358593, 'global_pooling': 'max', 'learning_rate': 0.0004003387205089106, 'weight_decay': 4.6397048678480954e-05, 'beta_0': 0.8434280579198624, 'beta_1': 0.9922539256692873, 'epsilon': 5.214912517776749e-07, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 183 with value: 0.5476273104865623.
[I 2025-03-03 04:43:05,954] Trial 214 finished with value: 0.5493008496774074 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9691381168924653, 'batch_size': 55, 'attention_heads': 13, 'hidden_dimension': 161, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5553385948211091, 'global_pooling': 'max', 'learning_rate': 0.0003961970889792795, 'weight_decay': 6.592204702908692e-05, 'beta_0': 0.8441967797308827, 'beta_1': 0.9919853973163861, 'epsilon': 5.095665749433205e-07, 'balanced_loss': True, 'epochs': 107, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 05:09:36,713] Trial 215 finished with value: 0.5421621196900989 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.968675641428578, 'batch_size': 59, 'attention_heads': 13, 'hidden_dimension': 166, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5663493998198833, 'global_pooling': 'max', 'learning_rate': 0.0003728606500497155, 'weight_decay': 6.601341222649791e-05, 'beta_0': 0.8471656197022671, 'beta_1': 0.9919524861132535, 'epsilon': 2.961258011315396e-07, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 05:35:49,143] Trial 216 finished with value: 0.5189972693179231 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9688500298366552, 'batch_size': 59, 'attention_heads': 13, 'hidden_dimension': 159, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5778693289456123, 'global_pooling': 'max', 'learning_rate': 0.000244635540500482, 'weight_decay': 7.018078215545456e-05, 'beta_0': 0.8466618506306057, 'beta_1': 0.992047341809418, 'epsilon': 2.9343135109585833e-07, 'balanced_loss': True, 'epochs': 107, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 42.60 GiB memory in use. Of the allocated memory 40.90 GiB is allocated by PyTorch, and 565.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-03 05:48:16,622] Trial 217 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9604101614639007, 'batch_size': 64, 'attention_heads': 13, 'hidden_dimension': 169, 'number_of_hidden_layers': 1, 'dropout_rate': 0.564652571248863, 'global_pooling': 'max', 'learning_rate': 0.0003361978949955461, 'weight_decay': 8.377154919986837e-05, 'beta_0': 0.8474266744425938, 'beta_1': 0.9923362120408677, 'epsilon': 2.1845129216728213e-07, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 06:13:09,993] Trial 218 finished with value: 0.5235170404336441 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9699676370388446, 'batch_size': 56, 'attention_heads': 13, 'hidden_dimension': 163, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5724687320623867, 'global_pooling': 'max', 'learning_rate': 0.00028096810498530743, 'weight_decay': 6.365928425911587e-05, 'beta_0': 0.8519635856446786, 'beta_1': 0.992499788845543, 'epsilon': 3.229086715604838e-07, 'balanced_loss': True, 'epochs': 99, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 06:38:24,985] Trial 219 finished with value: 0.5218462642211454 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.969499150727573, 'batch_size': 61, 'attention_heads': 13, 'hidden_dimension': 165, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5719067279249547, 'global_pooling': 'max', 'learning_rate': 0.00028479228910004096, 'weight_decay': 6.176961861765562e-05, 'beta_0': 0.8521551028581424, 'beta_1': 0.9918829687208895, 'epsilon': 4.0013538120777073e-07, 'balanced_loss': True, 'epochs': 100, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 07:05:37,080] Trial 220 finished with value: 0.5472475551763017 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9674339306384925, 'batch_size': 60, 'attention_heads': 13, 'hidden_dimension': 163, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5914872545530682, 'global_pooling': 'max', 'learning_rate': 0.00027150889673612747, 'weight_decay': 6.347050976658574e-05, 'beta_0': 0.8516433358276656, 'beta_1': 0.9919155232397986, 'epsilon': 4.312231333972843e-07, 'balanced_loss': True, 'epochs': 98, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 07:34:09,308] Trial 221 finished with value: 0.502352644788236 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9656494707546062, 'batch_size': 61, 'attention_heads': 13, 'hidden_dimension': 167, 'number_of_hidden_layers': 1, 'dropout_rate': 0.587909244318158, 'global_pooling': 'max', 'learning_rate': 0.0002428265084916737, 'weight_decay': 6.463531809383645e-05, 'beta_0': 0.8536780771277739, 'beta_1': 0.9917229664864688, 'epsilon': 3.744345075186542e-07, 'balanced_loss': True, 'epochs': 103, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.24 GiB is free. Including non-PyTorch memory, this process has 42.32 GiB memory in use. Of the allocated memory 38.94 GiB is allocated by PyTorch, and 2.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-03 08:00:09,174] Trial 222 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9692186011409244, 'batch_size': 69, 'attention_heads': 13, 'hidden_dimension': 174, 'number_of_hidden_layers': 1, 'dropout_rate': 0.571812619512831, 'global_pooling': 'max', 'learning_rate': 0.00029675022908118553, 'weight_decay': 6.626647660049181e-05, 'beta_0': 0.8519716283055635, 'beta_1': 0.991964988922852, 'epsilon': 3.155199910078718e-07, 'balanced_loss': True, 'epochs': 96, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 2.13 GiB. GPU 0 has a total capacity of 44.56 GiB of which 58.69 MiB is free. Including non-PyTorch memory, this process has 44.50 GiB memory in use. Of the allocated memory 41.06 GiB is allocated by PyTorch, and 2.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-03 08:12:49,279] Trial 223 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9608067864573545, 'batch_size': 60, 'attention_heads': 13, 'hidden_dimension': 163, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5837762823704031, 'global_pooling': 'max', 'learning_rate': 0.00026381366089291223, 'weight_decay': 7.786935247800916e-05, 'beta_0': 0.8514762875771124, 'beta_1': 0.9923557881091457, 'epsilon': 4.230164647114593e-07, 'balanced_loss': True, 'epochs': 99, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 132.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 28.69 MiB is free. Including non-PyTorch memory, this process has 44.53 GiB memory in use. Of the allocated memory 42.49 GiB is allocated by PyTorch, and 903.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-03 08:21:43,308] Trial 224 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8674220067164141, 'batch_size': 58, 'attention_heads': 12, 'hidden_dimension': 155, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5768565250726565, 'global_pooling': 'max', 'learning_rate': 0.00032958823177989987, 'weight_decay': 9.955750781542924e-05, 'beta_0': 0.8544591401371819, 'beta_1': 0.9920863096258385, 'epsilon': 2.588789134305757e-07, 'balanced_loss': True, 'epochs': 101, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 08:46:09,741] Trial 225 finished with value: 0.5232345122342644 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9715087187270749, 'batch_size': 56, 'attention_heads': 13, 'hidden_dimension': 162, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5892737458373265, 'global_pooling': 'max', 'learning_rate': 0.0003647171873329647, 'weight_decay': 5.6798222257087925e-05, 'beta_0': 0.8479884689601481, 'beta_1': 0.9911138080161436, 'epsilon': 3.5442005880946435e-07, 'balanced_loss': True, 'epochs': 99, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 09:10:30,532] Trial 226 finished with value: 0.5006419150838424 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9720642104031807, 'batch_size': 58, 'attention_heads': 13, 'hidden_dimension': 162, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5906779675688992, 'global_pooling': 'max', 'learning_rate': 0.00038570789332557736, 'weight_decay': 5.360756469313136e-05, 'beta_0': 0.847625921144088, 'beta_1': 0.9911108901775316, 'epsilon': 3.380903976218949e-07, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 09:34:56,933] Trial 227 finished with value: 0.4918800999910322 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9670076381716248, 'batch_size': 56, 'attention_heads': 12, 'hidden_dimension': 166, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5952420693547813, 'global_pooling': 'max', 'learning_rate': 0.0002270681312566618, 'weight_decay': 8.195811585695984e-05, 'beta_0': 0.8483933028389662, 'beta_1': 0.9916355704211447, 'epsilon': 1.9424913614178635e-07, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 09:59:17,521] Trial 228 finished with value: 0.5036640794391856 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9750415071943435, 'batch_size': 56, 'attention_heads': 13, 'hidden_dimension': 170, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5912509711902009, 'global_pooling': 'max', 'learning_rate': 0.0003471965005708529, 'weight_decay': 5.822449923050033e-05, 'beta_0': 0.846385822701955, 'beta_1': 0.9923873846578758, 'epsilon': 2.5353796998765537e-07, 'balanced_loss': True, 'epochs': 97, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 10:22:16,832] Trial 229 finished with value: 0.5113477439581565 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.971191548814688, 'batch_size': 63, 'attention_heads': 13, 'hidden_dimension': 158, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5703181080477578, 'global_pooling': 'max', 'learning_rate': 0.000284382351464964, 'weight_decay': 6.210564256311409e-05, 'beta_0': 0.8517346100743657, 'beta_1': 0.991928522341865, 'epsilon': 4.2911079784475315e-07, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 10:44:59,907] Trial 230 finished with value: 0.5151458447580775 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9664974598707201, 'batch_size': 58, 'attention_heads': 13, 'hidden_dimension': 164, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5786690104360827, 'global_pooling': 'max', 'learning_rate': 0.00042013859240128945, 'weight_decay': 6.965625624930733e-05, 'beta_0': 0.8504344993346682, 'beta_1': 0.9912543131138498, 'epsilon': 3.33740345085852e-07, 'balanced_loss': True, 'epochs': 101, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.54 GiB is free. Including non-PyTorch memory, this process has 43.01 GiB memory in use. Of the allocated memory 38.68 GiB is allocated by PyTorch, and 3.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-03 10:59:30,070] Trial 231 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.963006372812427, 'batch_size': 62, 'attention_heads': 13, 'hidden_dimension': 151, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5599262641947568, 'global_pooling': 'max', 'learning_rate': 0.00030248046699950704, 'weight_decay': 5.8140703936988706e-05, 'beta_0': 0.8560886497535792, 'beta_1': 0.9917693074134935, 'epsilon': 5.223563002352819e-07, 'balanced_loss': True, 'epochs': 107, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 530.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 208.69 MiB is free. Including non-PyTorch memory, this process has 44.35 GiB memory in use. Of the allocated memory 42.50 GiB is allocated by PyTorch, and 712.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-03 11:09:26,819] Trial 232 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8842747714159944, 'batch_size': 60, 'attention_heads': 14, 'hidden_dimension': 172, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5564890269959439, 'global_pooling': 'max', 'learning_rate': 0.00036347753773351827, 'weight_decay': 7.365307533185124e-05, 'beta_0': 0.8532764629189956, 'beta_1': 0.9925602764671893, 'epsilon': 4.455621927753166e-07, 'balanced_loss': True, 'epochs': 98, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 11:33:15,794] Trial 233 finished with value: 0.5044417836576933 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9712932285704812, 'batch_size': 56, 'attention_heads': 13, 'hidden_dimension': 142, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5669874651862993, 'global_pooling': 'max', 'learning_rate': 0.00023853658276311342, 'weight_decay': 5.2889171065032204e-05, 'beta_0': 0.8449176945725067, 'beta_1': 0.9949304642543575, 'epsilon': 1.2356805289432067e-07, 'balanced_loss': True, 'epochs': 93, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 11:56:00,090] Trial 234 finished with value: 0.5245564570330101 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9759342201588902, 'batch_size': 52, 'attention_heads': 14, 'hidden_dimension': 164, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5954248919501285, 'global_pooling': 'max', 'learning_rate': 0.0004496684199033535, 'weight_decay': 2.2825288689516315e-05, 'beta_0': 0.8484359711356312, 'beta_1': 0.9925993824540414, 'epsilon': 2.7883567936953996e-07, 'balanced_loss': True, 'epochs': 99, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 12:18:03,419] Trial 235 finished with value: 0.4858670288074689 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9820796361557589, 'batch_size': 52, 'attention_heads': 14, 'hidden_dimension': 155, 'number_of_hidden_layers': 1, 'dropout_rate': 0.589467598221295, 'global_pooling': 'max', 'learning_rate': 0.0004584894242515392, 'weight_decay': 2.325223994484948e-05, 'beta_0': 0.8483812418731981, 'beta_1': 0.9926385319141525, 'epsilon': 2.7081875599281083e-07, 'balanced_loss': True, 'epochs': 130, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 12:37:07,760] Trial 236 finished with value: 0.4983377375586414 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9767083170131411, 'batch_size': 55, 'attention_heads': 14, 'hidden_dimension': 131, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5542248264250482, 'global_pooling': 'max', 'learning_rate': 0.00042372780716982934, 'weight_decay': 2.632314485208035e-05, 'beta_0': 0.8394543063742002, 'beta_1': 0.9934549116658807, 'epsilon': 3.044732454330955e-07, 'balanced_loss': True, 'epochs': 104, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 12:59:21,990] Trial 237 finished with value: 0.501323581865962 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9763015230345049, 'batch_size': 51, 'attention_heads': 15, 'hidden_dimension': 161, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5930167716330212, 'global_pooling': 'max', 'learning_rate': 0.0007680845696936389, 'weight_decay': 2.085520889464717e-05, 'beta_0': 0.8458459558217428, 'beta_1': 0.9909009660870706, 'epsilon': 2.3800490892951307e-07, 'balanced_loss': True, 'epochs': 128, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 13:21:29,124] Trial 238 finished with value: 0.5178142040475588 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9651533216603124, 'batch_size': 54, 'attention_heads': 14, 'hidden_dimension': 146, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5820934457005517, 'global_pooling': 'max', 'learning_rate': 0.0004903140866094862, 'weight_decay': 3.226713486899875e-05, 'beta_0': 0.8417908699630269, 'beta_1': 0.9928061772263788, 'epsilon': 1.7139001872915583e-07, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 13:44:57,693] Trial 239 finished with value: 0.5137266345646333 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.972501587345959, 'batch_size': 56, 'attention_heads': 13, 'hidden_dimension': 167, 'number_of_hidden_layers': 1, 'dropout_rate': 0.59985412012191, 'global_pooling': 'max', 'learning_rate': 0.00032625480287020857, 'weight_decay': 6.459144874967874e-05, 'beta_0': 0.8501404916395666, 'beta_1': 0.9921084397295847, 'epsilon': 9.582406804969424e-08, 'balanced_loss': True, 'epochs': 95, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-03 14:08:53,278] Trial 240 finished with value: 0.48612653040292936 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9692333302311912, 'batch_size': 59, 'attention_heads': 14, 'hidden_dimension': 179, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5624251434429235, 'global_pooling': 'max', 'learning_rate': 0.0002611792899602083, 'weight_decay': 3.6944187672872364e-05, 'beta_0': 0.84737814410733, 'beta_1': 0.9914116660915158, 'epsilon': 3.626876364406191e-07, 'balanced_loss': True, 'epochs': 99, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 2.13 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.27 GiB is free. Including non-PyTorch memory, this process has 43.29 GiB memory in use. Of the allocated memory 39.54 GiB is allocated by PyTorch, and 2.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-03 14:21:48,367] Trial 241 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9589514010379702, 'batch_size': 52, 'attention_heads': 14, 'hidden_dimension': 162, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5500266097473416, 'global_pooling': 'max', 'learning_rate': 0.00038794385603063073, 'weight_decay': 5.057778982821504e-05, 'beta_0': 0.8522613045943571, 'beta_1': 0.9918251518044011, 'epsilon': 4.771435867508597e-07, 'balanced_loss': True, 'epochs': 99, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
slurmstepd: error: *** JOB 15068789 ON gpu004 CANCELLED AT 2025-03-03T14:24:21 DUE TO TIME LIMIT ***
