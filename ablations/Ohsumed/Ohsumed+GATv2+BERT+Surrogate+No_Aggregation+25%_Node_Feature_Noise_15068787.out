[I 2025-03-01 22:27:10,146] Using an existing study with name 'Ohsumed-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-No_Ablation-1.0-0.25' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors
[I 2025-03-01 22:45:52,380] Trial 229 finished with value: 0.6031643414335054 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9734546844555703, 'batch_size': 47, 'attention_heads': 9, 'hidden_dimension': 249, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4072399907192903, 'global_pooling': 'max', 'learning_rate': 0.0006794118637618939, 'weight_decay': 0.0005066797282584797, 'beta_0': 0.8394721127569283, 'beta_1': 0.9900164234047119, 'epsilon': 5.040876161982659e-06, 'balanced_loss': False, 'epochs': 173, 'early_stopping_patience': 18, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 94 with value: 0.6130243860768243.
[I 2025-03-01 23:04:04,050] Trial 230 finished with value: 0.5802639475026207 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9741473316723777, 'batch_size': 54, 'attention_heads': 9, 'hidden_dimension': 248, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40529386913111354, 'global_pooling': 'max', 'learning_rate': 0.0006051031386933398, 'weight_decay': 0.0005966687982420946, 'beta_0': 0.842880801720521, 'beta_1': 0.9900371706453751, 'epsilon': 4.708322458636021e-06, 'balanced_loss': False, 'epochs': 178, 'early_stopping_patience': 16, 'plateau_patience': 14, 'plateau_divider': 8}. Best is trial 94 with value: 0.6130243860768243.
[I 2025-03-01 23:22:40,325] Trial 231 finished with value: 0.5846187204584089 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9733021549228192, 'batch_size': 46, 'attention_heads': 9, 'hidden_dimension': 254, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4112495166209336, 'global_pooling': 'max', 'learning_rate': 0.0009759217307202024, 'weight_decay': 0.0005415077384958916, 'beta_0': 0.8425772115235948, 'beta_1': 0.9898664789439834, 'epsilon': 5.449927529080075e-06, 'balanced_loss': False, 'epochs': 174, 'early_stopping_patience': 18, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 94 with value: 0.6130243860768243.
[I 2025-03-01 23:40:56,963] Trial 232 finished with value: 0.577438569223352 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9787151469746361, 'batch_size': 51, 'attention_heads': 8, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4157141563379878, 'global_pooling': 'max', 'learning_rate': 0.000524475108205076, 'weight_decay': 0.0004911483358625795, 'beta_0': 0.8448356538937027, 'beta_1': 0.9900353129694603, 'epsilon': 3.106062592375028e-06, 'balanced_loss': True, 'epochs': 172, 'early_stopping_patience': 17, 'plateau_patience': 18, 'plateau_divider': 8}. Best is trial 94 with value: 0.6130243860768243.
[I 2025-03-02 00:01:09,978] Trial 233 finished with value: 0.6105059742326139 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9682895925711279, 'batch_size': 45, 'attention_heads': 10, 'hidden_dimension': 248, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4058520658382178, 'global_pooling': 'max', 'learning_rate': 0.0006779410103458723, 'weight_decay': 0.0006889777067787898, 'beta_0': 0.8387066246165158, 'beta_1': 0.9907958347972498, 'epsilon': 3.7797195034228928e-06, 'balanced_loss': False, 'epochs': 177, 'early_stopping_patience': 18, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 94 with value: 0.6130243860768243.
[I 2025-03-02 00:22:04,067] Trial 234 finished with value: 0.5791100456066648 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9645635936257756, 'batch_size': 48, 'attention_heads': 10, 'hidden_dimension': 247, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4057917215400913, 'global_pooling': 'max', 'learning_rate': 0.0008601761817612449, 'weight_decay': 0.0006421568355693386, 'beta_0': 0.8397472208090717, 'beta_1': 0.9904338379071131, 'epsilon': 7.79455353844485e-06, 'balanced_loss': False, 'epochs': 180, 'early_stopping_patience': 18, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 94 with value: 0.6130243860768243.
[I 2025-03-02 00:40:50,874] Trial 235 finished with value: 0.5535936094139267 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9833309194105025, 'batch_size': 45, 'attention_heads': 10, 'hidden_dimension': 249, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41873260850691973, 'global_pooling': 'mean', 'learning_rate': 0.0006686576871675632, 'weight_decay': 0.0007389654961967369, 'beta_0': 0.8387795156305593, 'beta_1': 0.990646770331361, 'epsilon': 4.58500876165519e-06, 'balanced_loss': False, 'epochs': 177, 'early_stopping_patience': 18, 'plateau_patience': 14, 'plateau_divider': 8}. Best is trial 94 with value: 0.6130243860768243.
[I 2025-03-02 01:12:06,615] Trial 236 finished with value: 0.5693718870693236 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9761882238654062, 'batch_size': 48, 'attention_heads': 10, 'hidden_dimension': 252, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4059357282006311, 'global_pooling': 'max', 'learning_rate': 4.5635710191635446e-05, 'weight_decay': 0.0005453053781866779, 'beta_0': 0.8461680584917609, 'beta_1': 0.9909907157883301, 'epsilon': 8.704807985893047e-07, 'balanced_loss': False, 'epochs': 182, 'early_stopping_patience': 18, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 94 with value: 0.6130243860768243.
[I 2025-03-02 01:32:37,483] Trial 237 finished with value: 0.6150648266023424 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9680976470829497, 'batch_size': 54, 'attention_heads': 10, 'hidden_dimension': 239, 'number_of_hidden_layers': 1, 'dropout_rate': 0.42423148293705304, 'global_pooling': 'max', 'learning_rate': 0.0013432862515951262, 'weight_decay': 0.00044171582575529706, 'beta_0': 0.8366155434565775, 'beta_1': 0.9898456485242396, 'epsilon': 3.4001927824300805e-06, 'balanced_loss': False, 'epochs': 185, 'early_stopping_patience': 18, 'plateau_patience': 12, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 01:52:48,056] Trial 238 finished with value: 0.5718792317910638 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9675040903270562, 'batch_size': 54, 'attention_heads': 10, 'hidden_dimension': 240, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4277978175289273, 'global_pooling': 'max', 'learning_rate': 0.0015949404048291938, 'weight_decay': 0.0004383131570863078, 'beta_0': 0.837908434567665, 'beta_1': 0.9899234192141051, 'epsilon': 3.8473525132376595e-06, 'balanced_loss': False, 'epochs': 185, 'early_stopping_patience': 18, 'plateau_patience': 12, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 02:11:59,956] Trial 239 finished with value: 0.5989135635526394 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9725240174707378, 'batch_size': 51, 'attention_heads': 10, 'hidden_dimension': 246, 'number_of_hidden_layers': 1, 'dropout_rate': 0.42065406596128657, 'global_pooling': 'max', 'learning_rate': 0.0013681404238735846, 'weight_decay': 0.0003986584815134557, 'beta_0': 0.8405485938014614, 'beta_1': 0.9895494059611065, 'epsilon': 3.676954705259333e-06, 'balanced_loss': False, 'epochs': 187, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 02:31:09,263] Trial 240 finished with value: 0.5717810943113611 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9720288564167943, 'batch_size': 52, 'attention_heads': 10, 'hidden_dimension': 249, 'number_of_hidden_layers': 1, 'dropout_rate': 0.419390163874625, 'global_pooling': 'max', 'learning_rate': 0.0014361698666567567, 'weight_decay': 0.00036633433613410835, 'beta_0': 0.8419174343048725, 'beta_1': 0.9895659404162203, 'epsilon': 3.6659203746284586e-06, 'balanced_loss': False, 'epochs': 123, 'early_stopping_patience': 16, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacity of 44.56 GiB of which 216.69 MiB is free. Including non-PyTorch memory, this process has 44.34 GiB memory in use. Of the allocated memory 40.95 GiB is allocated by PyTorch, and 2.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 02:46:14,670] Trial 241 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9609534309076145, 'batch_size': 43, 'attention_heads': 10, 'hidden_dimension': 234, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4252167707271089, 'global_pooling': 'max', 'learning_rate': 0.0011468973119893016, 'weight_decay': 0.00045225505604678753, 'beta_0': 0.8397789094153528, 'beta_1': 0.9903541050846263, 'epsilon': 3.880746458603989e-06, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 03:07:03,614] Trial 242 finished with value: 0.5811625700487242 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9682343497910422, 'batch_size': 50, 'attention_heads': 11, 'hidden_dimension': 238, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4101953974808905, 'global_pooling': 'max', 'learning_rate': 0.0019032228128640567, 'weight_decay': 0.0003919672338654356, 'beta_0': 0.8375028148402421, 'beta_1': 0.9907917394474244, 'epsilon': 2.989850996602023e-06, 'balanced_loss': False, 'epochs': 182, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 03:28:16,489] Trial 243 finished with value: 0.5789811436319523 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9729921731403524, 'batch_size': 55, 'attention_heads': 10, 'hidden_dimension': 245, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4309677726057678, 'global_pooling': 'max', 'learning_rate': 0.0013415517265959194, 'weight_decay': 0.000653446347764628, 'beta_0': 0.8421383535701057, 'beta_1': 0.990051428315231, 'epsilon': 5.058983378313405e-06, 'balanced_loss': False, 'epochs': 177, 'early_stopping_patience': 18, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
CUDA out of memory. Tried to allocate 2.09 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 43.20 GiB memory in use. Of the allocated memory 40.06 GiB is allocated by PyTorch, and 2.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 03:40:45,172] Trial 244 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9624672070927764, 'batch_size': 60, 'attention_heads': 10, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41507009875411505, 'global_pooling': 'max', 'learning_rate': 0.001014619383116774, 'weight_decay': 0.0007863670443677875, 'beta_0': 0.8389960053170381, 'beta_1': 0.9896311352587971, 'epsilon': 5.960441385288853e-06, 'balanced_loss': False, 'epochs': 186, 'early_stopping_patience': 18, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 237 with value: 0.6150648266023424.
CUDA out of memory. Tried to allocate 2.76 GiB. GPU 0 has a total capacity of 44.56 GiB of which 610.69 MiB is free. Including non-PyTorch memory, this process has 43.96 GiB memory in use. Of the allocated memory 42.20 GiB is allocated by PyTorch, and 621.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 03:58:00,705] Trial 245 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9208487448631859, 'batch_size': 50, 'attention_heads': 10, 'hidden_dimension': 235, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4662451503568609, 'global_pooling': 'max', 'learning_rate': 0.0008466839104488774, 'weight_decay': 0.0005046181302400922, 'beta_0': 0.8439184786209382, 'beta_1': 0.9892938421091612, 'epsilon': 3.942105777439002e-06, 'balanced_loss': False, 'epochs': 180, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 04:18:09,066] Trial 246 finished with value: 0.5736466135293291 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9668708319456555, 'batch_size': 48, 'attention_heads': 10, 'hidden_dimension': 249, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41249898410309105, 'global_pooling': 'max', 'learning_rate': 0.0011967723057375811, 'weight_decay': 0.0004278806716309334, 'beta_0': 0.8345226950568677, 'beta_1': 0.9901274163122927, 'epsilon': 2.6633839361094565e-06, 'balanced_loss': False, 'epochs': 175, 'early_stopping_patience': 18, 'plateau_patience': 14, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 04:36:44,470] Trial 247 finished with value: 0.6121470003434807 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9759338984908209, 'batch_size': 53, 'attention_heads': 10, 'hidden_dimension': 241, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4222237782309793, 'global_pooling': 'max', 'learning_rate': 0.0009780064878514728, 'weight_decay': 0.00034011805422177116, 'beta_0': 0.8363537034846967, 'beta_1': 0.9906073044798078, 'epsilon': 3.331321987322335e-06, 'balanced_loss': False, 'epochs': 183, 'early_stopping_patience': 18, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 04:55:50,646] Trial 248 finished with value: 0.580746746323032 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9759527016012141, 'batch_size': 53, 'attention_heads': 10, 'hidden_dimension': 242, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4202547177782304, 'global_pooling': 'max', 'learning_rate': 0.001004660699416642, 'weight_decay': 0.0003189185770215319, 'beta_0': 0.836689006699212, 'beta_1': 0.9906385946325464, 'epsilon': 3.0593471183522227e-06, 'balanced_loss': False, 'epochs': 184, 'early_stopping_patience': 18, 'plateau_patience': 17, 'plateau_divider': 7}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 05:15:11,273] Trial 249 finished with value: 0.5859900819416624 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9704919852831208, 'batch_size': 56, 'attention_heads': 10, 'hidden_dimension': 239, 'number_of_hidden_layers': 1, 'dropout_rate': 0.43855081379050664, 'global_pooling': 'max', 'learning_rate': 0.0007499200393025892, 'weight_decay': 0.0003565732707107093, 'beta_0': 0.8410218351690364, 'beta_1': 0.9914070028697075, 'epsilon': 3.4957068553642507e-06, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 18, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 05:34:20,890] Trial 250 finished with value: 0.5806819019638986 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.974854325788796, 'batch_size': 51, 'attention_heads': 10, 'hidden_dimension': 244, 'number_of_hidden_layers': 1, 'dropout_rate': 0.42578051304050546, 'global_pooling': 'max', 'learning_rate': 0.0015527437783935988, 'weight_decay': 0.0006151713260656864, 'beta_0': 0.8368825869887536, 'beta_1': 0.9909773969419283, 'epsilon': 4.633421828048917e-06, 'balanced_loss': False, 'epochs': 180, 'early_stopping_patience': 17, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 05:56:46,480] Trial 251 finished with value: 0.5823043715561632 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9708693999969009, 'batch_size': 58, 'attention_heads': 11, 'hidden_dimension': 252, 'number_of_hidden_layers': 1, 'dropout_rate': 0.47815496339640245, 'global_pooling': 'max', 'learning_rate': 0.0008875159420113547, 'weight_decay': 0.0005438869830401037, 'beta_0': 0.8482541359610494, 'beta_1': 0.9903853560501282, 'epsilon': 7.475507635045961e-06, 'balanced_loss': False, 'epochs': 174, 'early_stopping_patience': 18, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 06:15:51,948] Trial 252 finished with value: 0.5865790818271982 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9794357906511806, 'batch_size': 53, 'attention_heads': 10, 'hidden_dimension': 235, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4217726038233515, 'global_pooling': 'max', 'learning_rate': 0.0006844704838337751, 'weight_decay': 0.0004163033944296393, 'beta_0': 0.839620976909712, 'beta_1': 0.9898279094807351, 'epsilon': 2.519625019690294e-06, 'balanced_loss': False, 'epochs': 183, 'early_stopping_patience': 16, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 237 with value: 0.6150648266023424.
CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 96.69 MiB is free. Including non-PyTorch memory, this process has 44.46 GiB memory in use. Of the allocated memory 42.53 GiB is allocated by PyTorch, and 793.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 06:26:17,031] Trial 253 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8899217391976199, 'batch_size': 48, 'attention_heads': 9, 'hidden_dimension': 246, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4100814994189712, 'global_pooling': 'max', 'learning_rate': 0.0011071204945221754, 'weight_decay': 0.00047806646158311263, 'beta_0': 0.8328060611249326, 'beta_1': 0.9989845354601506, 'epsilon': 6.855635293810926e-07, 'balanced_loss': False, 'epochs': 178, 'early_stopping_patience': 17, 'plateau_patience': 12, 'plateau_divider': 7}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 06:45:53,410] Trial 254 finished with value: 0.5824627968267574 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9686977778571146, 'batch_size': 46, 'attention_heads': 10, 'hidden_dimension': 240, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41569360569347613, 'global_pooling': 'max', 'learning_rate': 0.001280095863523227, 'weight_decay': 0.0003201050382226727, 'beta_0': 0.8352264803194539, 'beta_1': 0.9894164472031267, 'epsilon': 3.7642693027672453e-06, 'balanced_loss': False, 'epochs': 186, 'early_stopping_patience': 18, 'plateau_patience': 12, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 07:06:37,504] Trial 255 finished with value: 0.5894295609690241 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9752864326623925, 'batch_size': 52, 'attention_heads': 13, 'hidden_dimension': 229, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40173297080479664, 'global_pooling': 'max', 'learning_rate': 0.0007920251321067475, 'weight_decay': 0.0005361413732362384, 'beta_0': 0.8378249946489288, 'beta_1': 0.9851476703965496, 'epsilon': 3.1354609001697542e-06, 'balanced_loss': False, 'epochs': 183, 'early_stopping_patience': 18, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 07:27:03,529] Trial 256 finished with value: 0.6069793473197684 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9637935815076818, 'batch_size': 43, 'attention_heads': 9, 'hidden_dimension': 252, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4075840948063954, 'global_pooling': 'max', 'learning_rate': 0.000978325669540005, 'weight_decay': 0.0003796501509205915, 'beta_0': 0.8267199727162949, 'beta_1': 0.9902263310408389, 'epsilon': 7.649413737560407e-07, 'balanced_loss': False, 'epochs': 173, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 07:47:48,883] Trial 257 finished with value: 0.5622007563679964 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9641433209337752, 'batch_size': 42, 'attention_heads': 10, 'hidden_dimension': 233, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40596392674273457, 'global_pooling': 'sum', 'learning_rate': 0.001027391141153791, 'weight_decay': 0.0006994607985397711, 'beta_0': 0.8257516050032864, 'beta_1': 0.9830181316508826, 'epsilon': 5.102812281202055e-07, 'balanced_loss': False, 'epochs': 189, 'early_stopping_patience': 17, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 08:03:37,243] Trial 258 finished with value: 0.5711508757544932 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9564318849015144, 'batch_size': 43, 'attention_heads': 9, 'hidden_dimension': 111, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40151521716746674, 'global_pooling': 'max', 'learning_rate': 0.0016868053950000325, 'weight_decay': 0.0002590712229711551, 'beta_0': 0.8890323145268471, 'beta_1': 0.9897344125537936, 'epsilon': 7.691930774487206e-07, 'balanced_loss': False, 'epochs': 176, 'early_stopping_patience': 16, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 08:25:10,423] Trial 259 finished with value: 0.5560009717337602 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9793650629256347, 'batch_size': 44, 'attention_heads': 11, 'hidden_dimension': 253, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5525508049455583, 'global_pooling': 'max', 'learning_rate': 0.0009518343994092687, 'weight_decay': 0.0003708666511890777, 'beta_0': 0.8271026902035261, 'beta_1': 0.9889645428954777, 'epsilon': 6.570843814982443e-07, 'balanced_loss': False, 'epochs': 179, 'early_stopping_patience': 17, 'plateau_patience': 12, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.88 GiB is free. Including non-PyTorch memory, this process has 42.67 GiB memory in use. Of the allocated memory 39.25 GiB is allocated by PyTorch, and 2.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 08:37:44,823] Trial 260 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9735394483743118, 'batch_size': 108, 'attention_heads': 9, 'hidden_dimension': 245, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4106852601881998, 'global_pooling': 'max', 'learning_rate': 0.0006290645304326128, 'weight_decay': 0.0008842893359595705, 'beta_0': 0.821991702891164, 'beta_1': 0.990016608574355, 'epsilon': 1.0419677786654615e-08, 'balanced_loss': False, 'epochs': 182, 'early_stopping_patience': 17, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 08:54:58,550] Trial 261 finished with value: 0.5845265823256678 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.96309126896089, 'batch_size': 47, 'attention_heads': 6, 'hidden_dimension': 237, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40507677245012325, 'global_pooling': 'max', 'learning_rate': 0.001341636913875142, 'weight_decay': 0.0002877947697920845, 'beta_0': 0.8312209926568386, 'beta_1': 0.9920142238619902, 'epsilon': 8.813250705717907e-07, 'balanced_loss': False, 'epochs': 186, 'early_stopping_patience': 19, 'plateau_patience': 17, 'plateau_divider': 9}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 09:14:04,266] Trial 262 finished with value: 0.5757158032625234 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9716599175574685, 'batch_size': 46, 'attention_heads': 10, 'hidden_dimension': 241, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4583058960770281, 'global_pooling': 'max', 'learning_rate': 0.0006419148958650176, 'weight_decay': 0.00035973663142022246, 'beta_0': 0.8286149287048654, 'beta_1': 0.9908293214494922, 'epsilon': 1.079164248089979e-06, 'balanced_loss': True, 'epochs': 174, 'early_stopping_patience': 12, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 09:34:54,061] Trial 263 finished with value: 0.6026138979981821 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.965943786970491, 'batch_size': 50, 'attention_heads': 10, 'hidden_dimension': 248, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4138635963777706, 'global_pooling': 'max', 'learning_rate': 0.0010826428104522077, 'weight_decay': 0.000235558258971351, 'beta_0': 0.8298698212601999, 'beta_1': 0.989249318482436, 'epsilon': 5.720283013789016e-07, 'balanced_loss': False, 'epochs': 178, 'early_stopping_patience': 19, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 09:56:53,572] Trial 264 finished with value: 0.5880784784412397 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9660084097529267, 'batch_size': 41, 'attention_heads': 10, 'hidden_dimension': 249, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41355570628027843, 'global_pooling': 'max', 'learning_rate': 0.0011575466951616066, 'weight_decay': 0.00023653167704289034, 'beta_0': 0.8299190820901031, 'beta_1': 0.9895649648737714, 'epsilon': 6.014436675785248e-07, 'balanced_loss': False, 'epochs': 178, 'early_stopping_patience': 19, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 44.56 GiB of which 282.69 MiB is free. Including non-PyTorch memory, this process has 44.28 GiB memory in use. Of the allocated memory 40.57 GiB is allocated by PyTorch, and 2.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 10:09:27,192] Trial 265 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9720860532788551, 'batch_size': 127, 'attention_heads': 10, 'hidden_dimension': 247, 'number_of_hidden_layers': 1, 'dropout_rate': 0.43227185045168676, 'global_pooling': 'max', 'learning_rate': 0.0014085165867580673, 'weight_decay': 0.00023011827692163885, 'beta_0': 0.8243289350749093, 'beta_1': 0.9891271460332085, 'epsilon': 7.910688765641567e-07, 'balanced_loss': False, 'epochs': 181, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 10:29:27,983] Trial 266 finished with value: 0.5700790387333751 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9770278461812695, 'batch_size': 50, 'attention_heads': 10, 'hidden_dimension': 255, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40980733418100074, 'global_pooling': 'max', 'learning_rate': 0.0018926493833228888, 'weight_decay': 0.00029931588156077585, 'beta_0': 0.8331932427880224, 'beta_1': 0.9891906156845119, 'epsilon': 4.1209290326117565e-07, 'balanced_loss': False, 'epochs': 189, 'early_stopping_patience': 19, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 10:48:09,049] Trial 267 finished with value: 0.5741652288199833 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9799397718708226, 'batch_size': 124, 'attention_heads': 10, 'hidden_dimension': 243, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4234493051320801, 'global_pooling': 'max', 'learning_rate': 0.0010018781506918712, 'weight_decay': 0.0004755229803828677, 'beta_0': 0.8264771808489914, 'beta_1': 0.9902765537352337, 'epsilon': 4.58103763890955e-07, 'balanced_loss': False, 'epochs': 185, 'early_stopping_patience': 17, 'plateau_patience': 12, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.32 GiB is free. Including non-PyTorch memory, this process has 43.23 GiB memory in use. Of the allocated memory 40.39 GiB is allocated by PyTorch, and 1.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 11:00:41,687] Trial 268 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9599772976154061, 'batch_size': 55, 'attention_heads': 11, 'hidden_dimension': 252, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40140367858420156, 'global_pooling': 'mean', 'learning_rate': 0.0008559062193475423, 'weight_decay': 0.0006146572800319084, 'beta_0': 0.8299213191116802, 'beta_1': 0.9898106953164428, 'epsilon': 5.106500627731055e-07, 'balanced_loss': False, 'epochs': 176, 'early_stopping_patience': 18, 'plateau_patience': 14, 'plateau_divider': 8}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 11:19:05,553] Trial 269 finished with value: 0.5843643952511267 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9664962762332133, 'batch_size': 49, 'attention_heads': 9, 'hidden_dimension': 247, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41602900434408413, 'global_pooling': 'max', 'learning_rate': 0.0011490589909300337, 'weight_decay': 0.0002070291417538028, 'beta_0': 0.8274070813687846, 'beta_1': 0.9905854036305806, 'epsilon': 6.010657664346622e-07, 'balanced_loss': False, 'epochs': 182, 'early_stopping_patience': 14, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 237 with value: 0.6150648266023424.
[I 2025-03-02 11:38:30,925] Trial 270 finished with value: 0.6215289180750414 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9760286907577013, 'batch_size': 57, 'attention_heads': 10, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40857706969983526, 'global_pooling': 'max', 'learning_rate': 0.0007007218307147797, 'weight_decay': 0.00025883600518567, 'beta_0': 0.8322027076219357, 'beta_1': 0.9895042601976805, 'epsilon': 8.601964870025037e-07, 'balanced_loss': False, 'epochs': 170, 'early_stopping_patience': 19, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 270 with value: 0.6215289180750414.
[I 2025-03-02 11:58:32,564] Trial 271 finished with value: 0.6000859082931697 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9739815283514964, 'batch_size': 58, 'attention_heads': 10, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4068467066084461, 'global_pooling': 'max', 'learning_rate': 0.0005810972560272737, 'weight_decay': 0.0002451133861328893, 'beta_0': 0.8330228851594695, 'beta_1': 0.9895019684075193, 'epsilon': 1.2591275656117298e-06, 'balanced_loss': False, 'epochs': 170, 'early_stopping_patience': 19, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 270 with value: 0.6215289180750414.
[I 2025-03-02 12:23:44,169] Trial 272 finished with value: 0.5984374790737338 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9712688927875133, 'batch_size': 58, 'attention_heads': 10, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3983184571203844, 'global_pooling': 'max', 'learning_rate': 0.0005622918328351948, 'weight_decay': 0.00025982870539181894, 'beta_0': 0.8329735198653653, 'beta_1': 0.9893952764909955, 'epsilon': 8.667842437174565e-07, 'balanced_loss': False, 'epochs': 169, 'early_stopping_patience': 19, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 270 with value: 0.6215289180750414.
[I 2025-03-02 12:47:50,318] Trial 273 finished with value: 0.560020607134103 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9767158656471482, 'batch_size': 60, 'attention_heads': 10, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3961260425819667, 'global_pooling': 'max', 'learning_rate': 0.0005193160309973921, 'weight_decay': 0.00028637178443361024, 'beta_0': 0.8333602295151735, 'beta_1': 0.9888323177996001, 'epsilon': 1.1165196293915655e-06, 'balanced_loss': False, 'epochs': 168, 'early_stopping_patience': 19, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 270 with value: 0.6215289180750414.
[I 2025-03-02 13:12:02,214] Trial 274 finished with value: 0.5648370231526533 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9738795227575334, 'batch_size': 53, 'attention_heads': 10, 'hidden_dimension': 255, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40601811184473613, 'global_pooling': 'max', 'learning_rate': 0.0006230437440393072, 'weight_decay': 0.00025677481444814074, 'beta_0': 0.835422079627852, 'beta_1': 0.9893528911548222, 'epsilon': 2.4627397539457676e-06, 'balanced_loss': False, 'epochs': 170, 'early_stopping_patience': 19, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 270 with value: 0.6215289180750414.
[I 2025-03-02 13:37:38,012] Trial 275 finished with value: 0.5855945227003118 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9695117121621475, 'batch_size': 58, 'attention_heads': 10, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.39767367207095855, 'global_pooling': 'max', 'learning_rate': 0.0005953915901621012, 'weight_decay': 0.00022719070938980989, 'beta_0': 0.8317308262996722, 'beta_1': 0.9892981283629553, 'epsilon': 5.596307792773463e-06, 'balanced_loss': False, 'epochs': 164, 'early_stopping_patience': 19, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 270 with value: 0.6215289180750414.
CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacity of 44.56 GiB of which 646.69 MiB is free. Including non-PyTorch memory, this process has 43.92 GiB memory in use. Of the allocated memory 42.57 GiB is allocated by PyTorch, and 210.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 13:54:40,677] Trial 276 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9539098878291111, 'batch_size': 56, 'attention_heads': 10, 'hidden_dimension': 251, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4018161840001507, 'global_pooling': 'max', 'learning_rate': 0.00044419332316817837, 'weight_decay': 0.000253865546855817, 'beta_0': 0.8337801661081032, 'beta_1': 0.9890556307976551, 'epsilon': 1.3181309795108364e-06, 'balanced_loss': False, 'epochs': 170, 'early_stopping_patience': 19, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 270 with value: 0.6215289180750414.
CUDA out of memory. Tried to allocate 2.05 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.78 GiB is free. Including non-PyTorch memory, this process has 42.77 GiB memory in use. Of the allocated memory 39.87 GiB is allocated by PyTorch, and 1.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 14:07:08,660] Trial 277 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9615597798318407, 'batch_size': 57, 'attention_heads': 10, 'hidden_dimension': 252, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4073142647100647, 'global_pooling': 'max', 'learning_rate': 0.0007012744742513349, 'weight_decay': 0.0003281538560731985, 'beta_0': 0.8310168497537229, 'beta_1': 0.988692926949649, 'epsilon': 8.754540259710369e-07, 'balanced_loss': False, 'epochs': 172, 'early_stopping_patience': 19, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 270 with value: 0.6215289180750414.
CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.96 GiB is free. Including non-PyTorch memory, this process has 42.59 GiB memory in use. Of the allocated memory 39.09 GiB is allocated by PyTorch, and 2.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 14:24:17,141] Trial 278 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9645478899971109, 'batch_size': 55, 'attention_heads': 10, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40124779895351537, 'global_pooling': 'max', 'learning_rate': 0.0005430248794198073, 'weight_decay': 0.00028207443933935737, 'beta_0': 0.8329360186273913, 'beta_1': 0.9895789130687662, 'epsilon': 2.761971586717717e-06, 'balanced_loss': False, 'epochs': 167, 'early_stopping_patience': 18, 'plateau_patience': 13, 'plateau_divider': 9}. Best is trial 270 with value: 0.6215289180750414.
slurmstepd: error: *** JOB 15068787 ON gpu028 CANCELLED AT 2025-03-02T14:26:56 DUE TO TIME LIMIT ***
