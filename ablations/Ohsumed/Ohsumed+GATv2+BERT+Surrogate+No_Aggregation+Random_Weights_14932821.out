[I 2025-02-20 14:09:36,930] Using an existing study with name 'Ohsumed-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-Random_Weights-0.0-0.0' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors
[I 2025-02-20 14:29:25,749] Trial 165 finished with value: 0.5675190704402191 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9798250161691116, 'batch_size': 78, 'attention_heads': 6, 'hidden_dimension': 232, 'number_of_hidden_layers': 2, 'dropout_rate': 0.599360138560289, 'global_pooling': 'mean', 'learning_rate': 0.001055448947275538, 'weight_decay': 6.999237816299276e-05, 'beta_0': 0.8030167512247272, 'beta_1': 0.9974958955176096, 'epsilon': 7.689607615185045e-07, 'balanced_loss': False, 'epochs': 128, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 9}. Best is trial 124 with value: 0.6267730254964805.
CUDA out of memory. Tried to allocate 142.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 30.69 MiB is free. Including non-PyTorch memory, this process has 44.52 GiB memory in use. Of the allocated memory 42.68 GiB is allocated by PyTorch, and 706.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 14:36:02,920] Trial 166 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8067168411280451, 'batch_size': 88, 'attention_heads': 8, 'hidden_dimension': 244, 'number_of_hidden_layers': 2, 'dropout_rate': 0.44239714347345066, 'global_pooling': 'max', 'learning_rate': 0.00028882219548195977, 'weight_decay': 5.304748503302373e-06, 'beta_0': 0.8051497829167699, 'beta_1': 0.9985055519034596, 'epsilon': 2.1102650450592767e-06, 'balanced_loss': False, 'epochs': 115, 'early_stopping_patience': 19, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 14:56:10,170] Trial 167 finished with value: 0.6021135388816701 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9858245148611515, 'batch_size': 76, 'attention_heads': 7, 'hidden_dimension': 252, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4477900625987228, 'global_pooling': 'max', 'learning_rate': 0.0007479212706282564, 'weight_decay': 8.109440825390488e-05, 'beta_0': 0.8150594155725279, 'beta_1': 0.9956544968802866, 'epsilon': 2.658001552995396e-06, 'balanced_loss': False, 'epochs': 105, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 15:18:01,636] Trial 168 finished with value: 0.6007076095561777 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9735688143261118, 'batch_size': 77, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 2, 'dropout_rate': 0.44485821281049837, 'global_pooling': 'max', 'learning_rate': 0.0009237448068745275, 'weight_decay': 7.80667251862258e-05, 'beta_0': 0.8154610024778938, 'beta_1': 0.9969605949173964, 'epsilon': 3.525450703252611e-06, 'balanced_loss': False, 'epochs': 107, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 15:39:47,948] Trial 169 finished with value: 0.6091521559202482 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9722198933599802, 'batch_size': 77, 'attention_heads': 7, 'hidden_dimension': 253, 'number_of_hidden_layers': 2, 'dropout_rate': 0.44892143301518955, 'global_pooling': 'max', 'learning_rate': 0.000900143367100436, 'weight_decay': 9.8648163028178e-05, 'beta_0': 0.8162804377588999, 'beta_1': 0.9971010705347388, 'epsilon': 2.432996087443842e-06, 'balanced_loss': False, 'epochs': 107, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 16:01:50,047] Trial 170 finished with value: 0.5961805396256276 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9713601624747871, 'batch_size': 76, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4492578238777209, 'global_pooling': 'max', 'learning_rate': 0.0006247855161608262, 'weight_decay': 9.653181992773393e-05, 'beta_0': 0.8217093416933392, 'beta_1': 0.9970032154698121, 'epsilon': 1.3780802659862338e-06, 'balanced_loss': False, 'epochs': 105, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 16:23:54,635] Trial 171 finished with value: 0.6075448943311565 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9716267757057404, 'batch_size': 76, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 2, 'dropout_rate': 0.452318207360413, 'global_pooling': 'max', 'learning_rate': 0.0006401596935889803, 'weight_decay': 9.871199981937864e-05, 'beta_0': 0.8208762907996996, 'beta_1': 0.9970551991101723, 'epsilon': 1.4459200194892078e-06, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
CUDA out of memory. Tried to allocate 1.73 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.73 GiB is free. Including non-PyTorch memory, this process has 42.83 GiB memory in use. Of the allocated memory 39.85 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 16:37:35,978] Trial 172 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9699435681425626, 'batch_size': 76, 'attention_heads': 7, 'hidden_dimension': 254, 'number_of_hidden_layers': 2, 'dropout_rate': 0.44948775139738034, 'global_pooling': 'max', 'learning_rate': 0.0006860881969066388, 'weight_decay': 9.77063958433665e-05, 'beta_0': 0.822585529817371, 'beta_1': 0.9967000372434576, 'epsilon': 1.3866266716190621e-06, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 16:59:55,369] Trial 173 finished with value: 0.5983417259689288 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9719426825149213, 'batch_size': 77, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 2, 'dropout_rate': 0.46317317921636403, 'global_pooling': 'max', 'learning_rate': 0.000850436559974343, 'weight_decay': 0.00011882447821703089, 'beta_0': 0.8193044718693522, 'beta_1': 0.9972709245626207, 'epsilon': 1.0120498971607908e-06, 'balanced_loss': False, 'epochs': 109, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 17:21:18,124] Trial 174 finished with value: 0.6092385096640307 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9753285807299813, 'batch_size': 71, 'attention_heads': 7, 'hidden_dimension': 252, 'number_of_hidden_layers': 2, 'dropout_rate': 0.45969017408341206, 'global_pooling': 'max', 'learning_rate': 0.0008515195742530823, 'weight_decay': 0.00011133631358578916, 'beta_0': 0.8183903625130838, 'beta_1': 0.9970264372651463, 'epsilon': 1.735757541122904e-06, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 17:41:42,052] Trial 175 finished with value: 0.5814247480292388 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9743647550671897, 'batch_size': 83, 'attention_heads': 6, 'hidden_dimension': 251, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4627052421438111, 'global_pooling': 'max', 'learning_rate': 0.000877601233455533, 'weight_decay': 0.0001141359646340846, 'beta_0': 0.8185850571514136, 'beta_1': 0.9970692196311571, 'epsilon': 9.965949784956378e-07, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 18:01:40,230] Trial 176 finished with value: 0.6081970901282269 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9672204945874763, 'batch_size': 74, 'attention_heads': 6, 'hidden_dimension': 242, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4753921123380541, 'global_pooling': 'max', 'learning_rate': 0.0011534319737493408, 'weight_decay': 0.00012585814273464738, 'beta_0': 0.8161108961026439, 'beta_1': 0.9958118368104545, 'epsilon': 6.256517778514748e-07, 'balanced_loss': True, 'epochs': 101, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 18:21:53,231] Trial 177 finished with value: 0.5989866621857183 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9664075784898092, 'batch_size': 74, 'attention_heads': 6, 'hidden_dimension': 243, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4754317094555478, 'global_pooling': 'max', 'learning_rate': 0.0011735393999616332, 'weight_decay': 0.00012522439370268417, 'beta_0': 0.8156149459730316, 'beta_1': 0.9958575361384528, 'epsilon': 6.1293043721256e-07, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 44.56 GiB of which 600.69 MiB is free. Including non-PyTorch memory, this process has 43.97 GiB memory in use. Of the allocated memory 41.65 GiB is allocated by PyTorch, and 1.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 18:35:14,909] Trial 178 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9672379943770657, 'batch_size': 74, 'attention_heads': 7, 'hidden_dimension': 241, 'number_of_hidden_layers': 2, 'dropout_rate': 0.48761261315583115, 'global_pooling': 'max', 'learning_rate': 0.0015241470387599352, 'weight_decay': 0.00013257641488347, 'beta_0': 0.8162743039331747, 'beta_1': 0.9959528300285393, 'epsilon': 5.424586181697925e-07, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 19:13:32,443] Trial 179 finished with value: 0.5472944893601037 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.974159159819633, 'batch_size': 79, 'attention_heads': 6, 'hidden_dimension': 251, 'number_of_hidden_layers': 2, 'dropout_rate': 0.47621343260042276, 'global_pooling': 'max', 'learning_rate': 2.9295290631360425e-05, 'weight_decay': 0.00015196008650194415, 'beta_0': 0.8204514621127847, 'beta_1': 0.9964716038707063, 'epsilon': 4.026866240746147e-07, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.69 GiB is free. Including non-PyTorch memory, this process has 42.86 GiB memory in use. Of the allocated memory 40.23 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 19:26:23,315] Trial 180 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9658746818136738, 'batch_size': 77, 'attention_heads': 7, 'hidden_dimension': 245, 'number_of_hidden_layers': 2, 'dropout_rate': 0.46986931452868425, 'global_pooling': 'max', 'learning_rate': 0.0008482059182724177, 'weight_decay': 0.00012763836805138122, 'beta_0': 0.815147361761772, 'beta_1': 0.9956969573843795, 'epsilon': 2.687948461022287e-07, 'balanced_loss': True, 'epochs': 101, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 19:46:17,158] Trial 181 finished with value: 0.6046957436154541 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.971183377452952, 'batch_size': 72, 'attention_heads': 6, 'hidden_dimension': 237, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4842487994714937, 'global_pooling': 'max', 'learning_rate': 0.0011268904571168018, 'weight_decay': 1.476624792687571e-06, 'beta_0': 0.8176651494478604, 'beta_1': 0.9961117242838821, 'epsilon': 6.279788028296351e-07, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 20:06:36,968] Trial 182 finished with value: 0.590126862349507 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9694815050918889, 'batch_size': 72, 'attention_heads': 6, 'hidden_dimension': 238, 'number_of_hidden_layers': 2, 'dropout_rate': 0.46343818092247535, 'global_pooling': 'max', 'learning_rate': 0.001091888235329164, 'weight_decay': 9.164297898636246e-05, 'beta_0': 0.8178983715031141, 'beta_1': 0.9965110899027423, 'epsilon': 8.93984002436997e-07, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 20:26:11,849] Trial 183 finished with value: 0.6038773654636745 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9716624043365283, 'batch_size': 75, 'attention_heads': 6, 'hidden_dimension': 256, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4845488398906174, 'global_pooling': 'max', 'learning_rate': 0.0007474446382978045, 'weight_decay': 3.1154964101659405e-06, 'beta_0': 0.8161912763810929, 'beta_1': 0.9959390978941878, 'epsilon': 6.353992988266465e-07, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 20:45:28,921] Trial 184 finished with value: 0.5995455359030482 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9777639504623055, 'batch_size': 74, 'attention_heads': 6, 'hidden_dimension': 246, 'number_of_hidden_layers': 2, 'dropout_rate': 0.48577634383084173, 'global_pooling': 'max', 'learning_rate': 0.000717201339163183, 'weight_decay': 1.2000589846647985e-06, 'beta_0': 0.8160938569705521, 'beta_1': 0.9961073067560522, 'epsilon': 5.782000172458026e-07, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 21:04:30,692] Trial 185 finished with value: 0.5796130508739424 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9786978815238345, 'batch_size': 71, 'attention_heads': 6, 'hidden_dimension': 251, 'number_of_hidden_layers': 2, 'dropout_rate': 0.48538567129417964, 'global_pooling': 'max', 'learning_rate': 0.0006761973521444303, 'weight_decay': 1.8318757922865447e-06, 'beta_0': 0.8172924162864535, 'beta_1': 0.9962148648251531, 'epsilon': 7.457641884519583e-07, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 4}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 21:23:52,787] Trial 186 finished with value: 0.6012854268923818 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9756502770458856, 'batch_size': 75, 'attention_heads': 6, 'hidden_dimension': 247, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5019101850613459, 'global_pooling': 'max', 'learning_rate': 0.0005219307354157647, 'weight_decay': 1.6182856327437864e-06, 'beta_0': 0.8144947669024266, 'beta_1': 0.9969224438262563, 'epsilon': 4.583737480548337e-07, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 21:43:11,480] Trial 187 finished with value: 0.6059704232627893 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9756395462355782, 'batch_size': 75, 'attention_heads': 6, 'hidden_dimension': 247, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4937037337958658, 'global_pooling': 'max', 'learning_rate': 0.0005252478686101117, 'weight_decay': 1.3675727462449857e-06, 'beta_0': 0.8154355197754384, 'beta_1': 0.9953218056922452, 'epsilon': 5.039697599068895e-07, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 22:01:43,753] Trial 188 finished with value: 0.6060797073398296 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9729749138154687, 'batch_size': 81, 'attention_heads': 5, 'hidden_dimension': 252, 'number_of_hidden_layers': 2, 'dropout_rate': 0.49499782999423303, 'global_pooling': 'max', 'learning_rate': 0.0004904670681098591, 'weight_decay': 1.2748884512501303e-06, 'beta_0': 0.8141779253657853, 'beta_1': 0.9968992468946625, 'epsilon': 3.680049860094537e-07, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 22:20:24,688] Trial 189 finished with value: 0.5887501050669551 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9760034859034786, 'batch_size': 81, 'attention_heads': 5, 'hidden_dimension': 237, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5088004939231672, 'global_pooling': 'max', 'learning_rate': 0.0004563291963512127, 'weight_decay': 1.5596146304852537e-06, 'beta_0': 0.8145608662438723, 'beta_1': 0.9955189417405079, 'epsilon': 4.1174133839737263e-07, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 22:39:37,573] Trial 190 finished with value: 0.6145321557109746 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9703968948974719, 'batch_size': 72, 'attention_heads': 5, 'hidden_dimension': 249, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4947296644038702, 'global_pooling': 'max', 'learning_rate': 0.0004970074399685064, 'weight_decay': 1.306543610223155e-06, 'beta_0': 0.8138256073547822, 'beta_1': 0.9953564328106439, 'epsilon': 2.4275748474147773e-07, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 20, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.30 GiB is free. Including non-PyTorch memory, this process has 43.25 GiB memory in use. Of the allocated memory 40.52 GiB is allocated by PyTorch, and 1.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-20 22:53:58,433] Trial 191 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9614182680756566, 'batch_size': 71, 'attention_heads': 5, 'hidden_dimension': 251, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4945275209239475, 'global_pooling': 'max', 'learning_rate': 0.000490097015718321, 'weight_decay': 2.519181533241473e-06, 'beta_0': 0.8185534774622483, 'beta_1': 0.9951916234231977, 'epsilon': 3.315841734701983e-07, 'balanced_loss': True, 'epochs': 122, 'early_stopping_patience': 20, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 23:13:04,935] Trial 192 finished with value: 0.5737692802469758 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9700074573567119, 'batch_size': 73, 'attention_heads': 5, 'hidden_dimension': 242, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4895889674936814, 'global_pooling': 'max', 'learning_rate': 0.0005967778461052383, 'weight_decay': 1.201096060417191e-06, 'beta_0': 0.8133524107562757, 'beta_1': 0.9953959755746058, 'epsilon': 2.465812430270148e-07, 'balanced_loss': True, 'epochs': 120, 'early_stopping_patience': 18, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 23:32:20,104] Trial 193 finished with value: 0.5967509041368533 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9630392657930581, 'batch_size': 71, 'attention_heads': 5, 'hidden_dimension': 252, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4365988096785715, 'global_pooling': 'mean', 'learning_rate': 0.00037975140136664343, 'weight_decay': 1.3979167514580272e-06, 'beta_0': 0.8170814601054274, 'beta_1': 0.9947561150469452, 'epsilon': 2.2024460012000917e-07, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 18, 'plateau_patience': 15, 'plateau_divider': 4}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-20 23:49:27,735] Trial 194 finished with value: 0.5821037651572395 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9817631465578655, 'batch_size': 79, 'attention_heads': 4, 'hidden_dimension': 248, 'number_of_hidden_layers': 2, 'dropout_rate': 0.48052602829012814, 'global_pooling': 'max', 'learning_rate': 0.000750739194388168, 'weight_decay': 1.05917228202127e-06, 'beta_0': 0.8118473523674933, 'beta_1': 0.9956309572646864, 'epsilon': 4.6294143814717723e-07, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 00:07:57,409] Trial 195 finished with value: 0.6012160157582855 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9713124137973049, 'batch_size': 84, 'attention_heads': 5, 'hidden_dimension': 235, 'number_of_hidden_layers': 2, 'dropout_rate': 0.47249414977235954, 'global_pooling': 'max', 'learning_rate': 0.0006253040606880561, 'weight_decay': 2.8318533401996695e-06, 'beta_0': 0.8207311378778505, 'beta_1': 0.997757510436132, 'epsilon': 2.959605919526989e-07, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 18, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 00:22:57,612] Trial 196 finished with value: 0.5745318936701624 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9801163360884877, 'batch_size': 67, 'attention_heads': 6, 'hidden_dimension': 38, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5030109528813362, 'global_pooling': 'max', 'learning_rate': 0.0009535281642572023, 'weight_decay': 1.3885827964051333e-06, 'beta_0': 0.813230204760105, 'beta_1': 0.9963268420098308, 'epsilon': 6.327668741991425e-07, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 00:42:56,723] Trial 197 finished with value: 0.5934957239137344 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9749152016995244, 'batch_size': 76, 'attention_heads': 6, 'hidden_dimension': 248, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5035281239635214, 'global_pooling': 'max', 'learning_rate': 0.0005115310200995672, 'weight_decay': 1.5036482722367682e-06, 'beta_0': 0.8149336540019567, 'beta_1': 0.9967167010502765, 'epsilon': 1.9635777744060425e-07, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 01:02:01,810] Trial 198 finished with value: 0.5980229929465734 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9777590013056011, 'batch_size': 75, 'attention_heads': 5, 'hidden_dimension': 244, 'number_of_hidden_layers': 2, 'dropout_rate': 0.49689887762483, 'global_pooling': 'max', 'learning_rate': 0.0005189262586148568, 'weight_decay': 1.8338156441072188e-06, 'beta_0': 0.8172240049659129, 'beta_1': 0.9950827806125678, 'epsilon': 5.064102237140907e-07, 'balanced_loss': True, 'epochs': 120, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 01:23:51,942] Trial 199 finished with value: 0.6188545172765579 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9673194470228772, 'batch_size': 73, 'attention_heads': 6, 'hidden_dimension': 256, 'number_of_hidden_layers': 2, 'dropout_rate': 0.481937041478152, 'global_pooling': 'max', 'learning_rate': 0.00042279645266927215, 'weight_decay': 2.1613523075096657e-06, 'beta_0': 0.8138756203651303, 'beta_1': 0.9958432754031057, 'epsilon': 1.332647706082705e-07, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
CUDA out of memory. Tried to allocate 1.55 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.32 GiB is free. Including non-PyTorch memory, this process has 43.24 GiB memory in use. Of the allocated memory 40.57 GiB is allocated by PyTorch, and 1.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 01:36:53,093] Trial 200 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9582156913283139, 'batch_size': 72, 'attention_heads': 6, 'hidden_dimension': 253, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4919999049327064, 'global_pooling': 'max', 'learning_rate': 0.00041114892190728105, 'weight_decay': 2.1928978330310237e-06, 'beta_0': 0.811599935085549, 'beta_1': 0.995880370319209, 'epsilon': 1.1781720059526856e-07, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 18, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.12 GiB is free. Including non-PyTorch memory, this process has 43.43 GiB memory in use. Of the allocated memory 40.51 GiB is allocated by PyTorch, and 1.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 01:51:47,792] Trial 201 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9667576357228659, 'batch_size': 73, 'attention_heads': 6, 'hidden_dimension': 253, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4795995045812529, 'global_pooling': 'max', 'learning_rate': 0.0007495867345695285, 'weight_decay': 1.153586170125209e-06, 'beta_0': 0.819237016946115, 'beta_1': 0.9946875334050093, 'epsilon': 3.5593630491011587e-07, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 4}. Best is trial 124 with value: 0.6267730254964805.
The selected strides are greater or equal to the total chunk size.
[I 2025-02-21 01:51:49,846] Trial 202 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9703301811338981, 'batch_size': 70, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4581635586361078, 'global_pooling': 'max', 'learning_rate': 0.0006104565131249792, 'weight_decay': 1.984087758670007e-06, 'beta_0': 0.8137456121414856, 'beta_1': 0.9953692163217918, 'epsilon': 1.6262777509685348e-07, 'balanced_loss': True, 'epochs': 106, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 02:10:34,354] Trial 203 finished with value: 0.5986375090866354 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9653808246973643, 'batch_size': 67, 'attention_heads': 4, 'hidden_dimension': 241, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4526578654208787, 'global_pooling': 'max', 'learning_rate': 0.0009709937430918129, 'weight_decay': 1.3471085884274717e-06, 'beta_0': 0.8102406648775194, 'beta_1': 0.9961854664912241, 'epsilon': 9.018746676993211e-08, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 02:30:00,776] Trial 204 finished with value: 0.599487918585015 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9818975345190321, 'batch_size': 80, 'attention_heads': 7, 'hidden_dimension': 249, 'number_of_hidden_layers': 2, 'dropout_rate': 0.46923448069390516, 'global_pooling': 'max', 'learning_rate': 0.0004393190626123419, 'weight_decay': 1.0514626199818916e-06, 'beta_0': 0.8170221683105454, 'beta_1': 0.9974504929626943, 'epsilon': 7.133644625509007e-07, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 18, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
CUDA out of memory. Tried to allocate 232.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 56.69 MiB is free. Including non-PyTorch memory, this process has 44.50 GiB memory in use. Of the allocated memory 42.62 GiB is allocated by PyTorch, and 749.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 02:38:27,366] Trial 205 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8524577705593, 'batch_size': 70, 'attention_heads': 5, 'hidden_dimension': 256, 'number_of_hidden_layers': 2, 'dropout_rate': 0.48066818688292495, 'global_pooling': 'max', 'learning_rate': 0.000752399520283224, 'weight_decay': 1.6431089455743706e-06, 'beta_0': 0.8235915445680044, 'beta_1': 0.9958042170172157, 'epsilon': 5.628031513288858e-08, 'balanced_loss': True, 'epochs': 100, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 02:58:42,525] Trial 206 finished with value: 0.6240683478696805 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9723681337262179, 'batch_size': 75, 'attention_heads': 7, 'hidden_dimension': 246, 'number_of_hidden_layers': 2, 'dropout_rate': 0.44458715728824644, 'global_pooling': 'max', 'learning_rate': 0.0013034492889476685, 'weight_decay': 1.2884439535043189e-06, 'beta_0': 0.8112813091765227, 'beta_1': 0.9937308193181377, 'epsilon': 1.8121835375855195e-06, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 03:19:11,519] Trial 207 finished with value: 0.5660143266372374 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9715185501612738, 'batch_size': 75, 'attention_heads': 7, 'hidden_dimension': 246, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4454467581539779, 'global_pooling': 'max', 'learning_rate': 0.0012108565037897692, 'weight_decay': 1.297486331836293e-06, 'beta_0': 0.8117227194083072, 'beta_1': 0.9948830346165018, 'epsilon': 1.718826874244013e-06, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 44.56 GiB of which 450.69 MiB is free. Including non-PyTorch memory, this process has 44.11 GiB memory in use. Of the allocated memory 41.89 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 03:34:14,931] Trial 208 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9683448292807205, 'batch_size': 73, 'attention_heads': 7, 'hidden_dimension': 250, 'number_of_hidden_layers': 2, 'dropout_rate': 0.43809301107531085, 'global_pooling': 'max', 'learning_rate': 0.001470006078760481, 'weight_decay': 2.158536634146776e-06, 'beta_0': 0.8139829214781066, 'beta_1': 0.9935260304924075, 'epsilon': 1.4775733547531517e-07, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 03:55:20,641] Trial 209 finished with value: 0.5870426090979869 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.974134540877035, 'batch_size': 78, 'attention_heads': 7, 'hidden_dimension': 239, 'number_of_hidden_layers': 2, 'dropout_rate': 0.45497766072809315, 'global_pooling': 'max', 'learning_rate': 0.0010042306523765125, 'weight_decay': 1.6738366157333945e-06, 'beta_0': 0.809470699288972, 'beta_1': 0.9965397972661085, 'epsilon': 1.846773289392884e-06, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 04:15:46,229] Trial 210 finished with value: 0.6228733381840309 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9790248271976002, 'batch_size': 72, 'attention_heads': 7, 'hidden_dimension': 252, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4436333917761505, 'global_pooling': 'max', 'learning_rate': 0.0007979558443319681, 'weight_decay': 1.2593500592990892e-06, 'beta_0': 0.8151813936811062, 'beta_1': 0.9939693465710033, 'epsilon': 1.1969393799763793e-06, 'balanced_loss': True, 'epochs': 104, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 04:34:51,457] Trial 211 finished with value: 0.5887245083539535 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9783835684003293, 'batch_size': 71, 'attention_heads': 6, 'hidden_dimension': 244, 'number_of_hidden_layers': 2, 'dropout_rate': 0.43425650624223167, 'global_pooling': 'max', 'learning_rate': 0.0006275442986322774, 'weight_decay': 1.1759357706792465e-06, 'beta_0': 0.8118598754363734, 'beta_1': 0.9939863246521341, 'epsilon': 8.251669870292484e-07, 'balanced_loss': True, 'epochs': 122, 'early_stopping_patience': 20, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
CUDA out of memory. Tried to allocate 2.41 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.10 GiB is free. Including non-PyTorch memory, this process has 42.45 GiB memory in use. Of the allocated memory 38.83 GiB is allocated by PyTorch, and 2.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 04:47:50,043] Trial 212 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9731241400728322, 'batch_size': 69, 'attention_heads': 16, 'hidden_dimension': 248, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4865059810697657, 'global_pooling': 'max', 'learning_rate': 0.0008655553085304299, 'weight_decay': 3.7499915150745744e-06, 'beta_0': 0.8164561166495863, 'beta_1': 0.993055772625068, 'epsilon': 1.1867423037987299e-06, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 18, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 05:03:15,025] Trial 213 finished with value: 0.5910179832892655 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9686203952272875, 'batch_size': 73, 'attention_heads': 7, 'hidden_dimension': 67, 'number_of_hidden_layers': 2, 'dropout_rate': 0.44169782901222465, 'global_pooling': 'max', 'learning_rate': 0.0011252724372634332, 'weight_decay': 1.3144080614365694e-06, 'beta_0': 0.8132940407964037, 'beta_1': 0.9937887890904784, 'epsilon': 1.5510694881169e-06, 'balanced_loss': True, 'epochs': 132, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 124 with value: 0.6267730254964805.
CUDA out of memory. Tried to allocate 1.66 GiB. GPU 0 has a total capacity of 44.56 GiB of which 376.69 MiB is free. Including non-PyTorch memory, this process has 44.19 GiB memory in use. Of the allocated memory 41.78 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 05:16:10,447] Trial 214 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9626350409747326, 'batch_size': 66, 'attention_heads': 7, 'hidden_dimension': 253, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4961025129623916, 'global_pooling': 'max', 'learning_rate': 0.0003730555731287915, 'weight_decay': 1.4997131619329005e-06, 'beta_0': 0.8080449775549601, 'beta_1': 0.9944055987997513, 'epsilon': 1.2025748777154097e-06, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 05:35:10,095] Trial 215 finished with value: 0.5804247761479373 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9803701102854351, 'batch_size': 72, 'attention_heads': 6, 'hidden_dimension': 256, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4498000977208296, 'global_pooling': 'max', 'learning_rate': 0.001434748300372669, 'weight_decay': 1.0442325359863485e-06, 'beta_0': 0.8189296556030783, 'beta_1': 0.9932872768090728, 'epsilon': 1.9672671519004834e-06, 'balanced_loss': True, 'epochs': 104, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
[I 2025-02-21 05:56:52,498] Trial 216 finished with value: 0.6089050498171161 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9767341599781539, 'batch_size': 68, 'attention_heads': 7, 'hidden_dimension': 243, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4592436835759411, 'global_pooling': 'max', 'learning_rate': 0.0005000817313333965, 'weight_decay': 1.9129903081544075e-06, 'beta_0': 0.8098847241129838, 'beta_1': 0.9946642518052885, 'epsilon': 1.9004169862699087e-08, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 124 with value: 0.6267730254964805.
slurmstepd: error: *** JOB 14932821 ON gpu040 CANCELLED AT 2025-02-21T06:09:19 DUE TO TIME LIMIT ***
