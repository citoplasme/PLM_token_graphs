[I 2025-02-26 20:02:37,822] Using an existing study with name 'Ohsumed-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-No_Ablation-1.0-0.25' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors
CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 84.69 MiB is free. Including non-PyTorch memory, this process has 44.47 GiB memory in use. Of the allocated memory 42.35 GiB is allocated by PyTorch, and 1003.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-26 20:14:20,846] Trial 44 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8466676110379248, 'batch_size': 80, 'attention_heads': 6, 'hidden_dimension': 120, 'number_of_hidden_layers': 1, 'dropout_rate': 0.30067000296169877, 'global_pooling': 'mean', 'learning_rate': 0.0019558557941218857, 'weight_decay': 0.000771941584765426, 'beta_0': 0.8206729336359705, 'beta_1': 0.9916690192540849, 'epsilon': 8.404075997206977e-07, 'balanced_loss': True, 'epochs': 50, 'early_stopping_patience': 22, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 41 with value: 0.557922295921326.
[I 2025-02-26 20:32:18,942] Trial 45 finished with value: 0.2891605729401083 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9991344148743269, 'batch_size': 108, 'attention_heads': 4, 'hidden_dimension': 140, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3403052773237466, 'global_pooling': 'mean', 'learning_rate': 0.004866959634903974, 'weight_decay': 0.00019469608967867367, 'beta_0': 0.8386869708558276, 'beta_1': 0.9929852133403209, 'epsilon': 1.5282726063969226e-06, 'balanced_loss': True, 'epochs': 61, 'early_stopping_patience': 24, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 41 with value: 0.557922295921326.
[I 2025-02-26 20:49:49,502] Trial 46 finished with value: 0.5566784293043974 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9752294075068226, 'batch_size': 126, 'attention_heads': 5, 'hidden_dimension': 229, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5034479594394721, 'global_pooling': 'max', 'learning_rate': 0.0026525334410036783, 'weight_decay': 0.00040013353864945403, 'beta_0': 0.8320993522643025, 'beta_1': 0.9898608040830842, 'epsilon': 3.1146976889593394e-06, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 4}. Best is trial 41 with value: 0.557922295921326.
CUDA out of memory. Tried to allocate 10.85 GiB. GPU 0 has a total capacity of 44.56 GiB of which 268.69 MiB is free. Including non-PyTorch memory, this process has 44.29 GiB memory in use. Of the allocated memory 42.81 GiB is allocated by PyTorch, and 343.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-26 21:03:13,870] Trial 47 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9152231184602143, 'batch_size': 128, 'attention_heads': 13, 'hidden_dimension': 231, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5295144933430532, 'global_pooling': 'max', 'learning_rate': 0.00044453212581172067, 'weight_decay': 0.00016621234121811437, 'beta_0': 0.8423810967202261, 'beta_1': 0.989662169813154, 'epsilon': 1.482219612759206e-06, 'balanced_loss': True, 'epochs': 141, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 41 with value: 0.557922295921326.
[I 2025-02-26 21:22:51,397] Trial 48 finished with value: 0.5557896754736045 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9728723324685701, 'batch_size': 118, 'attention_heads': 7, 'hidden_dimension': 203, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4679245956870072, 'global_pooling': 'max', 'learning_rate': 0.00026999977282961057, 'weight_decay': 0.0006612534189460309, 'beta_0': 0.8266246436990159, 'beta_1': 0.9902669454950498, 'epsilon': 3.053518109347288e-06, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 17, 'plateau_patience': 17, 'plateau_divider': 7}. Best is trial 41 with value: 0.557922295921326.
CUDA out of memory. Tried to allocate 2.62 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.56 GiB is free. Including non-PyTorch memory, this process has 41.99 GiB memory in use. Of the allocated memory 38.17 GiB is allocated by PyTorch, and 2.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-26 21:35:59,266] Trial 49 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9727745641964997, 'batch_size': 122, 'attention_heads': 10, 'hidden_dimension': 242, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5003122370656932, 'global_pooling': 'max', 'learning_rate': 0.00028912644384523044, 'weight_decay': 0.0006208608536988812, 'beta_0': 0.8250957655105561, 'beta_1': 0.98983974770984, 'epsilon': 6.02769489038304e-06, 'balanced_loss': False, 'epochs': 129, 'early_stopping_patience': 17, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 41 with value: 0.557922295921326.
CUDA out of memory. Tried to allocate 2.49 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.40 GiB is free. Including non-PyTorch memory, this process has 43.15 GiB memory in use. Of the allocated memory 39.39 GiB is allocated by PyTorch, and 2.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-26 21:49:05,841] Trial 50 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9537915880147833, 'batch_size': 117, 'attention_heads': 7, 'hidden_dimension': 202, 'number_of_hidden_layers': 2, 'dropout_rate': 0.46395219591109216, 'global_pooling': 'max', 'learning_rate': 0.00010534962009479461, 'weight_decay': 0.0008317312464979067, 'beta_0': 0.8409300501692601, 'beta_1': 0.9883340892493698, 'epsilon': 7.15626008476607e-06, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 13, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 41 with value: 0.557922295921326.
CUDA out of memory. Tried to allocate 3.95 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.26 GiB is free. Including non-PyTorch memory, this process has 42.29 GiB memory in use. Of the allocated memory 40.46 GiB is allocated by PyTorch, and 698.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-26 22:02:07,186] Trial 51 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9382778473935446, 'batch_size': 116, 'attention_heads': 8, 'hidden_dimension': 213, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5498452799192317, 'global_pooling': 'max', 'learning_rate': 0.0001484529049777752, 'weight_decay': 0.0002875701118985397, 'beta_0': 0.8519933304045685, 'beta_1': 0.9891733736599345, 'epsilon': 1.372930180842496e-05, 'balanced_loss': False, 'epochs': 155, 'early_stopping_patience': 11, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 41 with value: 0.557922295921326.
[I 2025-02-26 22:16:59,044] Trial 52 finished with value: 0.5299909600288643 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9896227028211253, 'batch_size': 124, 'attention_heads': 4, 'hidden_dimension': 229, 'number_of_hidden_layers': 1, 'dropout_rate': 0.46643536284549414, 'global_pooling': 'max', 'learning_rate': 0.0009247870881331911, 'weight_decay': 0.0005068729562320684, 'beta_0': 0.8187246616736172, 'beta_1': 0.9909432130050726, 'epsilon': 3.072290473313546e-06, 'balanced_loss': False, 'epochs': 161, 'early_stopping_patience': 19, 'plateau_patience': 17, 'plateau_divider': 7}. Best is trial 41 with value: 0.557922295921326.
[I 2025-02-26 22:34:50,238] Trial 53 finished with value: 0.5984719855482351 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9719055628494947, 'batch_size': 124, 'attention_heads': 6, 'hidden_dimension': 231, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4699419364216301, 'global_pooling': 'max', 'learning_rate': 0.0008578059284876293, 'weight_decay': 0.0005051817762723257, 'beta_0': 0.8320264597693887, 'beta_1': 0.9904089071011974, 'epsilon': 1.3859573824200844e-06, 'balanced_loss': False, 'epochs': 182, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-26 22:52:12,400] Trial 54 finished with value: 0.5938818211865101 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9733103905930357, 'batch_size': 123, 'attention_heads': 6, 'hidden_dimension': 245, 'number_of_hidden_layers': 1, 'dropout_rate': 0.46594407554790307, 'global_pooling': 'max', 'learning_rate': 0.001066205111718335, 'weight_decay': 0.0004943146629030139, 'beta_0': 0.8316696758337621, 'beta_1': 0.9904227617099716, 'epsilon': 1.3236106842191496e-06, 'balanced_loss': False, 'epochs': 186, 'early_stopping_patience': 18, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-26 23:09:59,200] Trial 55 finished with value: 0.5804252066894802 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9706267684583276, 'batch_size': 113, 'attention_heads': 6, 'hidden_dimension': 245, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4340930547747669, 'global_pooling': 'max', 'learning_rate': 0.0014391834423386424, 'weight_decay': 0.0003974274712668743, 'beta_0': 0.8323682751367023, 'beta_1': 0.9904435100282988, 'epsilon': 1.0292725848508365e-06, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 18, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-26 23:25:37,898] Trial 56 finished with value: 0.529677738244606 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9732304429141895, 'batch_size': 113, 'attention_heads': 6, 'hidden_dimension': 240, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4947074267547851, 'global_pooling': 'max', 'learning_rate': 0.0012635766811978743, 'weight_decay': 0.00036980061689963786, 'beta_0': 0.8331355151106058, 'beta_1': 0.9902116955515737, 'epsilon': 5.387463381362309e-07, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 18, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 53 with value: 0.5984719855482351.
CUDA out of memory. Tried to allocate 2.88 GiB. GPU 0 has a total capacity of 44.56 GiB of which 844.69 MiB is free. Including non-PyTorch memory, this process has 43.73 GiB memory in use. Of the allocated memory 39.73 GiB is allocated by PyTorch, and 2.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-26 23:38:46,365] Trial 57 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9576647975205771, 'batch_size': 121, 'attention_heads': 7, 'hidden_dimension': 249, 'number_of_hidden_layers': 1, 'dropout_rate': 0.43729236582964387, 'global_pooling': 'max', 'learning_rate': 0.0009060632024876922, 'weight_decay': 0.0006014914223436599, 'beta_0': 0.8318618013886317, 'beta_1': 0.9876693183458776, 'epsilon': 1.0132590262470244e-06, 'balanced_loss': False, 'epochs': 186, 'early_stopping_patience': 17, 'plateau_patience': 15, 'plateau_divider': 8}. Best is trial 53 with value: 0.5984719855482351.
CUDA out of memory. Tried to allocate 4.48 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.26 GiB is free. Including non-PyTorch memory, this process has 40.29 GiB memory in use. Of the allocated memory 38.79 GiB is allocated by PyTorch, and 363.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-26 23:51:52,218] Trial 58 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9453319085708776, 'batch_size': 126, 'attention_heads': 9, 'hidden_dimension': 224, 'number_of_hidden_layers': 1, 'dropout_rate': 0.517918080425066, 'global_pooling': 'max', 'learning_rate': 0.0016082010589275567, 'weight_decay': 0.0002565552445459089, 'beta_0': 0.8453638589641573, 'beta_1': 0.9890749642417513, 'epsilon': 1.4070471861626048e-06, 'balanced_loss': False, 'epochs': 176, 'early_stopping_patience': 18, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 53 with value: 0.5984719855482351.
CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.25 GiB is free. Including non-PyTorch memory, this process has 43.30 GiB memory in use. Of the allocated memory 40.35 GiB is allocated by PyTorch, and 1.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 00:04:55,893] Trial 59 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9685101716226844, 'batch_size': 119, 'attention_heads': 7, 'hidden_dimension': 248, 'number_of_hidden_layers': 1, 'dropout_rate': 0.47841076565216534, 'global_pooling': 'max', 'learning_rate': 0.0002941884705252226, 'weight_decay': 0.00044998568091434934, 'beta_0': 0.8389373998721872, 'beta_1': 0.991909397223259, 'epsilon': 6.119650459600285e-07, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 16, 'plateau_patience': 15, 'plateau_divider': 8}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 00:25:43,761] Trial 60 finished with value: 0.5455363947376696 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9613598831400806, 'batch_size': 114, 'attention_heads': 6, 'hidden_dimension': 221, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4363617475600825, 'global_pooling': 'max', 'learning_rate': 0.00019585474879423514, 'weight_decay': 0.0007668859545003913, 'beta_0': 0.8258698399517739, 'beta_1': 0.9926285435107085, 'epsilon': 1.9130211385748127e-07, 'balanced_loss': True, 'epochs': 162, 'early_stopping_patience': 18, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 00:42:19,192] Trial 61 finished with value: 0.4447011038674456 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9812373037433652, 'batch_size': 109, 'attention_heads': 6, 'hidden_dimension': 234, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4939691976082366, 'global_pooling': 'max', 'learning_rate': 0.00474861057956223, 'weight_decay': 0.0009589594387400725, 'beta_0': 0.8601147264828806, 'beta_1': 0.9902525732722547, 'epsilon': 2.784560524780357e-08, 'balanced_loss': False, 'epochs': 133, 'early_stopping_patience': 17, 'plateau_patience': 16, 'plateau_divider': 6}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 00:59:34,729] Trial 62 finished with value: 0.5466043615401752 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9927792691814326, 'batch_size': 128, 'attention_heads': 6, 'hidden_dimension': 210, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4718424197390463, 'global_pooling': 'max', 'learning_rate': 0.0005675287344931539, 'weight_decay': 0.0006576253606632265, 'beta_0': 0.8318389310526012, 'beta_1': 0.9877807232457687, 'epsilon': 1.8727135132020162e-06, 'balanced_loss': False, 'epochs': 181, 'early_stopping_patience': 15, 'plateau_patience': 15, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 01:16:07,005] Trial 63 finished with value: 0.5597284906785156 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9704791475179773, 'batch_size': 70, 'attention_heads': 5, 'hidden_dimension': 192, 'number_of_hidden_layers': 1, 'dropout_rate': 0.44696568296440553, 'global_pooling': 'max', 'learning_rate': 0.0009835461571842657, 'weight_decay': 0.0003303998401360612, 'beta_0': 0.8356454588168585, 'beta_1': 0.9916100405428, 'epsilon': 9.661918302623873e-07, 'balanced_loss': False, 'epochs': 196, 'early_stopping_patience': 21, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 01:32:57,784] Trial 64 finished with value: 0.5361688384154808 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9723268785076837, 'batch_size': 122, 'attention_heads': 5, 'hidden_dimension': 189, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4567382620086774, 'global_pooling': 'max', 'learning_rate': 0.0010203621478185104, 'weight_decay': 0.0003199658977364018, 'beta_0': 0.8349874369881859, 'beta_1': 0.9914487698191893, 'epsilon': 1.0353024908826856e-06, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 21, 'plateau_patience': 17, 'plateau_divider': 7}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 01:50:28,597] Trial 65 finished with value: 0.565903774002093 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9818120398972984, 'batch_size': 70, 'attention_heads': 7, 'hidden_dimension': 237, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41739204257335477, 'global_pooling': 'max', 'learning_rate': 0.0015427585398327143, 'weight_decay': 0.0001465744870266899, 'beta_0': 0.8492031400858341, 'beta_1': 0.9904577270856558, 'epsilon': 7.227923096505444e-07, 'balanced_loss': False, 'epochs': 198, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 02:09:05,472] Trial 66 finished with value: 0.5585230417403177 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.981553190261567, 'batch_size': 69, 'attention_heads': 8, 'hidden_dimension': 247, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4218066219216163, 'global_pooling': 'max', 'learning_rate': 0.0014252460315411727, 'weight_decay': 0.00012698415521208466, 'beta_0': 0.8488575326626983, 'beta_1': 0.9928996128067793, 'epsilon': 7.77362133896914e-07, 'balanced_loss': False, 'epochs': 181, 'early_stopping_patience': 21, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 02:27:19,961] Trial 67 finished with value: 0.5600569182029791 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9841428585987522, 'batch_size': 69, 'attention_heads': 8, 'hidden_dimension': 255, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4217726038233515, 'global_pooling': 'max', 'learning_rate': 0.0014628315088417933, 'weight_decay': 0.00014599964138716504, 'beta_0': 0.8507642531340834, 'beta_1': 0.9929852036157673, 'epsilon': 3.5611715699236717e-07, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 21, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 02:45:42,493] Trial 68 finished with value: 0.5796931245693845 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9819900293118372, 'batch_size': 70, 'attention_heads': 8, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4228221804814576, 'global_pooling': 'max', 'learning_rate': 0.0015010186788685228, 'weight_decay': 0.0001294905961978735, 'beta_0': 0.8501615468096555, 'beta_1': 0.994985148398215, 'epsilon': 2.028120810092216e-07, 'balanced_loss': False, 'epochs': 199, 'early_stopping_patience': 21, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 53 with value: 0.5984719855482351.
CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.68 GiB is free. Including non-PyTorch memory, this process has 42.88 GiB memory in use. Of the allocated memory 40.14 GiB is allocated by PyTorch, and 1.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 02:58:45,140] Trial 69 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9651110205324676, 'batch_size': 69, 'attention_heads': 9, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4038162672897638, 'global_pooling': 'max', 'learning_rate': 0.0010702060415566938, 'weight_decay': 0.00015274097982287825, 'beta_0': 0.8693674519254493, 'beta_1': 0.9949369627635911, 'epsilon': 3.936992469759502e-07, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 03:16:59,506] Trial 70 finished with value: 0.362818726146125 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9978124361191654, 'batch_size': 61, 'attention_heads': 10, 'hidden_dimension': 236, 'number_of_hidden_layers': 2, 'dropout_rate': 0.44575959060460135, 'global_pooling': 'max', 'learning_rate': 0.0008061425256260807, 'weight_decay': 0.000193973207754397, 'beta_0': 0.8451670516801146, 'beta_1': 0.995504147975658, 'epsilon': 1.7166158533089315e-07, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 03:32:14,049] Trial 71 finished with value: 0.5281579608644794 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9825488864141871, 'batch_size': 57, 'attention_heads': 8, 'hidden_dimension': 243, 'number_of_hidden_layers': 0, 'dropout_rate': 0.41457164608592795, 'global_pooling': 'max', 'learning_rate': 0.0015583021964937348, 'weight_decay': 0.00023689730671825368, 'beta_0': 0.8629725492588151, 'beta_1': 0.996189833919492, 'epsilon': 1.2385581391259118e-07, 'balanced_loss': False, 'epochs': 185, 'early_stopping_patience': 21, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 03:50:23,291] Trial 72 finished with value: 0.5859001883444016 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9829154929076321, 'batch_size': 71, 'attention_heads': 8, 'hidden_dimension': 249, 'number_of_hidden_layers': 1, 'dropout_rate': 0.42279189470715667, 'global_pooling': 'max', 'learning_rate': 0.0013931584225380918, 'weight_decay': 0.00013392584063152483, 'beta_0': 0.8500882657973746, 'beta_1': 0.9933182277646262, 'epsilon': 2.9776538149804545e-07, 'balanced_loss': False, 'epochs': 179, 'early_stopping_patience': 21, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 53 with value: 0.5984719855482351.
CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.76 GiB is free. Including non-PyTorch memory, this process has 42.79 GiB memory in use. Of the allocated memory 40.12 GiB is allocated by PyTorch, and 1.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 04:03:26,943] Trial 73 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9663721782463076, 'batch_size': 72, 'attention_heads': 9, 'hidden_dimension': 254, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4268089340368683, 'global_pooling': 'max', 'learning_rate': 0.0007440287728045121, 'weight_decay': 0.00011042318991316635, 'beta_0': 0.8517267606989212, 'beta_1': 0.9976533688659551, 'epsilon': 3.2907432454772664e-07, 'balanced_loss': False, 'epochs': 176, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 04:20:15,908] Trial 74 finished with value: 0.5541236759283351 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9898585092447091, 'batch_size': 72, 'attention_heads': 8, 'hidden_dimension': 250, 'number_of_hidden_layers': 1, 'dropout_rate': 0.39813919277246224, 'global_pooling': 'max', 'learning_rate': 0.0005463721307429633, 'weight_decay': 0.000138439185199204, 'beta_0': 0.8566604441160595, 'beta_1': 0.9939905988900896, 'epsilon': 6.977643730698656e-08, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 21, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.17 GiB is free. Including non-PyTorch memory, this process has 43.38 GiB memory in use. Of the allocated memory 39.90 GiB is allocated by PyTorch, and 2.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 04:33:18,174] Trial 75 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9557954748003527, 'batch_size': 63, 'attention_heads': 11, 'hidden_dimension': 240, 'number_of_hidden_layers': 1, 'dropout_rate': 0.44403795262666074, 'global_pooling': 'max', 'learning_rate': 0.0011788370629452194, 'weight_decay': 9.635111739256283e-05, 'beta_0': 0.8442202622946915, 'beta_1': 0.9942903240919234, 'epsilon': 2.524037922310455e-07, 'balanced_loss': False, 'epochs': 171, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 04:49:00,558] Trial 76 finished with value: 0.5380594846442848 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9938210121113705, 'batch_size': 77, 'attention_heads': 7, 'hidden_dimension': 218, 'number_of_hidden_layers': 1, 'dropout_rate': 0.430148018662891, 'global_pooling': 'max', 'learning_rate': 0.00038230068415333514, 'weight_decay': 0.0002056715751204772, 'beta_0': 0.8497174346885801, 'beta_1': 0.9932432636992542, 'epsilon': 4.805727946776295e-07, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
CUDA out of memory. Tried to allocate 3.50 GiB. GPU 0 has a total capacity of 44.56 GiB of which 904.69 MiB is free. Including non-PyTorch memory, this process has 43.67 GiB memory in use. Of the allocated memory 42.24 GiB is allocated by PyTorch, and 283.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 05:02:08,739] Trial 77 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9227454130944, 'batch_size': 67, 'attention_heads': 9, 'hidden_dimension': 234, 'number_of_hidden_layers': 1, 'dropout_rate': 0.391674112217425, 'global_pooling': 'max', 'learning_rate': 0.0016652417813327735, 'weight_decay': 4.3569168399706705e-05, 'beta_0': 0.8550583580228325, 'beta_1': 0.9917174214547846, 'epsilon': 1.2652758501268986e-07, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 21, 'plateau_patience': 23, 'plateau_divider': 8}. Best is trial 53 with value: 0.5984719855482351.
CUDA out of memory. Tried to allocate 2.06 GiB. GPU 0 has a total capacity of 44.56 GiB of which 290.69 MiB is free. Including non-PyTorch memory, this process has 44.27 GiB memory in use. Of the allocated memory 40.89 GiB is allocated by PyTorch, and 2.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 05:15:14,019] Trial 78 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.948379016425025, 'batch_size': 71, 'attention_heads': 7, 'hidden_dimension': 247, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41365377613107956, 'global_pooling': 'max', 'learning_rate': 0.002374670069723445, 'weight_decay': 0.000278407855178688, 'beta_0': 0.8695505200362676, 'beta_1': 0.9925018985810717, 'epsilon': 7.040254642706657e-07, 'balanced_loss': False, 'epochs': 196, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 05:28:53,294] Trial 79 finished with value: 0.024989960180156905 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9998243844550433, 'batch_size': 56, 'attention_heads': 8, 'hidden_dimension': 226, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4566714985437606, 'global_pooling': 'max', 'learning_rate': 0.004304806007219832, 'weight_decay': 0.00021338461944994173, 'beta_0': 0.8599322492030822, 'beta_1': 0.9920841446921796, 'epsilon': 3.4638785972520667e-07, 'balanced_loss': False, 'epochs': 179, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 05:45:27,162] Trial 80 finished with value: 0.5795433887436579 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9846022949953445, 'batch_size': 63, 'attention_heads': 6, 'hidden_dimension': 255, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4429393157726075, 'global_pooling': 'max', 'learning_rate': 0.000764040118773969, 'weight_decay': 7.756052749752958e-05, 'beta_0': 0.8520023412622937, 'beta_1': 0.9930570174960497, 'epsilon': 1.2267124663991274e-06, 'balanced_loss': False, 'epochs': 185, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 06:02:42,957] Trial 81 finished with value: 0.5801071050910988 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9846533471752966, 'batch_size': 80, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4082732825635817, 'global_pooling': 'max', 'learning_rate': 0.0007144194791583345, 'weight_decay': 7.4566008898222e-05, 'beta_0': 0.8518093258351589, 'beta_1': 0.9943871725675469, 'epsilon': 1.7458360071750327e-07, 'balanced_loss': False, 'epochs': 165, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 06:20:08,778] Trial 82 finished with value: 0.5772805041001593 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9833348363893221, 'batch_size': 62, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4088494536395386, 'global_pooling': 'max', 'learning_rate': 0.0004767507405990593, 'weight_decay': 8.072462045040402e-05, 'beta_0': 0.848005658550958, 'beta_1': 0.9951672862376072, 'epsilon': 8.203653295948511e-08, 'balanced_loss': False, 'epochs': 168, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 06:37:04,078] Trial 83 finished with value: 0.5771852476415692 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9860063770726781, 'batch_size': 79, 'attention_heads': 7, 'hidden_dimension': 245, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3716583147563173, 'global_pooling': 'max', 'learning_rate': 0.00047546052702887744, 'weight_decay': 8.452394995377882e-05, 'beta_0': 0.8481186256126887, 'beta_1': 0.9953088139108068, 'epsilon': 6.673443212108708e-08, 'balanced_loss': False, 'epochs': 168, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 06:52:27,689] Trial 84 finished with value: 0.571879663141737 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9920246211985849, 'batch_size': 80, 'attention_heads': 6, 'hidden_dimension': 243, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3658419233212428, 'global_pooling': 'max', 'learning_rate': 0.000682677357961197, 'weight_decay': 8.178621256095379e-05, 'beta_0': 0.859914768862095, 'beta_1': 0.9969689762971277, 'epsilon': 7.976111289138738e-08, 'balanced_loss': False, 'epochs': 170, 'early_stopping_patience': 19, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 07:09:41,801] Trial 85 finished with value: 0.5861322243472454 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9856672879049359, 'batch_size': 90, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3703286820527472, 'global_pooling': 'max', 'learning_rate': 0.0004677690426544348, 'weight_decay': 2.7162805134390553e-05, 'beta_0': 0.8538673030702643, 'beta_1': 0.9954710349435246, 'epsilon': 9.738669901091056e-08, 'balanced_loss': False, 'epochs': 165, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 07:27:30,585] Trial 86 finished with value: 0.5672438288130217 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9786295128497298, 'batch_size': 92, 'attention_heads': 6, 'hidden_dimension': 251, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40504161113470766, 'global_pooling': 'max', 'learning_rate': 0.0003530268729478569, 'weight_decay': 2.219610557138148e-05, 'beta_0': 0.8537770662084202, 'beta_1': 0.9943523282171534, 'epsilon': 2.4494373562515683e-08, 'balanced_loss': False, 'epochs': 162, 'early_stopping_patience': 19, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
CUDA out of memory. Tried to allocate 2.32 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.66 GiB is free. Including non-PyTorch memory, this process has 42.89 GiB memory in use. Of the allocated memory 39.56 GiB is allocated by PyTorch, and 2.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 07:40:41,221] Trial 87 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9623320079428848, 'batch_size': 103, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.390998338630292, 'global_pooling': 'max', 'learning_rate': 0.0005518637966605894, 'weight_decay': 2.5426229957365744e-05, 'beta_0': 0.8405901285997628, 'beta_1': 0.9960966023633837, 'epsilon': 1.0318721303613883e-07, 'balanced_loss': False, 'epochs': 167, 'early_stopping_patience': 18, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 104.69 MiB is free. Including non-PyTorch memory, this process has 44.45 GiB memory in use. Of the allocated memory 42.51 GiB is allocated by PyTorch, and 808.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 07:49:30,094] Trial 88 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8569748700812788, 'batch_size': 74, 'attention_heads': 6, 'hidden_dimension': 251, 'number_of_hidden_layers': 0, 'dropout_rate': 0.43358807135170085, 'global_pooling': 'max', 'learning_rate': 0.00080508521947905, 'weight_decay': 3.359809270319087e-05, 'beta_0': 0.875444942998774, 'beta_1': 0.9955609660000376, 'epsilon': 5.0371323105314685e-08, 'balanced_loss': False, 'epochs': 155, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 08:07:18,420] Trial 89 finished with value: 0.5612815928253528 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9949456739221335, 'batch_size': 63, 'attention_heads': 8, 'hidden_dimension': 237, 'number_of_hidden_layers': 1, 'dropout_rate': 0.44099050622232144, 'global_pooling': 'max', 'learning_rate': 0.00021121144912293995, 'weight_decay': 6.493606896722046e-05, 'beta_0': 0.863885987323642, 'beta_1': 0.9985499132900413, 'epsilon': 1.5056015903780545e-07, 'balanced_loss': False, 'epochs': 173, 'early_stopping_patience': 22, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 08:26:27,224] Trial 90 finished with value: 0.5108558475774617 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9888952224091324, 'batch_size': 88, 'attention_heads': 7, 'hidden_dimension': 231, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3850270690105954, 'global_pooling': 'max', 'learning_rate': 0.00036582319593919703, 'weight_decay': 5.1121566901263014e-05, 'beta_0': 0.8574795222239825, 'beta_1': 0.9972637401651254, 'epsilon': 2.0919978545262347e-07, 'balanced_loss': False, 'epochs': 184, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 8}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 09:07:38,482] Trial 91 finished with value: 0.4286030089054271 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.974809440489437, 'batch_size': 66, 'attention_heads': 6, 'hidden_dimension': 243, 'number_of_hidden_layers': 1, 'dropout_rate': 0.46063758619639306, 'global_pooling': 'max', 'learning_rate': 1.4409958627863634e-05, 'weight_decay': 4.039798487735588e-05, 'beta_0': 0.8431652557213617, 'beta_1': 0.9946423326936359, 'epsilon': 3.628502995812189e-08, 'balanced_loss': False, 'epochs': 187, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 09:24:37,579] Trial 92 finished with value: 0.57925790300314 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9849668781691951, 'batch_size': 78, 'attention_heads': 7, 'hidden_dimension': 244, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3702348329362516, 'global_pooling': 'max', 'learning_rate': 0.0004854273638683326, 'weight_decay': 0.0001068606132763201, 'beta_0': 0.8482098121165776, 'beta_1': 0.9953141819109373, 'epsilon': 6.181946187823895e-08, 'balanced_loss': False, 'epochs': 166, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 09:41:36,958] Trial 93 finished with value: 0.566960540987975 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9851785639603965, 'batch_size': 83, 'attention_heads': 6, 'hidden_dimension': 251, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4122256454777857, 'global_pooling': 'max', 'learning_rate': 0.0006747052354401922, 'weight_decay': 7.032216077870767e-05, 'beta_0': 0.8467264263625445, 'beta_1': 0.9935582033812594, 'epsilon': 9.510957303586194e-08, 'balanced_loss': False, 'epochs': 165, 'early_stopping_patience': 21, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 53 with value: 0.5984719855482351.
[I 2025-02-27 10:01:23,381] Trial 94 finished with value: 0.6130243860768243 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9692521484544494, 'batch_size': 54, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3985625660326877, 'global_pooling': 'max', 'learning_rate': 0.00044401201962245896, 'weight_decay': 9.488349930139096e-05, 'beta_0': 0.8528241879640202, 'beta_1': 0.9959270106093928, 'epsilon': 4.6395170735319275e-08, 'balanced_loss': False, 'epochs': 150, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 9}. Best is trial 94 with value: 0.6130243860768243.
[I 2025-02-27 10:19:52,278] Trial 95 finished with value: 0.5630095326630487 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9703654724474876, 'batch_size': 53, 'attention_heads': 8, 'hidden_dimension': 239, 'number_of_hidden_layers': 1, 'dropout_rate': 0.39690278597265854, 'global_pooling': 'max', 'learning_rate': 0.0011645293265900424, 'weight_decay': 0.00011485784560213577, 'beta_0': 0.8529904074601675, 'beta_1': 0.9958732306806938, 'epsilon': 1.0079146938900998e-08, 'balanced_loss': False, 'epochs': 149, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 94 with value: 0.6130243860768243.
[I 2025-02-27 10:38:46,870] Trial 96 finished with value: 0.5462941347341832 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9761647095829677, 'batch_size': 48, 'attention_heads': 7, 'hidden_dimension': 225, 'number_of_hidden_layers': 1, 'dropout_rate': 0.37364552714791927, 'global_pooling': 'max', 'learning_rate': 0.00015458457066865126, 'weight_decay': 1.5456404570724014e-05, 'beta_0': 0.8581754593504044, 'beta_1': 0.996509873261995, 'epsilon': 5.6766967509016854e-08, 'balanced_loss': False, 'epochs': 179, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 94 with value: 0.6130243860768243.
CUDA out of memory. Tried to allocate 136.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 102.69 MiB is free. Including non-PyTorch memory, this process has 44.45 GiB memory in use. Of the allocated memory 42.43 GiB is allocated by PyTorch, and 893.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 10:46:02,156] Trial 97 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8224231895620081, 'batch_size': 59, 'attention_heads': 6, 'hidden_dimension': 245, 'number_of_hidden_layers': 1, 'dropout_rate': 0.42677558286477224, 'global_pooling': 'max', 'learning_rate': 0.00032508928854599274, 'weight_decay': 0.00010061937913410916, 'beta_0': 0.8948458802248084, 'beta_1': 0.9941353677641398, 'epsilon': 3.732080876087225e-08, 'balanced_loss': False, 'epochs': 158, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 94 with value: 0.6130243860768243.
CUDA out of memory. Tried to allocate 2.12 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.26 GiB is free. Including non-PyTorch memory, this process has 43.29 GiB memory in use. Of the allocated memory 40.48 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 10:59:19,086] Trial 98 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9614503372274791, 'batch_size': 75, 'attention_heads': 7, 'hidden_dimension': 251, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3662551439860318, 'global_pooling': 'max', 'learning_rate': 0.00024645528810908506, 'weight_decay': 4.731997742402706e-05, 'beta_0': 0.8549172154477543, 'beta_1': 0.994637245927037, 'epsilon': 1.268108352201049e-06, 'balanced_loss': False, 'epochs': 177, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 94 with value: 0.6130243860768243.
[I 2025-02-27 11:18:50,640] Trial 99 finished with value: 0.5855189888745084 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9681576707415789, 'batch_size': 85, 'attention_heads': 6, 'hidden_dimension': 232, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4742743693004542, 'global_pooling': 'max', 'learning_rate': 0.0008279973735880705, 'weight_decay': 3.4663538044897525e-05, 'beta_0': 0.8375872525662803, 'beta_1': 0.9965897189615655, 'epsilon': 1.790347836040765e-06, 'balanced_loss': False, 'epochs': 173, 'early_stopping_patience': 23, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 94 with value: 0.6130243860768243.
[I 2025-02-27 11:37:31,594] Trial 100 finished with value: 0.5920241984112096 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9682363100428167, 'batch_size': 90, 'attention_heads': 6, 'hidden_dimension': 231, 'number_of_hidden_layers': 1, 'dropout_rate': 0.47670244352689956, 'global_pooling': 'max', 'learning_rate': 0.000853164390238609, 'weight_decay': 5.8735124200608015e-05, 'beta_0': 0.8395052770599435, 'beta_1': 0.9979693166536888, 'epsilon': 1.6879722529785724e-06, 'balanced_loss': False, 'epochs': 174, 'early_stopping_patience': 22, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 94 with value: 0.6130243860768243.
[I 2025-02-27 11:54:30,882] Trial 101 finished with value: 0.5394190147313976 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9584857872416862, 'batch_size': 90, 'attention_heads': 6, 'hidden_dimension': 219, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4778300773801912, 'global_pooling': 'max', 'learning_rate': 0.0008999163155237991, 'weight_decay': 3.0341431642312702e-05, 'beta_0': 0.8376904978810992, 'beta_1': 0.9979263446023969, 'epsilon': 1.7114742653745736e-06, 'balanced_loss': False, 'epochs': 174, 'early_stopping_patience': 23, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 94 with value: 0.6130243860768243.
slurmstepd: error: *** JOB 15030009 ON gpu049 CANCELLED AT 2025-02-27T12:02:19 DUE TO TIME LIMIT ***
