[I 2025-02-22 03:11:27,356] Using an existing study with name 'Ohsumed-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-Unitary_Weights-0.0-0.0' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors
[I 2025-02-22 03:26:34,436] Trial 277 finished with value: 0.587890731981147 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9778375286921738, 'batch_size': 115, 'attention_heads': 15, 'hidden_dimension': 41, 'number_of_hidden_layers': 1, 'dropout_rate': 0.39945303781784613, 'global_pooling': 'max', 'learning_rate': 0.0009611758309023207, 'weight_decay': 5.7181986649114745e-05, 'beta_0': 0.8298142982503558, 'beta_1': 0.9867836584252869, 'epsilon': 1.9352568172262824e-08, 'balanced_loss': True, 'epochs': 101, 'early_stopping_patience': 18, 'plateau_patience': 12, 'plateau_divider': 3}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 03:42:31,597] Trial 278 finished with value: 0.5827812991929807 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9848835425719915, 'batch_size': 35, 'attention_heads': 16, 'hidden_dimension': 70, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5159609076771594, 'global_pooling': 'max', 'learning_rate': 0.0007907193766262973, 'weight_decay': 5.304748503302373e-06, 'beta_0': 0.834026005579183, 'beta_1': 0.9884740790424308, 'epsilon': 1.6140164408915743e-08, 'balanced_loss': True, 'epochs': 187, 'early_stopping_patience': 18, 'plateau_patience': 13, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 03:58:06,222] Trial 279 finished with value: 0.6125406670764969 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9646674374549762, 'batch_size': 41, 'attention_heads': 15, 'hidden_dimension': 79, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4098306414839611, 'global_pooling': 'max', 'learning_rate': 0.0005313495622794518, 'weight_decay': 0.0007760649084121655, 'beta_0': 0.8159425485530569, 'beta_1': 0.9871167485631398, 'epsilon': 1.2098248958833519e-08, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 04:14:00,353] Trial 280 finished with value: 0.6027669259509699 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9640960032629557, 'batch_size': 45, 'attention_heads': 12, 'hidden_dimension': 84, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41115866790781047, 'global_pooling': 'max', 'learning_rate': 0.0002863942588569795, 'weight_decay': 0.0006408498435477714, 'beta_0': 0.8372662298532906, 'beta_1': 0.9861245220923046, 'epsilon': 1.2307432134256293e-08, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 17, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 04:29:12,101] Trial 281 finished with value: 0.6111743427735422 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.96773040427194, 'batch_size': 42, 'attention_heads': 16, 'hidden_dimension': 74, 'number_of_hidden_layers': 1, 'dropout_rate': 0.42026365397189613, 'global_pooling': 'max', 'learning_rate': 0.0004954324422649755, 'weight_decay': 0.0007571365861916951, 'beta_0': 0.804550770774706, 'beta_1': 0.9865390220872258, 'epsilon': 1.0052306928773502e-08, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 04:45:15,140] Trial 282 finished with value: 0.6082132390633816 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.961696820830221, 'batch_size': 43, 'attention_heads': 16, 'hidden_dimension': 78, 'number_of_hidden_layers': 1, 'dropout_rate': 0.42965610868665693, 'global_pooling': 'max', 'learning_rate': 0.00039911303289744506, 'weight_decay': 0.0007621973026136211, 'beta_0': 0.8460819151754755, 'beta_1': 0.9865093120647409, 'epsilon': 1.1260821282607782e-08, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 18, 'plateau_patience': 10, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 05:00:27,544] Trial 283 finished with value: 0.5657192832712861 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9671831190409935, 'batch_size': 48, 'attention_heads': 15, 'hidden_dimension': 76, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4174967867141169, 'global_pooling': 'mean', 'learning_rate': 0.0005198972538300713, 'weight_decay': 0.0009561590811333569, 'beta_0': 0.8017204011548279, 'beta_1': 0.9858708325128167, 'epsilon': 1.0205353723449496e-08, 'balanced_loss': True, 'epochs': 103, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 05:16:50,320] Trial 284 finished with value: 0.6140916195390453 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9647118050300781, 'batch_size': 42, 'attention_heads': 16, 'hidden_dimension': 85, 'number_of_hidden_layers': 1, 'dropout_rate': 0.42213032831232955, 'global_pooling': 'max', 'learning_rate': 0.0005048678693087798, 'weight_decay': 4.0294171416712954e-05, 'beta_0': 0.8043874230378569, 'beta_1': 0.9866879189233222, 'epsilon': 1.2457531425249269e-08, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 05:37:57,834] Trial 285 finished with value: 0.5753352865109879 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.957414979966054, 'batch_size': 42, 'attention_heads': 15, 'hidden_dimension': 80, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4245401931897804, 'global_pooling': 'max', 'learning_rate': 0.0003185466848424142, 'weight_decay': 4.12574850472957e-05, 'beta_0': 0.8067067270635068, 'beta_1': 0.9868252552289244, 'epsilon': 1.2440937642330695e-08, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 05:56:44,889] Trial 286 finished with value: 0.5689013467837812 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9644631049144664, 'batch_size': 41, 'attention_heads': 14, 'hidden_dimension': 89, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4210793145897338, 'global_pooling': 'sum', 'learning_rate': 0.000442724107421754, 'weight_decay': 5.0428690799805283e-05, 'beta_0': 0.8091308698263661, 'beta_1': 0.9871204996988597, 'epsilon': 1.0238455508774489e-08, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 18, 'plateau_patience': 10, 'plateau_divider': 7}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 06:22:59,200] Trial 287 finished with value: 0.08795253230604151 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9583172856486728, 'batch_size': 45, 'attention_heads': 16, 'hidden_dimension': 81, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4284462714949714, 'global_pooling': 'max', 'learning_rate': 0.09285939748894982, 'weight_decay': 5.0421426347706905e-05, 'beta_0': 0.8053184718293477, 'beta_1': 0.9861628780317047, 'epsilon': 1.8104716460765737e-07, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 19, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 06:38:10,934] Trial 288 finished with value: 0.588501972886293 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9687334760044535, 'batch_size': 42, 'attention_heads': 15, 'hidden_dimension': 75, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4336469497423902, 'global_pooling': 'max', 'learning_rate': 0.0005132146529166553, 'weight_decay': 3.7145696409334074e-05, 'beta_0': 0.8022955352985965, 'beta_1': 0.9864300072180483, 'epsilon': 6.353385725478803e-06, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 06:54:06,133] Trial 289 finished with value: 0.6080949535244645 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9621660055822242, 'batch_size': 41, 'attention_heads': 16, 'hidden_dimension': 70, 'number_of_hidden_layers': 1, 'dropout_rate': 0.42449136624417166, 'global_pooling': 'max', 'learning_rate': 0.00036248242273147457, 'weight_decay': 0.000587142586152667, 'beta_0': 0.8038385034834535, 'beta_1': 0.9873933143834982, 'epsilon': 1.17512486647331e-08, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 07:09:52,770] Trial 290 finished with value: 0.5704709174849001 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9654003750347185, 'batch_size': 44, 'attention_heads': 15, 'hidden_dimension': 77, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5124006212354995, 'global_pooling': 'max', 'learning_rate': 0.00045097751258083593, 'weight_decay': 3.964595131804143e-05, 'beta_0': 0.803486478395302, 'beta_1': 0.9853445078780126, 'epsilon': 1.366186021961484e-08, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 07:25:00,453] Trial 291 finished with value: 0.5970366350234672 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9701369589544702, 'batch_size': 46, 'attention_heads': 16, 'hidden_dimension': 72, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41382690872652916, 'global_pooling': 'max', 'learning_rate': 0.0005567029292263892, 'weight_decay': 4.567368141544264e-05, 'beta_0': 0.8400850425923168, 'beta_1': 0.9867014354280539, 'epsilon': 1.725293210787103e-08, 'balanced_loss': True, 'epochs': 107, 'early_stopping_patience': 18, 'plateau_patience': 10, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 07:40:21,783] Trial 292 finished with value: 0.5960214149411311 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9700678020940043, 'batch_size': 40, 'attention_heads': 14, 'hidden_dimension': 67, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4079697338925902, 'global_pooling': 'max', 'learning_rate': 0.00024730560808209164, 'weight_decay': 7.063027621780585e-05, 'beta_0': 0.8005527518729832, 'beta_1': 0.9870736860956769, 'epsilon': 1.0041920605721182e-08, 'balanced_loss': False, 'epochs': 122, 'early_stopping_patience': 19, 'plateau_patience': 11, 'plateau_divider': 7}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 07:55:58,341] Trial 293 finished with value: 0.600639315431099 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9556476702607589, 'batch_size': 38, 'attention_heads': 12, 'hidden_dimension': 66, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41870401465634455, 'global_pooling': 'max', 'learning_rate': 0.0005300434827650116, 'weight_decay': 1.476624792687571e-06, 'beta_0': 0.8044629874885154, 'beta_1': 0.9849178150862916, 'epsilon': 1.389800898730241e-08, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 08:12:06,441] Trial 294 finished with value: 0.6125459369736634 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9620766383782023, 'batch_size': 92, 'attention_heads': 16, 'hidden_dimension': 80, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3877845571550813, 'global_pooling': 'max', 'learning_rate': 0.0006566118626701506, 'weight_decay': 0.00047924843408306847, 'beta_0': 0.8075833829755132, 'beta_1': 0.9877276424901823, 'epsilon': 1.9133150315749975e-08, 'balanced_loss': True, 'epochs': 128, 'early_stopping_patience': 17, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 52.69 MiB is free. Including non-PyTorch memory, this process has 44.50 GiB memory in use. Of the allocated memory 42.66 GiB is allocated by PyTorch, and 705.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 08:20:16,960] Trial 295 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8600282630400856, 'batch_size': 89, 'attention_heads': 16, 'hidden_dimension': 82, 'number_of_hidden_layers': 1, 'dropout_rate': 0.38553196602330225, 'global_pooling': 'max', 'learning_rate': 0.0006254598548229381, 'weight_decay': 0.00031325907633248187, 'beta_0': 0.8062444366070309, 'beta_1': 0.9879285443820265, 'epsilon': 1.2475958630410927e-08, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 17, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 08:37:37,423] Trial 296 finished with value: 0.6025755754941394 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9604955164729863, 'batch_size': 44, 'attention_heads': 16, 'hidden_dimension': 87, 'number_of_hidden_layers': 1, 'dropout_rate': 0.38745847602229977, 'global_pooling': 'max', 'learning_rate': 0.000423732329621064, 'weight_decay': 5.867007730006312e-05, 'beta_0': 0.8090618850695057, 'beta_1': 0.9875991620235324, 'epsilon': 1.631961632455865e-08, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 17, 'plateau_patience': 10, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
CUDA out of memory. Tried to allocate 3.29 GiB. GPU 0 has a total capacity of 44.56 GiB of which 968.69 MiB is free. Including non-PyTorch memory, this process has 43.61 GiB memory in use. Of the allocated memory 41.46 GiB is allocated by PyTorch, and 1017.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 08:49:31,935] Trial 297 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9143876705050024, 'batch_size': 92, 'attention_heads': 16, 'hidden_dimension': 80, 'number_of_hidden_layers': 1, 'dropout_rate': 0.37980212472929253, 'global_pooling': 'max', 'learning_rate': 0.0006882940925757657, 'weight_decay': 2.692819127483391e-05, 'beta_0': 0.8032775572054667, 'beta_1': 0.9876271429659803, 'epsilon': 1.4685832052487984e-08, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 17, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 09:05:23,455] Trial 298 finished with value: 0.6076784707677683 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9641233208141571, 'batch_size': 42, 'attention_heads': 16, 'hidden_dimension': 76, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3915788846768015, 'global_pooling': 'max', 'learning_rate': 0.000501463358122502, 'weight_decay': 3.244793900797971e-05, 'beta_0': 0.8841877583436283, 'beta_1': 0.9882771608243811, 'epsilon': 1.864546500697233e-08, 'balanced_loss': True, 'epochs': 131, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
CUDA out of memory. Tried to allocate 1.97 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.97 GiB is free. Including non-PyTorch memory, this process has 42.58 GiB memory in use. Of the allocated memory 40.14 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 09:17:17,003] Trial 299 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9598890519940992, 'batch_size': 110, 'attention_heads': 16, 'hidden_dimension': 73, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4115186524300696, 'global_pooling': 'max', 'learning_rate': 0.0003643510639902244, 'weight_decay': 0.0004379807806924738, 'beta_0': 0.8078564333097897, 'beta_1': 0.9872956767129503, 'epsilon': 1.1793428857715293e-08, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 11, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
CUDA out of memory. Tried to allocate 2.05 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 42.74 GiB memory in use. Of the allocated memory 39.63 GiB is allocated by PyTorch, and 1.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 09:29:16,521] Trial 300 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9522918719881721, 'batch_size': 101, 'attention_heads': 16, 'hidden_dimension': 82, 'number_of_hidden_layers': 1, 'dropout_rate': 0.43926402414803495, 'global_pooling': 'max', 'learning_rate': 0.0005867899452663138, 'weight_decay': 0.0007457644550659424, 'beta_0': 0.806949750716587, 'beta_1': 0.9870039455449312, 'epsilon': 1.8438927317863282e-08, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
CUDA out of memory. Tried to allocate 2.34 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.09 GiB is free. Including non-PyTorch memory, this process has 42.46 GiB memory in use. Of the allocated memory 38.67 GiB is allocated by PyTorch, and 2.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 09:41:14,702] Trial 301 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9659845499555859, 'batch_size': 72, 'attention_heads': 16, 'hidden_dimension': 182, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4220300449223478, 'global_pooling': 'max', 'learning_rate': 0.000716095939011925, 'weight_decay': 0.0009933949374848793, 'beta_0': 0.8111446275007812, 'beta_1': 0.9866389823508513, 'epsilon': 4.8719043206201657e-05, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 17, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 09:58:25,351] Trial 302 finished with value: 0.6047769257177908 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9716185317792031, 'batch_size': 105, 'attention_heads': 15, 'hidden_dimension': 94, 'number_of_hidden_layers': 1, 'dropout_rate': 0.383423228051428, 'global_pooling': 'max', 'learning_rate': 0.0004381653798515745, 'weight_decay': 0.0006323083224482332, 'beta_0': 0.8422447568048478, 'beta_1': 0.9878208507200136, 'epsilon': 1.4210959105739835e-08, 'balanced_loss': False, 'epochs': 73, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.40 GiB is free. Including non-PyTorch memory, this process has 43.15 GiB memory in use. Of the allocated memory 40.70 GiB is allocated by PyTorch, and 1.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 10:10:20,989] Trial 303 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9628600158637741, 'batch_size': 96, 'attention_heads': 16, 'hidden_dimension': 85, 'number_of_hidden_layers': 4, 'dropout_rate': 0.39457343593559513, 'global_pooling': 'max', 'learning_rate': 0.0005521776033279462, 'weight_decay': 0.0008138165770932334, 'beta_0': 0.8831799556138579, 'beta_1': 0.98694902162463, 'epsilon': 2.7024530777994688e-08, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 10:27:50,906] Trial 304 finished with value: 0.5797852272334454 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9813097375720125, 'batch_size': 47, 'attention_heads': 13, 'hidden_dimension': 163, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40277927119196083, 'global_pooling': 'max', 'learning_rate': 0.0007661736389480028, 'weight_decay': 0.00046545775045050535, 'beta_0': 0.8100218129756057, 'beta_1': 0.9891797443766905, 'epsilon': 2.1152940886239897e-08, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 17, 'plateau_patience': 21, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 10:42:57,961] Trial 305 finished with value: 0.5992675823357714 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9728557696316941, 'batch_size': 44, 'attention_heads': 16, 'hidden_dimension': 70, 'number_of_hidden_layers': 1, 'dropout_rate': 0.43246680644729835, 'global_pooling': 'max', 'learning_rate': 0.0006703692978605164, 'weight_decay': 0.0003837120748012016, 'beta_0': 0.887879410968394, 'beta_1': 0.9874581158196248, 'epsilon': 1.1825137769160004e-08, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 18, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 10:59:18,177] Trial 306 finished with value: 0.5336784459205149 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9670021501339728, 'batch_size': 41, 'attention_heads': 15, 'hidden_dimension': 77, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41350891185323385, 'global_pooling': 'mean', 'learning_rate': 0.0003237296192776705, 'weight_decay': 4.2903330403077936e-05, 'beta_0': 0.8844852967728077, 'beta_1': 0.9900087064602682, 'epsilon': 1.5608211128094792e-08, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 18, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 11:18:08,626] Trial 307 finished with value: 0.554896178591857 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9565990072965126, 'batch_size': 80, 'attention_heads': 16, 'hidden_dimension': 64, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5400703939008541, 'global_pooling': 'max', 'learning_rate': 0.00018850620371234554, 'weight_decay': 0.0006902402690448511, 'beta_0': 0.8055333497602102, 'beta_1': 0.9880688935031166, 'epsilon': 3.24065985932786e-08, 'balanced_loss': True, 'epochs': 164, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 7}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 11:36:51,771] Trial 308 finished with value: 0.5696494737509333 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9890652955242615, 'batch_size': 46, 'attention_heads': 15, 'hidden_dimension': 72, 'number_of_hidden_layers': 1, 'dropout_rate': 0.39829950859923563, 'global_pooling': 'max', 'learning_rate': 0.0005064527980256106, 'weight_decay': 0.0005428411442112772, 'beta_0': 0.8813070611874708, 'beta_1': 0.9865130593710194, 'epsilon': 1.758663326060946e-08, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 11:51:07,404] Trial 309 finished with value: 0.5715826957108107 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9778065114612167, 'batch_size': 49, 'attention_heads': 14, 'hidden_dimension': 67, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3884560972615648, 'global_pooling': 'max', 'learning_rate': 0.0005831161906667146, 'weight_decay': 0.0007825825294956857, 'beta_0': 0.8859424193652261, 'beta_1': 0.9873291827354572, 'epsilon': 2.3551242050740885e-08, 'balanced_loss': True, 'epochs': 132, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 12:04:44,607] Trial 310 finished with value: 0.5301350655961709 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9718519722393889, 'batch_size': 40, 'attention_heads': 15, 'hidden_dimension': 33, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40647818708808314, 'global_pooling': 'sum', 'learning_rate': 0.00042516222661213567, 'weight_decay': 0.0005904875053772961, 'beta_0': 0.8079648402394193, 'beta_1': 0.9913248507614698, 'epsilon': 1.3260857136703438e-08, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 17, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 12:19:38,565] Trial 311 finished with value: 0.5875520701724836 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9682541137672158, 'batch_size': 77, 'attention_heads': 16, 'hidden_dimension': 63, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4179656900574262, 'global_pooling': 'max', 'learning_rate': 0.0008410899303939889, 'weight_decay': 0.00047980099763293054, 'beta_0': 0.8353274505994882, 'beta_1': 0.9909104976699193, 'epsilon': 2.0763294796496033e-08, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 16, 'plateau_patience': 16, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 12:35:49,418] Trial 312 finished with value: 0.5956690525336246 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9617159294897536, 'batch_size': 43, 'attention_heads': 15, 'hidden_dimension': 72, 'number_of_hidden_layers': 1, 'dropout_rate': 0.39453090550135084, 'global_pooling': 'max', 'learning_rate': 0.0006108237704818536, 'weight_decay': 0.0008831795363359886, 'beta_0': 0.8887193496538027, 'beta_1': 0.9883935118398901, 'epsilon': 1.025067559217154e-08, 'balanced_loss': True, 'epochs': 134, 'early_stopping_patience': 19, 'plateau_patience': 10, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 12:50:48,116] Trial 313 finished with value: 0.5833861385812015 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9806005501938762, 'batch_size': 39, 'attention_heads': 15, 'hidden_dimension': 78, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4999178664241133, 'global_pooling': 'max', 'learning_rate': 0.0007293032181217715, 'weight_decay': 0.0006918696312830557, 'beta_0': 0.8028619731753643, 'beta_1': 0.9857144146379866, 'epsilon': 1.5933447176481923e-08, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 18, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 13:06:58,764] Trial 314 finished with value: 0.326922201038664 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9755420113745382, 'batch_size': 43, 'attention_heads': 16, 'hidden_dimension': 44, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4093531486281741, 'global_pooling': 'max', 'learning_rate': 0.009506064190222313, 'weight_decay': 7.662258573506317e-05, 'beta_0': 0.8049161182141434, 'beta_1': 0.9902125867072915, 'epsilon': 2.494359734689916e-08, 'balanced_loss': False, 'epochs': 108, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 13:21:18,579] Trial 315 finished with value: 0.5858418241670268 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9852042864399804, 'batch_size': 37, 'attention_heads': 15, 'hidden_dimension': 63, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4005162569419514, 'global_pooling': 'max', 'learning_rate': 0.00046192767030285586, 'weight_decay': 5.546034186867293e-05, 'beta_0': 0.8118810248554224, 'beta_1': 0.9877237341967645, 'epsilon': 1.368339078555075e-08, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 16, 'plateau_patience': 14, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 13:34:46,218] Trial 316 finished with value: 0.5686511385994145 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.97236661586167, 'batch_size': 41, 'attention_heads': 16, 'hidden_dimension': 54, 'number_of_hidden_layers': 0, 'dropout_rate': 0.38950402360250647, 'global_pooling': 'max', 'learning_rate': 0.0003810812450857272, 'weight_decay': 6.401966602877981e-05, 'beta_0': 0.8285870779605395, 'beta_1': 0.9889619226412001, 'epsilon': 1.8947529252808604e-08, 'balanced_loss': True, 'epochs': 145, 'early_stopping_patience': 18, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 13:50:03,756] Trial 317 finished with value: 0.5836679376288858 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9655482879937283, 'batch_size': 86, 'attention_heads': 11, 'hidden_dimension': 86, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4246712754846899, 'global_pooling': 'max', 'learning_rate': 0.0007959690824535121, 'weight_decay': 0.0006229663565044591, 'beta_0': 0.8813757763969303, 'beta_1': 0.9868227621831432, 'epsilon': 4.168494875259482e-08, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 14:09:53,845] Trial 318 finished with value: 0.5810992912385178 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9768479927155737, 'batch_size': 46, 'attention_heads': 14, 'hidden_dimension': 219, 'number_of_hidden_layers': 1, 'dropout_rate': 0.38249803047714603, 'global_pooling': 'max', 'learning_rate': 0.0006097892718866461, 'weight_decay': 0.0007799728210399813, 'beta_0': 0.8145863028771109, 'beta_1': 0.9895294661719835, 'epsilon': 2.894054595209675e-08, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 17, 'plateau_patience': 12, 'plateau_divider': 6}. Best is trial 178 with value: 0.6309887944887639.
[I 2025-02-22 14:25:53,777] Trial 319 finished with value: 0.6095096811087786 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9683833237584595, 'batch_size': 50, 'attention_heads': 15, 'hidden_dimension': 75, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40607155392043337, 'global_pooling': 'max', 'learning_rate': 0.0005294292815961757, 'weight_decay': 0.0008862761935833478, 'beta_0': 0.8087168013613704, 'beta_1': 0.9863963265895743, 'epsilon': 1.2072552328225417e-08, 'balanced_loss': True, 'epochs': 122, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 178 with value: 0.6309887944887639.

[TRIAL] 178 [VALIDATION PERFORMANCE] 0.6309887944887639 [TRAINING LOSS] 0.02479329969818619 [VALIDATION LOSS] 2.146543089081259 

number                                     178
value                                 0.630989
params_threshold                      0.974101
params_attention_heads                      15
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           41
params_dropout_rate                   0.400851
params_early_stopping_patience              17
params_epochs                               88
params_global_pooling                      max
params_hidden_dimension                     60
params_learning_rate                  0.000841
params_number_of_hidden_layers               1
params_plateau_divider                       6
params_plateau_patience                     13
params_weight_decay                   0.000081
params_beta_0                         0.886658
params_beta_1                         0.990145
params_epsilon                             0.0
user_attrs_epoch                          27.0
user_attrs_training_loss              0.024793
user_attrs_validation_loss            2.146543
params_left_stride                         128
params_right_stride                        128
Name: 178, dtype: object
37 Val: 0.5952731237560495 Test: 0.5942386615675502
38 Val: 0.5855757370450402 Test: 0.5927642881377744
39 Val: 0.5995082375220682 Test: 0.619800836270746
40 Val: 0.6035495518853019 Test: 0.6375832757850175
41 Val: 0.6152747896815189 Test: 0.6252230784972628
42 Val: 0.6073294161635169 Test: 0.5928902395287244
43 Val: 0.5834639706568856 Test: 0.6136909073964858
44 Val: 0.6065557011218798 Test: 0.6114035839540789
45 Val: 0.6017531878256893 Test: 0.5963984453806671
46 Val: 0.5988301812414949 Test: 0.6222768811808512
Validation performance: 58.35 & 59.97 ± 0.97 & 61.53
Testing performance: 59.28 & 61.06 ± 1.59 & 63.76

[TRIAL] 104 [VALIDATION PERFORMANCE] 0.6257580154262087 [TRAINING LOSS] 0.018388478800521364 [VALIDATION LOSS] 2.21904388495854 

number                                     104
value                                 0.625758
params_threshold                      0.966263
params_attention_heads                      15
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           48
params_dropout_rate                   0.430458
params_early_stopping_patience              16
params_epochs                               77
params_global_pooling                      max
params_hidden_dimension                    129
params_learning_rate                  0.000577
params_number_of_hidden_layers               1
params_plateau_divider                       6
params_plateau_patience                     14
params_weight_decay                   0.000708
params_beta_0                          0.87326
params_beta_1                          0.98802
params_epsilon                             0.0
user_attrs_epoch                          23.0
user_attrs_training_loss              0.018388
user_attrs_validation_loss            2.219044
params_left_stride                         128
params_right_stride                        256
Name: 104, dtype: object
37 Val: 0.5864019444494514 Test: 0.6164193877147762
38 Val: 0.5989223969076007 Test: 0.6024745011080761
39 Val: 0.6116230414283169 Test: 0.623107439095409
40 Val: 0.5977444417848293 Test: 0.6098523947222587
41 Val: 0.6106173508950921 Test: 0.6306367152390315
42 Val: 0.6283818747946935 Test: 0.6157855332985328
43 Val: 0.5967951700863036 Test: 0.6044249209138819
slurmstepd: error: *** JOB 14947751 ON gpu009 CANCELLED AT 2025-02-22T19:11:39 DUE TO TIME LIMIT ***
