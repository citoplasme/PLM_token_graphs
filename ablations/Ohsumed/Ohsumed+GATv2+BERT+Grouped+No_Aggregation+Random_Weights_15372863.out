[I 2025-03-21 14:59:48,623] Using an existing study with name 'Ohsumed-GATv2-google-bert-bert-base-uncased-Grouped-No_Aggregation-Random_Weights-0.0-0.0' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors
[I 2025-03-21 15:17:16,817] Trial 93 finished with value: 0.6240538629118636 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8403908337852178, 'batch_size': 70, 'attention_heads': 13, 'hidden_dimension': 172, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4483584227003716, 'global_pooling': 'max', 'learning_rate': 0.0003449110801160815, 'weight_decay': 2.4380003254969343e-05, 'beta_0': 0.8107570759652568, 'beta_1': 0.9986058516758544, 'epsilon': 2.8379952327042688e-06, 'balanced_loss': False, 'epochs': 165, 'early_stopping_patience': 25, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 93 with value: 0.6240538629118636.
[I 2025-03-21 15:34:25,013] Trial 94 finished with value: 0.6086414721372906 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8376652106163734, 'batch_size': 70, 'attention_heads': 13, 'hidden_dimension': 176, 'number_of_hidden_layers': 1, 'dropout_rate': 0.45749157881399377, 'global_pooling': 'max', 'learning_rate': 0.0007448154329285245, 'weight_decay': 2.0423614854481413e-05, 'beta_0': 0.8094081558188949, 'beta_1': 0.9978158286420584, 'epsilon': 2.8008094544596866e-06, 'balanced_loss': False, 'epochs': 153, 'early_stopping_patience': 24, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 93 with value: 0.6240538629118636.
CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 648.69 MiB is free. Including non-PyTorch memory, this process has 43.92 GiB memory in use. Of the allocated memory 37.90 GiB is allocated by PyTorch, and 4.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-21 15:42:50,103] Trial 95 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.838641892917783, 'batch_size': 77, 'attention_heads': 13, 'hidden_dimension': 174, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4477900625987228, 'global_pooling': 'max', 'learning_rate': 0.0004758211345219215, 'weight_decay': 1.8426297747810097e-05, 'beta_0': 0.8120810928867955, 'beta_1': 0.9963966910169191, 'epsilon': 4.060283506143888e-06, 'balanced_loss': False, 'epochs': 154, 'early_stopping_patience': 24, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 93 with value: 0.6240538629118636.
CUDA out of memory. Tried to allocate 2.44 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.36 GiB is free. Including non-PyTorch memory, this process has 42.20 GiB memory in use. Of the allocated memory 38.54 GiB is allocated by PyTorch, and 2.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-21 15:51:13,957] Trial 96 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8305450803853488, 'batch_size': 69, 'attention_heads': 13, 'hidden_dimension': 176, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4564624598991165, 'global_pooling': 'max', 'learning_rate': 0.0007987647853873941, 'weight_decay': 1.243291697131217e-05, 'beta_0': 0.8071625404959376, 'beta_1': 0.9865915641172548, 'epsilon': 2.0844503895490383e-06, 'balanced_loss': False, 'epochs': 158, 'early_stopping_patience': 23, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 93 with value: 0.6240538629118636.
[I 2025-03-21 16:05:13,635] Trial 97 finished with value: 0.6101380667178621 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8219558139751809, 'batch_size': 70, 'attention_heads': 12, 'hidden_dimension': 170, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4728855757165088, 'global_pooling': 'max', 'learning_rate': 0.00075455573970282, 'weight_decay': 2.2257933871153182e-05, 'beta_0': 0.8092598100074712, 'beta_1': 0.9980348052548628, 'epsilon': 5.108033652963896e-06, 'balanced_loss': False, 'epochs': 180, 'early_stopping_patience': 16, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 93 with value: 0.6240538629118636.
CUDA out of memory. Tried to allocate 2.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.12 GiB is free. Including non-PyTorch memory, this process has 42.43 GiB memory in use. Of the allocated memory 39.01 GiB is allocated by PyTorch, and 2.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-21 16:13:10,521] Trial 98 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8237748347630897, 'batch_size': 70, 'attention_heads': 12, 'hidden_dimension': 185, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4461477951374735, 'global_pooling': 'max', 'learning_rate': 0.0007012355078405209, 'weight_decay': 2.4736755539387162e-05, 'beta_0': 0.8091887309680604, 'beta_1': 0.9978946606796578, 'epsilon': 5.342821399968831e-06, 'balanced_loss': False, 'epochs': 183, 'early_stopping_patience': 16, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 93 with value: 0.6240538629118636.
[I 2025-03-21 16:26:44,693] Trial 99 finished with value: 0.5854742327095709 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8399584914885614, 'batch_size': 67, 'attention_heads': 13, 'hidden_dimension': 200, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4861263171906729, 'global_pooling': 'max', 'learning_rate': 0.0013445164035646555, 'weight_decay': 1.4341619711348219e-05, 'beta_0': 0.8142310827886721, 'beta_1': 0.998458498664231, 'epsilon': 1.1135283389939805e-05, 'balanced_loss': False, 'epochs': 177, 'early_stopping_patience': 24, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 93 with value: 0.6240538629118636.
[I 2025-03-21 16:44:35,285] Trial 100 finished with value: 0.6162927719710192 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8445775099277586, 'batch_size': 76, 'attention_heads': 12, 'hidden_dimension': 190, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4732496217827875, 'global_pooling': 'max', 'learning_rate': 0.00033665158155137936, 'weight_decay': 8.865308764598578e-06, 'beta_0': 0.8172310161715238, 'beta_1': 0.9974312697502717, 'epsilon': 2.507815916825379e-06, 'balanced_loss': False, 'epochs': 189, 'early_stopping_patience': 23, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 93 with value: 0.6240538629118636.
CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.02 GiB is free. Including non-PyTorch memory, this process has 42.53 GiB memory in use. Of the allocated memory 38.75 GiB is allocated by PyTorch, and 2.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-21 16:52:34,287] Trial 101 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8211431927992492, 'batch_size': 77, 'attention_heads': 12, 'hidden_dimension': 179, 'number_of_hidden_layers': 1, 'dropout_rate': 0.47145937202911986, 'global_pooling': 'max', 'learning_rate': 0.00033193915551811646, 'weight_decay': 9.974357764071508e-06, 'beta_0': 0.8167920373743562, 'beta_1': 0.9939490903093637, 'epsilon': 3.102315581763744e-06, 'balanced_loss': False, 'epochs': 186, 'early_stopping_patience': 23, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 93 with value: 0.6240538629118636.
[I 2025-03-21 17:09:12,520] Trial 102 finished with value: 0.6360819998585139 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8460058004764209, 'batch_size': 73, 'attention_heads': 12, 'hidden_dimension': 196, 'number_of_hidden_layers': 1, 'dropout_rate': 0.47475618240508966, 'global_pooling': 'max', 'learning_rate': 0.0005386719121052289, 'weight_decay': 3.3414441307095585e-05, 'beta_0': 0.8209565992177353, 'beta_1': 0.9975311200429698, 'epsilon': 2.12456897843393e-06, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 22, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
CUDA out of memory. Tried to allocate 2.51 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.01 GiB is free. Including non-PyTorch memory, this process has 42.54 GiB memory in use. Of the allocated memory 38.87 GiB is allocated by PyTorch, and 2.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-21 17:17:10,449] Trial 103 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8335690572411265, 'batch_size': 81, 'attention_heads': 12, 'hidden_dimension': 189, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4611308517373819, 'global_pooling': 'max', 'learning_rate': 0.0004244608752947309, 'weight_decay': 3.326650995788426e-05, 'beta_0': 0.8126413509037278, 'beta_1': 0.9975626130776828, 'epsilon': 2.715861923825589e-06, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 22, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
CUDA out of memory. Tried to allocate 2.62 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.78 GiB is free. Including non-PyTorch memory, this process has 42.77 GiB memory in use. Of the allocated memory 38.93 GiB is allocated by PyTorch, and 2.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-21 17:25:07,928] Trial 104 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8448804888810453, 'batch_size': 72, 'attention_heads': 13, 'hidden_dimension': 209, 'number_of_hidden_layers': 1, 'dropout_rate': 0.45222220488412745, 'global_pooling': 'max', 'learning_rate': 0.0005626011089242127, 'weight_decay': 2.023582003318563e-05, 'beta_0': 0.8201385016899463, 'beta_1': 0.9968168667522583, 'epsilon': 4.72129568961046e-06, 'balanced_loss': False, 'epochs': 198, 'early_stopping_patience': 21, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 17:39:33,440] Trial 105 finished with value: 0.5900272750187697 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8371863293012174, 'batch_size': 76, 'attention_heads': 12, 'hidden_dimension': 171, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4752026129016589, 'global_pooling': 'max', 'learning_rate': 0.0010365389636845192, 'weight_decay': 7.731489682177785e-06, 'beta_0': 0.8041408362129272, 'beta_1': 0.9986018464587365, 'epsilon': 1.924494207400748e-06, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 16, 'plateau_patience': 24, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
CUDA out of memory. Tried to allocate 2.56 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.26 GiB is free. Including non-PyTorch memory, this process has 43.29 GiB memory in use. Of the allocated memory 39.45 GiB is allocated by PyTorch, and 2.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-21 17:47:28,545] Trial 106 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8308300405656355, 'batch_size': 84, 'attention_heads': 13, 'hidden_dimension': 193, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4706300643574092, 'global_pooling': 'max', 'learning_rate': 0.0007047662347899344, 'weight_decay': 1.7414672929656337e-05, 'beta_0': 0.816980837597623, 'beta_1': 0.9973556805480679, 'epsilon': 2.3590974009530945e-06, 'balanced_loss': False, 'epochs': 166, 'early_stopping_patience': 23, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 18:03:40,590] Trial 107 finished with value: 0.6237784059618616 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8445149805124497, 'batch_size': 73, 'attention_heads': 12, 'hidden_dimension': 195, 'number_of_hidden_layers': 1, 'dropout_rate': 0.49065373258769496, 'global_pooling': 'max', 'learning_rate': 0.0005372816891180658, 'weight_decay': 3.753871783612425e-05, 'beta_0': 0.8223956235752234, 'beta_1': 0.9978725842828623, 'epsilon': 6.191718549783674e-06, 'balanced_loss': False, 'epochs': 150, 'early_stopping_patience': 22, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 18:20:34,276] Trial 108 finished with value: 0.6145865129978418 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8470345445371708, 'batch_size': 73, 'attention_heads': 11, 'hidden_dimension': 200, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4904163969090223, 'global_pooling': 'max', 'learning_rate': 0.0005110397842809774, 'weight_decay': 3.9189265576703384e-05, 'beta_0': 0.8095131719345275, 'beta_1': 0.9979953585096657, 'epsilon': 7.223202714917294e-06, 'balanced_loss': False, 'epochs': 149, 'early_stopping_patience': 21, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 18:32:51,686] Trial 109 finished with value: 0.592394883255083 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.847915106882794, 'batch_size': 73, 'attention_heads': 11, 'hidden_dimension': 195, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4931096028693591, 'global_pooling': 'max', 'learning_rate': 0.000418968122827773, 'weight_decay': 2.2898343322648424e-05, 'beta_0': 0.8093218536378464, 'beta_1': 0.9979314291037443, 'epsilon': 5.969722003830905e-06, 'balanced_loss': False, 'epochs': 158, 'early_stopping_patience': 22, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.27 GiB is free. Including non-PyTorch memory, this process has 42.28 GiB memory in use. Of the allocated memory 38.42 GiB is allocated by PyTorch, and 2.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-21 18:41:14,504] Trial 110 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.8530836624128122, 'batch_size': 79, 'attention_heads': 12, 'hidden_dimension': 218, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4829636865083949, 'global_pooling': 'max', 'learning_rate': 0.0017030856823020916, 'weight_decay': 1.4145509641941795e-05, 'beta_0': 0.821861779300618, 'beta_1': 0.9985019725531807, 'epsilon': 1.54871928570964e-05, 'balanced_loss': False, 'epochs': 149, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
CUDA out of memory. Tried to allocate 2.63 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.68 GiB is free. Including non-PyTorch memory, this process has 42.88 GiB memory in use. Of the allocated memory 39.34 GiB is allocated by PyTorch, and 2.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-21 18:49:11,271] Trial 111 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8401587547722471, 'batch_size': 89, 'attention_heads': 11, 'hidden_dimension': 199, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5222902707955542, 'global_pooling': 'max', 'learning_rate': 0.0008027020039465182, 'weight_decay': 4.747693179158086e-06, 'beta_0': 0.8187666183975133, 'beta_1': 0.9964810519095708, 'epsilon': 7.8169080746541e-06, 'balanced_loss': False, 'epochs': 148, 'early_stopping_patience': 21, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.14 GiB is free. Including non-PyTorch memory, this process has 43.42 GiB memory in use. Of the allocated memory 39.33 GiB is allocated by PyTorch, and 2.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-21 18:57:49,945] Trial 112 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.843609002662581, 'batch_size': 84, 'attention_heads': 11, 'hidden_dimension': 208, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3513802320087346, 'global_pooling': 'sum', 'learning_rate': 0.00048128068938307797, 'weight_decay': 3.008963444001259e-05, 'beta_0': 0.8146759418586219, 'beta_1': 0.9981838449772429, 'epsilon': 4.142040503955374e-06, 'balanced_loss': False, 'epochs': 174, 'early_stopping_patience': 25, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
CUDA out of memory. Tried to allocate 2.46 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.43 GiB is free. Including non-PyTorch memory, this process has 42.12 GiB memory in use. Of the allocated memory 38.91 GiB is allocated by PyTorch, and 2.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-21 19:12:20,736] Trial 113 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.827613719209943, 'batch_size': 71, 'attention_heads': 12, 'hidden_dimension': 183, 'number_of_hidden_layers': 1, 'dropout_rate': 0.48439822481785766, 'global_pooling': 'max', 'learning_rate': 0.0005920993707419507, 'weight_decay': 4.1213678729513144e-05, 'beta_0': 0.8115398257517041, 'beta_1': 0.9979549342988024, 'epsilon': 1.038965701221864e-05, 'balanced_loss': False, 'epochs': 151, 'early_stopping_patience': 22, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 19:29:10,745] Trial 114 finished with value: 0.626254192564505 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8529202437250405, 'batch_size': 74, 'attention_heads': 12, 'hidden_dimension': 191, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4989918753092672, 'global_pooling': 'max', 'learning_rate': 0.0003226527654781974, 'weight_decay': 3.633701619099769e-05, 'beta_0': 0.8256109504457886, 'beta_1': 0.9977415268075019, 'epsilon': 6.6633663741660276e-06, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 19:46:10,765] Trial 115 finished with value: 0.6075525575876749 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8524946716250009, 'batch_size': 74, 'attention_heads': 12, 'hidden_dimension': 190, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5024525099863059, 'global_pooling': 'max', 'learning_rate': 0.00017732207118374013, 'weight_decay': 3.631463185094356e-05, 'beta_0': 0.8216851910992541, 'beta_1': 0.9985108329149162, 'epsilon': 6.624592222465384e-06, 'balanced_loss': False, 'epochs': 144, 'early_stopping_patience': 21, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 20:02:17,415] Trial 116 finished with value: 0.6200710823474509 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8634802308321894, 'batch_size': 67, 'attention_heads': 11, 'hidden_dimension': 203, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4931073831256455, 'global_pooling': 'max', 'learning_rate': 0.0002484311872273689, 'weight_decay': 2.6990914130182358e-05, 'beta_0': 0.8264055346407845, 'beta_1': 0.9970541243640823, 'epsilon': 3.054204549681143e-06, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 20, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 20:18:30,604] Trial 117 finished with value: 0.6101668602715214 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8614664619427771, 'batch_size': 67, 'attention_heads': 11, 'hidden_dimension': 205, 'number_of_hidden_layers': 1, 'dropout_rate': 0.49542558365355627, 'global_pooling': 'max', 'learning_rate': 0.0002585670227496316, 'weight_decay': 2.597645349544938e-05, 'beta_0': 0.8250223365516242, 'beta_1': 0.9971374216201387, 'epsilon': 8.720558562753084e-06, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 20, 'plateau_patience': 17, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 20:34:43,028] Trial 118 finished with value: 0.6165484625882506 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8604863591947955, 'batch_size': 67, 'attention_heads': 11, 'hidden_dimension': 202, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4906019543439648, 'global_pooling': 'max', 'learning_rate': 0.00023562201042146296, 'weight_decay': 4.890943763935716e-05, 'beta_0': 0.8267215682686968, 'beta_1': 0.9960483642497028, 'epsilon': 1.33607080174878e-05, 'balanced_loss': False, 'epochs': 189, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 20:49:59,549] Trial 119 finished with value: 0.6083602719280833 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8636079353675514, 'batch_size': 67, 'attention_heads': 10, 'hidden_dimension': 203, 'number_of_hidden_layers': 1, 'dropout_rate': 0.48907470565360733, 'global_pooling': 'max', 'learning_rate': 0.0002476283126647901, 'weight_decay': 5.2253938307117655e-05, 'beta_0': 0.8274158846311617, 'beta_1': 0.9961507771014593, 'epsilon': 1.8942633000866543e-05, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 20, 'plateau_patience': 17, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 21:05:19,341] Trial 120 finished with value: 0.6163883674601556 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8616445428227028, 'batch_size': 76, 'attention_heads': 11, 'hidden_dimension': 215, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5011176238321727, 'global_pooling': 'mean', 'learning_rate': 0.00033461159790829315, 'weight_decay': 3.136552149026973e-05, 'beta_0': 0.8252681658852252, 'beta_1': 0.9969175516022721, 'epsilon': 8.948293795793415e-06, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
CUDA out of memory. Tried to allocate 2.58 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.50 GiB is free. Including non-PyTorch memory, this process has 42.05 GiB memory in use. Of the allocated memory 38.30 GiB is allocated by PyTorch, and 2.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-21 21:20:20,444] Trial 121 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8474526053687236, 'batch_size': 77, 'attention_heads': 11, 'hidden_dimension': 216, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5010953686689265, 'global_pooling': 'mean', 'learning_rate': 0.00032938079906468106, 'weight_decay': 3.232687713669608e-05, 'beta_0': 0.8264665080364346, 'beta_1': 0.9965582899680169, 'epsilon': 1.6210794289113545e-05, 'balanced_loss': False, 'epochs': 199, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 21:35:36,064] Trial 122 finished with value: 0.6199237147079976 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8577955482567899, 'batch_size': 81, 'attention_heads': 10, 'hidden_dimension': 226, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4791276116366769, 'global_pooling': 'mean', 'learning_rate': 0.0002974645700402718, 'weight_decay': 1.6478405689185243e-06, 'beta_0': 0.8296405845764724, 'beta_1': 0.9956985205794459, 'epsilon': 1.0151530637631435e-05, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 21:52:29,809] Trial 123 finished with value: 0.6190694563513924 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8511948941458989, 'batch_size': 80, 'attention_heads': 10, 'hidden_dimension': 227, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4901825427089445, 'global_pooling': 'mean', 'learning_rate': 0.00018354097152655289, 'weight_decay': 1.0005072453856697e-06, 'beta_0': 0.8289150218765647, 'beta_1': 0.9954318872288241, 'epsilon': 1.091391753584075e-05, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 22:09:25,174] Trial 124 finished with value: 0.6136206464695269 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8572413351101089, 'batch_size': 80, 'attention_heads': 10, 'hidden_dimension': 225, 'number_of_hidden_layers': 1, 'dropout_rate': 0.48038516567883294, 'global_pooling': 'mean', 'learning_rate': 0.00018529756760964972, 'weight_decay': 1.0646855410401815e-06, 'beta_0': 0.8286579888169422, 'beta_1': 0.9955560395896861, 'epsilon': 1.336434614648947e-05, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 22:26:17,958] Trial 125 finished with value: 0.6047718276763883 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8767396894141065, 'batch_size': 74, 'attention_heads': 11, 'hidden_dimension': 245, 'number_of_hidden_layers': 1, 'dropout_rate': 0.48836861527850983, 'global_pooling': 'mean', 'learning_rate': 0.00021921940267043244, 'weight_decay': 1.401453749015921e-06, 'beta_0': 0.8301367931674055, 'beta_1': 0.995811435791783, 'epsilon': 8.898390567917841e-06, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 22:40:54,077] Trial 126 finished with value: 0.6096019125254262 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8639970212007061, 'batch_size': 80, 'attention_heads': 10, 'hidden_dimension': 212, 'number_of_hidden_layers': 1, 'dropout_rate': 0.49297074533820634, 'global_pooling': 'mean', 'learning_rate': 0.0003663276774168159, 'weight_decay': 2.006821862717277e-06, 'beta_0': 0.824774266032729, 'beta_1': 0.9952557907627477, 'epsilon': 2.205919071215278e-05, 'balanced_loss': False, 'epochs': 186, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 22:57:21,581] Trial 127 finished with value: 0.6088418298393156 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8583185070870841, 'batch_size': 83, 'attention_heads': 11, 'hidden_dimension': 228, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4819923640577898, 'global_pooling': 'mean', 'learning_rate': 0.0003070778105490588, 'weight_decay': 1.988354585324387e-06, 'beta_0': 0.8180188714198006, 'beta_1': 0.9968324500374246, 'epsilon': 1.2189924223225083e-05, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 20, 'plateau_patience': 14, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 23:12:01,839] Trial 128 finished with value: 0.6003075371176884 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8458854690597599, 'batch_size': 86, 'attention_heads': 10, 'hidden_dimension': 198, 'number_of_hidden_layers': 1, 'dropout_rate': 0.47725203392389354, 'global_pooling': 'mean', 'learning_rate': 0.00039595776368931546, 'weight_decay': 1.0005519890486601e-06, 'beta_0': 0.8206800004063225, 'beta_1': 0.995940888761773, 'epsilon': 7.330776345973864e-06, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 23:29:15,193] Trial 129 finished with value: 0.6036043434236692 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8418942151524754, 'batch_size': 78, 'attention_heads': 10, 'hidden_dimension': 220, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5026659336257693, 'global_pooling': 'mean', 'learning_rate': 0.0001395303360552458, 'weight_decay': 1.5717058037228284e-06, 'beta_0': 0.8237565975855418, 'beta_1': 0.99195922648419, 'epsilon': 3.962926498663112e-06, 'balanced_loss': False, 'epochs': 182, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-21 23:45:10,565] Trial 130 finished with value: 0.6109474397273782 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.850870422138454, 'batch_size': 75, 'attention_heads': 11, 'hidden_dimension': 193, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5075650491131244, 'global_pooling': 'mean', 'learning_rate': 0.00028859610944889554, 'weight_decay': 2.4928230730913612e-06, 'beta_0': 0.8151879937242511, 'beta_1': 0.9930577361162305, 'epsilon': 1.0069512556489805e-05, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 18, 'plateau_patience': 16, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 00:02:31,546] Trial 131 finished with value: 0.6300405128857146 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8546864922738081, 'batch_size': 72, 'attention_heads': 11, 'hidden_dimension': 211, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4865787752122318, 'global_pooling': 'mean', 'learning_rate': 0.00022282979596496095, 'weight_decay': 3.885351253604256e-05, 'beta_0': 0.822681862274776, 'beta_1': 0.9942927585490396, 'epsilon': 5.535327062866643e-06, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 00:18:56,586] Trial 132 finished with value: 0.5462142354238501 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.8599816816510837, 'batch_size': 76, 'attention_heads': 11, 'hidden_dimension': 209, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4977767234248793, 'global_pooling': 'mean', 'learning_rate': 0.0001867847395892952, 'weight_decay': 3.2428360068989045e-06, 'beta_0': 0.8229071411396237, 'beta_1': 0.9950572088204306, 'epsilon': 2.9411647922859272e-05, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 00:35:41,727] Trial 133 finished with value: 0.6105505472172054 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8549371129350866, 'batch_size': 72, 'attention_heads': 11, 'hidden_dimension': 229, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4905449864443867, 'global_pooling': 'mean', 'learning_rate': 0.00022776645456857643, 'weight_decay': 3.79363043876109e-05, 'beta_0': 0.8260175072087187, 'beta_1': 0.9943532790154133, 'epsilon': 6.654230579362843e-06, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 00:52:10,250] Trial 134 finished with value: 0.6203100081774965 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8478586852917618, 'batch_size': 73, 'attention_heads': 12, 'hidden_dimension': 205, 'number_of_hidden_layers': 1, 'dropout_rate': 0.48576302143929256, 'global_pooling': 'mean', 'learning_rate': 0.0003915510565642543, 'weight_decay': 4.8669721445427004e-05, 'beta_0': 0.8195887831895041, 'beta_1': 0.9963110678189376, 'epsilon': 1.3854469873911464e-05, 'balanced_loss': False, 'epochs': 185, 'early_stopping_patience': 21, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 01:09:10,061] Trial 135 finished with value: 0.6143739661722296 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8517557262536201, 'batch_size': 68, 'attention_heads': 12, 'hidden_dimension': 205, 'number_of_hidden_layers': 1, 'dropout_rate': 0.47595088601205726, 'global_pooling': 'mean', 'learning_rate': 0.0003226700693846329, 'weight_decay': 4.839394471331938e-05, 'beta_0': 0.818110210916013, 'beta_1': 0.9962800034985102, 'epsilon': 3.5945732298475535e-06, 'balanced_loss': False, 'epochs': 184, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 01:23:16,732] Trial 136 finished with value: 0.6211558647464781 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8706969003426315, 'batch_size': 79, 'attention_heads': 9, 'hidden_dimension': 240, 'number_of_hidden_layers': 1, 'dropout_rate': 0.48430354832085004, 'global_pooling': 'mean', 'learning_rate': 0.0003942521739788439, 'weight_decay': 5.573348533137604e-05, 'beta_0': 0.820466207773903, 'beta_1': 0.9968734976133827, 'epsilon': 1.968508565290617e-05, 'balanced_loss': False, 'epochs': 189, 'early_stopping_patience': 20, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 01:37:24,551] Trial 137 finished with value: 0.6083691204141626 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8705917462395575, 'batch_size': 81, 'attention_heads': 9, 'hidden_dimension': 236, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4857701616614992, 'global_pooling': 'mean', 'learning_rate': 0.0004192997628301864, 'weight_decay': 5.525115722051471e-05, 'beta_0': 0.821472847171546, 'beta_1': 0.9955609660000376, 'epsilon': 3.815909469634434e-05, 'balanced_loss': False, 'epochs': 179, 'early_stopping_patience': 20, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 01:53:02,733] Trial 138 finished with value: 0.618039840848377 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.86481407043506, 'batch_size': 78, 'attention_heads': 9, 'hidden_dimension': 248, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5084541246827724, 'global_pooling': 'mean', 'learning_rate': 0.00015391440134760728, 'weight_decay': 3.042936394466281e-05, 'beta_0': 0.8282200616845417, 'beta_1': 0.9905840386188667, 'epsilon': 5.869356981763297e-06, 'balanced_loss': False, 'epochs': 171, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 02:09:03,552] Trial 139 finished with value: 0.6046237282048842 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8740577028813817, 'batch_size': 78, 'attention_heads': 9, 'hidden_dimension': 247, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5102935247457677, 'global_pooling': 'mean', 'learning_rate': 0.00012586004301640795, 'weight_decay': 5.7781921250618733e-05, 'beta_0': 0.828540981048033, 'beta_1': 0.9906134059861827, 'epsilon': 1.965011675209187e-05, 'balanced_loss': False, 'epochs': 193, 'early_stopping_patience': 21, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 02:25:42,694] Trial 140 finished with value: 0.6157701950072519 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.864437121320439, 'batch_size': 89, 'attention_heads': 9, 'hidden_dimension': 251, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4942596447810689, 'global_pooling': 'mean', 'learning_rate': 0.00021868544076284512, 'weight_decay': 3.5863679582705416e-05, 'beta_0': 0.8312350053772452, 'beta_1': 0.994535932314239, 'epsilon': 1.3149374622771078e-05, 'balanced_loss': False, 'epochs': 171, 'early_stopping_patience': 20, 'plateau_patience': 18, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 02:42:09,920] Trial 141 finished with value: 0.6099411243614514 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.856237915137221, 'batch_size': 94, 'attention_heads': 9, 'hidden_dimension': 238, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4629743551745136, 'global_pooling': 'mean', 'learning_rate': 0.00014850701521114577, 'weight_decay': 1.6547117845291465e-06, 'beta_0': 0.8234250857510904, 'beta_1': 0.9937709621550329, 'epsilon': 5.5014131193023935e-06, 'balanced_loss': False, 'epochs': 185, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 02:58:26,366] Trial 142 finished with value: 0.615606224103231 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8681010949524437, 'batch_size': 72, 'attention_heads': 10, 'hidden_dimension': 222, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5172922850464075, 'global_pooling': 'mean', 'learning_rate': 0.00016119701721440115, 'weight_decay': 4.8483719882155775e-05, 'beta_0': 0.8271335149161151, 'beta_1': 0.9869309562747015, 'epsilon': 1.4383912512953828e-05, 'balanced_loss': False, 'epochs': 173, 'early_stopping_patience': 21, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 03:12:40,488] Trial 143 finished with value: 0.6038734873149496 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8597916360748852, 'batch_size': 79, 'attention_heads': 10, 'hidden_dimension': 216, 'number_of_hidden_layers': 1, 'dropout_rate': 0.49649201121786934, 'global_pooling': 'mean', 'learning_rate': 0.00026597338322637416, 'weight_decay': 3.0982158704771204e-05, 'beta_0': 0.8252090987358823, 'beta_1': 0.9969506234701621, 'epsilon': 1.0599950071285963e-05, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 18, 'plateau_patience': 15, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 03:28:16,089] Trial 144 finished with value: 0.5971164259477889 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8653764215724232, 'batch_size': 82, 'attention_heads': 12, 'hidden_dimension': 212, 'number_of_hidden_layers': 1, 'dropout_rate': 0.48288611075305105, 'global_pooling': 'mean', 'learning_rate': 0.00039640933222025463, 'weight_decay': 2.896363762339252e-05, 'beta_0': 0.8204316592427924, 'beta_1': 0.9960817228000486, 'epsilon': 4.3765898510877715e-06, 'balanced_loss': False, 'epochs': 196, 'early_stopping_patience': 19, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
CUDA out of memory. Tried to allocate 2.39 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.36 GiB is free. Including non-PyTorch memory, this process has 42.20 GiB memory in use. Of the allocated memory 36.32 GiB is allocated by PyTorch, and 4.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-22 03:41:51,827] Trial 145 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8529339115159602, 'batch_size': 74, 'attention_heads': 12, 'hidden_dimension': 229, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5108403149816756, 'global_pooling': 'mean', 'learning_rate': 0.00019459859535471207, 'weight_decay': 4.1573564778992836e-05, 'beta_0': 0.8296728176473313, 'beta_1': 0.9966393658801325, 'epsilon': 9.365119561559806e-06, 'balanced_loss': False, 'epochs': 159, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 03:59:03,614] Trial 146 finished with value: 0.616453206191968 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8616506162245557, 'batch_size': 69, 'attention_heads': 11, 'hidden_dimension': 243, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5044787939261092, 'global_pooling': 'mean', 'learning_rate': 0.00024920632402824843, 'weight_decay': 3.2988219705434974e-05, 'beta_0': 0.8193945831542644, 'beta_1': 0.9845124960725558, 'epsilon': 3.0754966360532124e-06, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 20, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 04:15:41,375] Trial 147 finished with value: 0.603959689703548 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8483216677355845, 'batch_size': 65, 'attention_heads': 9, 'hidden_dimension': 255, 'number_of_hidden_layers': 1, 'dropout_rate': 0.48718591234871944, 'global_pooling': 'mean', 'learning_rate': 0.0002426533484247548, 'weight_decay': 2.628749678534917e-05, 'beta_0': 0.8198928267025983, 'beta_1': 0.9950483862608229, 'epsilon': 3.365362741325424e-06, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 20, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 04:32:06,274] Trial 148 finished with value: 0.5887971527073783 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8584338673089692, 'batch_size': 68, 'attention_heads': 9, 'hidden_dimension': 241, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5065908474612595, 'global_pooling': 'mean', 'learning_rate': 0.00011891327155226962, 'weight_decay': 3.5574411542341575e-05, 'beta_0': 0.8139365363411379, 'beta_1': 0.9847798968531053, 'epsilon': 5.89640228083334e-06, 'balanced_loss': False, 'epochs': 193, 'early_stopping_patience': 20, 'plateau_patience': 18, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.15 GiB is free. Including non-PyTorch memory, this process has 42.41 GiB memory in use. Of the allocated memory 38.59 GiB is allocated by PyTorch, and 2.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-22 04:41:26,022] Trial 149 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8411056648756403, 'batch_size': 70, 'attention_heads': 10, 'hidden_dimension': 250, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5247022361485352, 'global_pooling': 'mean', 'learning_rate': 0.00017184566117048152, 'weight_decay': 4.477982830314449e-05, 'beta_0': 0.8156232835298529, 'beta_1': 0.9877362838000523, 'epsilon': 2.1845570013371763e-06, 'balanced_loss': False, 'epochs': 180, 'early_stopping_patience': 21, 'plateau_patience': 11, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
CUDA out of memory. Tried to allocate 2.65 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.43 GiB is free. Including non-PyTorch memory, this process has 42.12 GiB memory in use. Of the allocated memory 38.33 GiB is allocated by PyTorch, and 2.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-22 04:57:43,663] Trial 150 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8548583416144053, 'batch_size': 63, 'attention_heads': 13, 'hidden_dimension': 233, 'number_of_hidden_layers': 1, 'dropout_rate': 0.47780832429327047, 'global_pooling': 'mean', 'learning_rate': 0.0002837815305802002, 'weight_decay': 5.9732339695299494e-05, 'beta_0': 0.8222215841213538, 'beta_1': 0.9839745131054151, 'epsilon': 3.071269183552928e-06, 'balanced_loss': False, 'epochs': 168, 'early_stopping_patience': 20, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 05:15:42,827] Trial 151 finished with value: 0.6163114278630506 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8714079647802714, 'batch_size': 69, 'attention_heads': 12, 'hidden_dimension': 239, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4914776898662563, 'global_pooling': 'mean', 'learning_rate': 0.00021972749648478204, 'weight_decay': 1.2387415654927252e-06, 'beta_0': 0.8188635187478401, 'beta_1': 0.9933061012057172, 'epsilon': 1.875372678121264e-05, 'balanced_loss': False, 'epochs': 177, 'early_stopping_patience': 21, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 05:30:48,828] Trial 152 finished with value: 0.6092698031776134 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8349217871949223, 'batch_size': 85, 'attention_heads': 10, 'hidden_dimension': 185, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4679027875515393, 'global_pooling': 'mean', 'learning_rate': 0.0005035120257398628, 'weight_decay': 3.8881091433972714e-05, 'beta_0': 0.8322554971581948, 'beta_1': 0.9899455513194021, 'epsilon': 1.7028019969182776e-06, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 05:45:45,369] Trial 153 finished with value: 0.6256238011212789 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8628593994727689, 'batch_size': 72, 'attention_heads': 11, 'hidden_dimension': 201, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5025881358711746, 'global_pooling': 'mean', 'learning_rate': 0.00037748223775468, 'weight_decay': 3.025673834156195e-05, 'beta_0': 0.8242140630902316, 'beta_1': 0.9974472865172225, 'epsilon': 7.942965758617562e-06, 'balanced_loss': False, 'epochs': 162, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 06:00:50,800] Trial 154 finished with value: 0.6151876093188099 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8504592152289772, 'batch_size': 73, 'attention_heads': 11, 'hidden_dimension': 196, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5036744375394142, 'global_pooling': 'mean', 'learning_rate': 0.00039812522009201155, 'weight_decay': 2.480038279492961e-05, 'beta_0': 0.823425004700728, 'beta_1': 0.997437776893803, 'epsilon': 4.5343021720936714e-06, 'balanced_loss': False, 'epochs': 161, 'early_stopping_patience': 19, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 06:16:50,096] Trial 155 finished with value: 0.6158277300540783 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8615944393127831, 'batch_size': 66, 'attention_heads': 11, 'hidden_dimension': 202, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5975021424468195, 'global_pooling': 'mean', 'learning_rate': 0.0002755756940223659, 'weight_decay': 3.3090267487252884e-05, 'beta_0': 0.8283721576446609, 'beta_1': 0.9854885209695817, 'epsilon': 7.558263328926798e-06, 'balanced_loss': False, 'epochs': 162, 'early_stopping_patience': 18, 'plateau_patience': 16, 'plateau_divider': 9}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 06:33:17,453] Trial 156 finished with value: 0.6308643554784598 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8667778296778842, 'batch_size': 71, 'attention_heads': 11, 'hidden_dimension': 244, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5164601750155909, 'global_pooling': 'mean', 'learning_rate': 0.0006201984514081067, 'weight_decay': 2.8216257984889994e-05, 'beta_0': 0.8268854190703053, 'beta_1': 0.9971597838328528, 'epsilon': 1.168530677356423e-05, 'balanced_loss': False, 'epochs': 187, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
[I 2025-03-22 06:49:05,828] Trial 157 finished with value: 0.627780784127124 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8678275165595295, 'batch_size': 71, 'attention_heads': 12, 'hidden_dimension': 210, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5357915527667363, 'global_pooling': 'mean', 'learning_rate': 0.00047164410444110633, 'weight_decay': 2.883721211609378e-05, 'beta_0': 0.8272848664073503, 'beta_1': 0.9971616185469141, 'epsilon': 1.2291185202682125e-05, 'balanced_loss': False, 'epochs': 182, 'early_stopping_patience': 22, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 102 with value: 0.6360819998585139.
slurmstepd: error: *** JOB 15372863 ON gpu039 CANCELLED AT 2025-03-22T06:59:48 DUE TO TIME LIMIT ***
