[I 2025-02-22 03:11:37,148] Using an existing study with name 'Ohsumed-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-Random_Weights-0.0-0.0' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors
[I 2025-02-22 03:34:13,644] Trial 276 finished with value: 0.597478538286417 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9720801521589053, 'batch_size': 63, 'attention_heads': 8, 'hidden_dimension': 247, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4284973179710864, 'global_pooling': 'mean', 'learning_rate': 0.0004934013824057034, 'weight_decay': 1.5541662283739062e-06, 'beta_0': 0.8034965386995478, 'beta_1': 0.993673983914228, 'epsilon': 6.748603865553811e-08, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 03:55:51,074] Trial 277 finished with value: 0.5490056723736056 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9813412202031704, 'batch_size': 74, 'attention_heads': 7, 'hidden_dimension': 252, 'number_of_hidden_layers': 2, 'dropout_rate': 0.45759115510303155, 'global_pooling': 'mean', 'learning_rate': 0.00024652466920986127, 'weight_decay': 0.00011799808756836012, 'beta_0': 0.8113187837766732, 'beta_1': 0.9941830336274475, 'epsilon': 1.1181947846609476e-07, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 04:17:00,996] Trial 278 finished with value: 0.6099813674021577 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9701209609091134, 'batch_size': 69, 'attention_heads': 7, 'hidden_dimension': 236, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4443368987808616, 'global_pooling': 'mean', 'learning_rate': 0.0006626271791093684, 'weight_decay': 0.00014433919090732004, 'beta_0': 0.8075210851872329, 'beta_1': 0.9902353560071093, 'epsilon': 2.470717888451192e-08, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 20, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.63 GiB is free. Including non-PyTorch memory, this process has 42.92 GiB memory in use. Of the allocated memory 40.60 GiB is allocated by PyTorch, and 1.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 04:34:29,815] Trial 279 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9661525604024233, 'batch_size': 69, 'attention_heads': 7, 'hidden_dimension': 231, 'number_of_hidden_layers': 2, 'dropout_rate': 0.44263824784613914, 'global_pooling': 'mean', 'learning_rate': 0.0008379316784310054, 'weight_decay': 0.00016803042171144327, 'beta_0': 0.8066115569176301, 'beta_1': 0.9910796471077812, 'epsilon': 2.219062632786713e-08, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 20, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
CUDA out of memory. Tried to allocate 1.62 GiB. GPU 0 has a total capacity of 44.56 GiB of which 624.69 MiB is free. Including non-PyTorch memory, this process has 43.94 GiB memory in use. Of the allocated memory 41.71 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 04:46:33,215] Trial 280 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9615915084051091, 'batch_size': 71, 'attention_heads': 7, 'hidden_dimension': 236, 'number_of_hidden_layers': 2, 'dropout_rate': 0.44738197739433555, 'global_pooling': 'mean', 'learning_rate': 0.0001680398520169469, 'weight_decay': 0.00015140687059244835, 'beta_0': 0.807788054763312, 'beta_1': 0.9924856912418992, 'epsilon': 2.9682840212043337e-08, 'balanced_loss': True, 'epochs': 107, 'early_stopping_patience': 23, 'plateau_patience': 11, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 05:07:54,755] Trial 281 finished with value: 0.6033552850921015 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9702800029317523, 'batch_size': 65, 'attention_heads': 7, 'hidden_dimension': 239, 'number_of_hidden_layers': 2, 'dropout_rate': 0.46529583900135246, 'global_pooling': 'mean', 'learning_rate': 0.0006930384005728279, 'weight_decay': 0.00014064707642402407, 'beta_0': 0.8054437858513761, 'beta_1': 0.9981674244543272, 'epsilon': 2.009919031673284e-08, 'balanced_loss': True, 'epochs': 103, 'early_stopping_patience': 20, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 05:28:16,047] Trial 282 finished with value: 0.5963767701553436 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9763709410645091, 'batch_size': 67, 'attention_heads': 7, 'hidden_dimension': 243, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4534788566716326, 'global_pooling': 'mean', 'learning_rate': 0.00063960738984633, 'weight_decay': 0.00010409198000730845, 'beta_0': 0.8093096483120531, 'beta_1': 0.990216372819058, 'epsilon': 3.4018954406578806e-08, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 20, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.59 GiB is free. Including non-PyTorch memory, this process has 42.96 GiB memory in use. Of the allocated memory 40.73 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 05:43:03,512] Trial 283 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9681282584220499, 'batch_size': 70, 'attention_heads': 8, 'hidden_dimension': 230, 'number_of_hidden_layers': 2, 'dropout_rate': 0.43716973756282645, 'global_pooling': 'mean', 'learning_rate': 0.0008914141480116786, 'weight_decay': 0.00012016204653497987, 'beta_0': 0.8040140551268568, 'beta_1': 0.9948880370972221, 'epsilon': 2.408114437730566e-08, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 21, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 06:01:09,590] Trial 284 finished with value: 0.5757551053279711 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9854996056121508, 'batch_size': 68, 'attention_heads': 7, 'hidden_dimension': 237, 'number_of_hidden_layers': 2, 'dropout_rate': 0.42150799324526395, 'global_pooling': 'mean', 'learning_rate': 0.001305936408554536, 'weight_decay': 8.78736329445622e-05, 'beta_0': 0.8077767323735743, 'beta_1': 0.9940079822142005, 'epsilon': 1.2276177383873468e-08, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 22, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 06:20:56,158] Trial 285 finished with value: 0.572187510923014 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.980163509445693, 'batch_size': 76, 'attention_heads': 7, 'hidden_dimension': 245, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4437245780239489, 'global_pooling': 'mean', 'learning_rate': 0.0005767130057609342, 'weight_decay': 1.932351672371438e-06, 'beta_0': 0.8106650459441949, 'beta_1': 0.9986140967127081, 'epsilon': 1.480023205937956e-08, 'balanced_loss': True, 'epochs': 122, 'early_stopping_patience': 20, 'plateau_patience': 11, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 06:44:52,702] Trial 286 finished with value: 0.5877344300283618 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9734252075596879, 'batch_size': 73, 'attention_heads': 9, 'hidden_dimension': 242, 'number_of_hidden_layers': 2, 'dropout_rate': 0.430397549711943, 'global_pooling': 'mean', 'learning_rate': 0.00032280418731302674, 'weight_decay': 2.1847329839564276e-06, 'beta_0': 0.8014638647824721, 'beta_1': 0.9893713688325384, 'epsilon': 4.271617165531123e-08, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 21, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
CUDA out of memory. Tried to allocate 1.62 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 43.10 GiB memory in use. Of the allocated memory 40.60 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 06:57:24,683] Trial 287 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9591993810927628, 'batch_size': 70, 'attention_heads': 7, 'hidden_dimension': 249, 'number_of_hidden_layers': 2, 'dropout_rate': 0.457302467481953, 'global_pooling': 'mean', 'learning_rate': 0.00042764052146380163, 'weight_decay': 0.00013306092610675582, 'beta_0': 0.8061843159837485, 'beta_1': 0.9979370575638373, 'epsilon': 1.341196069606771e-06, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 07:17:34,858] Trial 288 finished with value: 0.5980191927564273 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.976209005093466, 'batch_size': 64, 'attention_heads': 7, 'hidden_dimension': 235, 'number_of_hidden_layers': 2, 'dropout_rate': 0.45097166311521164, 'global_pooling': 'max', 'learning_rate': 0.000846651686729974, 'weight_decay': 1.6568895094852871e-06, 'beta_0': 0.808611703308438, 'beta_1': 0.9914238717907788, 'epsilon': 2.631596764110395e-08, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 20, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
CUDA out of memory. Tried to allocate 2.89 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.19 GiB is free. Including non-PyTorch memory, this process has 42.36 GiB memory in use. Of the allocated memory 38.52 GiB is allocated by PyTorch, and 2.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 07:30:06,830] Trial 289 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9692656723955296, 'batch_size': 74, 'attention_heads': 15, 'hidden_dimension': 256, 'number_of_hidden_layers': 2, 'dropout_rate': 0.47095450701915725, 'global_pooling': 'max', 'learning_rate': 0.001002950781585231, 'weight_decay': 2.9957567126289117e-06, 'beta_0': 0.8032268254508028, 'beta_1': 0.9946158604845482, 'epsilon': 5.980902754895296e-08, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 21, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 07:47:57,575] Trial 290 finished with value: 0.6170642707807419 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9639927597002335, 'batch_size': 68, 'attention_heads': 8, 'hidden_dimension': 120, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4622072782333, 'global_pooling': 'mean', 'learning_rate': 0.0006546213963809599, 'weight_decay': 8.972709242399819e-05, 'beta_0': 0.811541373831557, 'beta_1': 0.9933763228789068, 'epsilon': 2.007632316812928e-08, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 21, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 08:22:13,360] Trial 291 finished with value: 0.3906842860939671 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9539987449539049, 'batch_size': 67, 'attention_heads': 7, 'hidden_dimension': 112, 'number_of_hidden_layers': 2, 'dropout_rate': 0.44701550397981543, 'global_pooling': 'max', 'learning_rate': 1.0993032231668202e-05, 'weight_decay': 8.19815388484908e-05, 'beta_0': 0.8118155789347916, 'beta_1': 0.9934617681875781, 'epsilon': 1.7488162105019988e-08, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 19, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 08:46:48,328] Trial 292 finished with value: 0.6098741637809318 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9649524583990168, 'batch_size': 65, 'attention_heads': 7, 'hidden_dimension': 154, 'number_of_hidden_layers': 2, 'dropout_rate': 0.43906805964193135, 'global_pooling': 'max', 'learning_rate': 0.0006651478815066364, 'weight_decay': 2.384558842307991e-06, 'beta_0': 0.8124673934428956, 'beta_1': 0.9920378091424676, 'epsilon': 1.9138874490716828e-08, 'balanced_loss': True, 'epochs': 120, 'early_stopping_patience': 20, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 09:08:48,020] Trial 293 finished with value: 0.5956927941173464 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9616485818153001, 'batch_size': 62, 'attention_heads': 6, 'hidden_dimension': 131, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4383867615313512, 'global_pooling': 'max', 'learning_rate': 0.0007455621084171772, 'weight_decay': 2.3175659137248382e-06, 'beta_0': 0.8117841428657678, 'beta_1': 0.9899115789357594, 'epsilon': 2.1027731958550418e-08, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 20, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 09:30:47,923] Trial 294 finished with value: 0.5612447154745388 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.964783147407945, 'batch_size': 65, 'attention_heads': 7, 'hidden_dimension': 110, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4304873921961346, 'global_pooling': 'mean', 'learning_rate': 0.0017609990329998377, 'weight_decay': 2.6518732684170138e-06, 'beta_0': 0.8137863518838527, 'beta_1': 0.9927181238229638, 'epsilon': 1.986625846661957e-08, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 20, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 09:54:45,843] Trial 295 finished with value: 0.575876836609402 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9656593439281944, 'batch_size': 68, 'attention_heads': 7, 'hidden_dimension': 150, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4418441474478392, 'global_pooling': 'max', 'learning_rate': 0.001147114712536031, 'weight_decay': 1.9429644723184325e-06, 'beta_0': 0.8103065269885095, 'beta_1': 0.99303478343354, 'epsilon': 1.4594022651839811e-08, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 21, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 10:16:18,688] Trial 296 finished with value: 0.5965097678729951 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9612451009535868, 'batch_size': 64, 'attention_heads': 7, 'hidden_dimension': 83, 'number_of_hidden_layers': 2, 'dropout_rate': 0.46088842909585515, 'global_pooling': 'max', 'learning_rate': 0.0006997167889406157, 'weight_decay': 2.414770338572442e-06, 'beta_0': 0.812034087204926, 'beta_1': 0.9920873173582672, 'epsilon': 2.4386122512249064e-08, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 20, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
CUDA out of memory. Tried to allocate 1.75 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.59 GiB is free. Including non-PyTorch memory, this process has 42.96 GiB memory in use. Of the allocated memory 40.54 GiB is allocated by PyTorch, and 1.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 10:29:26,062] Trial 297 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9681479875207585, 'batch_size': 66, 'attention_heads': 8, 'hidden_dimension': 248, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4344788615219225, 'global_pooling': 'mean', 'learning_rate': 0.0005642119072406695, 'weight_decay': 3.457878898345659e-06, 'beta_0': 0.8097771839573374, 'beta_1': 0.991642611676663, 'epsilon': 3.370007809744187e-08, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 20, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
CUDA out of memory. Tried to allocate 2.86 GiB. GPU 0 has a total capacity of 44.56 GiB of which 492.69 MiB is free. Including non-PyTorch memory, this process has 44.07 GiB memory in use. Of the allocated memory 39.87 GiB is allocated by PyTorch, and 3.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 10:46:24,339] Trial 298 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9568722436927721, 'batch_size': 62, 'attention_heads': 14, 'hidden_dimension': 242, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4471493960599906, 'global_pooling': 'max', 'learning_rate': 0.00021089017120307186, 'weight_decay': 1.0078771813724373e-06, 'beta_0': 0.812903352511861, 'beta_1': 0.9934276840472334, 'epsilon': 1.6238775409793182e-08, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 21, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 138.69 MiB is free. Including non-PyTorch memory, this process has 44.42 GiB memory in use. Of the allocated memory 42.24 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 10:58:35,054] Trial 299 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8695337235197207, 'batch_size': 68, 'attention_heads': 6, 'hidden_dimension': 245, 'number_of_hidden_layers': 2, 'dropout_rate': 0.44132871533390955, 'global_pooling': 'max', 'learning_rate': 0.01797522755588587, 'weight_decay': 1.86866095457056e-06, 'beta_0': 0.8057940085239051, 'beta_1': 0.993159714041311, 'epsilon': 1.146545679863872e-08, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 22, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 11:15:43,425] Trial 300 finished with value: 0.614523623775416 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9721343319708897, 'batch_size': 69, 'attention_heads': 9, 'hidden_dimension': 99, 'number_of_hidden_layers': 2, 'dropout_rate': 0.47655855821696497, 'global_pooling': 'max', 'learning_rate': 0.0010185181124942471, 'weight_decay': 1.5579594871397368e-06, 'beta_0': 0.8084952702455388, 'beta_1': 0.9924459181392463, 'epsilon': 1.8963235982575624e-08, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 21, 'plateau_patience': 11, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 11:34:29,418] Trial 301 finished with value: 0.5871671616139176 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9724033034360833, 'batch_size': 60, 'attention_heads': 10, 'hidden_dimension': 121, 'number_of_hidden_layers': 2, 'dropout_rate': 0.45591547871108523, 'global_pooling': 'mean', 'learning_rate': 0.0008779561947976381, 'weight_decay': 1.4988530647738111e-06, 'beta_0': 0.8085129348741354, 'beta_1': 0.9922525281157984, 'epsilon': 1.9124691515546688e-08, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 21, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 11:51:58,302] Trial 302 finished with value: 0.5821818116750355 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9811807054107005, 'batch_size': 69, 'attention_heads': 8, 'hidden_dimension': 142, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4470739574413542, 'global_pooling': 'max', 'learning_rate': 0.000713999608941455, 'weight_decay': 1.5692843762009033e-06, 'beta_0': 0.8094666472274652, 'beta_1': 0.9928462897162366, 'epsilon': 1.6953685664002157e-08, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 12:11:03,371] Trial 303 finished with value: 0.6107633417879624 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9740053594285957, 'batch_size': 66, 'attention_heads': 9, 'hidden_dimension': 128, 'number_of_hidden_layers': 2, 'dropout_rate': 0.43667691547153836, 'global_pooling': 'max', 'learning_rate': 0.0005821161417314908, 'weight_decay': 1.2259788060856723e-06, 'beta_0': 0.8047502777679921, 'beta_1': 0.9937037494561498, 'epsilon': 2.27625344075903e-08, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 9}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 12:28:27,011] Trial 304 finished with value: 0.6047078611067006 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9705818103208629, 'batch_size': 65, 'attention_heads': 9, 'hidden_dimension': 97, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4231418190901129, 'global_pooling': 'max', 'learning_rate': 0.0009822826696503438, 'weight_decay': 1.1802908584732509e-06, 'beta_0': 0.8001292890415056, 'beta_1': 0.9932329744298205, 'epsilon': 2.664613042656966e-08, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 22, 'plateau_patience': 20, 'plateau_divider': 9}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 12:47:38,007] Trial 305 finished with value: 0.6034136350233313 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9646491122295676, 'batch_size': 64, 'attention_heads': 9, 'hidden_dimension': 118, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4372058193797244, 'global_pooling': 'mean', 'learning_rate': 0.000582933707167807, 'weight_decay': 1.306263232843707e-06, 'beta_0': 0.8041095897637862, 'beta_1': 0.991994815017054, 'epsilon': 2.3702062480676016e-08, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 21, 'plateau_patience': 11, 'plateau_divider': 9}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 13:05:21,934] Trial 306 finished with value: 0.014445950089514447 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9731492594179006, 'batch_size': 66, 'attention_heads': 10, 'hidden_dimension': 137, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4326746236704023, 'global_pooling': 'max', 'learning_rate': 0.039348461092948, 'weight_decay': 1.1904323131013637e-06, 'beta_0': 0.8024953596976505, 'beta_1': 0.9925369291501862, 'epsilon': 3.08464565846136e-08, 'balanced_loss': True, 'epochs': 169, 'early_stopping_patience': 21, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 13:24:20,380] Trial 307 finished with value: 0.5923090045561139 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9689034000419388, 'batch_size': 71, 'attention_heads': 8, 'hidden_dimension': 126, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5935258171541828, 'global_pooling': 'max', 'learning_rate': 0.000814357683999259, 'weight_decay': 1.4296214179854541e-06, 'beta_0': 0.8056791602761554, 'beta_1': 0.9937751584813797, 'epsilon': 1.3026442407228228e-08, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 20, 'plateau_patience': 11, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 13:40:54,546] Trial 308 finished with value: 0.5904956792997755 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9742576156437337, 'batch_size': 62, 'attention_heads': 11, 'hidden_dimension': 72, 'number_of_hidden_layers': 2, 'dropout_rate': 0.42702560277649215, 'global_pooling': 'mean', 'learning_rate': 0.0006546285657221517, 'weight_decay': 1.6573120384675555e-06, 'beta_0': 0.8064490849346948, 'beta_1': 0.990592912575625, 'epsilon': 2.1153365458260152e-08, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 21, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 13:57:36,494] Trial 309 finished with value: 0.5823351675359391 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9799441282868232, 'batch_size': 67, 'attention_heads': 9, 'hidden_dimension': 91, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4406170614150105, 'global_pooling': 'max', 'learning_rate': 0.00027968625264077746, 'weight_decay': 1.0079342500347517e-06, 'beta_0': 0.8039938150448063, 'beta_1': 0.9926683471828487, 'epsilon': 3.3650154717857905e-08, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 22, 'plateau_patience': 21, 'plateau_divider': 9}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 14:13:37,475] Trial 310 finished with value: 0.5918999419221747 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9840140203043496, 'batch_size': 69, 'attention_heads': 9, 'hidden_dimension': 58, 'number_of_hidden_layers': 2, 'dropout_rate': 0.44968707230474164, 'global_pooling': 'max', 'learning_rate': 0.00037082854134974034, 'weight_decay': 1.37808352610343e-06, 'beta_0': 0.8081125649920717, 'beta_1': 0.9936367503804581, 'epsilon': 2.729773192553605e-08, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 20, 'plateau_patience': 11, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 14:30:50,457] Trial 311 finished with value: 0.5909352074614752 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9644465524166645, 'batch_size': 72, 'attention_heads': 8, 'hidden_dimension': 108, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4354283483301146, 'global_pooling': 'mean', 'learning_rate': 0.0013301624349027538, 'weight_decay': 6.137083477651089e-06, 'beta_0': 0.8069899466688586, 'beta_1': 0.9931259439681002, 'epsilon': 1.5682444569629585e-08, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 21, 'plateau_patience': 10, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
CUDA out of memory. Tried to allocate 376.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 292.69 MiB is free. Including non-PyTorch memory, this process has 44.27 GiB memory in use. Of the allocated memory 42.11 GiB is allocated by PyTorch, and 1.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 14:42:49,963] Trial 312 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9054881523175808, 'batch_size': 66, 'attention_heads': 9, 'hidden_dimension': 119, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5991673542332829, 'global_pooling': 'max', 'learning_rate': 0.0005279185313228481, 'weight_decay': 1.767929379849757e-06, 'beta_0': 0.8112145717542897, 'beta_1': 0.9889070740587371, 'epsilon': 2.3524609914392523e-08, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 20, 'plateau_patience': 19, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 15:08:52,879] Trial 313 finished with value: 0.034706937980477456 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9699144022384459, 'batch_size': 69, 'attention_heads': 8, 'hidden_dimension': 100, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4426803215324498, 'global_pooling': 'max', 'learning_rate': 0.009506064190222313, 'weight_decay': 2.1315575887736964e-06, 'beta_0': 0.8695943965814829, 'beta_1': 0.9942442458492107, 'epsilon': 1.8397831393286856e-08, 'balanced_loss': True, 'epochs': 120, 'early_stopping_patience': 19, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 15:25:02,487] Trial 314 finished with value: 0.6088858966279852 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9756722178559495, 'batch_size': 64, 'attention_heads': 10, 'hidden_dimension': 86, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4526369489599726, 'global_pooling': 'mean', 'learning_rate': 0.0010471394744959888, 'weight_decay': 1.472264737325139e-06, 'beta_0': 0.8049035659995134, 'beta_1': 0.9938964213790392, 'epsilon': 3.872802523825575e-08, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 20, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 15:42:35,740] Trial 315 finished with value: 0.5931868515473109 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9728931800404442, 'batch_size': 71, 'attention_heads': 7, 'hidden_dimension': 127, 'number_of_hidden_layers': 2, 'dropout_rate': 0.44494271153428216, 'global_pooling': 'max', 'learning_rate': 0.0007268189136538035, 'weight_decay': 1.327218574671161e-06, 'beta_0': 0.8024916566499276, 'beta_1': 0.9981411524652832, 'epsilon': 2.2636631484839685e-08, 'balanced_loss': True, 'epochs': 131, 'early_stopping_patience': 22, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 15:59:03,567] Trial 316 finished with value: 0.5687542868294534 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9799751886009934, 'batch_size': 67, 'attention_heads': 7, 'hidden_dimension': 115, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4762604198238559, 'global_pooling': 'max', 'learning_rate': 0.0003930908179755126, 'weight_decay': 1.1734721851291989e-06, 'beta_0': 0.8138486881082028, 'beta_1': 0.9934680018686902, 'epsilon': 3.091125856879892e-08, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 21, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 16:15:43,040] Trial 317 finished with value: 0.6034560729164077 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9674541106933713, 'batch_size': 59, 'attention_heads': 7, 'hidden_dimension': 106, 'number_of_hidden_layers': 2, 'dropout_rate': 0.43139038879360303, 'global_pooling': 'mean', 'learning_rate': 0.0005965396442144846, 'weight_decay': 1.7536362887492004e-06, 'beta_0': 0.8078339577297389, 'beta_1': 0.9987369808071047, 'epsilon': 1.556504693844391e-08, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 19, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 16:35:21,269] Trial 318 finished with value: 0.5940570912470965 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9873057753165578, 'batch_size': 119, 'attention_heads': 8, 'hidden_dimension': 251, 'number_of_hidden_layers': 2, 'dropout_rate': 0.46150516183481205, 'global_pooling': 'max', 'learning_rate': 0.0009081830000270385, 'weight_decay': 7.50779440641012e-05, 'beta_0': 0.8101638323574285, 'beta_1': 0.9976398002118257, 'epsilon': 1.8577875945618162e-07, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 20, 'plateau_patience': 11, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
CUDA out of memory. Tried to allocate 1.64 GiB. GPU 0 has a total capacity of 44.56 GiB of which 702.69 MiB is free. Including non-PyTorch memory, this process has 43.87 GiB memory in use. Of the allocated memory 42.38 GiB is allocated by PyTorch, and 346.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 16:47:56,376] Trial 319 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9289242335358053, 'batch_size': 70, 'attention_heads': 7, 'hidden_dimension': 145, 'number_of_hidden_layers': 2, 'dropout_rate': 0.43955224233980633, 'global_pooling': 'max', 'learning_rate': 0.0004672837052967897, 'weight_decay': 1.5707826918916856e-06, 'beta_0': 0.8051251555252873, 'beta_1': 0.9927861606557603, 'epsilon': 1.9797600913447498e-08, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 24, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 17:03:18,643] Trial 320 finished with value: 0.5218680885811832 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.976324592381942, 'batch_size': 65, 'attention_heads': 7, 'hidden_dimension': 95, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4500942065233885, 'global_pooling': 'mean', 'learning_rate': 0.00032642854291335677, 'weight_decay': 1.1501640136226925e-06, 'beta_0': 0.8016849045162368, 'beta_1': 0.9917742751980216, 'epsilon': 2.6125489831017977e-08, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 17:19:37,809] Trial 321 finished with value: 0.6060929000638162 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9697964372831621, 'batch_size': 63, 'attention_heads': 8, 'hidden_dimension': 75, 'number_of_hidden_layers': 2, 'dropout_rate': 0.41938934510525144, 'global_pooling': 'max', 'learning_rate': 0.0008181249404157208, 'weight_decay': 0.00018517868757974396, 'beta_0': 0.8117014660714081, 'beta_1': 0.9973678617147268, 'epsilon': 1.3333481694061977e-08, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 21, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 17:38:27,615] Trial 322 finished with value: 0.6098641789967347 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.963089042177629, 'batch_size': 72, 'attention_heads': 7, 'hidden_dimension': 137, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4547087566509812, 'global_pooling': 'max', 'learning_rate': 0.0006534037262138233, 'weight_decay': 2.156956720337834e-06, 'beta_0': 0.8077211847918898, 'beta_1': 0.998231813882821, 'epsilon': 1.2415918404029314e-07, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 21, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 17:53:10,514] Trial 323 finished with value: 0.4909662684808238 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9597043731363181, 'batch_size': 73, 'attention_heads': 7, 'hidden_dimension': 137, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5247508390402394, 'global_pooling': 'mean', 'learning_rate': 0.0006837176798233423, 'weight_decay': 2.367158525355647e-06, 'beta_0': 0.8078628217813261, 'beta_1': 0.9985619138566525, 'epsilon': 1.1854621595676613e-07, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 21, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 18:11:56,608] Trial 324 finished with value: 0.5889001215763969 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9639398621590791, 'batch_size': 72, 'attention_heads': 7, 'hidden_dimension': 124, 'number_of_hidden_layers': 2, 'dropout_rate': 0.45504053929219984, 'global_pooling': 'max', 'learning_rate': 0.00022851234471015479, 'weight_decay': 2.6893186716749585e-06, 'beta_0': 0.8061549307040576, 'beta_1': 0.9983010178527271, 'epsilon': 8.996369022828493e-08, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 21, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
CUDA out of memory. Tried to allocate 1.40 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 43.54 GiB memory in use. Of the allocated memory 41.06 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 18:25:00,538] Trial 325 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9565870448541576, 'batch_size': 75, 'attention_heads': 7, 'hidden_dimension': 141, 'number_of_hidden_layers': 2, 'dropout_rate': 0.46381161326280096, 'global_pooling': 'max', 'learning_rate': 0.0005248537519296085, 'weight_decay': 2.209357192855382e-06, 'beta_0': 0.8043790138203663, 'beta_1': 0.99896011086767, 'epsilon': 1.2821885332085713e-07, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 22, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 225 with value: 0.6277360957804677.
CUDA out of memory. Tried to allocate 1.32 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 43.33 GiB memory in use. Of the allocated memory 41.22 GiB is allocated by PyTorch, and 989.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 18:37:41,284] Trial 326 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9530417865416722, 'batch_size': 77, 'attention_heads': 7, 'hidden_dimension': 133, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4464220672744538, 'global_pooling': 'mean', 'learning_rate': 0.0010295714625236773, 'weight_decay': 1.959229558016198e-06, 'beta_0': 0.8086769305349466, 'beta_1': 0.9939760996237051, 'epsilon': 1.4657784386738653e-07, 'balanced_loss': True, 'epochs': 107, 'early_stopping_patience': 21, 'plateau_patience': 12, 'plateau_divider': 6}. Best is trial 225 with value: 0.6277360957804677.
[I 2025-02-22 19:03:04,645] Trial 327 finished with value: 0.5920824042639176 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9618846607439259, 'batch_size': 61, 'attention_heads': 7, 'hidden_dimension': 127, 'number_of_hidden_layers': 2, 'dropout_rate': 0.45426560911992714, 'global_pooling': 'max', 'learning_rate': 0.0004111858482747542, 'weight_decay': 1.9506768178150196e-06, 'beta_0': 0.806228524402391, 'beta_1': 0.9923397235996537, 'epsilon': 1.0027479771663299e-08, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 21, 'plateau_patience': 14, 'plateau_divider': 9}. Best is trial 225 with value: 0.6277360957804677.
slurmstepd: error: *** JOB 14969018 ON gpu029 CANCELLED AT 2025-02-22T19:11:39 DUE TO TIME LIMIT ***
