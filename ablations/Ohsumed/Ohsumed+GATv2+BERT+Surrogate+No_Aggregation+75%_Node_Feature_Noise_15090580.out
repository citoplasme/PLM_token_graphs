[I 2025-03-04 05:01:17,850] Using an existing study with name 'Ohsumed-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-No_Ablation-1.0-0.75' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors
[I 2025-03-04 05:23:05,980] Trial 243 finished with value: 0.503166934179044 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9764931865442082, 'batch_size': 57, 'attention_heads': 13, 'hidden_dimension': 151, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5725090102782167, 'global_pooling': 'max', 'learning_rate': 0.00064396282970412, 'weight_decay': 4.3770971284666556e-05, 'beta_0': 0.8447526188443734, 'beta_1': 0.992447520715315, 'epsilon': 9.333613770660342e-07, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 242.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 146.69 MiB is free. Including non-PyTorch memory, this process has 44.41 GiB memory in use. Of the allocated memory 42.69 GiB is allocated by PyTorch, and 585.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-04 05:29:36,763] Trial 244 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8067168411280451, 'batch_size': 55, 'attention_heads': 14, 'hidden_dimension': 134, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5998087315924654, 'global_pooling': 'max', 'learning_rate': 0.000302937502551676, 'weight_decay': 5.884741851970317e-05, 'beta_0': 0.8491031377240011, 'beta_1': 0.9942727112468105, 'epsilon': 3.698775151530098e-07, 'balanced_loss': True, 'epochs': 106, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 05:51:06,322] Trial 245 finished with value: 0.514169169530336 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9672811475853681, 'batch_size': 53, 'attention_heads': 12, 'hidden_dimension': 165, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5265844183474868, 'global_pooling': 'max', 'learning_rate': 0.00036985269412214127, 'weight_decay': 2.8173851222024158e-05, 'beta_0': 0.8438069219464068, 'beta_1': 0.99309881414639, 'epsilon': 2.0455383256103782e-07, 'balanced_loss': True, 'epochs': 103, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 06:12:41,141] Trial 246 finished with value: 0.5102136443868127 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9722854226967568, 'batch_size': 78, 'attention_heads': 13, 'hidden_dimension': 142, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5544459994690587, 'global_pooling': 'max', 'learning_rate': 0.00047218521906502715, 'weight_decay': 9.04001790968791e-05, 'beta_0': 0.8471283229245644, 'beta_1': 0.9922914566560084, 'epsilon': 1.3228130602058947e-06, 'balanced_loss': True, 'epochs': 132, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 06:32:17,101] Trial 247 finished with value: 0.5103089500394217 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.983679743202059, 'batch_size': 84, 'attention_heads': 14, 'hidden_dimension': 128, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5465687170230249, 'global_pooling': 'max', 'learning_rate': 0.0005718472742076182, 'weight_decay': 7.564823993932144e-05, 'beta_0': 0.8507434821737264, 'beta_1': 0.9935043243028018, 'epsilon': 2.939663764560888e-07, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.84 GiB is free. Including non-PyTorch memory, this process has 42.72 GiB memory in use. Of the allocated memory 39.16 GiB is allocated by PyTorch, and 2.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-04 06:44:54,582] Trial 248 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9616817871494773, 'batch_size': 60, 'attention_heads': 15, 'hidden_dimension': 155, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5661173709567237, 'global_pooling': 'max', 'learning_rate': 0.00028912644384523044, 'weight_decay': 5.264897754347802e-05, 'beta_0': 0.8414119394526599, 'beta_1': 0.9916229600639305, 'epsilon': 5.773439296578608e-07, 'balanced_loss': True, 'epochs': 100, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 07:06:45,072] Trial 249 finished with value: 0.483953638752107 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9792358053346392, 'batch_size': 51, 'attention_heads': 14, 'hidden_dimension': 173, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5760811398451086, 'global_pooling': 'max', 'learning_rate': 0.0008595049665546255, 'weight_decay': 4.0038854124976054e-05, 'beta_0': 0.8456311848462552, 'beta_1': 0.9929100678962858, 'epsilon': 8.980654476664571e-07, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 07:28:42,730] Trial 250 finished with value: 0.516683789404575 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9696612122087952, 'batch_size': 54, 'attention_heads': 14, 'hidden_dimension': 159, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5334153031619663, 'global_pooling': 'max', 'learning_rate': 0.0004049649832731897, 'weight_decay': 4.5717104860721055e-05, 'beta_0': 0.8431779419209959, 'beta_1': 0.9923053873629804, 'epsilon': 5.257888635411158e-07, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 07:53:39,663] Trial 251 finished with value: 0.5223726930654519 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9684861705602597, 'batch_size': 57, 'attention_heads': 14, 'hidden_dimension': 158, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5415041707364195, 'global_pooling': 'max', 'learning_rate': 0.0003605846748411568, 'weight_decay': 4.703511914293051e-05, 'beta_0': 0.8437342867554773, 'beta_1': 0.9920412524661089, 'epsilon': 4.410267288240863e-07, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 4}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.85 GiB is free. Including non-PyTorch memory, this process has 42.71 GiB memory in use. Of the allocated memory 39.41 GiB is allocated by PyTorch, and 2.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-04 08:08:56,703] Trial 252 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9656360268421191, 'batch_size': 57, 'attention_heads': 14, 'hidden_dimension': 166, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5397763975083026, 'global_pooling': 'max', 'learning_rate': 0.0003498037411844937, 'weight_decay': 6.15979875666081e-05, 'beta_0': 0.8481198008812171, 'beta_1': 0.9919380353771596, 'epsilon': 4.0002782675717193e-07, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 4}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 08:30:00,595] Trial 253 finished with value: 0.5217133400691126 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9734252075596879, 'batch_size': 58, 'attention_heads': 14, 'hidden_dimension': 147, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5430434345579019, 'global_pooling': 'max', 'learning_rate': 0.0004703849467451481, 'weight_decay': 2.3065060449006166e-05, 'beta_0': 0.8387973183828513, 'beta_1': 0.9925441393375193, 'epsilon': 6.807428039013935e-07, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 08:53:00,629] Trial 254 finished with value: 0.5125928429502641 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9687065223443319, 'batch_size': 55, 'attention_heads': 13, 'hidden_dimension': 136, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5497141653067095, 'global_pooling': 'max', 'learning_rate': 0.00024844627222928516, 'weight_decay': 4.871444603058687e-05, 'beta_0': 0.844387535572843, 'beta_1': 0.9916262298070234, 'epsilon': 4.0329179434256924e-07, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 2.12 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.68 GiB is free. Including non-PyTorch memory, this process has 42.87 GiB memory in use. Of the allocated memory 40.09 GiB is allocated by PyTorch, and 1.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-04 09:09:15,232] Trial 255 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9627406316662943, 'batch_size': 52, 'attention_heads': 15, 'hidden_dimension': 153, 'number_of_hidden_layers': 1, 'dropout_rate': 0.559138481010463, 'global_pooling': 'max', 'learning_rate': 0.0003289992426156556, 'weight_decay': 3.666245780968247e-05, 'beta_0': 0.840285272325152, 'beta_1': 0.9920556132843859, 'epsilon': 2.32668695672082e-07, 'balanced_loss': True, 'epochs': 133, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 09:29:00,417] Trial 256 finished with value: 0.5003234795605654 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9772148905606595, 'batch_size': 61, 'attention_heads': 13, 'hidden_dimension': 141, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5325088720137772, 'global_pooling': 'max', 'learning_rate': 0.0005577782725184355, 'weight_decay': 6.59631794518502e-05, 'beta_0': 0.8457988081642085, 'beta_1': 0.9912917670704983, 'epsilon': 1.0736437777671021e-06, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 4}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 1.89 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.16 GiB is free. Including non-PyTorch memory, this process has 43.39 GiB memory in use. Of the allocated memory 40.39 GiB is allocated by PyTorch, and 1.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-04 09:41:49,943] Trial 257 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9572820901645159, 'batch_size': 57, 'attention_heads': 14, 'hidden_dimension': 162, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5843734444546227, 'global_pooling': 'max', 'learning_rate': 0.000672297031604504, 'weight_decay': 5.68319318763617e-05, 'beta_0': 0.8542735917949091, 'beta_1': 0.9926729422522842, 'epsilon': 3.1944761553930476e-07, 'balanced_loss': True, 'epochs': 92, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 10:02:37,945] Trial 258 finished with value: 0.5071081771027888 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9738122415116042, 'batch_size': 54, 'attention_heads': 14, 'hidden_dimension': 170, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5459156256865141, 'global_pooling': 'max', 'learning_rate': 0.0010772406900180012, 'weight_decay': 4.3005227238711415e-05, 'beta_0': 0.8495540308193967, 'beta_1': 0.9931332214193546, 'epsilon': 8.011075594998859e-07, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 10:26:37,866] Trial 259 finished with value: 0.524314615413731 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9658304536022214, 'batch_size': 59, 'attention_heads': 13, 'hidden_dimension': 132, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5553838595562012, 'global_pooling': 'max', 'learning_rate': 0.0004308187495958843, 'weight_decay': 3.183461025482407e-05, 'beta_0': 0.8421006081408028, 'beta_1': 0.9938654756574928, 'epsilon': 4.7490347350575003e-07, 'balanced_loss': True, 'epochs': 96, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 10:47:49,072] Trial 260 finished with value: 0.49802103275632864 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9652098281777134, 'batch_size': 50, 'attention_heads': 14, 'hidden_dimension': 133, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5539687739796693, 'global_pooling': 'max', 'learning_rate': 0.0004407754565069513, 'weight_decay': 3.0973080279591e-05, 'beta_0': 0.8426710154296122, 'beta_1': 0.9944626626591244, 'epsilon': 6.710149607633682e-07, 'balanced_loss': True, 'epochs': 96, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 2.11 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.11 GiB is free. Including non-PyTorch memory, this process has 42.45 GiB memory in use. Of the allocated memory 40.74 GiB is allocated by PyTorch, and 571.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-04 11:05:58,148] Trial 261 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9608428200315424, 'batch_size': 59, 'attention_heads': 15, 'hidden_dimension': 127, 'number_of_hidden_layers': 1, 'dropout_rate': 0.54190915442463, 'global_pooling': 'max', 'learning_rate': 0.0005127553005699315, 'weight_decay': 2.7321674485503736e-05, 'beta_0': 0.8422047001754487, 'beta_1': 0.9939974406563489, 'epsilon': 9.840729769011158e-07, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 11:25:41,663] Trial 262 finished with value: 0.5011966962671351 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9716364022034019, 'batch_size': 56, 'attention_heads': 12, 'hidden_dimension': 138, 'number_of_hidden_layers': 1, 'dropout_rate': 0.527114306900032, 'global_pooling': 'max', 'learning_rate': 0.00037831658301652076, 'weight_decay': 3.3415410946861424e-05, 'beta_0': 0.8399615105470806, 'beta_1': 0.9934058770201161, 'epsilon': 5.020589883262453e-07, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 11:43:15,180] Trial 263 finished with value: 0.5069070354681088 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.980620669327886, 'batch_size': 53, 'attention_heads': 10, 'hidden_dimension': 144, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5352407672996204, 'global_pooling': 'max', 'learning_rate': 0.0007154831289687372, 'weight_decay': 3.9345837788992223e-05, 'beta_0': 0.8439925358585701, 'beta_1': 0.9938849267637939, 'epsilon': 1.2048776193729115e-06, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 18, 'plateau_patience': 25, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 12:07:14,009] Trial 264 finished with value: 0.525659269205404 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.966362936205757, 'batch_size': 48, 'attention_heads': 13, 'hidden_dimension': 132, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5595572710439205, 'global_pooling': 'max', 'learning_rate': 0.00044880238179081147, 'weight_decay': 2.3789691303373824e-05, 'beta_0': 0.8459286556404401, 'beta_1': 0.9950178564204549, 'epsilon': 5.702940422531794e-07, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 12:25:50,556] Trial 265 finished with value: 0.4900947206429297 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9754375035246439, 'batch_size': 66, 'attention_heads': 13, 'hidden_dimension': 132, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5612528047512432, 'global_pooling': 'max', 'learning_rate': 0.000599776825820764, 'weight_decay': 2.5145433201002414e-05, 'beta_0': 0.8476994830913995, 'beta_1': 0.9952455245278697, 'epsilon': 4.866683582252392e-07, 'balanced_loss': True, 'epochs': 130, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 12:43:15,034] Trial 266 finished with value: 0.5113906398858135 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.985523789011151, 'batch_size': 47, 'attention_heads': 13, 'hidden_dimension': 126, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3567462754747118, 'global_pooling': 'max', 'learning_rate': 0.00036165059188577106, 'weight_decay': 2.207715072124606e-05, 'beta_0': 0.8468065111842689, 'beta_1': 0.9943947760873284, 'epsilon': 5.620773243584427e-07, 'balanced_loss': True, 'epochs': 122, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 13:03:57,180] Trial 267 finished with value: 0.49767517951046597 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9655593679124412, 'batch_size': 58, 'attention_heads': 13, 'hidden_dimension': 130, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5541499337345239, 'global_pooling': 'max', 'learning_rate': 0.0005052720767691594, 'weight_decay': 1.9869088284311274e-05, 'beta_0': 0.8371669402040937, 'beta_1': 0.9948989718661126, 'epsilon': 2.8193083690920506e-07, 'balanced_loss': True, 'epochs': 95, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 13:25:20,755] Trial 268 finished with value: 0.5003218748752919 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9581554673189249, 'batch_size': 49, 'attention_heads': 13, 'hidden_dimension': 149, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5502657350501234, 'global_pooling': 'max', 'learning_rate': 0.000867617614868553, 'weight_decay': 3.1065964164187517e-05, 'beta_0': 0.8458791433141348, 'beta_1': 0.994783570966726, 'epsilon': 3.542255716655415e-07, 'balanced_loss': True, 'epochs': 103, 'early_stopping_patience': 16, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 13:46:32,777] Trial 269 finished with value: 0.515505359533098 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9718201518570564, 'batch_size': 55, 'attention_heads': 13, 'hidden_dimension': 135, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5595232079657748, 'global_pooling': 'max', 'learning_rate': 0.0004314440232390398, 'weight_decay': 1.5503176999913695e-05, 'beta_0': 0.8488405844115364, 'beta_1': 0.994199638117981, 'epsilon': 8.207673757745318e-07, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 19, 'plateau_patience': 25, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 14:10:48,778] Trial 270 finished with value: 0.511692453326235 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9784551109980061, 'batch_size': 63, 'attention_heads': 14, 'hidden_dimension': 153, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5679236791163615, 'global_pooling': 'max', 'learning_rate': 0.0003208694042416876, 'weight_decay': 2.5169162627310953e-05, 'beta_0': 0.8425271828851252, 'beta_1': 0.9936468332816067, 'epsilon': 1.5882163782251388e-07, 'balanced_loss': True, 'epochs': 132, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 14:32:26,185] Trial 271 finished with value: 0.5035453608429935 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9636397329481158, 'batch_size': 50, 'attention_heads': 11, 'hidden_dimension': 157, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5461505054284095, 'global_pooling': 'max', 'learning_rate': 0.0005455329377789981, 'weight_decay': 5.175151133122358e-05, 'beta_0': 0.8410305273638038, 'beta_1': 0.9951634962833855, 'epsilon': 5.3131589007189034e-08, 'balanced_loss': True, 'epochs': 107, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 14:53:34,516] Trial 272 finished with value: 0.49301966965528266 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9707757158577492, 'batch_size': 56, 'attention_heads': 14, 'hidden_dimension': 138, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5935411462439559, 'global_pooling': 'max', 'learning_rate': 0.0006534710547926234, 'weight_decay': 2.7689066110144118e-05, 'beta_0': 0.8455183002006502, 'beta_1': 0.9908511721430694, 'epsilon': 4.68566292847145e-07, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 15:16:35,763] Trial 273 finished with value: 0.4884708472033628 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9819306321093217, 'batch_size': 47, 'attention_heads': 13, 'hidden_dimension': 147, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5584901705390184, 'global_pooling': 'max', 'learning_rate': 0.00022798250407194968, 'weight_decay': 3.528742555428842e-05, 'beta_0': 0.8501641146638109, 'beta_1': 0.9925199909723339, 'epsilon': 2.1732503411856292e-07, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 15:36:59,949] Trial 274 finished with value: 0.5080320528917988 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9677494863392222, 'batch_size': 59, 'attention_heads': 15, 'hidden_dimension': 125, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5207649920321383, 'global_pooling': 'max', 'learning_rate': 0.0003749544873063979, 'weight_decay': 7.837735539122141e-05, 'beta_0': 0.8478077526778783, 'beta_1': 0.9945912825368017, 'epsilon': 5.872061136485998e-07, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 15, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 15:56:24,790] Trial 275 finished with value: 0.5208978995215727 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9745333718769262, 'batch_size': 52, 'attention_heads': 12, 'hidden_dimension': 130, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3255418473113868, 'global_pooling': 'max', 'learning_rate': 0.00028103016271464925, 'weight_decay': 5.320185138935691e-05, 'beta_0': 0.8442781415405577, 'beta_1': 0.9921868013127969, 'epsilon': 1.2877612031130187e-06, 'balanced_loss': True, 'epochs': 120, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.54 GiB is free. Including non-PyTorch memory, this process has 43.01 GiB memory in use. Of the allocated memory 41.35 GiB is allocated by PyTorch, and 525.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-04 16:11:43,445] Trial 276 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.960733420586854, 'batch_size': 54, 'attention_heads': 14, 'hidden_dimension': 143, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5491452369700375, 'global_pooling': 'max', 'learning_rate': 0.00045292075117353103, 'weight_decay': 6.925926046770304e-05, 'beta_0': 0.841284353056773, 'beta_1': 0.9933516941714645, 'epsilon': 9.738104389134e-07, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 16:32:08,631] Trial 277 finished with value: 0.4980960389598693 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9764192766550168, 'batch_size': 49, 'attention_heads': 13, 'hidden_dimension': 159, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5365310773002905, 'global_pooling': 'max', 'learning_rate': 0.000754073873714575, 'weight_decay': 3.983143993375296e-05, 'beta_0': 0.838574211120932, 'beta_1': 0.9929367555443933, 'epsilon': 3.080620561763718e-08, 'balanced_loss': True, 'epochs': 135, 'early_stopping_patience': 18, 'plateau_patience': 25, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 16:54:29,132] Trial 278 finished with value: 0.4881863084672267 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9889544802135175, 'batch_size': 57, 'attention_heads': 14, 'hidden_dimension': 135, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5540520238864232, 'global_pooling': 'max', 'learning_rate': 0.0003623609681104767, 'weight_decay': 4.703428894039097e-05, 'beta_0': 0.8465184002598208, 'beta_1': 0.9955834757290306, 'epsilon': 7.389015454823221e-07, 'balanced_loss': True, 'epochs': 98, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 17:15:16,804] Trial 279 finished with value: 0.5206155281837799 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9648619430539909, 'batch_size': 54, 'attention_heads': 13, 'hidden_dimension': 123, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5301777250504567, 'global_pooling': 'max', 'learning_rate': 0.0005244511304256913, 'weight_decay': 3.0261136516706983e-05, 'beta_0': 0.8519835645546534, 'beta_1': 0.9912946802668124, 'epsilon': 2.6696542996437015e-07, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 16, 'plateau_patience': 23, 'plateau_divider': 4}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 17:32:03,466] Trial 280 finished with value: 0.019833480745742035 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9695297464430751, 'batch_size': 51, 'attention_heads': 9, 'hidden_dimension': 151, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5635724848112672, 'global_pooling': 'max', 'learning_rate': 0.009506064190222313, 'weight_decay': 2.2269719598246228e-05, 'beta_0': 0.8446717276957656, 'beta_1': 0.993829726760145, 'epsilon': 3.511609572667137e-07, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 2.12 GiB. GPU 0 has a total capacity of 44.56 GiB of which 654.69 MiB is free. Including non-PyTorch memory, this process has 43.91 GiB memory in use. Of the allocated memory 40.31 GiB is allocated by PyTorch, and 2.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-04 17:45:26,929] Trial 281 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9567928145373547, 'batch_size': 59, 'attention_heads': 14, 'hidden_dimension': 141, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5427962943601312, 'global_pooling': 'max', 'learning_rate': 0.001008754297963268, 'weight_decay': 1.753479440639071e-05, 'beta_0': 0.8492852040438238, 'beta_1': 0.9916054479252973, 'epsilon': 4.26388187372286e-07, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 17, 'plateau_patience': 25, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 18:11:14,290] Trial 282 finished with value: 0.5218872709734343 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9791463531037538, 'batch_size': 101, 'attention_heads': 15, 'hidden_dimension': 161, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5458551659835571, 'global_pooling': 'max', 'learning_rate': 0.0003207451873633927, 'weight_decay': 5.764820566064183e-05, 'beta_0': 0.8425173652543665, 'beta_1': 0.9926189673477291, 'epsilon': 6.22666824476772e-07, 'balanced_loss': True, 'epochs': 106, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 18:38:59,591] Trial 283 finished with value: 0.478996067498325 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9734591999474458, 'batch_size': 48, 'attention_heads': 13, 'hidden_dimension': 129, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5361326157504936, 'global_pooling': 'max', 'learning_rate': 0.0002204476319398445, 'weight_decay': 4.6759489950138956e-05, 'beta_0': 0.8470322041329471, 'beta_1': 0.9921456845255002, 'epsilon': 3.127440381726872e-07, 'balanced_loss': True, 'epochs': 92, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 19:01:08,739] Trial 284 finished with value: 0.5143868653089725 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9671795769508947, 'batch_size': 56, 'attention_heads': 14, 'hidden_dimension': 146, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5549312138050668, 'global_pooling': 'max', 'learning_rate': 0.00041679855813188724, 'weight_decay': 6.605117417672957e-05, 'beta_0': 0.8507459069347351, 'beta_1': 0.9943738025658243, 'epsilon': 8.575885677721052e-07, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 19:20:11,511] Trial 285 finished with value: 0.47685747544313406 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9840507959380574, 'batch_size': 61, 'attention_heads': 13, 'hidden_dimension': 136, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5876660477654118, 'global_pooling': 'max', 'learning_rate': 0.0006477303957636033, 'weight_decay': 8.896232105749552e-05, 'beta_0': 0.839491430991226, 'beta_1': 0.9932998796280437, 'epsilon': 1.048942533914352e-06, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 18, 'plateau_patience': 25, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 44.56 GiB of which 944.69 MiB is free. Including non-PyTorch memory, this process has 43.63 GiB memory in use. Of the allocated memory 38.86 GiB is allocated by PyTorch, and 3.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-04 19:33:20,158] Trial 286 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9619289456853692, 'batch_size': 52, 'attention_heads': 14, 'hidden_dimension': 156, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5685442134340789, 'global_pooling': 'max', 'learning_rate': 0.0002982875402746617, 'weight_decay': 3.6065893081755434e-05, 'beta_0': 0.8451346496541271, 'beta_1': 0.9927643031536812, 'epsilon': 1.8281883452736411e-07, 'balanced_loss': True, 'epochs': 120, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 19:53:59,225] Trial 287 finished with value: 0.5254791387835979 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9714659141169433, 'batch_size': 55, 'attention_heads': 12, 'hidden_dimension': 166, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5495084518358709, 'global_pooling': 'max', 'learning_rate': 0.0005049024202574731, 'weight_decay': 5.405492893414438e-05, 'beta_0': 0.8484729442965298, 'beta_1': 0.9918273337372215, 'epsilon': 2.3471337355799997e-07, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 20:15:36,226] Trial 288 finished with value: 0.4937397976719977 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9752037902441513, 'batch_size': 54, 'attention_heads': 13, 'hidden_dimension': 177, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5621840786956497, 'global_pooling': 'max', 'learning_rate': 0.0005538494236022267, 'weight_decay': 5.7172244556637386e-05, 'beta_0': 0.8533251683230677, 'beta_1': 0.9949595288175177, 'epsilon': 2.3390714771436534e-07, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 20:35:11,438] Trial 289 finished with value: 0.5174000693606664 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9799121383482646, 'batch_size': 51, 'attention_heads': 12, 'hidden_dimension': 171, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5491859084550769, 'global_pooling': 'max', 'learning_rate': 0.0007676355597263025, 'weight_decay': 7.500235039927882e-05, 'beta_0': 0.8499503560832802, 'beta_1': 0.9941087333788503, 'epsilon': 1.4690786583241988e-07, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
[I 2025-03-04 20:53:26,202] Trial 290 finished with value: 0.3554533051863505 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9711568851239275, 'batch_size': 45, 'attention_heads': 12, 'hidden_dimension': 167, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5757081884378322, 'global_pooling': 'sum', 'learning_rate': 0.0006335254692578817, 'weight_decay': 2.4922248517910684e-05, 'beta_0': 0.8479483550418916, 'beta_1': 0.9918185491245957, 'epsilon': 8.592906515724889e-08, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 214 with value: 0.5493008496774074.
slurmstepd: error: *** JOB 15090580 ON gpu032 CANCELLED AT 2025-03-04T21:01:21 DUE TO TIME LIMIT ***
