[I 2025-02-20 05:35:53,331] Using an existing study with name 'SST-2-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-Single_Unitary_Weight-0.0-0.0' instead of creating a new one.
Optimization already completed.

[TRIAL] 39 [VALIDATION PERFORMANCE] 0.9105504587155964 [TRAINING LOSS] 0.07390049090680048 [VALIDATION LOSS] 0.5065680823754519 

number                                      39
value                                  0.91055
params_threshold                      0.593845
params_attention_heads                       9
params_balanced_loss                      True
params_embedding_pooling_operation        mean
params_attention_pooling_operation         max
params_batch_size                           53
params_dropout_rate                   0.430709
params_early_stopping_patience              21
params_epochs                              135
params_global_pooling                     mean
params_hidden_dimension                    186
params_learning_rate                  0.001179
params_number_of_hidden_layers               3
params_plateau_divider                       7
params_plateau_patience                     24
params_weight_decay                   0.000042
params_beta_0                         0.884861
params_beta_1                         0.983909
params_epsilon                        0.000021
user_attrs_epoch                          18.0
user_attrs_training_loss                0.0739
user_attrs_validation_loss            0.506568
Name: 39, dtype: object
37 Val: 0.9025229357798165 Test: 0.8978583196046128
38 Val: 0.8956422018348624 Test: 0.8923668314113125
39 Val: 0.8967889908256881 Test: 0.8973091707852828
40 Val: 0.9036697247706422 Test: 0.8802855573860516
41 Val: 0.8979357798165137 Test: 0.8967600219659527
42 Val: 0.9059633027522935 Test: 0.8989566172432729
43 Val: 0.9048165137614679 Test: 0.886326194398682
44 Val: 0.9013761467889908 Test: 0.8874244920373421
45 Val: 0.8990825688073395 Test: 0.8901702361339923
46 Val: 0.9036697247706422 Test: 0.8896210873146623
Validation performance: 89.56 & 90.11 ± 0.36 & 90.6
Testing performance: 88.03 & 89.17 ± 0.61 & 89.9

[TRIAL] 210 [VALIDATION PERFORMANCE] 0.9094036697247706 [TRAINING LOSS] 0.08097970085284135 [VALIDATION LOSS] 0.337885183799598 

number                                     210
value                                 0.909404
params_threshold                      0.475873
params_attention_heads                      12
params_balanced_loss                     False
params_embedding_pooling_operation         max
params_attention_pooling_operation         max
params_batch_size                           49
params_dropout_rate                   0.531629
params_early_stopping_patience              23
params_epochs                              112
params_global_pooling                     mean
params_hidden_dimension                    152
params_learning_rate                  0.000675
params_number_of_hidden_layers               2
params_plateau_divider                       2
params_plateau_patience                     24
params_weight_decay                   0.000214
params_beta_0                         0.847312
params_beta_1                         0.991091
params_epsilon                        0.000002
user_attrs_epoch                          22.0
user_attrs_training_loss               0.08098
user_attrs_validation_loss            0.337885
Name: 210, dtype: object
37 Val: 0.9025229357798165 Test: 0.8940142778693025
38 Val: 0.8967889908256881 Test: 0.8907193849533224
39 Val: 0.9013761467889908 Test: 0.8967600219659527
40 Val: 0.8990825688073395 Test: 0.900604063701263
41 Val: 0.9048165137614679 Test: 0.8989566172432729
42 Val: 0.9025229357798165 Test: 0.8901702361339923
43 Val: 0.8990825688073395 Test: 0.8896210873146623
44 Val: 0.9013761467889908 Test: 0.8929159802306426
45 Val: 0.9036697247706422 Test: 0.899505766062603
46 Val: 0.9025229357798165 Test: 0.900054914881933
Validation performance: 89.68 & 90.14 ± 0.24 & 90.48
Testing performance: 88.96 & 89.53 ± 0.44 & 90.06

[TRIAL] 252 [VALIDATION PERFORMANCE] 0.908256880733945 [TRAINING LOSS] 0.1912368499944287 [VALIDATION LOSS] 0.290075606134321 

number                                     252
value                                 0.908257
params_threshold                      0.452007
params_attention_heads                      12
params_balanced_loss                     False
params_embedding_pooling_operation         max
params_attention_pooling_operation         max
params_batch_size                           32
params_dropout_rate                   0.504262
params_early_stopping_patience              22
params_epochs                              113
params_global_pooling                     mean
params_hidden_dimension                    144
params_learning_rate                  0.001212
params_number_of_hidden_layers               2
params_plateau_divider                       2
params_plateau_patience                     22
params_weight_decay                   0.000085
params_beta_0                         0.840094
params_beta_1                         0.991306
params_epsilon                        0.000001
user_attrs_epoch                          10.0
user_attrs_training_loss              0.191237
user_attrs_validation_loss            0.290076
Name: 252, dtype: object
37 Val: 0.9013761467889908 Test: 0.8934651290499726
38 Val: 0.8979357798165137 Test: 0.8918176825919825
39 Val: 0.9036697247706422 Test: 0.9022515101592532
40 Val: 0.9048165137614679 Test: 0.8929159802306426
41 Val: 0.9013761467889908 Test: 0.8945634266886326
42 Val: 0.9071100917431193 Test: 0.8896210873146623
43 Val: 0.9036697247706422 Test: 0.8901702361339923
44 Val: 0.9071100917431193 Test: 0.8945634266886326
45 Val: 0.9048165137614679 Test: 0.8945634266886326
46 Val: 0.9013761467889908 Test: 0.8962108731466227
Validation performance: 89.79 & 90.33 ± 0.29 & 90.71
Testing performance: 88.96 & 89.4 ± 0.36 & 90.23

[TRIAL] 121 [VALIDATION PERFORMANCE] 0.908256880733945 [TRAINING LOSS] 0.05380821813171654 [VALIDATION LOSS] 0.42703438687481377 

number                                     121
value                                 0.908257
params_threshold                      0.419471
params_attention_heads                      11
params_balanced_loss                      True
params_embedding_pooling_operation         max
params_attention_pooling_operation        mean
params_batch_size                           47
params_dropout_rate                   0.519986
params_early_stopping_patience              21
params_epochs                              118
params_global_pooling                     mean
params_hidden_dimension                    119
params_learning_rate                  0.001609
params_number_of_hidden_layers               4
params_plateau_divider                       3
params_plateau_patience                     10
params_weight_decay                   0.000014
params_beta_0                         0.886492
params_beta_1                         0.985094
params_epsilon                        0.000043
user_attrs_epoch                          27.0
user_attrs_training_loss              0.053808
user_attrs_validation_loss            0.427034
Name: 121, dtype: object
37 Val: 0.893348623853211 Test: 0.8929159802306426
38 Val: 0.8944954128440367 Test: 0.8907193849533224
39 Val: 0.8922018348623854 Test: 0.8901702361339923
40 Val: 0.9059633027522935 Test: 0.899505766062603
41 Val: 0.9025229357798165 Test: 0.8967600219659527
42 Val: 0.8979357798165137 Test: 0.8868753432180121
43 Val: 0.9002293577981652 Test: 0.8978583196046128
44 Val: 0.8922018348623854 Test: 0.8956617243272927
45 Val: 0.9048165137614679 Test: 0.8940142778693025
46 Val: 0.8956422018348624 Test: 0.8962108731466227
Validation performance: 89.22 & 89.79 ± 0.52 & 90.6
Testing performance: 88.69 & 89.41 ± 0.39 & 89.95

[TRIAL] 43 [VALIDATION PERFORMANCE] 0.908256880733945 [TRAINING LOSS] 0.020480574728342905 [VALIDATION LOSS] 0.6447915143022934 

number                                      43
value                                 0.908257
params_threshold                      0.574194
params_attention_heads                       9
params_balanced_loss                      True
params_embedding_pooling_operation        mean
params_attention_pooling_operation         max
params_batch_size                           78
params_dropout_rate                   0.384741
params_early_stopping_patience              25
params_epochs                              136
params_global_pooling                     mean
params_hidden_dimension                    163
params_learning_rate                  0.001391
params_number_of_hidden_layers               4
params_plateau_divider                       8
params_plateau_patience                     23
params_weight_decay                   0.000024
params_beta_0                         0.894023
params_beta_1                          0.98113
params_epsilon                             0.0
user_attrs_epoch                          26.0
user_attrs_training_loss              0.020481
user_attrs_validation_loss            0.644792
Name: 43, dtype: object
37 Val: 0.9013761467889908 Test: 0.8890719384953323
38 Val: 0.9013761467889908 Test: 0.8846787479406919
39 Val: 0.9094036697247706 Test: 0.8978583196046128
40 Val: 0.9013761467889908 Test: 0.8951125755079626
41 Val: 0.8967889908256881 Test: 0.8901702361339923
42 Val: 0.9048165137614679 Test: 0.8945634266886326
43 Val: 0.9036697247706422 Test: 0.8912685337726524
44 Val: 0.9025229357798165 Test: 0.8945634266886326
45 Val: 0.9036697247706422 Test: 0.8923668314113125
46 Val: 0.9059633027522935 Test: 0.886326194398682
Validation performance: 89.68 & 90.31 ± 0.33 & 90.94
Testing performance: 88.47 & 89.16 ± 0.41 & 89.79

[SST-2] Elapsed time: 308.0326257387797 minutes.
