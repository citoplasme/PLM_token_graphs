[I 2025-03-22 05:40:11,413] Using an existing study with name 'SST-2-GATv2-google-bert-bert-base-uncased-Grouped-No_Aggregation-Single_Unitary_Weight-0.0-0.0' instead of creating a new one.
Optimization already completed.

[TRIAL] 236 [VALIDATION PERFORMANCE] 0.9094036697247706 [TRAINING LOSS] 0.16149675803926755 [VALIDATION LOSS] 0.3071768156119755 

number                                     236
value                                 0.909404
params_threshold                      0.553471
params_attention_heads                       8
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                          131
params_dropout_rate                   0.419923
params_early_stopping_patience              14
params_epochs                               54
params_global_pooling                     mean
params_hidden_dimension                    146
params_learning_rate                  0.000875
params_number_of_hidden_layers               2
params_plateau_divider                       7
params_plateau_patience                     11
params_weight_decay                   0.000222
params_beta_0                         0.864609
params_beta_1                          0.98051
params_epsilon                             0.0
user_attrs_epoch                           8.0
user_attrs_training_loss              0.161497
user_attrs_validation_loss            0.307177
Name: 236, dtype: object
37 Val: 0.8990825688073395 Test: 0.8962108731466227
38 Val: 0.9013761467889908 Test: 0.8956617243272927
39 Val: 0.9036697247706422 Test: 0.8978583196046128
40 Val: 0.9048165137614679 Test: 0.8841295991213619
41 Val: 0.9059633027522935 Test: 0.8951125755079626
42 Val: 0.9036697247706422 Test: 0.8868753432180121
43 Val: 0.8990825688073395 Test: 0.8868753432180121
44 Val: 0.9048165137614679 Test: 0.8907193849533224
45 Val: 0.9025229357798165 Test: 0.8896210873146623
46 Val: 0.9036697247706422 Test: 0.8934651290499726
Validation performance: 89.91 & 90.29 ± 0.24 & 90.6
Testing performance: 88.41 & 89.17 ± 0.47 & 89.79

[TRIAL] 169 [VALIDATION PERFORMANCE] 0.9094036697247706 [TRAINING LOSS] 0.12056800016822915 [VALIDATION LOSS] 0.37335584809382755 

number                                     169
value                                 0.909404
params_threshold                      0.465431
params_attention_heads                       7
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                          147
params_dropout_rate                   0.478516
params_early_stopping_patience              16
params_epochs                              104
params_global_pooling                     mean
params_hidden_dimension                    150
params_learning_rate                  0.002284
params_number_of_hidden_layers               2
params_plateau_divider                       7
params_plateau_patience                     16
params_weight_decay                   0.000023
params_beta_0                         0.878316
params_beta_1                          0.98261
params_epsilon                        0.000001
user_attrs_epoch                          16.0
user_attrs_training_loss              0.120568
user_attrs_validation_loss            0.373356
Name: 169, dtype: object
37 Val: 0.9025229357798165 Test: 0.8907193849533224
38 Val: 0.9036697247706422 Test: 0.8918176825919825
39 Val: 0.9048165137614679 Test: 0.8874244920373421
40 Val: 0.9036697247706422 Test: 0.8901702361339923
41 Val: 0.9002293577981652 Test: 0.8885227896760022
42 Val: 0.8990825688073395 Test: 0.8945634266886326
43 Val: 0.8956422018348624 Test: 0.8824821526633718
44 Val: 0.8990825688073395 Test: 0.8841295991213619
45 Val: 0.8956422018348624 Test: 0.8907193849533224
46 Val: 0.9013761467889908 Test: 0.8923668314113125
Validation performance: 89.56 & 90.06 ± 0.32 & 90.48
Testing performance: 88.25 & 88.93 ± 0.37 & 89.46

[TRIAL] 111 [VALIDATION PERFORMANCE] 0.9094036697247706 [TRAINING LOSS] 0.06819684175299663 [VALIDATION LOSS] 0.37666859158447813 

number                                     111
value                                 0.909404
params_threshold                      0.494701
params_attention_heads                       7
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                          138
params_dropout_rate                   0.428099
params_early_stopping_patience              15
params_epochs                               80
params_global_pooling                     mean
params_hidden_dimension                    152
params_learning_rate                  0.001451
params_number_of_hidden_layers               2
params_plateau_divider                       7
params_plateau_patience                     11
params_weight_decay                   0.000441
params_beta_0                         0.865154
params_beta_1                         0.981043
params_epsilon                             0.0
user_attrs_epoch                          15.0
user_attrs_training_loss              0.068197
user_attrs_validation_loss            0.376669
Name: 111, dtype: object
37 Val: 0.9002293577981652 Test: 0.8874244920373421
38 Val: 0.9013761467889908 Test: 0.8918176825919825
39 Val: 0.9094036697247706 Test: 0.8934651290499726
40 Val: 0.9025229357798165 Test: 0.8896210873146623
41 Val: 0.8990825688073395 Test: 0.8945634266886326
42 Val: 0.9036697247706422 Test: 0.8940142778693025
43 Val: 0.9036697247706422 Test: 0.8890719384953323
44 Val: 0.8979357798165137 Test: 0.885777045579352
45 Val: 0.9002293577981652 Test: 0.8874244920373421
46 Val: 0.8990825688073395 Test: 0.8962108731466227
Validation performance: 89.79 & 90.17 ± 0.33 & 90.94
Testing performance: 88.58 & 89.09 ± 0.36 & 89.62

[TRIAL] 121 [VALIDATION PERFORMANCE] 0.908256880733945 [TRAINING LOSS] 0.20569068690141043 [VALIDATION LOSS] 0.27340614630116356 

number                                     121
value                                 0.908257
params_threshold                      0.495264
params_attention_heads                       4
params_balanced_loss                      True
params_embedding_pooling_operation        mean
params_attention_pooling_operation         max
params_batch_size                           97
params_dropout_rate                   0.503811
params_early_stopping_patience              12
params_epochs                               52
params_global_pooling                     mean
params_hidden_dimension                    163
params_learning_rate                  0.001062
params_number_of_hidden_layers               2
params_plateau_divider                       9
params_plateau_patience                     10
params_weight_decay                   0.000275
params_beta_0                         0.880437
params_beta_1                         0.983047
params_epsilon                             0.0
user_attrs_epoch                           9.0
user_attrs_training_loss              0.205691
user_attrs_validation_loss            0.273406
Name: 121, dtype: object
37 Val: 0.9002293577981652 Test: 0.8934651290499726
38 Val: 0.8944954128440367 Test: 0.8830313014827018
39 Val: 0.8967889908256881 Test: 0.8846787479406919
40 Val: 0.9013761467889908 Test: 0.8912685337726524
41 Val: 0.9025229357798165 Test: 0.8885227896760022
42 Val: 0.9048165137614679 Test: 0.8874244920373421
43 Val: 0.9128440366972477 Test: 0.8951125755079626
44 Val: 0.9002293577981652 Test: 0.8890719384953323
45 Val: 0.9013761467889908 Test: 0.8912685337726524
46 Val: 0.8967889908256881 Test: 0.8868753432180121
Validation performance: 89.45 & 90.11 ± 0.51 & 91.28
Testing performance: 88.3 & 88.91 ± 0.38 & 89.51

[TRIAL] 220 [VALIDATION PERFORMANCE] 0.908256880733945 [TRAINING LOSS] 0.02051874179393053 [VALIDATION LOSS] 0.5077524461916515 

number                                     220
value                                 0.908257
params_threshold                      0.415809
params_attention_heads                       9
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                          140
params_dropout_rate                   0.428725
params_early_stopping_patience              18
params_epochs                              107
params_global_pooling                      max
params_hidden_dimension                    174
params_learning_rate                  0.000597
params_number_of_hidden_layers               2
params_plateau_divider                       9
params_plateau_patience                     11
params_weight_decay                    0.00043
params_beta_0                         0.857366
params_beta_1                         0.987813
params_epsilon                        0.000001
user_attrs_epoch                          24.0
user_attrs_training_loss              0.020519
user_attrs_validation_loss            0.507752
Name: 220, dtype: object
37 Val: 0.8979357798165137 Test: 0.8962108731466227
38 Val: 0.8956422018348624 Test: 0.900604063701263
39 Val: 0.9013761467889908 Test: 0.886326194398682
40 Val: 0.8990825688073395 Test: 0.8989566172432729
41 Val: 0.9071100917431193 Test: 0.8962108731466227
42 Val: 0.9059633027522935 Test: 0.8967600219659527
43 Val: 0.9002293577981652 Test: 0.8923668314113125
44 Val: 0.8990825688073395 Test: 0.886326194398682
45 Val: 0.8990825688073395 Test: 0.8918176825919825
46 Val: 0.8990825688073395 Test: 0.8940142778693025
Validation performance: 89.56 & 90.05 ± 0.35 & 90.71
Testing performance: 88.63 & 89.4 ± 0.48 & 90.06

[SST-2] Elapsed time: 157.47375733057657 minutes.
