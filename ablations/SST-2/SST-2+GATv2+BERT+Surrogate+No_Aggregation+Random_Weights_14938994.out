[I 2025-02-19 06:17:14,775] Using an existing study with name 'SST-2-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-Random_Weights-0.0-0.0' instead of creating a new one.
[I 2025-02-19 06:21:34,172] Trial 235 finished with value: 0.9025229357798165 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.5044399148503256, 'batch_size': 187, 'attention_heads': 4, 'hidden_dimension': 162, 'number_of_hidden_layers': 1, 'dropout_rate': 0.446125739705934, 'global_pooling': 'max', 'learning_rate': 0.0031899372201185335, 'weight_decay': 0.0001916056335271048, 'beta_0': 0.8283499619157786, 'beta_1': 0.9833926499039356, 'epsilon': 3.139028769129572e-07, 'balanced_loss': False, 'epochs': 155, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 4}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 06:26:04,644] Trial 236 finished with value: 0.9025229357798165 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.47098258866344184, 'batch_size': 170, 'attention_heads': 5, 'hidden_dimension': 174, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4395458393584757, 'global_pooling': 'max', 'learning_rate': 0.002266217793000595, 'weight_decay': 0.00026851493695071967, 'beta_0': 0.8300758795361731, 'beta_1': 0.984914742817788, 'epsilon': 1.1645006073139374e-08, 'balanced_loss': False, 'epochs': 151, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 4}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 06:30:31,194] Trial 237 finished with value: 0.8990825688073395 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.47935109213824845, 'batch_size': 57, 'attention_heads': 4, 'hidden_dimension': 176, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4587088588976696, 'global_pooling': 'max', 'learning_rate': 0.002872620784292176, 'weight_decay': 0.00030561049196898963, 'beta_0': 0.8537677460623109, 'beta_1': 0.9846571966932733, 'epsilon': 1.472199752421102e-07, 'balanced_loss': False, 'epochs': 159, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 4}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 06:34:52,001] Trial 238 finished with value: 0.8990825688073395 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.45703286812360694, 'batch_size': 79, 'attention_heads': 5, 'hidden_dimension': 171, 'number_of_hidden_layers': 1, 'dropout_rate': 0.44776387450754074, 'global_pooling': 'max', 'learning_rate': 0.0019618410506916117, 'weight_decay': 0.000219974711516157, 'beta_0': 0.834707321597353, 'beta_1': 0.98254762520835, 'epsilon': 1.0280259573948954e-08, 'balanced_loss': False, 'epochs': 149, 'early_stopping_patience': 25, 'plateau_patience': 22, 'plateau_divider': 4}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 06:39:08,500] Trial 239 finished with value: 0.8990825688073395 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.6113839208364176, 'batch_size': 68, 'attention_heads': 6, 'hidden_dimension': 185, 'number_of_hidden_layers': 1, 'dropout_rate': 0.45428244945018026, 'global_pooling': 'max', 'learning_rate': 0.002567675799210642, 'weight_decay': 0.000422741587349248, 'beta_0': 0.8279125606778784, 'beta_1': 0.9838938632860412, 'epsilon': 4.86427259114566e-07, 'balanced_loss': False, 'epochs': 155, 'early_stopping_patience': 25, 'plateau_patience': 24, 'plateau_divider': 4}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 06:43:13,219] Trial 240 finished with value: 0.9059633027522935 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.4921207687985146, 'batch_size': 176, 'attention_heads': 4, 'hidden_dimension': 152, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4365534058344213, 'global_pooling': 'max', 'learning_rate': 0.003202581681081389, 'weight_decay': 0.00037311397030408795, 'beta_0': 0.8437761910607869, 'beta_1': 0.9852076573214708, 'epsilon': 2.7814490285961685e-08, 'balanced_loss': False, 'epochs': 143, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 5}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 06:48:03,943] Trial 241 finished with value: 0.8979357798165137 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.5121558422206323, 'batch_size': 73, 'attention_heads': 4, 'hidden_dimension': 148, 'number_of_hidden_layers': 1, 'dropout_rate': 0.42956127915064374, 'global_pooling': 'max', 'learning_rate': 0.0047828825067540055, 'weight_decay': 0.0008283633886302362, 'beta_0': 0.843849028667796, 'beta_1': 0.9851358153866698, 'epsilon': 2.5460924133173122e-08, 'balanced_loss': False, 'epochs': 152, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 5}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 06:52:01,562] Trial 242 finished with value: 0.9036697247706422 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6330450170589833, 'batch_size': 173, 'attention_heads': 4, 'hidden_dimension': 142, 'number_of_hidden_layers': 1, 'dropout_rate': 0.44019956711046215, 'global_pooling': 'max', 'learning_rate': 0.00182028134123128, 'weight_decay': 0.00039543727855156344, 'beta_0': 0.8408300861767316, 'beta_1': 0.9854420636343587, 'epsilon': 2.8073476302872514e-08, 'balanced_loss': False, 'epochs': 147, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 5}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 06:57:47,636] Trial 243 finished with value: 0.8979357798165137 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.4837649444087237, 'batch_size': 60, 'attention_heads': 13, 'hidden_dimension': 151, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4334168746502659, 'global_pooling': 'max', 'learning_rate': 0.0036148943516515924, 'weight_decay': 0.0005060559787539526, 'beta_0': 0.8467019038272263, 'beta_1': 0.9820751597957876, 'epsilon': 2.1783669120537366e-08, 'balanced_loss': False, 'epochs': 157, 'early_stopping_patience': 24, 'plateau_patience': 25, 'plateau_divider': 5}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 07:01:45,714] Trial 244 finished with value: 0.9071100917431193 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.46760864813536185, 'batch_size': 180, 'attention_heads': 4, 'hidden_dimension': 155, 'number_of_hidden_layers': 1, 'dropout_rate': 0.44389386263994574, 'global_pooling': 'max', 'learning_rate': 0.0030195471147282885, 'weight_decay': 0.0003294529655421006, 'beta_0': 0.8430955374193454, 'beta_1': 0.9863268125899984, 'epsilon': 3.9595502221062713e-07, 'balanced_loss': False, 'epochs': 142, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 4}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 07:05:45,875] Trial 245 finished with value: 0.8887614678899083 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.49955061749576496, 'batch_size': 184, 'attention_heads': 4, 'hidden_dimension': 153, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4439314898100992, 'global_pooling': 'max', 'learning_rate': 0.002252683588755671, 'weight_decay': 0.00036742657692836794, 'beta_0': 0.8434627945587749, 'beta_1': 0.986003923156005, 'epsilon': 3.8692941423321504e-07, 'balanced_loss': False, 'epochs': 143, 'early_stopping_patience': 25, 'plateau_patience': 24, 'plateau_divider': 6}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 07:09:49,134] Trial 246 finished with value: 0.8956422018348624 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.4710815995391731, 'batch_size': 178, 'attention_heads': 4, 'hidden_dimension': 157, 'number_of_hidden_layers': 1, 'dropout_rate': 0.43677717355371526, 'global_pooling': 'max', 'learning_rate': 0.003272180330290832, 'weight_decay': 0.00025693544930871563, 'beta_0': 0.8413949661811285, 'beta_1': 0.9857410074798664, 'epsilon': 3.1001131774157276e-07, 'balanced_loss': False, 'epochs': 139, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 4}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 07:13:49,762] Trial 247 finished with value: 0.8990825688073395 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.4988814567145536, 'batch_size': 181, 'attention_heads': 4, 'hidden_dimension': 161, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4117706934891172, 'global_pooling': 'max', 'learning_rate': 0.0025636660050090175, 'weight_decay': 0.00029821103705662653, 'beta_0': 0.8454654069954839, 'beta_1': 0.9862147369661988, 'epsilon': 3.846249087616821e-08, 'balanced_loss': False, 'epochs': 145, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 4}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 07:17:40,454] Trial 248 finished with value: 0.908256880733945 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6016143770237856, 'batch_size': 190, 'attention_heads': 4, 'hidden_dimension': 145, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4445274913106207, 'global_pooling': 'max', 'learning_rate': 0.0041151886692037615, 'weight_decay': 0.0003383908333437654, 'beta_0': 0.8447220765617042, 'beta_1': 0.9850894035643588, 'epsilon': 1.944193383170264e-08, 'balanced_loss': False, 'epochs': 150, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 4}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 07:21:45,748] Trial 249 finished with value: 0.9025229357798165 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.46505727868454194, 'batch_size': 168, 'attention_heads': 4, 'hidden_dimension': 137, 'number_of_hidden_layers': 1, 'dropout_rate': 0.42790513753364634, 'global_pooling': 'max', 'learning_rate': 0.0047001692916373156, 'weight_decay': 0.0003492815970770206, 'beta_0': 0.8497860364238531, 'beta_1': 0.9851864796824097, 'epsilon': 2.090701272152122e-08, 'balanced_loss': False, 'epochs': 148, 'early_stopping_patience': 25, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 07:25:27,337] Trial 250 finished with value: 0.8944954128440367 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.5970548776258093, 'batch_size': 174, 'attention_heads': 4, 'hidden_dimension': 155, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4349543021186696, 'global_pooling': 'max', 'learning_rate': 0.003807954982810346, 'weight_decay': 0.000426489028785135, 'beta_0': 0.8391537989873226, 'beta_1': 0.9856026360551801, 'epsilon': 1.904143592777768e-08, 'balanced_loss': False, 'epochs': 154, 'early_stopping_patience': 13, 'plateau_patience': 23, 'plateau_divider': 4}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 07:29:44,226] Trial 251 finished with value: 0.8967889908256881 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.5301890406730728, 'batch_size': 192, 'attention_heads': 4, 'hidden_dimension': 166, 'number_of_hidden_layers': 1, 'dropout_rate': 0.44975898967683625, 'global_pooling': 'sum', 'learning_rate': 0.006239182131384664, 'weight_decay': 0.00031685688490312123, 'beta_0': 0.8421637068596525, 'beta_1': 0.9847580921027118, 'epsilon': 6.23439008276965e-07, 'balanced_loss': False, 'epochs': 162, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 4}. Best is trial 115 with value: 0.911697247706422.
[I 2025-02-19 07:33:46,091] Trial 252 finished with value: 0.9025229357798165 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.49396336000311625, 'batch_size': 189, 'attention_heads': 4, 'hidden_dimension': 153, 'number_of_hidden_layers': 1, 'dropout_rate': 0.44149554117570816, 'global_pooling': 'max', 'learning_rate': 0.004531628156114001, 'weight_decay': 0.0003868643450818315, 'beta_0': 0.8438089389391891, 'beta_1': 0.984988101013163, 'epsilon': 5.253666472285879e-07, 'balanced_loss': False, 'epochs': 141, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 4}. Best is trial 115 with value: 0.911697247706422.

[TRIAL] 115 [VALIDATION PERFORMANCE] 0.911697247706422 [TRAINING LOSS] 0.22824077383946564 [VALIDATION LOSS] 0.2807440360387166 

number                                     115
value                                 0.911697
params_threshold                      0.635113
params_attention_heads                       8
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           59
params_dropout_rate                   0.434957
params_early_stopping_patience              24
params_epochs                              151
params_global_pooling                      max
params_hidden_dimension                     87
params_learning_rate                  0.001912
params_number_of_hidden_layers               1
params_plateau_divider                       3
params_plateau_patience                     24
params_weight_decay                   0.000345
params_beta_0                         0.842721
params_beta_1                         0.982764
params_epsilon                             0.0
user_attrs_epoch                           6.0
user_attrs_training_loss              0.228241
user_attrs_validation_loss            0.280744
Name: 115, dtype: object
37 Val: 0.9002293577981652 Test: 0.8989566172432729
38 Val: 0.9105504587155964 Test: 0.8940142778693025
39 Val: 0.9059633027522935 Test: 0.8923668314113125
40 Val: 0.9036697247706422 Test: 0.8901702361339923
41 Val: 0.8979357798165137 Test: 0.8824821526633718
42 Val: 0.9105504587155964 Test: 0.8846787479406919
43 Val: 0.9036697247706422 Test: 0.8962108731466227
44 Val: 0.9036697247706422 Test: 0.8874244920373421
45 Val: 0.9002293577981652 Test: 0.8934651290499726
46 Val: 0.8979357798165137 Test: 0.8824821526633718
Validation performance: 89.79 & 90.34 ± 0.46 & 91.06
Testing performance: 88.25 & 89.02 ± 0.58 & 89.9

[TRIAL] 85 [VALIDATION PERFORMANCE] 0.9105504587155964 [TRAINING LOSS] 0.09438438384924816 [VALIDATION LOSS] 0.3028857852690495 

number                                      85
value                                  0.91055
params_threshold                      0.620271
params_attention_heads                       6
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           72
params_dropout_rate                   0.426974
params_early_stopping_patience              25
params_epochs                              146
params_global_pooling                      max
params_hidden_dimension                     75
params_learning_rate                  0.001613
params_number_of_hidden_layers               1
params_plateau_divider                       4
params_plateau_patience                     24
params_weight_decay                   0.000345
params_beta_0                         0.842704
params_beta_1                         0.983151
params_epsilon                        0.000001
user_attrs_epoch                          17.0
user_attrs_training_loss              0.094384
user_attrs_validation_loss            0.302886
Name: 85, dtype: object
37 Val: 0.9036697247706422 Test: 0.8951125755079626
38 Val: 0.9071100917431193 Test: 0.8929159802306426
39 Val: 0.893348623853211 Test: 0.8846787479406919
40 Val: 0.9013761467889908 Test: 0.8896210873146623
41 Val: 0.9071100917431193 Test: 0.8929159802306426
42 Val: 0.8990825688073395 Test: 0.8846787479406919
43 Val: 0.9048165137614679 Test: 0.8901702361339923
44 Val: 0.8944954128440367 Test: 0.8890719384953323
45 Val: 0.9013761467889908 Test: 0.8912685337726524
46 Val: 0.9013761467889908 Test: 0.885227896760022
Validation performance: 89.33 & 90.14 ± 0.47 & 90.71
Testing performance: 88.47 & 88.96 ± 0.37 & 89.51

[TRIAL] 158 [VALIDATION PERFORMANCE] 0.9105504587155964 [TRAINING LOSS] 0.08011203368262547 [VALIDATION LOSS] 0.3791405533750852 

number                                     158
value                                  0.91055
params_threshold                      0.622963
params_attention_heads                       5
params_balanced_loss                     False
params_embedding_pooling_operation        mean
params_attention_pooling_operation         max
params_batch_size                          170
params_dropout_rate                   0.441416
params_early_stopping_patience              25
params_epochs                              163
params_global_pooling                      max
params_hidden_dimension                    222
params_learning_rate                  0.001724
params_number_of_hidden_layers               1
params_plateau_divider                       3
params_plateau_patience                     25
params_weight_decay                   0.000036
params_beta_0                         0.852778
params_beta_1                         0.982268
params_epsilon                             0.0
user_attrs_epoch                          16.0
user_attrs_training_loss              0.080112
user_attrs_validation_loss            0.379141
Name: 158, dtype: object
37 Val: 0.9002293577981652 Test: 0.8841295991213619
38 Val: 0.8967889908256881 Test: 0.8923668314113125
39 Val: 0.9025229357798165 Test: 0.8973091707852828
40 Val: 0.9036697247706422 Test: 0.8918176825919825
41 Val: 0.9013761467889908 Test: 0.8879736408566722
42 Val: 0.9013761467889908 Test: 0.8934651290499726
43 Val: 0.9002293577981652 Test: 0.8896210873146623
44 Val: 0.8990825688073395 Test: 0.8934651290499726
45 Val: 0.9013761467889908 Test: 0.8951125755079626
46 Val: 0.9036697247706422 Test: 0.8929159802306426
Validation performance: 89.68 & 90.1 ± 0.21 & 90.37
Testing performance: 88.41 & 89.18 ± 0.38 & 89.73

[TRIAL] 151 [VALIDATION PERFORMANCE] 0.9094036697247706 [TRAINING LOSS] 0.09094514411229354 [VALIDATION LOSS] 0.33463576138019563 

number                                     151
value                                 0.909404
params_threshold                      0.602102
params_attention_heads                       4
params_balanced_loss                     False
params_embedding_pooling_operation        mean
params_attention_pooling_operation         max
params_batch_size                          178
params_dropout_rate                   0.439578
params_early_stopping_patience              25
params_epochs                              151
params_global_pooling                      max
params_hidden_dimension                    229
params_learning_rate                  0.002499
params_number_of_hidden_layers               1
params_plateau_divider                       3
params_plateau_patience                     25
params_weight_decay                   0.000064
params_beta_0                         0.845104
params_beta_1                         0.981777
params_epsilon                             0.0
user_attrs_epoch                          18.0
user_attrs_training_loss              0.090945
user_attrs_validation_loss            0.334636
Name: 151, dtype: object
37 Val: 0.9002293577981652 Test: 0.8978583196046128
38 Val: 0.9002293577981652 Test: 0.8896210873146623
39 Val: 0.9025229357798165 Test: 0.8868753432180121
40 Val: 0.9013761467889908 Test: 0.8775398132894014
41 Val: 0.9013761467889908 Test: 0.8824821526633718
42 Val: 0.9013761467889908 Test: 0.8868753432180121
43 Val: 0.9002293577981652 Test: 0.8769906644700713
44 Val: 0.9002293577981652 Test: 0.8874244920373421
45 Val: 0.8967889908256881 Test: 0.8885227896760022
46 Val: 0.9048165137614679 Test: 0.8868753432180121
Validation performance: 89.68 & 90.09 ± 0.2 & 90.48
Testing performance: 87.7 & 88.61 ± 0.61 & 89.79

[TRIAL] 178 [VALIDATION PERFORMANCE] 0.9094036697247706 [TRAINING LOSS] 0.04387946018880797 [VALIDATION LOSS] 0.4359738432935306 

number                                     178
value                                 0.909404
params_threshold                      0.565728
params_attention_heads                       6
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation        mean
params_batch_size                           64
params_dropout_rate                   0.438154
params_early_stopping_patience              25
params_epochs                              148
params_global_pooling                      max
params_hidden_dimension                    152
params_learning_rate                  0.001989
params_number_of_hidden_layers               1
params_plateau_divider                       3
params_plateau_patience                     25
params_weight_decay                    0.00027
params_beta_0                         0.831222
params_beta_1                         0.984711
params_epsilon                        0.000001
user_attrs_epoch                          30.0
user_attrs_training_loss              0.043879
user_attrs_validation_loss            0.435974
Name: 178, dtype: object
37 Val: 0.9025229357798165 Test: 0.8841295991213619
38 Val: 0.8990825688073395 Test: 0.8945634266886326
39 Val: 0.9013761467889908 Test: 0.8934651290499726
40 Val: 0.9105504587155964 Test: 0.8918176825919825
41 Val: 0.9048165137614679 Test: 0.8984074684239429
42 Val: 0.8990825688073395 Test: 0.8956617243272927
43 Val: 0.8979357798165137 Test: 0.8918176825919825
44 Val: 0.9002293577981652 Test: 0.8846787479406919
45 Val: 0.893348623853211 Test: 0.9011532125205931
46 Val: 0.9048165137614679 Test: 0.8885227896760022
Validation performance: 89.33 & 90.14 ± 0.47 & 91.06
Testing performance: 88.41 & 89.24 ± 0.55 & 90.12

[SST-2] Elapsed time: 286.4894187808037 minutes.
