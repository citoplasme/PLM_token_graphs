[I 2025-02-28 04:39:48,957] Using an existing study with name 'R8-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-No_Ablation-1.0-0.75' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors
[I 2025-02-28 04:52:15,650] Trial 185 finished with value: 0.9185934435869356 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8895433018899833, 'batch_size': 105, 'attention_heads': 10, 'hidden_dimension': 156, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3105271785784352, 'global_pooling': 'max', 'learning_rate': 0.0006420701096891997, 'weight_decay': 9.218956466997034e-05, 'beta_0': 0.8062361121756615, 'beta_1': 0.9853220402534155, 'epsilon': 3.0671210176074825e-05, 'balanced_loss': True, 'epochs': 132, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 05:03:47,892] Trial 186 finished with value: 0.9213859512902145 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8977397575575317, 'batch_size': 109, 'attention_heads': 10, 'hidden_dimension': 138, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3196461233701725, 'global_pooling': 'max', 'learning_rate': 0.000894983134095696, 'weight_decay': 0.00010457250886543781, 'beta_0': 0.8030160748111322, 'beta_1': 0.9858517325934124, 'epsilon': 1.6954850163714778e-05, 'balanced_loss': True, 'epochs': 120, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 05:15:13,551] Trial 187 finished with value: 0.9200651711058196 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9136622816642896, 'batch_size': 114, 'attention_heads': 12, 'hidden_dimension': 143, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30674787558585365, 'global_pooling': 'max', 'learning_rate': 0.000699415422428791, 'weight_decay': 8.392598647065949e-05, 'beta_0': 0.8101044080736128, 'beta_1': 0.9844911381568927, 'epsilon': 2.066517589520501e-05, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 05:26:34,738] Trial 188 finished with value: 0.9100581660558498 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9233223278295427, 'batch_size': 101, 'attention_heads': 12, 'hidden_dimension': 153, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3250121687369574, 'global_pooling': 'sum', 'learning_rate': 0.0010759618815266638, 'weight_decay': 0.0001922944066524455, 'beta_0': 0.882392592049285, 'beta_1': 0.986533722957407, 'epsilon': 1.426497813088517e-05, 'balanced_loss': True, 'epochs': 139, 'early_stopping_patience': 21, 'plateau_patience': 19, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 05:36:45,416] Trial 189 finished with value: 0.9211917558303881 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9062769752534506, 'batch_size': 94, 'attention_heads': 11, 'hidden_dimension': 134, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31684589476342384, 'global_pooling': 'max', 'learning_rate': 0.001487194707523672, 'weight_decay': 0.00013097754560537675, 'beta_0': 0.8057161141179291, 'beta_1': 0.9853716514302114, 'epsilon': 1.5614228071471595e-07, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 4.17 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.40 GiB is free. Including non-PyTorch memory, this process has 41.15 GiB memory in use. Of the allocated memory 38.82 GiB is allocated by PyTorch, and 1.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 05:44:48,583] Trial 190 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8844777363272924, 'batch_size': 106, 'attention_heads': 11, 'hidden_dimension': 162, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3363013079791181, 'global_pooling': 'max', 'learning_rate': 0.0017959685912828168, 'weight_decay': 4.066103414580242e-05, 'beta_0': 0.813919184873932, 'beta_1': 0.986140161525676, 'epsilon': 2.7026120808981225e-05, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 05:55:57,037] Trial 191 finished with value: 0.9167799492590849 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8947058001731572, 'batch_size': 98, 'attention_heads': 9, 'hidden_dimension': 150, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30735800000610125, 'global_pooling': 'max', 'learning_rate': 0.0008541420018993603, 'weight_decay': 7.303879870605071e-05, 'beta_0': 0.8075949443711604, 'beta_1': 0.9870363573006038, 'epsilon': 1.209554889835269e-05, 'balanced_loss': True, 'epochs': 106, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.22 GiB is free. Including non-PyTorch memory, this process has 41.34 GiB memory in use. Of the allocated memory 35.75 GiB is allocated by PyTorch, and 4.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 06:03:48,336] Trial 192 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9011069352542422, 'batch_size': 111, 'attention_heads': 12, 'hidden_dimension': 170, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33129613228412064, 'global_pooling': 'max', 'learning_rate': 0.0010258857899659805, 'weight_decay': 4.768952363214681e-05, 'beta_0': 0.8000809982642864, 'beta_1': 0.985665621742577, 'epsilon': 6.0662554719562944e-05, 'balanced_loss': True, 'epochs': 147, 'early_stopping_patience': 17, 'plateau_patience': 22, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 06:15:01,019] Trial 193 finished with value: 0.9145598969806461 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9190549425468908, 'batch_size': 115, 'attention_heads': 11, 'hidden_dimension': 156, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31394799416216845, 'global_pooling': 'max', 'learning_rate': 0.0006937741268225034, 'weight_decay': 9.830866079266888e-05, 'beta_0': 0.8120014850940022, 'beta_1': 0.985037584003403, 'epsilon': 3.876868087779793e-05, 'balanced_loss': True, 'epochs': 134, 'early_stopping_patience': 21, 'plateau_patience': 23, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 06:27:00,827] Trial 194 finished with value: 0.926796999925308 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9098937725193187, 'batch_size': 101, 'attention_heads': 13, 'hidden_dimension': 144, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3220249848087693, 'global_pooling': 'max', 'learning_rate': 0.0013668305007704887, 'weight_decay': 0.00011950990431496575, 'beta_0': 0.8046646083210779, 'beta_1': 0.9874976134514227, 'epsilon': 3.1443692442008074e-05, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 06:38:00,915] Trial 195 finished with value: 0.9198513392008401 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.911891889864487, 'batch_size': 103, 'attention_heads': 13, 'hidden_dimension': 144, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3235649081588862, 'global_pooling': 'max', 'learning_rate': 0.0013512247797074705, 'weight_decay': 0.00011189287016968891, 'beta_0': 0.8041791588403616, 'beta_1': 0.9874089724214851, 'epsilon': 3.160013972963531e-05, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 06:50:02,345] Trial 196 finished with value: 0.9303388281659841 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.905050215327807, 'batch_size': 98, 'attention_heads': 13, 'hidden_dimension': 147, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3295284281529541, 'global_pooling': 'max', 'learning_rate': 0.0016164431114826586, 'weight_decay': 0.00014519800803989153, 'beta_0': 0.8022428186107712, 'beta_1': 0.9868231888320064, 'epsilon': 2.38065636464218e-05, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 3.91 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.29 GiB is free. Including non-PyTorch memory, this process has 41.27 GiB memory in use. Of the allocated memory 36.77 GiB is allocated by PyTorch, and 3.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 06:58:14,174] Trial 197 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8902464030356145, 'batch_size': 95, 'attention_heads': 13, 'hidden_dimension': 139, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32786379215807643, 'global_pooling': 'max', 'learning_rate': 0.001841318402459848, 'weight_decay': 0.0001479145941564937, 'beta_0': 0.8046272688232392, 'beta_1': 0.9868184696316992, 'epsilon': 2.230518902642666e-05, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 07:09:17,461] Trial 198 finished with value: 0.9208856413943836 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9277825853631393, 'batch_size': 83, 'attention_heads': 13, 'hidden_dimension': 147, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31907135284843013, 'global_pooling': 'max', 'learning_rate': 0.002131171728705191, 'weight_decay': 0.00012365182304426042, 'beta_0': 0.8089216274976735, 'beta_1': 0.988139701379067, 'epsilon': 2.805610587286104e-05, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 07:19:37,434] Trial 199 finished with value: 0.9092870678880115 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9092899208331999, 'batch_size': 91, 'attention_heads': 8, 'hidden_dimension': 143, 'number_of_hidden_layers': 0, 'dropout_rate': 0.517918080425066, 'global_pooling': 'max', 'learning_rate': 0.0010735779855978382, 'weight_decay': 0.00015050100107450264, 'beta_0': 0.802694699846677, 'beta_1': 0.987509735538255, 'epsilon': 3.4755012635124584e-05, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 17, 'plateau_patience': 25, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 4.39 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.65 GiB is free. Including non-PyTorch memory, this process has 40.90 GiB memory in use. Of the allocated memory 38.15 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 07:27:48,863] Trial 200 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9008204046419536, 'batch_size': 99, 'attention_heads': 14, 'hidden_dimension': 150, 'number_of_hidden_layers': 0, 'dropout_rate': 0.333104579371857, 'global_pooling': 'mean', 'learning_rate': 0.001545511231338601, 'weight_decay': 0.00013044931280332763, 'beta_0': 0.8070780864822962, 'beta_1': 0.9863796104123708, 'epsilon': 2.2109717790398443e-05, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 07:38:50,194] Trial 201 finished with value: 0.906430362397029 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9170120194104674, 'batch_size': 120, 'attention_heads': 10, 'hidden_dimension': 138, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31148364606749407, 'global_pooling': 'max', 'learning_rate': 0.0008890908929924234, 'weight_decay': 0.00017908541165032908, 'beta_0': 0.8057328305322159, 'beta_1': 0.987074058057138, 'epsilon': 4.711600399523489e-05, 'balanced_loss': True, 'epochs': 122, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 4.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.69 GiB is free. Including non-PyTorch memory, this process has 40.86 GiB memory in use. Of the allocated memory 39.02 GiB is allocated by PyTorch, and 703.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 07:45:41,712] Trial 202 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8937187340369486, 'batch_size': 88, 'attention_heads': 13, 'hidden_dimension': 165, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3243355988561308, 'global_pooling': 'max', 'learning_rate': 0.0022452090277932314, 'weight_decay': 0.00011496104811685922, 'beta_0': 0.801669187799849, 'beta_1': 0.9880288825186951, 'epsilon': 8.007863567449022e-05, 'balanced_loss': True, 'epochs': 132, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 07:56:17,889] Trial 203 finished with value: 0.9164321479290307 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9329346697367862, 'batch_size': 73, 'attention_heads': 13, 'hidden_dimension': 133, 'number_of_hidden_layers': 0, 'dropout_rate': 0.304188030401789, 'global_pooling': 'max', 'learning_rate': 0.0005188591163493757, 'weight_decay': 9.352142728471103e-05, 'beta_0': 0.8104800984950775, 'beta_1': 0.9920653700012144, 'epsilon': 1.8958972418891205e-05, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 17, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 4.64 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 43.34 GiB memory in use. Of the allocated memory 37.86 GiB is allocated by PyTorch, and 4.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 08:04:20,862] Trial 204 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8743469824055139, 'batch_size': 107, 'attention_heads': 10, 'hidden_dimension': 184, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3171965586102721, 'global_pooling': 'mean', 'learning_rate': 0.0012950214349010441, 'weight_decay': 3.462710434508339e-05, 'beta_0': 0.8039086096866898, 'beta_1': 0.9865118896274515, 'epsilon': 2.571568840284945e-05, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 08:16:12,801] Trial 205 finished with value: 0.9326105766404118 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9047708498187969, 'batch_size': 102, 'attention_heads': 12, 'hidden_dimension': 153, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3389794191013542, 'global_pooling': 'max', 'learning_rate': 0.0011718789633567172, 'weight_decay': 8.297329731212484e-05, 'beta_0': 0.801944362660041, 'beta_1': 0.9859919393378549, 'epsilon': 1.5607721574329488e-05, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 08:28:02,042] Trial 206 finished with value: 0.9268042605490693 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9066640968966209, 'batch_size': 102, 'attention_heads': 12, 'hidden_dimension': 160, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33689383015149893, 'global_pooling': 'max', 'learning_rate': 0.0010933620697624938, 'weight_decay': 6.449604173804131e-05, 'beta_0': 0.8018623716916563, 'beta_1': 0.9860847517526089, 'epsilon': 1.6196390454000633e-05, 'balanced_loss': True, 'epochs': 130, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 08:39:49,299] Trial 207 finished with value: 0.925255388943234 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8996911978543014, 'batch_size': 98, 'attention_heads': 12, 'hidden_dimension': 175, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33773993697005866, 'global_pooling': 'max', 'learning_rate': 0.0015769848899216175, 'weight_decay': 6.219602526381312e-05, 'beta_0': 0.8017736219714124, 'beta_1': 0.9860483515789457, 'epsilon': 1.5716635474752884e-05, 'balanced_loss': True, 'epochs': 131, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 08:51:11,848] Trial 208 finished with value: 0.9207107188591647 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9208574158566527, 'batch_size': 101, 'attention_heads': 12, 'hidden_dimension': 161, 'number_of_hidden_layers': 0, 'dropout_rate': 0.45769073109288033, 'global_pooling': 'max', 'learning_rate': 0.0010847419197225273, 'weight_decay': 7.741523267321176e-05, 'beta_0': 0.8007527751719432, 'beta_1': 0.9868816525475097, 'epsilon': 1.894150176315332e-05, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 4.02 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 41.93 GiB memory in use. Of the allocated memory 37.30 GiB is allocated by PyTorch, and 3.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 08:59:01,286] Trial 209 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8847350115643514, 'batch_size': 110, 'attention_heads': 12, 'hidden_dimension': 168, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3414679844706221, 'global_pooling': 'max', 'learning_rate': 0.0013162282930230034, 'weight_decay': 5.442244584179973e-05, 'beta_0': 0.8000117619450509, 'beta_1': 0.9862138672189166, 'epsilon': 1.608971930839271e-05, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 17, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 09:08:44,407] Trial 210 finished with value: 0.9172444339405629 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9055974978142443, 'batch_size': 94, 'attention_heads': 6, 'hidden_dimension': 147, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3329358056127627, 'global_pooling': 'max', 'learning_rate': 0.0018442616677247963, 'weight_decay': 6.91527331378686e-05, 'beta_0': 0.803118404912585, 'beta_1': 0.9873834887980782, 'epsilon': 2.1325759088553852e-05, 'balanced_loss': True, 'epochs': 136, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 09:21:05,340] Trial 211 finished with value: 0.9221482810419184 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9148127275366607, 'batch_size': 102, 'attention_heads': 14, 'hidden_dimension': 159, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32695954590238485, 'global_pooling': 'max', 'learning_rate': 0.0009717480589344185, 'weight_decay': 0.00010811676453066738, 'beta_0': 0.8050419080496756, 'beta_1': 0.9857391276642242, 'epsilon': 9.682709557027873e-05, 'balanced_loss': True, 'epochs': 151, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.84 GiB is free. Including non-PyTorch memory, this process has 40.71 GiB memory in use. Of the allocated memory 35.49 GiB is allocated by PyTorch, and 4.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 09:30:56,507] Trial 212 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8939830873565383, 'batch_size': 91, 'attention_heads': 12, 'hidden_dimension': 172, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3372319627402998, 'global_pooling': 'max', 'learning_rate': 0.0008063831458737323, 'weight_decay': 4.313627172196132e-05, 'beta_0': 0.8028938218410573, 'beta_1': 0.9865999935458711, 'epsilon': 1.3633412091165279e-05, 'balanced_loss': True, 'epochs': 156, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 6}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 09:42:31,515] Trial 213 finished with value: 0.9278319772281751 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9013455991591665, 'batch_size': 97, 'attention_heads': 12, 'hidden_dimension': 154, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34445072420842215, 'global_pooling': 'mean', 'learning_rate': 0.0011652289440280538, 'weight_decay': 0.00013957669732983727, 'beta_0': 0.8051321350518816, 'beta_1': 0.9903525471761326, 'epsilon': 6.856035502213603e-05, 'balanced_loss': True, 'epochs': 103, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 3.92 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.89 GiB is free. Including non-PyTorch memory, this process has 40.66 GiB memory in use. Of the allocated memory 36.22 GiB is allocated by PyTorch, and 3.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 09:52:26,203] Trial 214 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8898390304216452, 'batch_size': 97, 'attention_heads': 13, 'hidden_dimension': 152, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3503487961825875, 'global_pooling': 'mean', 'learning_rate': 0.0012419724863713074, 'weight_decay': 0.00016364757209947505, 'beta_0': 0.8050388786401663, 'beta_1': 0.9908138626598593, 'epsilon': 6.881706530602039e-05, 'balanced_loss': True, 'epochs': 99, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 10:03:51,794] Trial 215 finished with value: 0.9230513124473114 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.899675820203332, 'batch_size': 108, 'attention_heads': 12, 'hidden_dimension': 155, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34291890070593434, 'global_pooling': 'mean', 'learning_rate': 0.001552975161788381, 'weight_decay': 0.00015146051739836112, 'beta_0': 0.8029545937344181, 'beta_1': 0.9896469979710593, 'epsilon': 5.5124636207323764e-05, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 10:15:09,744] Trial 216 finished with value: 0.922411901113324 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9073850256701296, 'batch_size': 101, 'attention_heads': 12, 'hidden_dimension': 144, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33014745370902815, 'global_pooling': 'mean', 'learning_rate': 0.0011452752931759348, 'weight_decay': 0.00013019916295819856, 'beta_0': 0.8068273720304863, 'beta_1': 0.9909825163228317, 'epsilon': 7.556977394850683e-05, 'balanced_loss': True, 'epochs': 107, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 10:25:37,574] Trial 217 finished with value: 0.9208627624490985 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9138398892217429, 'batch_size': 86, 'attention_heads': 12, 'hidden_dimension': 165, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3354872065277128, 'global_pooling': 'mean', 'learning_rate': 0.0009282019235516535, 'weight_decay': 0.00010348961581254707, 'beta_0': 0.8046692135594169, 'beta_1': 0.9903325389921023, 'epsilon': 2.526935009439046e-05, 'balanced_loss': True, 'epochs': 104, 'early_stopping_patience': 17, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 10:36:27,535] Trial 218 finished with value: 0.915636388738806 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9032949672019907, 'batch_size': 95, 'attention_heads': 12, 'hidden_dimension': 161, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3469119869702269, 'global_pooling': 'mean', 'learning_rate': 0.0014788550794376694, 'weight_decay': 0.0001332835300307145, 'beta_0': 0.8278010232352994, 'beta_1': 0.9901029686746456, 'epsilon': 3.977150154308051e-05, 'balanced_loss': True, 'epochs': 96, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 10:47:30,595] Trial 219 finished with value: 0.9356472007314912 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.92453635089992, 'batch_size': 112, 'attention_heads': 12, 'hidden_dimension': 148, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3548580131468682, 'global_pooling': 'max', 'learning_rate': 0.0010882474076991302, 'weight_decay': 0.00019449777818456729, 'beta_0': 0.8089022549236493, 'beta_1': 0.9861169663307052, 'epsilon': 1.6849445553057757e-05, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 10:59:41,499] Trial 220 finished with value: 0.906603420825256 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9231045511840262, 'batch_size': 115, 'attention_heads': 13, 'hidden_dimension': 148, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3510223031523733, 'global_pooling': 'sum', 'learning_rate': 0.0007993771809997689, 'weight_decay': 0.00019513020662919795, 'beta_0': 0.808928343069558, 'beta_1': 0.9859881249763907, 'epsilon': 1.7249126077488822e-05, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 11:08:38,573] Trial 221 finished with value: 0.9087798613545499 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9354593176704213, 'batch_size': 119, 'attention_heads': 5, 'hidden_dimension': 144, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3556325156614351, 'global_pooling': 'max', 'learning_rate': 0.001117870316593779, 'weight_decay': 7.857744805791583e-05, 'beta_0': 0.8063481909782609, 'beta_1': 0.9855082039575667, 'epsilon': 1.0010498198142002e-05, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 11:18:38,452] Trial 222 finished with value: 0.9127364878489206 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9266311941336657, 'batch_size': 112, 'attention_heads': 11, 'hidden_dimension': 154, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34418578371504394, 'global_pooling': 'mean', 'learning_rate': 0.0010040210503372603, 'weight_decay': 4.721373907022313e-05, 'beta_0': 0.8017535410273715, 'beta_1': 0.9862891100735084, 'epsilon': 1.4836759153931104e-05, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.35 GiB is free. Including non-PyTorch memory, this process has 41.21 GiB memory in use. Of the allocated memory 36.82 GiB is allocated by PyTorch, and 3.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 11:26:46,174] Trial 223 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.882020969264488, 'batch_size': 106, 'attention_heads': 12, 'hidden_dimension': 141, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3678849465563037, 'global_pooling': 'max', 'learning_rate': 0.0013469071461210105, 'weight_decay': 0.00011462785262170894, 'beta_0': 0.8042040113760731, 'beta_1': 0.9868025164122555, 'epsilon': 9.984598990114282e-05, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 6}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 2.48 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.53 GiB is free. Including non-PyTorch memory, this process has 43.03 GiB memory in use. Of the allocated memory 41.50 GiB is allocated by PyTorch, and 388.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 11:34:22,896] Trial 224 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8951509518230152, 'batch_size': 111, 'attention_heads': 12, 'hidden_dimension': 149, 'number_of_hidden_layers': 3, 'dropout_rate': 0.33909610740576107, 'global_pooling': 'max', 'learning_rate': 0.0007613325157833629, 'weight_decay': 6.442704678257116e-05, 'beta_0': 0.8083273040025637, 'beta_1': 0.9851372676594922, 'epsilon': 1.2117196766918735e-05, 'balanced_loss': False, 'epochs': 108, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 11:45:05,977] Trial 225 finished with value: 0.9157756964714517 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9095939590817076, 'batch_size': 103, 'attention_heads': 12, 'hidden_dimension': 157, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3281363455749261, 'global_pooling': 'max', 'learning_rate': 0.001871506003874825, 'weight_decay': 0.00017233559618467142, 'beta_0': 0.8105559506066095, 'beta_1': 0.9857501675425742, 'epsilon': 2.3368979646133797e-05, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 11:56:36,140] Trial 226 finished with value: 0.9176319749499867 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9170881948580122, 'batch_size': 99, 'attention_heads': 12, 'hidden_dimension': 167, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35982373570770226, 'global_pooling': 'max', 'learning_rate': 0.0010928241776338374, 'weight_decay': 0.00015488693549625012, 'beta_0': 0.8141223372738146, 'beta_1': 0.9904413587030093, 'epsilon': 3.2821288357680036e-05, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 17, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 12:08:21,020] Trial 227 finished with value: 0.9182964341119995 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9010580919766181, 'batch_size': 80, 'attention_heads': 12, 'hidden_dimension': 152, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32241379392224573, 'global_pooling': 'max', 'learning_rate': 0.0013420540108373769, 'weight_decay': 9.881835855043579e-05, 'beta_0': 0.8119334485680765, 'beta_1': 0.986322410578561, 'epsilon': 1.868842445842119e-05, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-28 12:19:59,260] Trial 228 finished with value: 0.940926033029364 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9099548204201955, 'batch_size': 91, 'attention_heads': 12, 'hidden_dimension': 147, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3322505367611438, 'global_pooling': 'max', 'learning_rate': 0.0015127134664074465, 'weight_decay': 0.0002090854193023883, 'beta_0': 0.8020787456143477, 'beta_1': 0.9898469909712994, 'epsilon': 8.394734793114386e-05, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 12:32:15,408] Trial 229 finished with value: 0.9197120360912049 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9145022918578242, 'batch_size': 107, 'attention_heads': 13, 'hidden_dimension': 146, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3339858295117192, 'global_pooling': 'max', 'learning_rate': 0.0009007136635943512, 'weight_decay': 0.00022732536542631427, 'beta_0': 0.8016883736790514, 'beta_1': 0.98926654252192, 'epsilon': 8.601180519747106e-05, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 12:43:42,666] Trial 230 finished with value: 0.9338088865705356 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8897976641795766, 'batch_size': 96, 'attention_heads': 11, 'hidden_dimension': 138, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3439887694989688, 'global_pooling': 'max', 'learning_rate': 0.0011584996177415026, 'weight_decay': 0.00023313454526206794, 'beta_0': 0.8028994383991266, 'beta_1': 0.9871327842474158, 'epsilon': 7.253478705306841e-05, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 12:55:09,461] Trial 231 finished with value: 0.9134940652143294 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8858483974537995, 'batch_size': 95, 'attention_heads': 11, 'hidden_dimension': 137, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3482820073411897, 'global_pooling': 'max', 'learning_rate': 0.00126279725900854, 'weight_decay': 0.00023105634333620646, 'beta_0': 0.8002500701340198, 'beta_1': 0.9865677948299199, 'epsilon': 7.737038927100516e-05, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 13:13:12,539] Trial 232 finished with value: 0.8836946187450403 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.927656993183656, 'batch_size': 91, 'attention_heads': 11, 'hidden_dimension': 128, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3570120911526522, 'global_pooling': 'max', 'learning_rate': 1.4409958627863634e-05, 'weight_decay': 0.0002678068172586913, 'beta_0': 0.8027538495490407, 'beta_1': 0.986001478046032, 'epsilon': 6.626683922733978e-05, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 13:23:53,909] Trial 233 finished with value: 0.9171402045761774 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8909888715059494, 'batch_size': 98, 'attention_heads': 11, 'hidden_dimension': 144, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3443489060357939, 'global_pooling': 'max', 'learning_rate': 0.002106208694054547, 'weight_decay': 0.0003451040804621503, 'beta_0': 0.8038744605496535, 'beta_1': 0.9848459753372676, 'epsilon': 8.410094797966964e-05, 'balanced_loss': True, 'epochs': 132, 'early_stopping_patience': 17, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 13:31:56,638] Trial 234 finished with value: 0.9096044967248326 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9435055580167245, 'batch_size': 85, 'attention_heads': 11, 'hidden_dimension': 119, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3389024621551731, 'global_pooling': 'max', 'learning_rate': 0.0016883793619448483, 'weight_decay': 0.0002134228061659423, 'beta_0': 0.8018555615836782, 'beta_1': 0.9853690590743254, 'epsilon': 6.462847556338359e-05, 'balanced_loss': True, 'epochs': 120, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 13:43:47,507] Trial 235 finished with value: 0.9184698452164907 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8981318956396188, 'batch_size': 103, 'attention_heads': 12, 'hidden_dimension': 140, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3313830203301394, 'global_pooling': 'max', 'learning_rate': 0.0011018386289559743, 'weight_decay': 0.00020205979780994887, 'beta_0': 0.805521852481019, 'beta_1': 0.9877110183375769, 'epsilon': 5.040294360745294e-05, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 13:55:48,569] Trial 236 finished with value: 0.9187852626322874 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9062440079475316, 'batch_size': 117, 'attention_heads': 12, 'hidden_dimension': 151, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33500557905538325, 'global_pooling': 'max', 'learning_rate': 0.0008791183438982762, 'weight_decay': 0.0002667864678559882, 'beta_0': 0.805822233158948, 'beta_1': 0.9872013833782063, 'epsilon': 6.022800130502584e-05, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 14:07:05,694] Trial 237 finished with value: 0.9203915210257465 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8960086413973904, 'batch_size': 108, 'attention_heads': 12, 'hidden_dimension': 134, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32021838309385775, 'global_pooling': 'mean', 'learning_rate': 0.0011644639271931566, 'weight_decay': 0.00018005799863581506, 'beta_0': 0.8026775809813014, 'beta_1': 0.9869631712149273, 'epsilon': 7.742941019122728e-05, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 14:17:35,325] Trial 238 finished with value: 0.9281083883007641 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9199618509938947, 'batch_size': 101, 'attention_heads': 13, 'hidden_dimension': 147, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3394380255644083, 'global_pooling': 'max', 'learning_rate': 0.0013929797483512492, 'weight_decay': 8.592347387009746e-05, 'beta_0': 0.8948458802248084, 'beta_1': 0.9866234199454161, 'epsilon': 1.8693140495610695e-05, 'balanced_loss': True, 'epochs': 106, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 14:28:59,976] Trial 239 finished with value: 0.9195520470974048 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9222253583552792, 'batch_size': 97, 'attention_heads': 13, 'hidden_dimension': 141, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34198160609653194, 'global_pooling': 'max', 'learning_rate': 0.0014373956282245225, 'weight_decay': 8.409029795527284e-05, 'beta_0': 0.8991485942629155, 'beta_1': 0.9861635257228185, 'epsilon': 1.7741702467376604e-05, 'balanced_loss': True, 'epochs': 106, 'early_stopping_patience': 19, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 14:39:35,612] Trial 240 finished with value: 0.911177035407284 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9122495077742304, 'batch_size': 101, 'attention_heads': 13, 'hidden_dimension': 149, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3529618340037451, 'global_pooling': 'max', 'learning_rate': 0.0016001947524835736, 'weight_decay': 0.00011541804525954191, 'beta_0': 0.8044120072957507, 'beta_1': 0.9856899477207244, 'epsilon': 1.4053303657637982e-05, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 17, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 43.49 GiB memory in use. Of the allocated memory 41.85 GiB is allocated by PyTorch, and 500.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 14:47:16,152] Trial 241 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9188860383374142, 'batch_size': 89, 'attention_heads': 14, 'hidden_dimension': 155, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3451103456120235, 'global_pooling': 'max', 'learning_rate': 0.0024355872820191397, 'weight_decay': 8.677974081636987e-05, 'beta_0': 0.8003826619012923, 'beta_1': 0.9866093185052361, 'epsilon': 2.0654479976640287e-05, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 14:57:56,503] Trial 242 finished with value: 0.9177829818690846 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9340019465747457, 'batch_size': 94, 'attention_heads': 13, 'hidden_dimension': 159, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34046676370627443, 'global_pooling': 'max', 'learning_rate': 0.001261215234564931, 'weight_decay': 9.69843025363305e-05, 'beta_0': 0.8960148355560718, 'beta_1': 0.98641468679317, 'epsilon': 1.650268616887402e-05, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 15:09:18,642] Trial 243 finished with value: 0.923279256194114 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9083023361270657, 'batch_size': 103, 'attention_heads': 13, 'hidden_dimension': 145, 'number_of_hidden_layers': 0, 'dropout_rate': 0.41159849104593105, 'global_pooling': 'max', 'learning_rate': 0.0010345071924519216, 'weight_decay': 7.005262529323439e-05, 'beta_0': 0.8906861000601678, 'beta_1': 0.9869092947788397, 'epsilon': 2.216608743656681e-05, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 15:19:45,800] Trial 244 finished with value: 0.9207938872548844 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9273506923649684, 'batch_size': 99, 'attention_heads': 11, 'hidden_dimension': 135, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33433538102853283, 'global_pooling': 'max', 'learning_rate': 0.001919730592667078, 'weight_decay': 0.00013840862402092694, 'beta_0': 0.8951739651598892, 'beta_1': 0.9861330802270974, 'epsilon': 1.1538680640700096e-05, 'balanced_loss': True, 'epochs': 138, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 15:31:29,404] Trial 245 finished with value: 0.9239915677174684 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9022214415656711, 'batch_size': 111, 'attention_heads': 12, 'hidden_dimension': 148, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3278921871776053, 'global_pooling': 'max', 'learning_rate': 0.0007174459967617052, 'weight_decay': 5.497934878875556e-05, 'beta_0': 0.8071967745160816, 'beta_1': 0.9871111581243813, 'epsilon': 9.958202952618965e-05, 'balanced_loss': True, 'epochs': 100, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 4.62 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 42.27 GiB memory in use. Of the allocated memory 40.34 GiB is allocated by PyTorch, and 797.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 15:39:04,980] Trial 246 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.7682382471515864, 'batch_size': 108, 'attention_heads': 11, 'hidden_dimension': 140, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32352973990467815, 'global_pooling': 'max', 'learning_rate': 0.0008981573394816216, 'weight_decay': 0.00011870287539616277, 'beta_0': 0.8038489559666876, 'beta_1': 0.9899091630949867, 'epsilon': 2.6015573859896628e-05, 'balanced_loss': True, 'epochs': 103, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 15:50:03,608] Trial 247 finished with value: 0.923965713623194 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8929336780162311, 'batch_size': 104, 'attention_heads': 12, 'hidden_dimension': 147, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32890172462762873, 'global_pooling': 'mean', 'learning_rate': 0.0014143643487748814, 'weight_decay': 3.74577041968801e-05, 'beta_0': 0.8976231933217192, 'beta_1': 0.9875593546171824, 'epsilon': 7.173288654839777e-05, 'balanced_loss': True, 'epochs': 106, 'early_stopping_patience': 17, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 16:02:14,870] Trial 248 finished with value: 0.9231610827638015 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9042841024920324, 'batch_size': 92, 'attention_heads': 13, 'hidden_dimension': 150, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3376767744983003, 'global_pooling': 'max', 'learning_rate': 0.001097884527241135, 'weight_decay': 8.253308266223695e-05, 'beta_0': 0.8020123077849232, 'beta_1': 0.9856806314672409, 'epsilon': 1.9215506182387446e-05, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 16:13:57,579] Trial 249 finished with value: 0.9157690075866576 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9157510811402947, 'batch_size': 113, 'attention_heads': 12, 'hidden_dimension': 155, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3157155209232545, 'global_pooling': 'max', 'learning_rate': 0.0009572645910478848, 'weight_decay': 9.537359345880652e-05, 'beta_0': 0.8921103392497549, 'beta_1': 0.9866288427124905, 'epsilon': 5.5735882898540926e-05, 'balanced_loss': True, 'epochs': 133, 'early_stopping_patience': 18, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-02-28 16:25:46,054] Trial 250 finished with value: 0.9186609524617464 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8787900404998055, 'batch_size': 100, 'attention_heads': 10, 'hidden_dimension': 142, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3313772184726487, 'global_pooling': 'max', 'learning_rate': 0.0005990926690121329, 'weight_decay': 0.00019139178454184415, 'beta_0': 0.8060621553951618, 'beta_1': 0.9872969555196086, 'epsilon': 1.550521368970676e-05, 'balanced_loss': True, 'epochs': 128, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 3.88 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.67 GiB is free. Including non-PyTorch memory, this process has 40.89 GiB memory in use. Of the allocated memory 36.05 GiB is allocated by PyTorch, and 3.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 16:35:46,848] Trial 251 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8891688616650395, 'batch_size': 96, 'attention_heads': 12, 'hidden_dimension': 162, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34894339772133687, 'global_pooling': 'mean', 'learning_rate': 0.0014960481343671338, 'weight_decay': 0.00010528579755182643, 'beta_0': 0.803333319569026, 'beta_1': 0.9851108329330455, 'epsilon': 2.3671587978191828e-05, 'balanced_loss': True, 'epochs': 130, 'early_stopping_patience': 17, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
slurmstepd: error: *** JOB 15061628 ON gpu043 CANCELLED AT 2025-02-28T16:39:56 DUE TO TIME LIMIT ***
