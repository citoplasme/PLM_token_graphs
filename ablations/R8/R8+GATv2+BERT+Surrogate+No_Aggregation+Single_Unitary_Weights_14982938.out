[I 2025-02-22 04:47:22,427] Using an existing study with name 'R8-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-Single_Unitary_Weight-0.0-0.0' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors
[I 2025-02-22 05:03:53,335] Trial 235 finished with value: 0.9377086809371697 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.831281789277487, 'batch_size': 65, 'attention_heads': 9, 'hidden_dimension': 102, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5879998946230415, 'global_pooling': 'sum', 'learning_rate': 0.00041435114068532643, 'weight_decay': 9.423824881281044e-05, 'beta_0': 0.8440087402465902, 'beta_1': 0.991585607493101, 'epsilon': 5.748366835372866e-07, 'balanced_loss': False, 'epochs': 141, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 05:17:39,392] Trial 236 finished with value: 0.9398292235101626 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8819649301869523, 'batch_size': 49, 'attention_heads': 9, 'hidden_dimension': 108, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5717278172101037, 'global_pooling': 'sum', 'learning_rate': 0.0006164787664410075, 'weight_decay': 8.24710390728015e-05, 'beta_0': 0.8484713880849535, 'beta_1': 0.990539228239549, 'epsilon': 7.71719928012894e-07, 'balanced_loss': False, 'epochs': 138, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 05:32:31,347] Trial 237 finished with value: 0.9446596490376897 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.871372188885148, 'batch_size': 56, 'attention_heads': 9, 'hidden_dimension': 122, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5816415878376805, 'global_pooling': 'sum', 'learning_rate': 0.0004671344754367315, 'weight_decay': 0.00010626748211632025, 'beta_0': 0.84616975461787, 'beta_1': 0.9922044544163472, 'epsilon': 4.3489498811942565e-07, 'balanced_loss': False, 'epochs': 134, 'early_stopping_patience': 22, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 05:50:59,214] Trial 238 finished with value: 0.9439223448591981 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.860026267806165, 'batch_size': 62, 'attention_heads': 10, 'hidden_dimension': 118, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5948468949173421, 'global_pooling': 'sum', 'learning_rate': 0.000518593025006436, 'weight_decay': 7.40256377788727e-05, 'beta_0': 0.8496948061652673, 'beta_1': 0.9909869305240726, 'epsilon': 6.59920616830193e-07, 'balanced_loss': False, 'epochs': 147, 'early_stopping_patience': 24, 'plateau_patience': 16, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 06:08:33,284] Trial 239 finished with value: 0.9535452538646271 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.852731168037124, 'batch_size': 44, 'attention_heads': 10, 'hidden_dimension': 107, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5776271383772554, 'global_pooling': 'max', 'learning_rate': 0.0003940300862384704, 'weight_decay': 9.045388258886786e-05, 'beta_0': 0.8437229229564334, 'beta_1': 0.9919451840540928, 'epsilon': 3.3584310308021153e-07, 'balanced_loss': False, 'epochs': 142, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 06:28:55,065] Trial 240 finished with value: 0.9517130558084306 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8223287492227609, 'batch_size': 68, 'attention_heads': 9, 'hidden_dimension': 126, 'number_of_hidden_layers': 2, 'dropout_rate': 0.589338004362401, 'global_pooling': 'max', 'learning_rate': 0.0006917699272489631, 'weight_decay': 6.321905949110438e-05, 'beta_0': 0.8468487930816099, 'beta_1': 0.9913727501271301, 'epsilon': 9.300660279929299e-07, 'balanced_loss': False, 'epochs': 135, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 06:51:06,898] Trial 241 finished with value: 0.9473890712721003 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8457290663349524, 'batch_size': 48, 'attention_heads': 8, 'hidden_dimension': 113, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5999619663387435, 'global_pooling': 'max', 'learning_rate': 0.0005082021461443074, 'weight_decay': 0.00010400566620711107, 'beta_0': 0.8519949764588627, 'beta_1': 0.9894124259812417, 'epsilon': 1.1531194538383066e-06, 'balanced_loss': False, 'epochs': 138, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
CUDA out of memory. Tried to allocate 3.19 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.95 GiB is free. Including non-PyTorch memory, this process has 41.60 GiB memory in use. Of the allocated memory 39.78 GiB is allocated by PyTorch, and 690.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 06:57:35,214] Trial 242 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8178549749737316, 'batch_size': 145, 'attention_heads': 9, 'hidden_dimension': 96, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5834107365725583, 'global_pooling': 'max', 'learning_rate': 0.000403025890453018, 'weight_decay': 4.376254050816172e-05, 'beta_0': 0.8451294649711526, 'beta_1': 0.9908561784726574, 'epsilon': 5.775146457591628e-07, 'balanced_loss': True, 'epochs': 157, 'early_stopping_patience': 22, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 07:15:46,439] Trial 243 finished with value: 0.9511091347469189 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8389522932912489, 'batch_size': 54, 'attention_heads': 9, 'hidden_dimension': 117, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5717664199271774, 'global_pooling': 'max', 'learning_rate': 0.0008297379772325237, 'weight_decay': 5.5863831680607585e-05, 'beta_0': 0.8488376129222922, 'beta_1': 0.9900851603356186, 'epsilon': 7.06833808003643e-07, 'balanced_loss': False, 'epochs': 146, 'early_stopping_patience': 22, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacity of 44.56 GiB of which 962.69 MiB is free. Including non-PyTorch memory, this process has 43.61 GiB memory in use. Of the allocated memory 42.08 GiB is allocated by PyTorch, and 392.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 07:22:31,849] Trial 244 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7245403477753477, 'batch_size': 60, 'attention_heads': 9, 'hidden_dimension': 102, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5911681889627258, 'global_pooling': 'max', 'learning_rate': 0.0006491114490202802, 'weight_decay': 7.227295699958715e-05, 'beta_0': 0.843290385617928, 'beta_1': 0.9916697858346237, 'epsilon': 1.3627946125118339e-06, 'balanced_loss': False, 'epochs': 160, 'early_stopping_patience': 23, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 07:38:23,714] Trial 245 finished with value: 0.9386984556990947 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.8312623483538416, 'batch_size': 76, 'attention_heads': 10, 'hidden_dimension': 122, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5786416791073612, 'global_pooling': 'max', 'learning_rate': 0.0010121435467374403, 'weight_decay': 0.00011839332056938963, 'beta_0': 0.8634459858534687, 'beta_1': 0.9921827530798394, 'epsilon': 9.203931989240999e-07, 'balanced_loss': False, 'epochs': 128, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 07:56:36,534] Trial 246 finished with value: 0.9574003927247151 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8396461220120438, 'batch_size': 72, 'attention_heads': 11, 'hidden_dimension': 109, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5738274778930991, 'global_pooling': 'max', 'learning_rate': 0.0005125142710759714, 'weight_decay': 5.1313330196934175e-05, 'beta_0': 0.8669674613545394, 'beta_1': 0.9912698778794443, 'epsilon': 1.1790809005179264e-06, 'balanced_loss': False, 'epochs': 132, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
CUDA out of memory. Tried to allocate 3.42 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.15 GiB is free. Including non-PyTorch memory, this process has 43.40 GiB memory in use. Of the allocated memory 38.71 GiB is allocated by PyTorch, and 3.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 08:21:29,451] Trial 247 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8362170822589671, 'batch_size': 74, 'attention_heads': 11, 'hidden_dimension': 111, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5686457967292258, 'global_pooling': 'max', 'learning_rate': 0.0005487767379563383, 'weight_decay': 5.100783789572823e-05, 'beta_0': 0.8704023042152831, 'beta_1': 0.9911447220553284, 'epsilon': 1.2153199394753285e-06, 'balanced_loss': False, 'epochs': 133, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 08:39:23,750] Trial 248 finished with value: 0.9501259524713148 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8481677429434418, 'batch_size': 69, 'attention_heads': 11, 'hidden_dimension': 107, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5749632067919664, 'global_pooling': 'max', 'learning_rate': 0.0004436420547633991, 'weight_decay': 3.7463365264421726e-05, 'beta_0': 0.8671338720999519, 'beta_1': 0.9905193094904933, 'epsilon': 9.998467279522892e-07, 'balanced_loss': False, 'epochs': 141, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 08:55:18,386] Trial 249 finished with value: 0.9559510449128019 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8261325739301512, 'batch_size': 64, 'attention_heads': 9, 'hidden_dimension': 91, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5627812731161357, 'global_pooling': 'max', 'learning_rate': 0.00035627411387260656, 'weight_decay': 8.566329538045242e-05, 'beta_0': 0.8677897153155035, 'beta_1': 0.9912834571518138, 'epsilon': 1.394529262142115e-06, 'balanced_loss': False, 'epochs': 137, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 09:10:08,351] Trial 250 finished with value: 0.9547957184251703 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8305942657616934, 'batch_size': 64, 'attention_heads': 9, 'hidden_dimension': 92, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5646526764478023, 'global_pooling': 'max', 'learning_rate': 0.0006113718296758709, 'weight_decay': 6.1024727896254526e-05, 'beta_0': 0.8659890242088026, 'beta_1': 0.9912670239685245, 'epsilon': 1.4942681344175812e-06, 'balanced_loss': False, 'epochs': 139, 'early_stopping_patience': 22, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 09:29:08,611] Trial 251 finished with value: 0.9503437566493246 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8281700485865139, 'batch_size': 63, 'attention_heads': 9, 'hidden_dimension': 89, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5634960389972328, 'global_pooling': 'max', 'learning_rate': 0.00011504749251045055, 'weight_decay': 6.251733002846164e-05, 'beta_0': 0.8671742136028109, 'beta_1': 0.9914385589353117, 'epsilon': 1.607954184401295e-06, 'balanced_loss': False, 'epochs': 136, 'early_stopping_patience': 22, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 09:43:36,676] Trial 252 finished with value: 0.9376886050555242 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8407385686076588, 'batch_size': 70, 'attention_heads': 9, 'hidden_dimension': 93, 'number_of_hidden_layers': 2, 'dropout_rate': 0.565178835296902, 'global_pooling': 'max', 'learning_rate': 0.0006390938886325315, 'weight_decay': 5.0702012289199094e-05, 'beta_0': 0.8690877336622549, 'beta_1': 0.9908660666074518, 'epsilon': 1.4872023143865196e-06, 'balanced_loss': False, 'epochs': 132, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 10:01:57,909] Trial 253 finished with value: 0.9409357266997895 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.709735388083387, 'batch_size': 60, 'attention_heads': 8, 'hidden_dimension': 91, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5560659550673709, 'global_pooling': 'max', 'learning_rate': 0.000486448919812873, 'weight_decay': 8.209044919083723e-05, 'beta_0': 0.8411432224206771, 'beta_1': 0.9912719600519596, 'epsilon': 1.3290605271338458e-06, 'balanced_loss': False, 'epochs': 139, 'early_stopping_patience': 20, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 10:17:07,486] Trial 254 finished with value: 0.9447405139673879 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8323169462919169, 'batch_size': 53, 'attention_heads': 9, 'hidden_dimension': 99, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5938024109608993, 'global_pooling': 'sum', 'learning_rate': 0.00037249405596865106, 'weight_decay': 5.8201617571337365e-05, 'beta_0': 0.8483680702394667, 'beta_1': 0.991690672677137, 'epsilon': 1.7397467407522698e-06, 'balanced_loss': False, 'epochs': 125, 'early_stopping_patience': 21, 'plateau_patience': 17, 'plateau_divider': 5}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 10:32:07,454] Trial 255 finished with value: 0.9613269733415453 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.817399095302284, 'batch_size': 66, 'attention_heads': 9, 'hidden_dimension': 85, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5875680369895678, 'global_pooling': 'max', 'learning_rate': 0.0007643121879946766, 'weight_decay': 6.728996832033656e-05, 'beta_0': 0.865835069106796, 'beta_1': 0.9903615953331837, 'epsilon': 1.2490072667058486e-06, 'balanced_loss': False, 'epochs': 137, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 10:45:42,848] Trial 256 finished with value: 0.9537875773296558 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8183309942069762, 'batch_size': 66, 'attention_heads': 9, 'hidden_dimension': 83, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5856329121346686, 'global_pooling': 'max', 'learning_rate': 0.0008565614255620041, 'weight_decay': 7.065858701773686e-05, 'beta_0': 0.8661288514460246, 'beta_1': 0.9903392339197588, 'epsilon': 8.229494606177846e-07, 'balanced_loss': False, 'epochs': 136, 'early_stopping_patience': 22, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
CUDA out of memory. Tried to allocate 3.89 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.40 GiB is free. Including non-PyTorch memory, this process has 41.15 GiB memory in use. Of the allocated memory 39.75 GiB is allocated by PyTorch, and 257.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 10:51:28,681] Trial 257 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8073136326677686, 'batch_size': 72, 'attention_heads': 16, 'hidden_dimension': 129, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5955047632104152, 'global_pooling': 'max', 'learning_rate': 0.0007356983848341112, 'weight_decay': 8.563592892827999e-05, 'beta_0': 0.8462545968567357, 'beta_1': 0.9898695861836347, 'epsilon': 1.2510882284887967e-06, 'balanced_loss': False, 'epochs': 130, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 11:06:56,181] Trial 258 finished with value: 0.9536106503191444 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8245088917193943, 'batch_size': 57, 'attention_heads': 9, 'hidden_dimension': 87, 'number_of_hidden_layers': 2, 'dropout_rate': 0.588056444508676, 'global_pooling': 'max', 'learning_rate': 0.0006387762746537223, 'weight_decay': 4.691071211294522e-05, 'beta_0': 0.870666656928692, 'beta_1': 0.9906282871074941, 'epsilon': 5.72609066293159e-07, 'balanced_loss': False, 'epochs': 140, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 11:22:11,598] Trial 259 finished with value: 0.9502752449522044 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8749044814092701, 'batch_size': 64, 'attention_heads': 9, 'hidden_dimension': 124, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5832999664965528, 'global_pooling': 'mean', 'learning_rate': 0.0008796250207145781, 'weight_decay': 6.966457914034294e-05, 'beta_0': 0.8684520509583128, 'beta_1': 0.9910906307395195, 'epsilon': 4.3436698190776934e-07, 'balanced_loss': False, 'epochs': 137, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 11:42:46,546] Trial 260 finished with value: 0.9479788184855672 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8118723175863312, 'batch_size': 60, 'attention_heads': 8, 'hidden_dimension': 118, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5943442531893989, 'global_pooling': 'max', 'learning_rate': 0.00033536208298127915, 'weight_decay': 6.39577025916039e-05, 'beta_0': 0.8424865982817448, 'beta_1': 0.989323105500579, 'epsilon': 1.1431859933594992e-06, 'balanced_loss': False, 'epochs': 133, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 12:01:11,479] Trial 261 finished with value: 0.9499434157077505 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8632383967330607, 'batch_size': 78, 'attention_heads': 9, 'hidden_dimension': 114, 'number_of_hidden_layers': 2, 'dropout_rate': 0.599895003428233, 'global_pooling': 'max', 'learning_rate': 0.0004223306926624186, 'weight_decay': 4.2814331751147346e-05, 'beta_0': 0.8508177246069031, 'beta_1': 0.9907772253235457, 'epsilon': 7.054859292769096e-07, 'balanced_loss': False, 'epochs': 143, 'early_stopping_patience': 22, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 12:13:28,461] Trial 262 finished with value: 0.9398758213448013 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8908409595382584, 'batch_size': 68, 'attention_heads': 9, 'hidden_dimension': 96, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5891095511964977, 'global_pooling': 'max', 'learning_rate': 0.0005613505245128322, 'weight_decay': 5.65825725248652e-05, 'beta_0': 0.8450755915731903, 'beta_1': 0.9903646989876385, 'epsilon': 9.042517813535443e-07, 'balanced_loss': False, 'epochs': 138, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 12:29:15,391] Trial 263 finished with value: 0.9544451811883641 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8194494947525095, 'batch_size': 52, 'attention_heads': 9, 'hidden_dimension': 80, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5803536467679584, 'global_pooling': 'max', 'learning_rate': 0.000758062145450115, 'weight_decay': 9.739465266856944e-05, 'beta_0': 0.8395044088656582, 'beta_1': 0.9901036162164464, 'epsilon': 1.3853321781857322e-06, 'balanced_loss': False, 'epochs': 142, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 36 with value: 0.966858574697526.
CUDA out of memory. Tried to allocate 3.90 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.63 GiB is free. Including non-PyTorch memory, this process has 40.92 GiB memory in use. Of the allocated memory 35.83 GiB is allocated by PyTorch, and 3.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 12:35:58,385] Trial 264 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.8279793193347865, 'batch_size': 73, 'attention_heads': 8, 'hidden_dimension': 188, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5855319764421231, 'global_pooling': 'max', 'learning_rate': 0.00013743171225014274, 'weight_decay': 7.651209509709033e-05, 'beta_0': 0.8477424003757191, 'beta_1': 0.9917777715012248, 'epsilon': 1.0815841216769204e-06, 'balanced_loss': False, 'epochs': 139, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 12:51:47,948] Trial 265 finished with value: 0.3042564796197802 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8549393441230531, 'batch_size': 57, 'attention_heads': 10, 'hidden_dimension': 128, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5923953676972342, 'global_pooling': 'max', 'learning_rate': 0.039348461092948, 'weight_decay': 3.6598747660206205e-05, 'beta_0': 0.8660947172655109, 'beta_1': 0.9888366779488384, 'epsilon': 8.088353557743027e-07, 'balanced_loss': False, 'epochs': 133, 'early_stopping_patience': 23, 'plateau_patience': 19, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 13:15:24,156] Trial 266 finished with value: 0.9534044867419119 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8422851925658217, 'batch_size': 63, 'attention_heads': 9, 'hidden_dimension': 119, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5741525402948912, 'global_pooling': 'max', 'learning_rate': 0.000274747557878749, 'weight_decay': 4.719454446921828e-05, 'beta_0': 0.8312328817360154, 'beta_1': 0.9912913788122187, 'epsilon': 1.4750800657058212e-06, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 24, 'plateau_patience': 17, 'plateau_divider': 7}. Best is trial 36 with value: 0.966858574697526.
CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.51 GiB is free. Including non-PyTorch memory, this process has 42.04 GiB memory in use. Of the allocated memory 40.59 GiB is allocated by PyTorch, and 302.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 13:28:16,972] Trial 267 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6832863425756103, 'batch_size': 49, 'attention_heads': 11, 'hidden_dimension': 84, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5834864692767614, 'global_pooling': 'max', 'learning_rate': 0.0004933123118557341, 'weight_decay': 9.113342787044721e-05, 'beta_0': 0.8441268171488563, 'beta_1': 0.9908724529344648, 'epsilon': 5.220293989370382e-07, 'balanced_loss': False, 'epochs': 135, 'early_stopping_patience': 22, 'plateau_patience': 19, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 13:52:56,622] Trial 268 finished with value: 0.9567463560279652 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8151036823625142, 'batch_size': 67, 'attention_heads': 9, 'hidden_dimension': 111, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5999816283963337, 'global_pooling': 'max', 'learning_rate': 0.0004025618883741579, 'weight_decay': 5.2932934605306545e-05, 'beta_0': 0.847796457351629, 'beta_1': 0.991489188795913, 'epsilon': 1.8701329778727855e-06, 'balanced_loss': False, 'epochs': 144, 'early_stopping_patience': 22, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 14:12:38,537] Trial 269 finished with value: 0.960118756655517 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8168057094474912, 'batch_size': 66, 'attention_heads': 9, 'hidden_dimension': 107, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5988326176509661, 'global_pooling': 'max', 'learning_rate': 0.0006151276254714061, 'weight_decay': 5.4397103736860405e-05, 'beta_0': 0.8504061829118548, 'beta_1': 0.9920501061250241, 'epsilon': 2.0722318804996074e-06, 'balanced_loss': False, 'epochs': 141, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 14:33:12,980] Trial 270 finished with value: 0.9444719965678968 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.814865136481034, 'batch_size': 70, 'attention_heads': 9, 'hidden_dimension': 110, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5957260220134503, 'global_pooling': 'max', 'learning_rate': 0.0006545945419283956, 'weight_decay': 5.455429990365642e-05, 'beta_0': 0.8510163876999448, 'beta_1': 0.9919432096479913, 'epsilon': 2.1376625535987844e-06, 'balanced_loss': False, 'epochs': 141, 'early_stopping_patience': 22, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 14:51:30,554] Trial 271 finished with value: 0.9538812829804013 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8053915167185484, 'batch_size': 66, 'attention_heads': 9, 'hidden_dimension': 105, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5996039725532127, 'global_pooling': 'max', 'learning_rate': 0.0005979429450839805, 'weight_decay': 6.0956255412706776e-05, 'beta_0': 0.8493030033376421, 'beta_1': 0.9916651486436198, 'epsilon': 1.885022923244819e-06, 'balanced_loss': False, 'epochs': 144, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
CUDA out of memory. Tried to allocate 4.15 GiB. GPU 0 has a total capacity of 44.56 GiB of which 692.69 MiB is free. Including non-PyTorch memory, this process has 43.88 GiB memory in use. Of the allocated memory 42.08 GiB is allocated by PyTorch, and 666.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-22 14:57:24,672] Trial 272 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.812921766691259, 'batch_size': 74, 'attention_heads': 9, 'hidden_dimension': 243, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5910492339148393, 'global_pooling': 'max', 'learning_rate': 0.0010116586733553011, 'weight_decay': 5.092156227368922e-05, 'beta_0': 0.8472543504383869, 'beta_1': 0.9913451510384722, 'epsilon': 2.603662313023088e-06, 'balanced_loss': False, 'epochs': 130, 'early_stopping_patience': 22, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 15:14:35,981] Trial 273 finished with value: 0.951933558969933 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8303101218575876, 'batch_size': 67, 'attention_heads': 8, 'hidden_dimension': 113, 'number_of_hidden_layers': 2, 'dropout_rate': 0.594508215070569, 'global_pooling': 'sum', 'learning_rate': 0.0007476262463000852, 'weight_decay': 6.413161032275508e-05, 'beta_0': 0.8516538408739466, 'beta_1': 0.9923364721796819, 'epsilon': 2.2431263491593514e-06, 'balanced_loss': False, 'epochs': 136, 'early_stopping_patience': 21, 'plateau_patience': 18, 'plateau_divider': 10}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 15:35:12,392] Trial 274 finished with value: 0.9478677232703113 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8229946231467061, 'batch_size': 79, 'attention_heads': 9, 'hidden_dimension': 109, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5889685853589831, 'global_pooling': 'max', 'learning_rate': 0.0005358471266003323, 'weight_decay': 6.908451251246665e-05, 'beta_0': 0.8481600473899771, 'beta_1': 0.9909317067311344, 'epsilon': 1.6317809649115332e-06, 'balanced_loss': False, 'epochs': 139, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 15:56:17,396] Trial 275 finished with value: 0.960293542805698 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8368645869734757, 'batch_size': 62, 'attention_heads': 10, 'hidden_dimension': 102, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5960301274641351, 'global_pooling': 'max', 'learning_rate': 0.00043751961405963326, 'weight_decay': 8.178621256095379e-05, 'beta_0': 0.852342495557661, 'beta_1': 0.9920011080071182, 'epsilon': 8.11668853030786e-08, 'balanced_loss': False, 'epochs': 145, 'early_stopping_patience': 25, 'plateau_patience': 19, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 16:15:48,409] Trial 276 finished with value: 0.9495809330098781 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.8364989817580086, 'batch_size': 63, 'attention_heads': 10, 'hidden_dimension': 106, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5867899709574077, 'global_pooling': 'max', 'learning_rate': 0.00041124238091590454, 'weight_decay': 4.5209169183534045e-05, 'beta_0': 0.852468804998103, 'beta_1': 0.9921917665484906, 'epsilon': 2.1418537681050344e-06, 'balanced_loss': False, 'epochs': 146, 'early_stopping_patience': 25, 'plateau_patience': 19, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
[I 2025-02-22 16:36:38,757] Trial 277 finished with value: 0.9404741562741793 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8165719455743351, 'batch_size': 60, 'attention_heads': 10, 'hidden_dimension': 102, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5998908204501632, 'global_pooling': 'max', 'learning_rate': 9.158412664804169e-05, 'weight_decay': 5.541207491952917e-05, 'beta_0': 0.8538819171238232, 'beta_1': 0.9897598023186863, 'epsilon': 1.2042405593244008e-07, 'balanced_loss': False, 'epochs': 144, 'early_stopping_patience': 22, 'plateau_patience': 19, 'plateau_divider': 6}. Best is trial 36 with value: 0.966858574697526.
slurmstepd: error: *** JOB 14982938 ON gpu015 CANCELLED AT 2025-02-22T16:47:24 DUE TO TIME LIMIT ***
