[I 2025-03-26 19:44:50,593] Using an existing study with name 'R8-GATv2-google-bert-bert-base-uncased-Grouped-No_Aggregation-Random_Attentions-0.0-0.0' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors
[I 2025-03-26 19:56:22,748] Trial 131 finished with value: 0.9357882243440507 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8324102345214144, 'batch_size': 177, 'attention_heads': 8, 'hidden_dimension': 210, 'number_of_hidden_layers': 1, 'dropout_rate': 0.592355027071522, 'global_pooling': 'max', 'learning_rate': 0.00012713466911927127, 'weight_decay': 0.00015894990235212675, 'beta_0': 0.8244089252481981, 'beta_1': 0.9886408076500726, 'epsilon': 2.861760568614729e-05, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 15, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-26 20:11:53,402] Trial 132 finished with value: 0.9444240879726258 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8153408259047762, 'batch_size': 181, 'attention_heads': 9, 'hidden_dimension': 191, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5998087315924654, 'global_pooling': 'max', 'learning_rate': 0.00016699258259929645, 'weight_decay': 0.00018866355771293523, 'beta_0': 0.810174578011564, 'beta_1': 0.9862092954989977, 'epsilon': 4.675556747437533e-05, 'balanced_loss': False, 'epochs': 143, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.45 GiB is free. Including non-PyTorch memory, this process has 42.10 GiB memory in use. Of the allocated memory 37.81 GiB is allocated by PyTorch, and 3.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-26 20:29:28,453] Trial 133 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7176247617495617, 'batch_size': 168, 'attention_heads': 8, 'hidden_dimension': 179, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5746543092556939, 'global_pooling': 'max', 'learning_rate': 7.672448423770113e-05, 'weight_decay': 0.00014111726281880292, 'beta_0': 0.8215043810419257, 'beta_1': 0.9868711569064067, 'epsilon': 6.0183901502885305e-05, 'balanced_loss': False, 'epochs': 134, 'early_stopping_patience': 15, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-26 20:42:56,537] Trial 134 finished with value: 0.9512356815325362 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8254333961344931, 'batch_size': 188, 'attention_heads': 9, 'hidden_dimension': 222, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5838210846199465, 'global_pooling': 'max', 'learning_rate': 0.00014321390928710706, 'weight_decay': 0.0002394017548307583, 'beta_0': 0.8082684706756714, 'beta_1': 0.9879372074760409, 'epsilon': 8.446606640182656e-05, 'balanced_loss': False, 'epochs': 119, 'early_stopping_patience': 16, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-26 20:53:21,759] Trial 135 finished with value: 0.6288155738436472 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7983128592339079, 'batch_size': 181, 'attention_heads': 9, 'hidden_dimension': 226, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5624930932312815, 'global_pooling': 'max', 'learning_rate': 0.04111834324236489, 'weight_decay': 0.00021031219286570685, 'beta_0': 0.8146983284390906, 'beta_1': 0.9891530458224448, 'epsilon': 3.821976078206465e-05, 'balanced_loss': False, 'epochs': 131, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 4}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-26 21:08:56,389] Trial 136 finished with value: 0.9546486968732029 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8437755413958989, 'batch_size': 174, 'attention_heads': 10, 'hidden_dimension': 214, 'number_of_hidden_layers': 1, 'dropout_rate': 0.570762392192725, 'global_pooling': 'max', 'learning_rate': 9.507674754787386e-05, 'weight_decay': 0.0002681531576057962, 'beta_0': 0.8018149382532267, 'beta_1': 0.9872564820743223, 'epsilon': 1.6192995712433024e-05, 'balanced_loss': False, 'epochs': 140, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-26 21:22:05,952] Trial 137 finished with value: 0.9516555671511817 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8094115384946869, 'batch_size': 187, 'attention_heads': 9, 'hidden_dimension': 219, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5769350318299393, 'global_pooling': 'max', 'learning_rate': 0.00014467652355247462, 'weight_decay': 0.0003252427053292566, 'beta_0': 0.8054760557688277, 'beta_1': 0.9821436491930277, 'epsilon': 3.286356604517106e-05, 'balanced_loss': False, 'epochs': 122, 'early_stopping_patience': 16, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
CUDA out of memory. Tried to allocate 3.58 GiB. GPU 0 has a total capacity of 44.56 GiB of which 900.69 MiB is free. Including non-PyTorch memory, this process has 43.67 GiB memory in use. Of the allocated memory 39.21 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-26 21:28:39,119] Trial 138 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7762880551270479, 'batch_size': 226, 'attention_heads': 9, 'hidden_dimension': 203, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5583347031390126, 'global_pooling': 'max', 'learning_rate': 0.00021399466289793472, 'weight_decay': 0.00018160883367995454, 'beta_0': 0.8116740149937998, 'beta_1': 0.98763154810557, 'epsilon': 2.56185539887451e-05, 'balanced_loss': False, 'epochs': 136, 'early_stopping_patience': 16, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-26 21:52:26,228] Trial 139 finished with value: 0.9449501920595387 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8364767588502112, 'batch_size': 191, 'attention_heads': 10, 'hidden_dimension': 235, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5690502961839867, 'global_pooling': 'max', 'learning_rate': 4.015757892927034e-05, 'weight_decay': 0.0001178475319146265, 'beta_0': 0.8092701007958544, 'beta_1': 0.9835634391336578, 'epsilon': 5.4470200017720924e-05, 'balanced_loss': False, 'epochs': 124, 'early_stopping_patience': 17, 'plateau_patience': 21, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-26 22:08:08,650] Trial 140 finished with value: 0.936887953417139 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8268259365160944, 'batch_size': 198, 'attention_heads': 8, 'hidden_dimension': 229, 'number_of_hidden_layers': 1, 'dropout_rate': 0.345905393090294, 'global_pooling': 'max', 'learning_rate': 5.507572937722376e-05, 'weight_decay': 0.00028779957876476223, 'beta_0': 0.8134496849430504, 'beta_1': 0.9863883858172716, 'epsilon': 7.235381659415623e-05, 'balanced_loss': False, 'epochs': 129, 'early_stopping_patience': 19, 'plateau_patience': 13, 'plateau_divider': 7}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-26 22:34:33,175] Trial 141 finished with value: 0.727879072081585 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.7957203745313448, 'batch_size': 170, 'attention_heads': 9, 'hidden_dimension': 207, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5878612276879394, 'global_pooling': 'sum', 'learning_rate': 0.09285939748894982, 'weight_decay': 0.00037763274371983906, 'beta_0': 0.8041819144883646, 'beta_1': 0.9870133278054045, 'epsilon': 4.459083342533209e-05, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 15, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
CUDA out of memory. Tried to allocate 3.37 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.18 GiB is free. Including non-PyTorch memory, this process has 41.38 GiB memory in use. Of the allocated memory 39.91 GiB is allocated by PyTorch, and 326.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-26 22:40:45,530] Trial 142 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.6900940108791095, 'batch_size': 183, 'attention_heads': 10, 'hidden_dimension': 196, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5810436037856189, 'global_pooling': 'max', 'learning_rate': 0.00036217698005598236, 'weight_decay': 0.00022539781360559174, 'beta_0': 0.8172162502118832, 'beta_1': 0.9859544233651004, 'epsilon': 4.4963903283706145e-06, 'balanced_loss': False, 'epochs': 133, 'early_stopping_patience': 14, 'plateau_patience': 10, 'plateau_divider': 8}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-26 22:51:33,409] Trial 143 finished with value: 0.9465890697143025 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8152717893809883, 'batch_size': 161, 'attention_heads': 9, 'hidden_dimension': 217, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5623365145516735, 'global_pooling': 'max', 'learning_rate': 0.00012164960711128122, 'weight_decay': 0.000449511487123892, 'beta_0': 0.8103970789523948, 'beta_1': 0.9806694126636429, 'epsilon': 1.827709546448811e-05, 'balanced_loss': False, 'epochs': 142, 'early_stopping_patience': 18, 'plateau_patience': 15, 'plateau_divider': 4}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-26 23:04:51,246] Trial 144 finished with value: 0.956549851561169 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8543298296689287, 'batch_size': 206, 'attention_heads': 9, 'hidden_dimension': 202, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5563785214557694, 'global_pooling': 'max', 'learning_rate': 0.00017299622694926206, 'weight_decay': 0.0006084251758635677, 'beta_0': 0.8068840110714841, 'beta_1': 0.9884044336803819, 'epsilon': 1.8882534541815663e-06, 'balanced_loss': False, 'epochs': 157, 'early_stopping_patience': 16, 'plateau_patience': 14, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-26 23:17:33,627] Trial 145 finished with value: 0.9527247198492574 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8522519096776965, 'batch_size': 216, 'attention_heads': 8, 'hidden_dimension': 201, 'number_of_hidden_layers': 2, 'dropout_rate': 0.531455953633539, 'global_pooling': 'max', 'learning_rate': 0.00017265470872775113, 'weight_decay': 0.0005989011033082029, 'beta_0': 0.8075211087526911, 'beta_1': 0.9884460375444394, 'epsilon': 2.7563657512626777e-05, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 16, 'plateau_patience': 14, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-26 23:29:43,543] Trial 146 finished with value: 0.9536459890382551 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8053227398006302, 'batch_size': 208, 'attention_heads': 9, 'hidden_dimension': 211, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5510984107352735, 'global_pooling': 'max', 'learning_rate': 0.000272852934507306, 'weight_decay': 0.0002600445984874423, 'beta_0': 0.8060383092932306, 'beta_1': 0.9888222211269144, 'epsilon': 1.8863989019438621e-06, 'balanced_loss': False, 'epochs': 120, 'early_stopping_patience': 16, 'plateau_patience': 14, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
CUDA out of memory. Tried to allocate 2.72 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.12 GiB is free. Including non-PyTorch memory, this process has 42.43 GiB memory in use. Of the allocated memory 39.11 GiB is allocated by PyTorch, and 2.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-26 23:38:42,324] Trial 147 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8196600808896614, 'batch_size': 178, 'attention_heads': 9, 'hidden_dimension': 224, 'number_of_hidden_layers': 2, 'dropout_rate': 0.540161704100585, 'global_pooling': 'max', 'learning_rate': 0.00010043180620413084, 'weight_decay': 0.000692184556711923, 'beta_0': 0.8029335398800677, 'beta_1': 0.9881000764376134, 'epsilon': 8.08990326063759e-05, 'balanced_loss': False, 'epochs': 161, 'early_stopping_patience': 17, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-26 23:55:18,324] Trial 148 finished with value: 0.9531875807464176 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.842614096022782, 'batch_size': 192, 'attention_heads': 10, 'hidden_dimension': 207, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5707723445976537, 'global_pooling': 'max', 'learning_rate': 6.957583756646446e-05, 'weight_decay': 0.00035143799979922037, 'beta_0': 0.8087440250321305, 'beta_1': 0.9850091342329885, 'epsilon': 3.837644307128516e-05, 'balanced_loss': False, 'epochs': 137, 'early_stopping_patience': 15, 'plateau_patience': 13, 'plateau_divider': 7}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 00:09:39,199] Trial 149 finished with value: 0.9623861999435553 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7848383993824077, 'batch_size': 165, 'attention_heads': 9, 'hidden_dimension': 195, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5543967401242582, 'global_pooling': 'max', 'learning_rate': 0.00015647721402230292, 'weight_decay': 0.00015782541819918565, 'beta_0': 0.811719306565616, 'beta_1': 0.9876840508269739, 'epsilon': 5.0520274291371196e-05, 'balanced_loss': False, 'epochs': 108, 'early_stopping_patience': 17, 'plateau_patience': 12, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 00:22:35,519] Trial 150 finished with value: 0.9436795234863056 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7617065925529541, 'batch_size': 165, 'attention_heads': 9, 'hidden_dimension': 185, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5556570584714715, 'global_pooling': 'max', 'learning_rate': 0.00019067568894771966, 'weight_decay': 0.00016800181186193698, 'beta_0': 0.8158722416119397, 'beta_1': 0.9877316651439276, 'epsilon': 5.404567377666507e-05, 'balanced_loss': False, 'epochs': 108, 'early_stopping_patience': 17, 'plateau_patience': 12, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 00:34:55,283] Trial 151 finished with value: 0.9572088021174885 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7910598139616196, 'batch_size': 151, 'attention_heads': 8, 'hidden_dimension': 195, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3667073300885664, 'global_pooling': 'max', 'learning_rate': 0.00010654538647559142, 'weight_decay': 0.00015177530668380575, 'beta_0': 0.81204578294392, 'beta_1': 0.986620162482845, 'epsilon': 6.319831373246671e-05, 'balanced_loss': False, 'epochs': 112, 'early_stopping_patience': 16, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 00:50:12,271] Trial 152 finished with value: 0.9350050328402755 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7844109946271566, 'batch_size': 145, 'attention_heads': 11, 'hidden_dimension': 191, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4592330700843365, 'global_pooling': 'max', 'learning_rate': 8.41433984554695e-05, 'weight_decay': 0.0001465744870266899, 'beta_0': 0.8131783769907965, 'beta_1': 0.9856400804608647, 'epsilon': 6.177932260209164e-05, 'balanced_loss': False, 'epochs': 111, 'early_stopping_patience': 16, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 01:02:50,119] Trial 153 finished with value: 0.9539151522533582 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7904436783414825, 'batch_size': 166, 'attention_heads': 8, 'hidden_dimension': 197, 'number_of_hidden_layers': 1, 'dropout_rate': 0.30649285629851986, 'global_pooling': 'max', 'learning_rate': 0.00011479617701392796, 'weight_decay': 0.00012250155104074421, 'beta_0': 0.8193591581576363, 'beta_1': 0.9866559659320328, 'epsilon': 3.442303098379133e-05, 'balanced_loss': False, 'epochs': 98, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 01:15:39,115] Trial 154 finished with value: 0.9511300269205356 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7716866238045252, 'batch_size': 156, 'attention_heads': 9, 'hidden_dimension': 193, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4217726038233515, 'global_pooling': 'max', 'learning_rate': 0.00013937396248384998, 'weight_decay': 0.0001995062457533497, 'beta_0': 0.89986087646536, 'beta_1': 0.9873844300362989, 'epsilon': 4.770375617535342e-05, 'balanced_loss': False, 'epochs': 131, 'early_stopping_patience': 16, 'plateau_patience': 12, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 01:27:51,964] Trial 155 finished with value: 0.9535466462592951 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8007847983658877, 'batch_size': 173, 'attention_heads': 8, 'hidden_dimension': 201, 'number_of_hidden_layers': 1, 'dropout_rate': 0.33407299368127963, 'global_pooling': 'max', 'learning_rate': 0.00010238083765826649, 'weight_decay': 0.00024079051476391517, 'beta_0': 0.8114550298447376, 'beta_1': 0.9871245842414451, 'epsilon': 6.962288329160737e-05, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 16, 'plateau_patience': 13, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 01:38:05,769] Trial 156 finished with value: 0.9540283080916496 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8107022097109938, 'batch_size': 139, 'attention_heads': 9, 'hidden_dimension': 187, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3949168276144636, 'global_pooling': 'max', 'learning_rate': 0.00024629494263186507, 'weight_decay': 0.00015477095525483773, 'beta_0': 0.809766891538847, 'beta_1': 0.9862667659736805, 'epsilon': 8.573657828662051e-05, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 15, 'plateau_patience': 10, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
CUDA out of memory. Tried to allocate 3.39 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.58 GiB is free. Including non-PyTorch memory, this process has 41.97 GiB memory in use. Of the allocated memory 37.34 GiB is allocated by PyTorch, and 3.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-27 01:44:25,147] Trial 157 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7836647282852731, 'batch_size': 237, 'attention_heads': 10, 'hidden_dimension': 205, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5464396785790432, 'global_pooling': 'max', 'learning_rate': 0.00016397142711258015, 'weight_decay': 8.834531508263835e-05, 'beta_0': 0.8144701701322116, 'beta_1': 0.9865768603338375, 'epsilon': 2.3519458706032403e-05, 'balanced_loss': False, 'epochs': 107, 'early_stopping_patience': 17, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 01:56:53,831] Trial 158 finished with value: 0.9481862885997031 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8327083676988731, 'batch_size': 149, 'attention_heads': 8, 'hidden_dimension': 195, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5270970363733656, 'global_pooling': 'max', 'learning_rate': 0.0001244672361331485, 'weight_decay': 0.00029884357918490986, 'beta_0': 0.8079008251269421, 'beta_1': 0.9883714392188776, 'epsilon': 4.5635576020883504e-05, 'balanced_loss': False, 'epochs': 146, 'early_stopping_patience': 15, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 02:07:50,544] Trial 159 finished with value: 0.9533368279175407 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7945617538112648, 'batch_size': 153, 'attention_heads': 9, 'hidden_dimension': 213, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3660971377098415, 'global_pooling': 'max', 'learning_rate': 0.00032263573470323834, 'weight_decay': 0.0001844053422396685, 'beta_0': 0.8117252869420475, 'beta_1': 0.9845002292033166, 'epsilon': 9.930225036439506e-05, 'balanced_loss': False, 'epochs': 112, 'early_stopping_patience': 16, 'plateau_patience': 13, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 02:23:42,285] Trial 160 finished with value: 0.9553242271518245 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8207667171646158, 'batch_size': 177, 'attention_heads': 10, 'hidden_dimension': 168, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5911720060905842, 'global_pooling': 'max', 'learning_rate': 7.350907714361112e-05, 'weight_decay': 0.0002149089827251824, 'beta_0': 0.8096654664509423, 'beta_1': 0.9877561578208721, 'epsilon': 5.723578304685331e-05, 'balanced_loss': False, 'epochs': 134, 'early_stopping_patience': 16, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 02:39:07,925] Trial 161 finished with value: 0.9284677765115247 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8591056164627554, 'batch_size': 228, 'attention_heads': 10, 'hidden_dimension': 169, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5947968364784652, 'global_pooling': 'max', 'learning_rate': 6.433045688667963e-05, 'weight_decay': 1.0005072453856697e-06, 'beta_0': 0.8158640948834964, 'beta_1': 0.9892259548442244, 'epsilon': 5.7630545685731785e-05, 'balanced_loss': False, 'epochs': 139, 'early_stopping_patience': 17, 'plateau_patience': 12, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 02:53:03,078] Trial 162 finished with value: 0.9368232767279139 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8042176829830648, 'batch_size': 184, 'attention_heads': 11, 'hidden_dimension': 182, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4431315366339285, 'global_pooling': 'max', 'learning_rate': 7.895880169700702e-05, 'weight_decay': 0.00014044316410383222, 'beta_0': 0.8383165309359527, 'beta_1': 0.9877711006203604, 'epsilon': 3.131213254651858e-05, 'balanced_loss': False, 'epochs': 134, 'early_stopping_patience': 14, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 03:08:50,527] Trial 163 finished with value: 0.9410253741879081 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7897673230025111, 'batch_size': 179, 'attention_heads': 10, 'hidden_dimension': 178, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3733016643584086, 'global_pooling': 'sum', 'learning_rate': 4.383104369851794e-05, 'weight_decay': 0.0001018890768535773, 'beta_0': 0.8051938518300548, 'beta_1': 0.9880013656076687, 'epsilon': 1.3080554551901277e-05, 'balanced_loss': False, 'epochs': 124, 'early_stopping_patience': 16, 'plateau_patience': 12, 'plateau_divider': 7}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 03:27:19,802] Trial 164 finished with value: 0.9586564644242107 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8202688306555348, 'batch_size': 173, 'attention_heads': 10, 'hidden_dimension': 209, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5902627913833448, 'global_pooling': 'max', 'learning_rate': 9.309451458595084e-05, 'weight_decay': 0.00021814904828573132, 'beta_0': 0.8103613831504307, 'beta_1': 0.9868895859643068, 'epsilon': 4.361307873759735e-05, 'balanced_loss': False, 'epochs': 128, 'early_stopping_patience': 16, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 03:42:28,609] Trial 165 finished with value: 0.9517326757558727 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8128341859532966, 'batch_size': 168, 'attention_heads': 10, 'hidden_dimension': 201, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5897456800540515, 'global_pooling': 'max', 'learning_rate': 9.732879296281352e-05, 'weight_decay': 0.0002060390162555678, 'beta_0': 0.8088243322679624, 'beta_1': 0.9871446431816402, 'epsilon': 6.647169512397537e-05, 'balanced_loss': False, 'epochs': 132, 'early_stopping_patience': 15, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 04:00:40,032] Trial 166 finished with value: 0.9570358567364664 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8284552243524341, 'batch_size': 161, 'attention_heads': 10, 'hidden_dimension': 210, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5797842814859049, 'global_pooling': 'max', 'learning_rate': 7.445034702276573e-05, 'weight_decay': 0.00016417449119744736, 'beta_0': 0.812994604592689, 'beta_1': 0.9940455074966158, 'epsilon': 3.787359912777412e-05, 'balanced_loss': False, 'epochs': 136, 'early_stopping_patience': 17, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 04:19:39,040] Trial 167 finished with value: 0.9592931443026529 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8266202807609379, 'batch_size': 159, 'attention_heads': 11, 'hidden_dimension': 199, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5760583831709843, 'global_pooling': 'max', 'learning_rate': 6.304387638130346e-05, 'weight_decay': 0.00015857171138048296, 'beta_0': 0.8136256523407243, 'beta_1': 0.9948571709653549, 'epsilon': 3.6570056721468516e-05, 'balanced_loss': False, 'epochs': 129, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 04:43:31,924] Trial 168 finished with value: 0.9543896533157528 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8272867891604017, 'batch_size': 159, 'attention_heads': 11, 'hidden_dimension': 208, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5765640091778911, 'global_pooling': 'max', 'learning_rate': 3.2275613508538614e-05, 'weight_decay': 0.0001305192126272149, 'beta_0': 0.8131925549340694, 'beta_1': 0.993966663150687, 'epsilon': 3.76194213700303e-05, 'balanced_loss': False, 'epochs': 129, 'early_stopping_patience': 17, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 05:01:35,473] Trial 169 finished with value: 0.9231019885206488 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.8406653837306169, 'batch_size': 153, 'attention_heads': 11, 'hidden_dimension': 198, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5589962673859579, 'global_pooling': 'max', 'learning_rate': 5.7374005789559726e-05, 'weight_decay': 0.00015957853499057697, 'beta_0': 0.8179172050683485, 'beta_1': 0.9941019136892474, 'epsilon': 2.2672974342396132e-05, 'balanced_loss': False, 'epochs': 125, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 05:16:55,262] Trial 170 finished with value: 0.9434159257062453 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8518156279507064, 'batch_size': 158, 'attention_heads': 11, 'hidden_dimension': 218, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5661182456094976, 'global_pooling': 'max', 'learning_rate': 5.101711186117133e-05, 'weight_decay': 0.0001671356997503762, 'beta_0': 0.8139006422955127, 'beta_1': 0.9947797194042972, 'epsilon': 3.0595217586881355e-05, 'balanced_loss': True, 'epochs': 156, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 7}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 05:28:44,742] Trial 171 finished with value: 0.9451360191012186 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8344216433363719, 'batch_size': 164, 'attention_heads': 10, 'hidden_dimension': 189, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5736122074676062, 'global_pooling': 'max', 'learning_rate': 0.00019571289773929145, 'weight_decay': 0.00025692639111343356, 'beta_0': 0.8118275081664967, 'beta_1': 0.9933660999802496, 'epsilon': 1.8129553996188146e-05, 'balanced_loss': False, 'epochs': 168, 'early_stopping_patience': 17, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 05:44:53,350] Trial 172 finished with value: 0.9546403619356653 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.828223524702718, 'batch_size': 149, 'attention_heads': 11, 'hidden_dimension': 210, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5365825605307321, 'global_pooling': 'max', 'learning_rate': 0.00010504720377585733, 'weight_decay': 0.0008377560483000726, 'beta_0': 0.8067410565888804, 'beta_1': 0.9951441372377166, 'epsilon': 2.601478986620648e-05, 'balanced_loss': False, 'epochs': 115, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 05:57:39,667] Trial 173 finished with value: 0.9486895001099872 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8452454129389811, 'batch_size': 144, 'attention_heads': 10, 'hidden_dimension': 203, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5513634044057059, 'global_pooling': 'max', 'learning_rate': 0.0001527557608366994, 'weight_decay': 0.00011005786698185947, 'beta_0': 0.8152110660375453, 'beta_1': 0.9956623629694672, 'epsilon': 3.877596747902699e-05, 'balanced_loss': False, 'epochs': 117, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 06:12:05,379] Trial 174 finished with value: 0.9465744478665283 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8215441569684307, 'batch_size': 170, 'attention_heads': 10, 'hidden_dimension': 193, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5991334376069016, 'global_pooling': 'max', 'learning_rate': 7.159445087018534e-05, 'weight_decay': 0.00021890676640503483, 'beta_0': 0.8076458957926665, 'beta_1': 0.987660406427782, 'epsilon': 5.6685050778001606e-05, 'balanced_loss': False, 'epochs': 135, 'early_stopping_patience': 16, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 06:29:14,758] Trial 175 finished with value: 0.9495572529233554 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8199791832296404, 'batch_size': 162, 'attention_heads': 10, 'hidden_dimension': 197, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5924503645871004, 'global_pooling': 'max', 'learning_rate': 7.816370411061494e-05, 'weight_decay': 0.0002314737593295278, 'beta_0': 0.8094781668520616, 'beta_1': 0.9886855841411613, 'epsilon': 6.904936667125854e-05, 'balanced_loss': False, 'epochs': 131, 'early_stopping_patience': 16, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 06:51:35,904] Trial 176 finished with value: 0.9590831271596657 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7980453151109109, 'batch_size': 175, 'attention_heads': 10, 'hidden_dimension': 160, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5851414858812612, 'global_pooling': 'max', 'learning_rate': 6.29140968482093e-05, 'weight_decay': 0.00018090160208446526, 'beta_0': 0.8120967307579676, 'beta_1': 0.995362065607889, 'epsilon': 8.07644690168996e-05, 'balanced_loss': False, 'epochs': 142, 'early_stopping_patience': 17, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
CUDA out of memory. Tried to allocate 3.50 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 41.86 GiB memory in use. Of the allocated memory 37.50 GiB is allocated by PyTorch, and 3.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-27 06:59:03,687] Trial 177 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8045752831217773, 'batch_size': 175, 'attention_heads': 10, 'hidden_dimension': 221, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5783025581176378, 'global_pooling': 'max', 'learning_rate': 6.188828720372731e-05, 'weight_decay': 0.0001340613555202968, 'beta_0': 0.8126397079660118, 'beta_1': 0.9953815296232287, 'epsilon': 6.494480994390999e-07, 'balanced_loss': False, 'epochs': 142, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 07:13:17,487] Trial 178 finished with value: 0.9584927136961765 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7968818146467607, 'batch_size': 167, 'attention_heads': 9, 'hidden_dimension': 144, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5860136636919615, 'global_pooling': 'max', 'learning_rate': 0.00011430432978432224, 'weight_decay': 0.0001780975329447933, 'beta_0': 0.8166917359797087, 'beta_1': 0.9958197557973061, 'epsilon': 7.425856392736451e-05, 'balanced_loss': False, 'epochs': 138, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 07:31:05,797] Trial 179 finished with value: 0.9622389888054297 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7801030448207381, 'batch_size': 220, 'attention_heads': 11, 'hidden_dimension': 147, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5852068823127917, 'global_pooling': 'max', 'learning_rate': 0.00011607537374379506, 'weight_decay': 0.00017959320174721358, 'beta_0': 0.8124419520917524, 'beta_1': 0.9962867079410268, 'epsilon': 9.029507850020078e-05, 'balanced_loss': False, 'epochs': 139, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 07:47:37,146] Trial 180 finished with value: 0.9576477985403378 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7874555305072805, 'batch_size': 223, 'attention_heads': 11, 'hidden_dimension': 153, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5868799160696584, 'global_pooling': 'max', 'learning_rate': 0.0001175172666536426, 'weight_decay': 4.1567221381313865e-05, 'beta_0': 0.8117635062302111, 'beta_1': 0.9967269152594854, 'epsilon': 8.102049583868763e-05, 'balanced_loss': False, 'epochs': 148, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 4}. Best is trial 96 with value: 0.9639957428651793.
CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.45 GiB is free. Including non-PyTorch memory, this process has 42.10 GiB memory in use. Of the allocated memory 35.16 GiB is allocated by PyTorch, and 5.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-27 07:55:26,306] Trial 181 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7660972395051774, 'batch_size': 220, 'attention_heads': 11, 'hidden_dimension': 141, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5828016971255658, 'global_pooling': 'max', 'learning_rate': 0.00011339191317796662, 'weight_decay': 4.604786539397432e-05, 'beta_0': 0.8111984095213928, 'beta_1': 0.996722558204713, 'epsilon': 8.19947857977916e-05, 'balanced_loss': False, 'epochs': 144, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 4}. Best is trial 96 with value: 0.9639957428651793.
CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.50 GiB is free. Including non-PyTorch memory, this process has 42.05 GiB memory in use. Of the allocated memory 37.80 GiB is allocated by PyTorch, and 3.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-27 08:02:30,140] Trial 182 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7791105773373918, 'batch_size': 229, 'attention_heads': 11, 'hidden_dimension': 143, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5874047200492929, 'global_pooling': 'max', 'learning_rate': 5.1138731906069995e-05, 'weight_decay': 3.6254284884200576e-05, 'beta_0': 0.8208135814099858, 'beta_1': 0.9962841574836113, 'epsilon': 8.536673272192495e-05, 'balanced_loss': False, 'epochs': 148, 'early_stopping_patience': 18, 'plateau_patience': 10, 'plateau_divider': 3}. Best is trial 96 with value: 0.9639957428651793.
CUDA out of memory. Tried to allocate 3.38 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.34 GiB is free. Including non-PyTorch memory, this process has 41.22 GiB memory in use. Of the allocated memory 37.16 GiB is allocated by PyTorch, and 2.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-27 08:08:57,227] Trial 183 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7866544441630932, 'batch_size': 222, 'attention_heads': 12, 'hidden_dimension': 157, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5845988842099, 'global_pooling': 'max', 'learning_rate': 8.546437388852575e-05, 'weight_decay': 1.8312037149086118e-05, 'beta_0': 0.8536988197805749, 'beta_1': 0.9958979041713705, 'epsilon': 7.555346750218048e-05, 'balanced_loss': False, 'epochs': 140, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 4}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 08:24:08,453] Trial 184 finished with value: 0.960486618282093 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7975273659238538, 'batch_size': 212, 'attention_heads': 11, 'hidden_dimension': 146, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5933126020931577, 'global_pooling': 'max', 'learning_rate': 0.00012485434027084027, 'weight_decay': 0.00015579181098502668, 'beta_0': 0.8131814204245874, 'beta_1': 0.9970562105464836, 'epsilon': 8.506454182316072e-05, 'balanced_loss': False, 'epochs': 137, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 08:40:27,313] Trial 185 finished with value: 0.9590391775925383 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7947197146209962, 'batch_size': 213, 'attention_heads': 11, 'hidden_dimension': 128, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5996177694284556, 'global_pooling': 'max', 'learning_rate': 0.0001298804434030473, 'weight_decay': 0.0001495611927637227, 'beta_0': 0.8134533398813152, 'beta_1': 0.9968674673284978, 'epsilon': 9.636633127951488e-05, 'balanced_loss': False, 'epochs': 137, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 7}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 08:58:56,003] Trial 186 finished with value: 0.9582576569593337 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7969501101151409, 'batch_size': 213, 'attention_heads': 11, 'hidden_dimension': 148, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5998343662270524, 'global_pooling': 'max', 'learning_rate': 0.00012114867387397615, 'weight_decay': 0.00015413990638893995, 'beta_0': 0.8172688755599303, 'beta_1': 0.9973398526703277, 'epsilon': 9.994682269080937e-05, 'balanced_loss': False, 'epochs': 137, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 7}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 09:14:59,668] Trial 187 finished with value: 0.952406339911152 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7772842618582139, 'batch_size': 212, 'attention_heads': 12, 'hidden_dimension': 127, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5992745986819116, 'global_pooling': 'max', 'learning_rate': 0.00012863932827491097, 'weight_decay': 0.00014646380686547642, 'beta_0': 0.8183282146134399, 'beta_1': 0.997688044263924, 'epsilon': 9.812061435913872e-05, 'balanced_loss': False, 'epochs': 142, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 7}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 09:33:23,199] Trial 188 finished with value: 0.962939803189778 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7942891178870506, 'batch_size': 216, 'attention_heads': 11, 'hidden_dimension': 147, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5942147482516268, 'global_pooling': 'max', 'learning_rate': 0.00011649265230669162, 'weight_decay': 5.9732339695299494e-05, 'beta_0': 0.8156997423668905, 'beta_1': 0.9965724700476373, 'epsilon': 9.441750236955821e-05, 'balanced_loss': False, 'epochs': 151, 'early_stopping_patience': 18, 'plateau_patience': 10, 'plateau_divider': 7}. Best is trial 96 with value: 0.9639957428651793.
[I 2025-03-27 09:53:13,462] Trial 189 finished with value: 0.9677807933054435 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7964533129972768, 'batch_size': 216, 'attention_heads': 11, 'hidden_dimension': 148, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5952448574701158, 'global_pooling': 'max', 'learning_rate': 0.00011769685594204999, 'weight_decay': 7.725952972453206e-05, 'beta_0': 0.8174184029245578, 'beta_1': 0.9971401128757812, 'epsilon': 9.972808461560592e-05, 'balanced_loss': False, 'epochs': 152, 'early_stopping_patience': 18, 'plateau_patience': 10, 'plateau_divider': 7}. Best is trial 189 with value: 0.9677807933054435.
[I 2025-03-27 10:08:59,533] Trial 190 finished with value: 0.9482030365362344 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.795984371426578, 'batch_size': 217, 'attention_heads': 11, 'hidden_dimension': 147, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5950376023701632, 'global_pooling': 'max', 'learning_rate': 0.00015832304454109432, 'weight_decay': 7.871878594870247e-05, 'beta_0': 0.8181643222619652, 'beta_1': 0.9970518995845699, 'epsilon': 9.863222259942059e-05, 'balanced_loss': False, 'epochs': 151, 'early_stopping_patience': 18, 'plateau_patience': 10, 'plateau_divider': 7}. Best is trial 189 with value: 0.9677807933054435.
[I 2025-03-27 10:24:29,011] Trial 191 finished with value: 0.953587957966201 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7985910699350046, 'batch_size': 214, 'attention_heads': 12, 'hidden_dimension': 138, 'number_of_hidden_layers': 1, 'dropout_rate': 0.593155741713359, 'global_pooling': 'max', 'learning_rate': 0.00013883978518421203, 'weight_decay': 5.579301061819919e-05, 'beta_0': 0.8234367028661332, 'beta_1': 0.9982489764412812, 'epsilon': 9.962200260944619e-05, 'balanced_loss': False, 'epochs': 139, 'early_stopping_patience': 18, 'plateau_patience': 10, 'plateau_divider': 7}. Best is trial 189 with value: 0.9677807933054435.
[I 2025-03-27 10:43:21,277] Trial 192 finished with value: 0.9477360063517973 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7984629468520614, 'batch_size': 209, 'attention_heads': 11, 'hidden_dimension': 150, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5997990044589058, 'global_pooling': 'max', 'learning_rate': 8.830781717385297e-05, 'weight_decay': 6.901411306259276e-05, 'beta_0': 0.8207131593489249, 'beta_1': 0.9972226730500607, 'epsilon': 7.813731688327701e-05, 'balanced_loss': False, 'epochs': 137, 'early_stopping_patience': 19, 'plateau_patience': 10, 'plateau_divider': 7}. Best is trial 189 with value: 0.9677807933054435.
[I 2025-03-27 10:58:42,540] Trial 193 finished with value: 0.9474279283862723 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.779283285535352, 'batch_size': 212, 'attention_heads': 11, 'hidden_dimension': 136, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5922469725708517, 'global_pooling': 'max', 'learning_rate': 0.00010324673691562987, 'weight_decay': 9.463297405392627e-05, 'beta_0': 0.8155559382526323, 'beta_1': 0.9974891526351255, 'epsilon': 7.079574778762421e-05, 'balanced_loss': True, 'epochs': 144, 'early_stopping_patience': 19, 'plateau_patience': 10, 'plateau_divider': 7}. Best is trial 189 with value: 0.9677807933054435.
CUDA out of memory. Tried to allocate 3.61 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.93 GiB is free. Including non-PyTorch memory, this process has 42.62 GiB memory in use. Of the allocated memory 39.02 GiB is allocated by PyTorch, and 2.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-27 11:16:52,942] Trial 194 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7854540117465841, 'batch_size': 223, 'attention_heads': 11, 'hidden_dimension': 154, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5872324005057962, 'global_pooling': 'max', 'learning_rate': 0.00011735590423219324, 'weight_decay': 5.2301564636944133e-05, 'beta_0': 0.8168264378009396, 'beta_1': 0.9968056209185067, 'epsilon': 8.718671290311527e-05, 'balanced_loss': False, 'epochs': 152, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 7}. Best is trial 189 with value: 0.9677807933054435.
CUDA out of memory. Tried to allocate 3.44 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.36 GiB is free. Including non-PyTorch memory, this process has 41.19 GiB memory in use. Of the allocated memory 37.51 GiB is allocated by PyTorch, and 2.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-27 11:25:17,918] Trial 195 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7899301404544548, 'batch_size': 218, 'attention_heads': 11, 'hidden_dimension': 160, 'number_of_hidden_layers': 1, 'dropout_rate': 0.587792843977217, 'global_pooling': 'max', 'learning_rate': 0.00012436092500657376, 'weight_decay': 3.394109066508899e-05, 'beta_0': 0.8146173511341884, 'beta_1': 0.9965362228539472, 'epsilon': 8.20334205976808e-05, 'balanced_loss': False, 'epochs': 148, 'early_stopping_patience': 18, 'plateau_patience': 10, 'plateau_divider': 7}. Best is trial 189 with value: 0.9677807933054435.
[I 2025-03-27 11:40:14,418] Trial 196 finished with value: 0.9558347797773699 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8022659146397616, 'batch_size': 219, 'attention_heads': 11, 'hidden_dimension': 131, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5999635227377889, 'global_pooling': 'max', 'learning_rate': 0.0001403308750603726, 'weight_decay': 3.986500952006863e-05, 'beta_0': 0.8169916953863067, 'beta_1': 0.9961440822942613, 'epsilon': 7.37865326182015e-05, 'balanced_loss': False, 'epochs': 147, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 7}. Best is trial 189 with value: 0.9677807933054435.
slurmstepd: error: *** JOB 15517471 ON gpu014 CANCELLED AT 2025-03-27T11:44:56 DUE TO TIME LIMIT ***
