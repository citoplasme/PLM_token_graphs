[I 2025-02-19 07:45:21,445] Using an existing study with name 'R8-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-Unitary_Weights-0.0-0.0' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors
[I 2025-02-19 08:06:58,453] Trial 70 finished with value: 0.9431860775578499 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8139727810498604, 'batch_size': 40, 'attention_heads': 7, 'hidden_dimension': 43, 'number_of_hidden_layers': 4, 'dropout_rate': 0.38435276626541437, 'global_pooling': 'max', 'learning_rate': 9.160495114419476e-05, 'weight_decay': 0.000248207624495199, 'beta_0': 0.8251085139900901, 'beta_1': 0.9985672110814261, 'epsilon': 6.37059467099655e-05, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 25, 'plateau_patience': 10, 'plateau_divider': 7}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 08:20:07,708] Trial 71 finished with value: 0.9377482346183165 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8790262948602622, 'batch_size': 33, 'attention_heads': 6, 'hidden_dimension': 39, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3433239929736871, 'global_pooling': 'sum', 'learning_rate': 0.00032548599169771763, 'weight_decay': 0.00015260108239596807, 'beta_0': 0.818162023834649, 'beta_1': 0.9989890793763844, 'epsilon': 4.691205685049336e-05, 'balanced_loss': True, 'epochs': 187, 'early_stopping_patience': 24, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 08:34:26,281] Trial 72 finished with value: 0.940248374613424 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8921641630003816, 'batch_size': 51, 'attention_heads': 6, 'hidden_dimension': 56, 'number_of_hidden_layers': 4, 'dropout_rate': 0.557225915600345, 'global_pooling': 'max', 'learning_rate': 0.00040981723193064725, 'weight_decay': 0.00028974924778340697, 'beta_0': 0.8081345853403209, 'beta_1': 0.9978226431763466, 'epsilon': 2.2094860255768444e-05, 'balanced_loss': True, 'epochs': 179, 'early_stopping_patience': 22, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 08:49:58,183] Trial 73 finished with value: 0.9458578727501974 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8503215390855797, 'batch_size': 57, 'attention_heads': 7, 'hidden_dimension': 40, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3705368299819056, 'global_pooling': 'max', 'learning_rate': 0.00018638528068887626, 'weight_decay': 0.00038570594782372437, 'beta_0': 0.8316622181179635, 'beta_1': 0.9967273200013751, 'epsilon': 3.5314611768939145e-05, 'balanced_loss': True, 'epochs': 54, 'early_stopping_patience': 21, 'plateau_patience': 10, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 09:01:09,476] Trial 74 finished with value: 0.946269207596522 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8377501554390465, 'batch_size': 59, 'attention_heads': 7, 'hidden_dimension': 32, 'number_of_hidden_layers': 4, 'dropout_rate': 0.40667361016739967, 'global_pooling': 'max', 'learning_rate': 0.0006614552908990887, 'weight_decay': 0.0001948827921370378, 'beta_0': 0.8240277422962999, 'beta_1': 0.998223794600569, 'epsilon': 4.851816333746055e-05, 'balanced_loss': True, 'epochs': 158, 'early_stopping_patience': 22, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 09:12:08,830] Trial 75 finished with value: 0.9349007177441044 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8816748444711588, 'batch_size': 37, 'attention_heads': 8, 'hidden_dimension': 51, 'number_of_hidden_layers': 4, 'dropout_rate': 0.32475062689998546, 'global_pooling': 'max', 'learning_rate': 0.0010378290564567487, 'weight_decay': 0.0005314188300518397, 'beta_0': 0.8138560797586009, 'beta_1': 0.9934041785570591, 'epsilon': 9.98422220370324e-05, 'balanced_loss': False, 'epochs': 187, 'early_stopping_patience': 16, 'plateau_patience': 12, 'plateau_divider': 7}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 09:22:29,015] Trial 76 finished with value: 0.9276136483672659 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9422221340377213, 'batch_size': 51, 'attention_heads': 6, 'hidden_dimension': 79, 'number_of_hidden_layers': 4, 'dropout_rate': 0.35536580393937883, 'global_pooling': 'max', 'learning_rate': 0.00026874515423999987, 'weight_decay': 5.108721527149817e-05, 'beta_0': 0.8337868931260863, 'beta_1': 0.9957668185010695, 'epsilon': 2.610763395363221e-05, 'balanced_loss': False, 'epochs': 108, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 09:33:17,070] Trial 77 finished with value: 0.9502744991858483 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.890463287969986, 'batch_size': 80, 'attention_heads': 5, 'hidden_dimension': 61, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3904430237686731, 'global_pooling': 'max', 'learning_rate': 0.0005904452702014789, 'weight_decay': 0.0003243611745593694, 'beta_0': 0.8027322845825232, 'beta_1': 0.9973676816135978, 'epsilon': 5.653661924399017e-05, 'balanced_loss': False, 'epochs': 102, 'early_stopping_patience': 21, 'plateau_patience': 12, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 09:56:21,345] Trial 78 finished with value: 0.9419518487221114 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8709472955791373, 'batch_size': 78, 'attention_heads': 5, 'hidden_dimension': 62, 'number_of_hidden_layers': 4, 'dropout_rate': 0.39036870514135474, 'global_pooling': 'max', 'learning_rate': 2.599626205287101e-05, 'weight_decay': 0.00026967294811849527, 'beta_0': 0.8111671039131884, 'beta_1': 0.9977391207259245, 'epsilon': 7.653858824417693e-05, 'balanced_loss': True, 'epochs': 101, 'early_stopping_patience': 21, 'plateau_patience': 12, 'plateau_divider': 8}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 10:08:02,869] Trial 79 finished with value: 0.9361229132235771 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9129927032206487, 'batch_size': 69, 'attention_heads': 5, 'hidden_dimension': 57, 'number_of_hidden_layers': 4, 'dropout_rate': 0.37003818505237596, 'global_pooling': 'max', 'learning_rate': 0.0015222618457045557, 'weight_decay': 2.5504284169671337e-05, 'beta_0': 0.8039066647918418, 'beta_1': 0.9949427939796296, 'epsilon': 1.693775696523718e-05, 'balanced_loss': False, 'epochs': 84, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 10:16:06,820] Trial 80 finished with value: 0.9363776798191417 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8549833087674192, 'batch_size': 108, 'attention_heads': 5, 'hidden_dimension': 47, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4009448663136207, 'global_pooling': 'max', 'learning_rate': 0.000670279210820912, 'weight_decay': 8.08375841912842e-05, 'beta_0': 0.8217795857858681, 'beta_1': 0.988785465914006, 'epsilon': 2.8940809108813315e-05, 'balanced_loss': False, 'epochs': 96, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 10:25:13,128] Trial 81 finished with value: 0.9352428623782816 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9245769570827503, 'batch_size': 175, 'attention_heads': 4, 'hidden_dimension': 37, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4252274943520279, 'global_pooling': 'mean', 'learning_rate': 0.0005626011089242127, 'weight_decay': 0.0008658408582651527, 'beta_0': 0.8024081156386, 'beta_1': 0.9963006142440681, 'epsilon': 7.071491148237569e-05, 'balanced_loss': False, 'epochs': 90, 'early_stopping_patience': 23, 'plateau_patience': 25, 'plateau_divider': 7}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 10:43:01,805] Trial 82 finished with value: 0.948163958245801 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8957088375392818, 'batch_size': 63, 'attention_heads': 6, 'hidden_dimension': 89, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5742718123591308, 'global_pooling': 'max', 'learning_rate': 0.0003999013182275229, 'weight_decay': 0.0003405840775495563, 'beta_0': 0.8551901950035609, 'beta_1': 0.9970957757741983, 'epsilon': 5.0195725111679423e-05, 'balanced_loss': False, 'epochs': 116, 'early_stopping_patience': 22, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.26 GiB is free. Including non-PyTorch memory, this process has 43.29 GiB memory in use. Of the allocated memory 41.14 GiB is allocated by PyTorch, and 1.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 10:49:09,503] Trial 83 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8891231553338531, 'batch_size': 83, 'attention_heads': 6, 'hidden_dimension': 169, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3773051415619586, 'global_pooling': 'max', 'learning_rate': 0.0011666133034542525, 'weight_decay': 0.00042348267576964893, 'beta_0': 0.8065221501543557, 'beta_1': 0.9984562192539211, 'epsilon': 3.885549390111645e-05, 'balanced_loss': False, 'epochs': 66, 'early_stopping_patience': 22, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 1.36 GiB. GPU 0 has a total capacity of 44.56 GiB of which 554.69 MiB is free. Including non-PyTorch memory, this process has 44.01 GiB memory in use. Of the allocated memory 42.65 GiB is allocated by PyTorch, and 218.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 10:54:54,727] Trial 84 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.804699560811736, 'batch_size': 38, 'attention_heads': 7, 'hidden_dimension': 185, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5890298269528468, 'global_pooling': 'max', 'learning_rate': 0.0008892888768378503, 'weight_decay': 0.00021699876311249164, 'beta_0': 0.8004928121294693, 'beta_1': 0.9973940610852418, 'epsilon': 1.6730451272866315e-05, 'balanced_loss': False, 'epochs': 61, 'early_stopping_patience': 14, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 11:05:56,755] Trial 85 finished with value: 0.9352954993256238 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9051766588666359, 'batch_size': 45, 'attention_heads': 5, 'hidden_dimension': 68, 'number_of_hidden_layers': 4, 'dropout_rate': 0.357663592941112, 'global_pooling': 'max', 'learning_rate': 0.00017013388010521868, 'weight_decay': 0.00015703524036374486, 'beta_0': 0.8264373020658173, 'beta_1': 0.9967319979955008, 'epsilon': 7.669922215298661e-06, 'balanced_loss': False, 'epochs': 53, 'early_stopping_patience': 20, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 11:19:05,216] Trial 86 finished with value: 0.9446938746469487 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8264979654578779, 'batch_size': 60, 'attention_heads': 5, 'hidden_dimension': 53, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3906227431116851, 'global_pooling': 'max', 'learning_rate': 0.0005525014767665068, 'weight_decay': 1.476624792687571e-06, 'beta_0': 0.8193002227781778, 'beta_1': 0.9980773028013399, 'epsilon': 6.213772542969386e-05, 'balanced_loss': False, 'epochs': 59, 'early_stopping_patience': 22, 'plateau_patience': 13, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 1.37 GiB. GPU 0 has a total capacity of 44.56 GiB of which 318.69 MiB is free. Including non-PyTorch memory, this process has 44.24 GiB memory in use. Of the allocated memory 42.01 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 11:25:08,055] Trial 87 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8768098240754307, 'batch_size': 251, 'attention_heads': 6, 'hidden_dimension': 62, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5323525696698727, 'global_pooling': 'max', 'learning_rate': 0.00033350013683302275, 'weight_decay': 0.0005978711716056399, 'beta_0': 0.8297608410557211, 'beta_1': 0.9974577270373367, 'epsilon': 4.092806403965517e-05, 'balanced_loss': False, 'epochs': 65, 'early_stopping_patience': 23, 'plateau_patience': 15, 'plateau_divider': 4}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 11:34:40,063] Trial 88 finished with value: 0.9056713602596077 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9630689548127416, 'batch_size': 73, 'attention_heads': 6, 'hidden_dimension': 82, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5537160471391475, 'global_pooling': 'max', 'learning_rate': 0.0021493395158541724, 'weight_decay': 0.00035502513058759664, 'beta_0': 0.8954138963359831, 'beta_1': 0.9811827415612769, 'epsilon': 8.736800892755806e-05, 'balanced_loss': False, 'epochs': 50, 'early_stopping_patience': 21, 'plateau_patience': 24, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 11:51:19,100] Trial 89 finished with value: 0.949235435735794 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8430752031546397, 'batch_size': 51, 'attention_heads': 4, 'hidden_dimension': 78, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5774189570027763, 'global_pooling': 'max', 'learning_rate': 0.0013785300877880936, 'weight_decay': 0.00048039697958427005, 'beta_0': 0.8654620551432674, 'beta_1': 0.996057046730669, 'epsilon': 2.961381096103901e-05, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 24, 'plateau_patience': 13, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 3.11 GiB. GPU 0 has a total capacity of 44.56 GiB of which 360.69 MiB is free. Including non-PyTorch memory, this process has 44.20 GiB memory in use. Of the allocated memory 42.29 GiB is allocated by PyTorch, and 781.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 11:58:47,454] Trial 90 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8638832120608578, 'batch_size': 90, 'attention_heads': 7, 'hidden_dimension': 248, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5464227150670571, 'global_pooling': 'max', 'learning_rate': 0.00023856375198443922, 'weight_decay': 0.00031337947067994464, 'beta_0': 0.872833457332779, 'beta_1': 0.9858659799391807, 'epsilon': 5.423376562447528e-05, 'balanced_loss': False, 'epochs': 101, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 2.29 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 43.49 GiB memory in use. Of the allocated memory 42.04 GiB is allocated by PyTorch, and 312.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 12:04:50,128] Trial 91 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.897716182384343, 'batch_size': 184, 'attention_heads': 15, 'hidden_dimension': 68, 'number_of_hidden_layers': 3, 'dropout_rate': 0.526815267991117, 'global_pooling': 'sum', 'learning_rate': 0.0009564926360387149, 'weight_decay': 1.845672763110208e-05, 'beta_0': 0.8999711577647799, 'beta_1': 0.9989476534899697, 'epsilon': 2.971344842068007e-06, 'balanced_loss': False, 'epochs': 138, 'early_stopping_patience': 21, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 12:18:16,057] Trial 92 finished with value: 0.9448077387625282 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8632808890924352, 'batch_size': 45, 'attention_heads': 4, 'hidden_dimension': 74, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5680167309723584, 'global_pooling': 'max', 'learning_rate': 0.0004579368049004751, 'weight_decay': 0.00040969831580449053, 'beta_0': 0.877352343386978, 'beta_1': 0.9946088172407769, 'epsilon': 1.8982468541794913e-05, 'balanced_loss': False, 'epochs': 57, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 838.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 670.69 MiB is free. Including non-PyTorch memory, this process has 43.90 GiB memory in use. Of the allocated memory 41.88 GiB is allocated by PyTorch, and 889.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 12:27:56,565] Trial 93 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.7885601794570483, 'batch_size': 32, 'attention_heads': 4, 'hidden_dimension': 99, 'number_of_hidden_layers': 4, 'dropout_rate': 0.562711943009173, 'global_pooling': 'max', 'learning_rate': 0.0004976629393660101, 'weight_decay': 0.00028636289135512515, 'beta_0': 0.8606632651841727, 'beta_1': 0.9936237355228025, 'epsilon': 1.1586035847795963e-05, 'balanced_loss': False, 'epochs': 55, 'early_stopping_patience': 22, 'plateau_patience': 16, 'plateau_divider': 4}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 12:39:46,366] Trial 94 finished with value: 0.9497034462206784 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8871311472187076, 'batch_size': 67, 'attention_heads': 5, 'hidden_dimension': 41, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5387583286118954, 'global_pooling': 'max', 'learning_rate': 0.0007389779146343024, 'weight_decay': 0.0008130550506397139, 'beta_0': 0.8759859615646937, 'beta_1': 0.9922288214085544, 'epsilon': 4.653236031440376e-06, 'balanced_loss': False, 'epochs': 76, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 4}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 12:51:50,755] Trial 95 finished with value: 0.9459720729192098 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9270299807698965, 'batch_size': 68, 'attention_heads': 5, 'hidden_dimension': 41, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5380683219509458, 'global_pooling': 'max', 'learning_rate': 0.0007359986900960311, 'weight_decay': 0.0008317578033643216, 'beta_0': 0.8631732619849731, 'beta_1': 0.9923752939455737, 'epsilon': 4.579700903045573e-06, 'balanced_loss': False, 'epochs': 87, 'early_stopping_patience': 24, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 13:05:55,840] Trial 96 finished with value: 0.9389330705489556 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8861517670921449, 'batch_size': 80, 'attention_heads': 5, 'hidden_dimension': 59, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5491188383293585, 'global_pooling': 'max', 'learning_rate': 0.0018233640834062913, 'weight_decay': 0.0009942136230259022, 'beta_0': 0.8753365159000845, 'beta_1': 0.9914434709786046, 'epsilon': 3.1919055252132074e-06, 'balanced_loss': False, 'epochs': 92, 'early_stopping_patience': 25, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 13:21:44,358] Trial 97 finished with value: 0.9445820632881374 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8738585026634581, 'batch_size': 56, 'attention_heads': 6, 'hidden_dimension': 48, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5868050821733934, 'global_pooling': 'max', 'learning_rate': 0.0006514963403839811, 'weight_decay': 0.0006219118320353214, 'beta_0': 0.8713997938944671, 'beta_1': 0.9926451420833349, 'epsilon': 5.640801488313658e-07, 'balanced_loss': False, 'epochs': 76, 'early_stopping_patience': 22, 'plateau_patience': 14, 'plateau_divider': 4}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 13:29:35,419] Trial 98 finished with value: 0.8876843367638756 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9501149295122995, 'batch_size': 97, 'attention_heads': 5, 'hidden_dimension': 37, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5761531130196434, 'global_pooling': 'max', 'learning_rate': 0.0027740279555670475, 'weight_decay': 3.716003797783955e-05, 'beta_0': 0.8679836278577827, 'beta_1': 0.9930986475386805, 'epsilon': 1.6340869965491423e-06, 'balanced_loss': False, 'epochs': 68, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 13:38:59,962] Trial 99 finished with value: 0.9402278854405848 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9036174283225199, 'batch_size': 74, 'attention_heads': 6, 'hidden_dimension': 52, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5615761247814852, 'global_pooling': 'mean', 'learning_rate': 0.0010004741507078877, 'weight_decay': 0.00021494993819103767, 'beta_0': 0.8932407060746541, 'beta_1': 0.990213856487789, 'epsilon': 1.2055572786455822e-06, 'balanced_loss': False, 'epochs': 61, 'early_stopping_patience': 24, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 13:51:00,975] Trial 100 finished with value: 0.9568754035467383 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8534110828895503, 'batch_size': 63, 'attention_heads': 5, 'hidden_dimension': 43, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4187385773963423, 'global_pooling': 'max', 'learning_rate': 0.00036465437814280603, 'weight_decay': 0.00013212720399192497, 'beta_0': 0.8424528049481033, 'beta_1': 0.9953773142861102, 'epsilon': 1.3695088101232912e-05, 'balanced_loss': False, 'epochs': 119, 'early_stopping_patience': 21, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 14:01:53,728] Trial 101 finished with value: 0.9376037981719952 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8548529308990611, 'batch_size': 62, 'attention_heads': 4, 'hidden_dimension': 32, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4131044558267531, 'global_pooling': 'max', 'learning_rate': 0.0003076218476206465, 'weight_decay': 0.00012831741043223938, 'beta_0': 0.8456613111798746, 'beta_1': 0.9953969816853745, 'epsilon': 2.6309482540008254e-05, 'balanced_loss': True, 'epochs': 122, 'early_stopping_patience': 21, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 14:14:36,271] Trial 102 finished with value: 0.9556169784121664 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.832030370766525, 'batch_size': 68, 'attention_heads': 5, 'hidden_dimension': 43, 'number_of_hidden_layers': 4, 'dropout_rate': 0.39766089962996926, 'global_pooling': 'max', 'learning_rate': 0.00039362961317710295, 'weight_decay': 0.00017923431026382663, 'beta_0': 0.8398362715567742, 'beta_1': 0.9938278225173183, 'epsilon': 9.313519371167005e-06, 'balanced_loss': False, 'epochs': 105, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 14:28:09,654] Trial 103 finished with value: 0.9367821745557277 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8196763565641042, 'batch_size': 88, 'attention_heads': 6, 'hidden_dimension': 45, 'number_of_hidden_layers': 4, 'dropout_rate': 0.39650412621555015, 'global_pooling': 'max', 'learning_rate': 0.00041829223821223207, 'weight_decay': 0.00010504474874244084, 'beta_0': 0.8386796029871294, 'beta_1': 0.994037939647195, 'epsilon': 9.00350854670933e-06, 'balanced_loss': False, 'epochs': 119, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 9}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 14:40:43,254] Trial 104 finished with value: 0.944884924458804 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8307979539842448, 'batch_size': 49, 'attention_heads': 5, 'hidden_dimension': 50, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4233752731744017, 'global_pooling': 'max', 'learning_rate': 0.00020059981598719799, 'weight_decay': 0.00016271772694042544, 'beta_0': 0.8471041471159511, 'beta_1': 0.9986406029097187, 'epsilon': 1.4389441520894726e-05, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 21, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 44.56 GiB of which 502.69 MiB is free. Including non-PyTorch memory, this process has 44.06 GiB memory in use. Of the allocated memory 42.30 GiB is allocated by PyTorch, and 625.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 14:46:50,639] Trial 105 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8429785962057138, 'batch_size': 85, 'attention_heads': 7, 'hidden_dimension': 145, 'number_of_hidden_layers': 4, 'dropout_rate': 0.40356113953976974, 'global_pooling': 'max', 'learning_rate': 0.00014486919542002722, 'weight_decay': 0.00017284802117034797, 'beta_0': 0.8430427711543711, 'beta_1': 0.9970253162751386, 'epsilon': 7.402058151927188e-06, 'balanced_loss': False, 'epochs': 115, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 15:02:43,909] Trial 106 finished with value: 0.9517161890865059 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8148415200493998, 'batch_size': 72, 'attention_heads': 4, 'hidden_dimension': 68, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3788756712891915, 'global_pooling': 'max', 'learning_rate': 0.0003683551347818754, 'weight_decay': 0.00012719337272097068, 'beta_0': 0.8517103638499142, 'beta_1': 0.9981355921924943, 'epsilon': 4.183376013791662e-05, 'balanced_loss': False, 'epochs': 111, 'early_stopping_patience': 22, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 15:14:58,631] Trial 107 finished with value: 0.9383597702377702 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.805586716842827, 'batch_size': 54, 'attention_heads': 4, 'hidden_dimension': 66, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3783902944955356, 'global_pooling': 'max', 'learning_rate': 0.00028917962612750247, 'weight_decay': 0.0001252483767781787, 'beta_0': 0.8515619525710992, 'beta_1': 0.9982543633596702, 'epsilon': 6.141745700935551e-05, 'balanced_loss': False, 'epochs': 110, 'early_stopping_patience': 18, 'plateau_patience': 14, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 15:27:24,122] Trial 108 finished with value: 0.939838525213893 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8179800579557351, 'batch_size': 41, 'attention_heads': 4, 'hidden_dimension': 36, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3943114451957969, 'global_pooling': 'max', 'learning_rate': 0.00023376153619804945, 'weight_decay': 7.488571980128315e-05, 'beta_0': 0.8402776862771599, 'beta_1': 0.994469017535415, 'epsilon': 1.9632561853423956e-05, 'balanced_loss': False, 'epochs': 107, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 2.07 GiB. GPU 0 has a total capacity of 44.56 GiB of which 280.69 MiB is free. Including non-PyTorch memory, this process has 44.28 GiB memory in use. Of the allocated memory 42.01 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 15:35:00,869] Trial 109 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.6938703441076921, 'batch_size': 75, 'attention_heads': 4, 'hidden_dimension': 161, 'number_of_hidden_layers': 4, 'dropout_rate': 0.38290938777440053, 'global_pooling': 'max', 'learning_rate': 0.0005480180394344302, 'weight_decay': 0.00023370038406778188, 'beta_0': 0.8547904129552882, 'beta_1': 0.9937310644060885, 'epsilon': 1.1618181762345229e-05, 'balanced_loss': False, 'epochs': 115, 'early_stopping_patience': 22, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 1.13 GiB. GPU 0 has a total capacity of 44.56 GiB of which 804.69 MiB is free. Including non-PyTorch memory, this process has 43.77 GiB memory in use. Of the allocated memory 41.59 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 15:43:14,226] Trial 110 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8376366554578848, 'batch_size': 133, 'attention_heads': 5, 'hidden_dimension': 55, 'number_of_hidden_layers': 4, 'dropout_rate': 0.430552896515249, 'global_pooling': 'max', 'learning_rate': 0.00036455007493526996, 'weight_decay': 9.461610477998478e-05, 'beta_0': 0.8495253351984624, 'beta_1': 0.9951367774745259, 'epsilon': 3.123839862772377e-05, 'balanced_loss': False, 'epochs': 135, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 15:57:04,057] Trial 111 finished with value: 0.9261659883110323 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8508306116279221, 'batch_size': 36, 'attention_heads': 4, 'hidden_dimension': 60, 'number_of_hidden_layers': 4, 'dropout_rate': 0.417465295088407, 'global_pooling': 'sum', 'learning_rate': 0.0008437121425676963, 'weight_decay': 5.6235336589541564e-05, 'beta_0': 0.8362199694129565, 'beta_1': 0.9977285827302191, 'epsilon': 2.355145030971415e-05, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 13, 'plateau_patience': 14, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 924.69 MiB is free. Including non-PyTorch memory, this process has 43.65 GiB memory in use. Of the allocated memory 41.57 GiB is allocated by PyTorch, and 956.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 16:03:52,441] Trial 112 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.809576228965012, 'batch_size': 71, 'attention_heads': 5, 'hidden_dimension': 71, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4454467581539779, 'global_pooling': 'max', 'learning_rate': 0.00036375976856689015, 'weight_decay': 0.00018678717243450675, 'beta_0': 0.8442733745368182, 'beta_1': 0.9957277428002622, 'epsilon': 4.3016415619178846e-05, 'balanced_loss': False, 'epochs': 112, 'early_stopping_patience': 22, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 16:11:36,295] Trial 113 finished with value: 0.9481252418043247 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8273093240737086, 'batch_size': 64, 'attention_heads': 5, 'hidden_dimension': 44, 'number_of_hidden_layers': 0, 'dropout_rate': 0.39044964398215176, 'global_pooling': 'max', 'learning_rate': 0.0006120306136896399, 'weight_decay': 0.00013725105742731759, 'beta_0': 0.8597558820104848, 'beta_1': 0.9964962201160273, 'epsilon': 3.500501829402589e-05, 'balanced_loss': False, 'epochs': 99, 'early_stopping_patience': 22, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 16:28:31,690] Trial 114 finished with value: 0.9408161770734726 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8696181840226446, 'batch_size': 58, 'attention_heads': 6, 'hidden_dimension': 88, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3668969576399881, 'global_pooling': 'max', 'learning_rate': 0.0004702705750625018, 'weight_decay': 0.0002667620785774051, 'beta_0': 0.8572334837260018, 'beta_1': 0.9985933990682934, 'epsilon': 5.663052847805696e-05, 'balanced_loss': False, 'epochs': 93, 'early_stopping_patience': 21, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 2.08 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.19 GiB is free. Including non-PyTorch memory, this process has 43.36 GiB memory in use. Of the allocated memory 41.83 GiB is allocated by PyTorch, and 385.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 16:34:52,798] Trial 115 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.7861519379560281, 'batch_size': 78, 'attention_heads': 11, 'hidden_dimension': 81, 'number_of_hidden_layers': 4, 'dropout_rate': 0.40831640608071557, 'global_pooling': 'max', 'learning_rate': 0.0002781899029947819, 'weight_decay': 0.00010732209997194029, 'beta_0': 0.8528584673696736, 'beta_1': 0.9980153648250184, 'epsilon': 7.176230436883953e-05, 'balanced_loss': False, 'epochs': 128, 'early_stopping_patience': 22, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 894.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 460.69 MiB is free. Including non-PyTorch memory, this process has 44.10 GiB memory in use. Of the allocated memory 42.49 GiB is allocated by PyTorch, and 469.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 16:43:50,945] Trial 116 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7975873774722888, 'batch_size': 66, 'attention_heads': 6, 'hidden_dimension': 47, 'number_of_hidden_layers': 4, 'dropout_rate': 0.37443181871441106, 'global_pooling': 'max', 'learning_rate': 0.0012529341939376895, 'weight_decay': 0.0003647139372437763, 'beta_0': 0.8144251282546732, 'beta_1': 0.9975702777551932, 'epsilon': 8.660365374681661e-05, 'balanced_loss': False, 'epochs': 53, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
The selected strides are greater or equal to the total chunk size.
[I 2025-02-19 16:43:52,880] Trial 117 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.83843922120196, 'batch_size': 61, 'attention_heads': 4, 'hidden_dimension': 69, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3841506875092894, 'global_pooling': 'max', 'learning_rate': 0.0008045146995969798, 'weight_decay': 0.000473681402983729, 'beta_0': 0.8477024627021552, 'beta_1': 0.9971855330401088, 'epsilon': 5.543701602892214e-06, 'balanced_loss': False, 'epochs': 120, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 16:52:11,144] Trial 118 finished with value: 0.9511616112492205 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9112385880129716, 'batch_size': 72, 'attention_heads': 5, 'hidden_dimension': 39, 'number_of_hidden_layers': 2, 'dropout_rate': 0.36183597873779066, 'global_pooling': 'max', 'learning_rate': 0.0003720344226915488, 'weight_decay': 0.0005634502080141185, 'beta_0': 0.8416871892779233, 'beta_1': 0.9980975573307581, 'epsilon': 4.0977432722847e-05, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 22, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 17:00:20,674] Trial 119 finished with value: 0.9288698118099856 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9113116166419527, 'batch_size': 48, 'attention_heads': 5, 'hidden_dimension': 37, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3535961636928408, 'global_pooling': 'mean', 'learning_rate': 0.0002123438340143152, 'weight_decay': 0.0005418725095615001, 'beta_0': 0.8410381650126818, 'beta_1': 0.9986616760713373, 'epsilon': 8.020510323386456e-07, 'balanced_loss': False, 'epochs': 126, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 17:07:41,649] Trial 120 finished with value: 0.9278049235375153 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9411908761727245, 'batch_size': 102, 'attention_heads': 5, 'hidden_dimension': 54, 'number_of_hidden_layers': 2, 'dropout_rate': 0.34946400671480093, 'global_pooling': 'max', 'learning_rate': 0.0015088374239343254, 'weight_decay': 0.0006785760651066595, 'beta_0': 0.8340746103152719, 'beta_1': 0.9981131192386633, 'epsilon': 2.2611033267426262e-06, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 15, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 17:16:44,671] Trial 121 finished with value: 0.9337418674725777 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9204052539821128, 'batch_size': 81, 'attention_heads': 4, 'hidden_dimension': 32, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3971315187105466, 'global_pooling': 'max', 'learning_rate': 0.00035470706321968817, 'weight_decay': 0.0003054168645264454, 'beta_0': 0.8442619432030037, 'beta_1': 0.9989460082882325, 'epsilon': 3.593983030970339e-08, 'balanced_loss': False, 'epochs': 144, 'early_stopping_patience': 11, 'plateau_patience': 16, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 17:25:12,362] Trial 122 finished with value: 0.9398032064797093 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8948353213194356, 'batch_size': 71, 'attention_heads': 5, 'hidden_dimension': 42, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3651512417117755, 'global_pooling': 'max', 'learning_rate': 0.00044941380468104474, 'weight_decay': 0.0004439685555405586, 'beta_0': 0.8372323412492686, 'beta_1': 0.9969639761125871, 'epsilon': 4.433111980119415e-05, 'balanced_loss': False, 'epochs': 105, 'early_stopping_patience': 22, 'plateau_patience': 21, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 17:35:06,878] Trial 123 finished with value: 0.9385682122729594 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8833440365351836, 'batch_size': 53, 'attention_heads': 6, 'hidden_dimension': 62, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3618840128526416, 'global_pooling': 'max', 'learning_rate': 0.000547231831505257, 'weight_decay': 0.00021831393814483196, 'beta_0': 0.8310716787877415, 'beta_1': 0.9983199143192222, 'epsilon': 3.635267577106866e-05, 'balanced_loss': False, 'epochs': 170, 'early_stopping_patience': 23, 'plateau_patience': 14, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 17:46:00,026] Trial 124 finished with value: 0.9494056795719237 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.856889174838681, 'batch_size': 42, 'attention_heads': 6, 'hidden_dimension': 76, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3888544415918247, 'global_pooling': 'max', 'learning_rate': 0.0010823782484812982, 'weight_decay': 0.00035367071740730977, 'beta_0': 0.8504186540136237, 'beta_1': 0.9960290434504488, 'epsilon': 5.107328180194445e-05, 'balanced_loss': False, 'epochs': 118, 'early_stopping_patience': 22, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 17:55:55,379] Trial 125 finished with value: 0.9455098511428225 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.910428402266575, 'batch_size': 74, 'attention_heads': 5, 'hidden_dimension': 48, 'number_of_hidden_layers': 4, 'dropout_rate': 0.32576992693953044, 'global_pooling': 'max', 'learning_rate': 0.0003856528894517473, 'weight_decay': 0.0005559549101689054, 'beta_0': 0.8401891766432986, 'beta_1': 0.997816430126177, 'epsilon': 2.6488089952862112e-05, 'balanced_loss': False, 'epochs': 50, 'early_stopping_patience': 21, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 18:09:39,641] Trial 126 finished with value: 0.9331979805703037 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9012407133839452, 'batch_size': 59, 'attention_heads': 8, 'hidden_dimension': 38, 'number_of_hidden_layers': 4, 'dropout_rate': 0.37407207752694693, 'global_pooling': 'max', 'learning_rate': 0.00010151332981547815, 'weight_decay': 0.0002557363182741616, 'beta_0': 0.8586045926427881, 'beta_1': 0.997363139188736, 'epsilon': 6.818347422881147e-05, 'balanced_loss': False, 'epochs': 111, 'early_stopping_patience': 23, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacity of 44.56 GiB of which 254.69 MiB is free. Including non-PyTorch memory, this process has 44.30 GiB memory in use. Of the allocated memory 42.64 GiB is allocated by PyTorch, and 528.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 18:15:55,719] Trial 127 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8127185325181091, 'batch_size': 65, 'attention_heads': 4, 'hidden_dimension': 222, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5713535641024666, 'global_pooling': 'max', 'learning_rate': 0.0002534788779166377, 'weight_decay': 0.00018138416886008903, 'beta_0': 0.8277300666939974, 'beta_1': 0.9965252542806619, 'epsilon': 1.7026513970698906e-05, 'balanced_loss': True, 'epochs': 134, 'early_stopping_patience': 22, 'plateau_patience': 16, 'plateau_divider': 6}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 18:30:33,584] Trial 128 finished with value: 0.9555033499479924 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8484467457290026, 'batch_size': 69, 'attention_heads': 7, 'hidden_dimension': 58, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4010224117679768, 'global_pooling': 'max', 'learning_rate': 0.0003184207344418881, 'weight_decay': 1.943362282986019e-05, 'beta_0': 0.8836367550399516, 'beta_1': 0.9947401093579326, 'epsilon': 4.133320323618649e-05, 'balanced_loss': False, 'epochs': 55, 'early_stopping_patience': 23, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.09 GiB is free. Including non-PyTorch memory, this process has 42.46 GiB memory in use. Of the allocated memory 38.66 GiB is allocated by PyTorch, and 2.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 18:37:04,756] Trial 129 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8480590692779444, 'batch_size': 77, 'attention_heads': 7, 'hidden_dimension': 164, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40153681411600034, 'global_pooling': 'max', 'learning_rate': 0.000315445758941686, 'weight_decay': 1.4004958125418983e-05, 'beta_0': 0.8852880111765054, 'beta_1': 0.9940996792974961, 'epsilon': 2.3696124060775214e-05, 'balanced_loss': False, 'epochs': 152, 'early_stopping_patience': 24, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
CUDA out of memory. Tried to allocate 2.24 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.79 GiB is free. Including non-PyTorch memory, this process has 42.76 GiB memory in use. Of the allocated memory 41.02 GiB is allocated by PyTorch, and 606.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-19 18:43:21,810] Trial 130 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8234451239365101, 'batch_size': 84, 'attention_heads': 7, 'hidden_dimension': 153, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41577738984592955, 'global_pooling': 'max', 'learning_rate': 0.00014255006794241197, 'weight_decay': 2.0673554869033553e-05, 'beta_0': 0.8829959961130754, 'beta_1': 0.994760467390205, 'epsilon': 1.0160419818666346e-05, 'balanced_loss': False, 'epochs': 53, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 18:52:04,710] Trial 131 finished with value: 0.9462242134343237 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7682382471515864, 'batch_size': 69, 'attention_heads': 7, 'hidden_dimension': 53, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3809055273834813, 'global_pooling': 'max', 'learning_rate': 0.0006400301939647472, 'weight_decay': 1.591980325846444e-05, 'beta_0': 0.8536591025987567, 'beta_1': 0.9930655911016589, 'epsilon': 1.0592218827507921e-08, 'balanced_loss': False, 'epochs': 60, 'early_stopping_patience': 23, 'plateau_patience': 13, 'plateau_divider': 7}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 19:10:10,798] Trial 132 finished with value: 0.9474689003563146 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8341176608297033, 'batch_size': 61, 'attention_heads': 6, 'hidden_dimension': 59, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5955246397791231, 'global_pooling': 'max', 'learning_rate': 0.00044137206005296747, 'weight_decay': 2.822893652305309e-05, 'beta_0': 0.8786850885219756, 'beta_1': 0.9954610579248291, 'epsilon': 4.344481822921187e-05, 'balanced_loss': False, 'epochs': 57, 'early_stopping_patience': 22, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 19:21:38,489] Trial 133 finished with value: 0.9501912126084316 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8742902961926795, 'batch_size': 55, 'attention_heads': 5, 'hidden_dimension': 64, 'number_of_hidden_layers': 4, 'dropout_rate': 0.40899142695501645, 'global_pooling': 'max', 'learning_rate': 0.0005155467360717735, 'weight_decay': 0.00041542669706980156, 'beta_0': 0.8621638887079555, 'beta_1': 0.9943529441302542, 'epsilon': 3.2071117052617e-05, 'balanced_loss': False, 'epochs': 183, 'early_stopping_patience': 22, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
[I 2025-02-19 19:38:01,185] Trial 134 finished with value: 0.9411351559568801 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8770401219668924, 'batch_size': 55, 'attention_heads': 8, 'hidden_dimension': 65, 'number_of_hidden_layers': 4, 'dropout_rate': 0.408569386943305, 'global_pooling': 'max', 'learning_rate': 0.0005245938871661496, 'weight_decay': 0.0007441368848958007, 'beta_0': 0.8641510647020628, 'beta_1': 0.9934975486419442, 'epsilon': 5.575604357082137e-05, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 23, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 22 with value: 0.9581019307014222.
slurmstepd: error: *** JOB 14938999 ON gpu003 CANCELLED AT 2025-02-19T19:45:27 DUE TO TIME LIMIT ***
