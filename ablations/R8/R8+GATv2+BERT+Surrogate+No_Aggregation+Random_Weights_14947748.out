[I 2025-02-20 22:28:29,160] Using an existing study with name 'R8-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-Random_Weights-0.0-0.0' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors
[I 2025-02-20 22:37:56,505] Trial 286 finished with value: 0.9473870093906092 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7946247125937629, 'batch_size': 111, 'attention_heads': 5, 'hidden_dimension': 63, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5061397796283508, 'global_pooling': 'max', 'learning_rate': 0.002162057148420792, 'weight_decay': 5.044853138403894e-05, 'beta_0': 0.8303359706453954, 'beta_1': 0.9848351273041035, 'epsilon': 1.900122696063707e-05, 'balanced_loss': True, 'epochs': 81, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-20 22:46:38,768] Trial 287 finished with value: 0.9398096607846816 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8007038210045601, 'batch_size': 105, 'attention_heads': 4, 'hidden_dimension': 56, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5246447415772895, 'global_pooling': 'mean', 'learning_rate': 0.002630406567317863, 'weight_decay': 4.830592283772963e-05, 'beta_0': 0.8311596479314091, 'beta_1': 0.9836811086480114, 'epsilon': 2.0349713534469538e-05, 'balanced_loss': True, 'epochs': 87, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-20 22:56:57,179] Trial 288 finished with value: 0.943601477643426 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.776642202549367, 'batch_size': 101, 'attention_heads': 5, 'hidden_dimension': 61, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5157260788804118, 'global_pooling': 'max', 'learning_rate': 0.002014686054365883, 'weight_decay': 5.451347991522981e-05, 'beta_0': 0.8286748043584649, 'beta_1': 0.9844805907037701, 'epsilon': 1.3577029804690848e-05, 'balanced_loss': True, 'epochs': 97, 'early_stopping_patience': 15, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-20 23:05:06,229] Trial 289 finished with value: 0.9352708397511234 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7888426238536452, 'batch_size': 97, 'attention_heads': 5, 'hidden_dimension': 50, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5054094135211308, 'global_pooling': 'max', 'learning_rate': 0.0039954152369951505, 'weight_decay': 6.636422608524622e-05, 'beta_0': 0.8318347364988462, 'beta_1': 0.983448796037551, 'epsilon': 1.687727656832722e-05, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 16, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-20 23:14:29,218] Trial 290 finished with value: 0.9555978368625347 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7855894865181235, 'batch_size': 110, 'attention_heads': 5, 'hidden_dimension': 56, 'number_of_hidden_layers': 1, 'dropout_rate': 0.50187825674516, 'global_pooling': 'max', 'learning_rate': 0.003106262875866564, 'weight_decay': 7.117958040022258e-05, 'beta_0': 0.8254324346542132, 'beta_1': 0.9837928534226327, 'epsilon': 2.1330364281521825e-05, 'balanced_loss': True, 'epochs': 93, 'early_stopping_patience': 22, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-20 23:24:10,826] Trial 291 finished with value: 0.9520535716660508 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7824697786239749, 'batch_size': 108, 'attention_heads': 5, 'hidden_dimension': 57, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5026807803630334, 'global_pooling': 'max', 'learning_rate': 0.0034103298496111468, 'weight_decay': 6.190870993653108e-05, 'beta_0': 0.8272102604888273, 'beta_1': 0.9836927692578664, 'epsilon': 2.4238835275839713e-05, 'balanced_loss': True, 'epochs': 94, 'early_stopping_patience': 21, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-20 23:34:02,228] Trial 292 finished with value: 0.9364443125386157 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.8068905918826514, 'batch_size': 103, 'attention_heads': 4, 'hidden_dimension': 52, 'number_of_hidden_layers': 1, 'dropout_rate': 0.49457679656545467, 'global_pooling': 'max', 'learning_rate': 0.002433168833702676, 'weight_decay': 7.322869435189457e-05, 'beta_0': 0.8343214833188934, 'beta_1': 0.9841518547333575, 'epsilon': 1.9710317368778697e-05, 'balanced_loss': True, 'epochs': 91, 'early_stopping_patience': 22, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-20 23:46:59,247] Trial 293 finished with value: 0.9487553479872515 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7848809697535866, 'batch_size': 112, 'attention_heads': 5, 'hidden_dimension': 61, 'number_of_hidden_layers': 1, 'dropout_rate': 0.50832887599105, 'global_pooling': 'max', 'learning_rate': 0.002978958179599663, 'weight_decay': 9.77063958433665e-05, 'beta_0': 0.8246757611091903, 'beta_1': 0.9829990538924883, 'epsilon': 2.285098497506468e-05, 'balanced_loss': True, 'epochs': 94, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-20 23:57:25,799] Trial 294 finished with value: 0.9464926172335835 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7930324743927297, 'batch_size': 108, 'attention_heads': 5, 'hidden_dimension': 54, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5180923727264846, 'global_pooling': 'max', 'learning_rate': 0.004444316091951049, 'weight_decay': 6.328660148552118e-05, 'beta_0': 0.8303413648908893, 'beta_1': 0.9839319392019288, 'epsilon': 2.8470005074640452e-05, 'balanced_loss': True, 'epochs': 99, 'early_stopping_patience': 22, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 00:06:03,859] Trial 295 finished with value: 0.9433838288621776 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7745204926449678, 'batch_size': 95, 'attention_heads': 5, 'hidden_dimension': 45, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5008816676790033, 'global_pooling': 'max', 'learning_rate': 0.0025413767783327903, 'weight_decay': 6.058035803692001e-05, 'beta_0': 0.8252742441120084, 'beta_1': 0.9834198009339259, 'epsilon': 2.5658640827692523e-05, 'balanced_loss': True, 'epochs': 92, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 00:16:17,867] Trial 296 finished with value: 0.9558068143370142 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7977860663031539, 'batch_size': 99, 'attention_heads': 5, 'hidden_dimension': 65, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5013330516996292, 'global_pooling': 'mean', 'learning_rate': 0.0020715968101365652, 'weight_decay': 4.338723677350277e-05, 'beta_0': 0.822224914622008, 'beta_1': 0.9827997593867575, 'epsilon': 2.0206867856340153e-05, 'balanced_loss': True, 'epochs': 88, 'early_stopping_patience': 24, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
CUDA out of memory. Tried to allocate 1.79 GiB. GPU 0 has a total capacity of 44.56 GiB of which 866.69 MiB is free. Including non-PyTorch memory, this process has 43.71 GiB memory in use. Of the allocated memory 41.18 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 00:22:26,502] Trial 297 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.79862130583728, 'batch_size': 104, 'attention_heads': 5, 'hidden_dimension': 128, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5111153429764421, 'global_pooling': 'mean', 'learning_rate': 0.002937548541881943, 'weight_decay': 4.665411887286319e-05, 'beta_0': 0.8181690416761559, 'beta_1': 0.9828045038034154, 'epsilon': 2.033315614033146e-05, 'balanced_loss': True, 'epochs': 86, 'early_stopping_patience': 24, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 00:32:27,509] Trial 298 finished with value: 0.9537342200734021 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8031353648631191, 'batch_size': 98, 'attention_heads': 5, 'hidden_dimension': 65, 'number_of_hidden_layers': 1, 'dropout_rate': 0.49906738059796707, 'global_pooling': 'mean', 'learning_rate': 0.002203795463768059, 'weight_decay': 4.2381309550026074e-05, 'beta_0': 0.8210534482920994, 'beta_1': 0.9832466666640369, 'epsilon': 1.741093509474818e-05, 'balanced_loss': True, 'epochs': 89, 'early_stopping_patience': 24, 'plateau_patience': 14, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 00:41:23,622] Trial 299 finished with value: 0.9415091567489056 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.784390463976746, 'batch_size': 40, 'attention_heads': 4, 'hidden_dimension': 61, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5073482603207703, 'global_pooling': 'mean', 'learning_rate': 0.0018777974293114493, 'weight_decay': 5.121011680274621e-05, 'beta_0': 0.8206297690494649, 'beta_1': 0.9846875305254011, 'epsilon': 2.1224206070380227e-05, 'balanced_loss': True, 'epochs': 83, 'early_stopping_patience': 24, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 00:49:56,674] Trial 300 finished with value: 0.9447262125797526 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7776847351143481, 'batch_size': 96, 'attention_heads': 5, 'hidden_dimension': 49, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4915050659778227, 'global_pooling': 'mean', 'learning_rate': 0.0034259581884446676, 'weight_decay': 7.028551141627299e-05, 'beta_0': 0.8230601994636395, 'beta_1': 0.9826757421656014, 'epsilon': 1.6730806809334684e-05, 'balanced_loss': True, 'epochs': 94, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 00:59:44,957] Trial 301 finished with value: 0.9505290574272561 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7920937031497587, 'batch_size': 50, 'attention_heads': 5, 'hidden_dimension': 66, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5002152660422375, 'global_pooling': 'mean', 'learning_rate': 0.001825633875110082, 'weight_decay': 5.596979613377856e-05, 'beta_0': 0.8344770205833089, 'beta_1': 0.9837091312744539, 'epsilon': 2.4228302439197945e-05, 'balanced_loss': True, 'epochs': 89, 'early_stopping_patience': 25, 'plateau_patience': 10, 'plateau_divider': 9}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 01:08:37,130] Trial 302 finished with value: 0.9507218902106398 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7880308600631748, 'batch_size': 44, 'attention_heads': 5, 'hidden_dimension': 57, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4870834084935775, 'global_pooling': 'mean', 'learning_rate': 0.0022498113951368768, 'weight_decay': 4.444844399803642e-05, 'beta_0': 0.8264943567379585, 'beta_1': 0.9841049579254673, 'epsilon': 1.2994784065253657e-05, 'balanced_loss': True, 'epochs': 99, 'early_stopping_patience': 24, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 01:16:46,063] Trial 303 finished with value: 0.938262859742619 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8082868036175028, 'batch_size': 117, 'attention_heads': 5, 'hidden_dimension': 61, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5102664884571734, 'global_pooling': 'mean', 'learning_rate': 0.0017754837304125887, 'weight_decay': 3.9848920218836605e-05, 'beta_0': 0.8288050742774455, 'beta_1': 0.9829934634753069, 'epsilon': 2.127916531603357e-05, 'balanced_loss': True, 'epochs': 76, 'early_stopping_patience': 16, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 01:28:02,366] Trial 304 finished with value: 0.945396781547731 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7983070582699296, 'batch_size': 101, 'attention_heads': 5, 'hidden_dimension': 53, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4823711641894486, 'global_pooling': 'max', 'learning_rate': 0.00259979749619453, 'weight_decay': 0.0008538144782744095, 'beta_0': 0.8361369357794394, 'beta_1': 0.9834918607988937, 'epsilon': 1.8298113349881144e-05, 'balanced_loss': True, 'epochs': 97, 'early_stopping_patience': 25, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 01:37:29,207] Trial 305 finished with value: 0.9531363609393604 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7806405172792249, 'batch_size': 107, 'attention_heads': 4, 'hidden_dimension': 66, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4908571838076378, 'global_pooling': 'max', 'learning_rate': 0.004614085251424803, 'weight_decay': 4.705686772229174e-05, 'beta_0': 0.8323719013867933, 'beta_1': 0.982637481429321, 'epsilon': 2.8081188717163747e-05, 'balanced_loss': True, 'epochs': 106, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 3}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 01:47:28,051] Trial 306 finished with value: 0.9490506599995292 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7704998644430608, 'batch_size': 88, 'attention_heads': 5, 'hidden_dimension': 58, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5028896101134324, 'global_pooling': 'max', 'learning_rate': 0.0035391818506974484, 'weight_decay': 5.491990409757063e-05, 'beta_0': 0.8228042530754016, 'beta_1': 0.9832515584612209, 'epsilon': 2.4537542443505775e-05, 'balanced_loss': True, 'epochs': 103, 'early_stopping_patience': 25, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 01:58:17,611] Trial 307 finished with value: 0.9426451778025857 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7926043623081409, 'batch_size': 49, 'attention_heads': 6, 'hidden_dimension': 63, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5195764812442853, 'global_pooling': 'max', 'learning_rate': 0.002002322383489597, 'weight_decay': 8.879354715857365e-05, 'beta_0': 0.8355887801879947, 'beta_1': 0.9842771869805348, 'epsilon': 1.5104529001060531e-05, 'balanced_loss': True, 'epochs': 84, 'early_stopping_patience': 17, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 02:07:21,520] Trial 308 finished with value: 0.9467463970399097 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7881106454422365, 'batch_size': 93, 'attention_heads': 5, 'hidden_dimension': 48, 'number_of_hidden_layers': 1, 'dropout_rate': 0.49847989513947705, 'global_pooling': 'max', 'learning_rate': 0.0016040758953552933, 'weight_decay': 6.415409145318351e-05, 'beta_0': 0.829772333998677, 'beta_1': 0.985149102270723, 'epsilon': 1.804903655826362e-05, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 24, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 275 with value: 0.9656322221957822.
CUDA out of memory. Tried to allocate 1.46 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.13 GiB is free. Including non-PyTorch memory, this process has 43.43 GiB memory in use. Of the allocated memory 41.10 GiB is allocated by PyTorch, and 1.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 02:13:37,896] Trial 309 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7795041124758245, 'batch_size': 99, 'attention_heads': 7, 'hidden_dimension': 57, 'number_of_hidden_layers': 1, 'dropout_rate': 0.48066762563985493, 'global_pooling': 'max', 'learning_rate': 0.0023407661548718013, 'weight_decay': 0.0002080503663887869, 'beta_0': 0.8335522802670611, 'beta_1': 0.9837654576723828, 'epsilon': 3.2397896349067095e-05, 'balanced_loss': True, 'epochs': 90, 'early_stopping_patience': 22, 'plateau_patience': 11, 'plateau_divider': 10}. Best is trial 275 with value: 0.9656322221957822.
CUDA out of memory. Tried to allocate 1.70 GiB. GPU 0 has a total capacity of 44.56 GiB of which 892.69 MiB is free. Including non-PyTorch memory, this process has 43.68 GiB memory in use. Of the allocated memory 41.02 GiB is allocated by PyTorch, and 1.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 02:19:41,006] Trial 310 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8015403438683573, 'batch_size': 111, 'attention_heads': 8, 'hidden_dimension': 69, 'number_of_hidden_layers': 1, 'dropout_rate': 0.490864893088685, 'global_pooling': 'mean', 'learning_rate': 0.003048488102207125, 'weight_decay': 0.00028699904851449225, 'beta_0': 0.8374666949265492, 'beta_1': 0.9832822219171252, 'epsilon': 9.861346131238787e-05, 'balanced_loss': True, 'epochs': 93, 'early_stopping_patience': 25, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 02:28:25,987] Trial 311 finished with value: 0.9283356825930068 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8146312060055001, 'batch_size': 54, 'attention_heads': 6, 'hidden_dimension': 52, 'number_of_hidden_layers': 1, 'dropout_rate': 0.48616505414585515, 'global_pooling': 'max', 'learning_rate': 0.005381571591325451, 'weight_decay': 4.031512726123543e-05, 'beta_0': 0.8813796643166926, 'beta_1': 0.9829613979699942, 'epsilon': 2.1196146172501337e-05, 'balanced_loss': True, 'epochs': 96, 'early_stopping_patience': 21, 'plateau_patience': 11, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 02:38:12,338] Trial 312 finished with value: 0.9337360493009942 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7686487158276794, 'batch_size': 40, 'attention_heads': 5, 'hidden_dimension': 65, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4772104936651319, 'global_pooling': 'max', 'learning_rate': 0.001289387011606908, 'weight_decay': 6.007134482578597e-05, 'beta_0': 0.8353311370199, 'beta_1': 0.9845457037758446, 'epsilon': 2.653033805587645e-05, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 5}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 02:47:26,056] Trial 313 finished with value: 0.940095718651696 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7951420669044014, 'batch_size': 43, 'attention_heads': 5, 'hidden_dimension': 59, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4713954616383331, 'global_pooling': 'max', 'learning_rate': 0.0016579371710937325, 'weight_decay': 4.565060580652444e-05, 'beta_0': 0.8312891073490025, 'beta_1': 0.9825620438348822, 'epsilon': 1.28580398697203e-05, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 24, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 02:57:06,247] Trial 314 finished with value: 0.9613718042653205 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7862545197062983, 'batch_size': 104, 'attention_heads': 6, 'hidden_dimension': 54, 'number_of_hidden_layers': 1, 'dropout_rate': 0.483309037236963, 'global_pooling': 'max', 'learning_rate': 0.0027710721622963173, 'weight_decay': 3.3149584524899616e-06, 'beta_0': 0.8246409491914808, 'beta_1': 0.9838294405697342, 'epsilon': 1.6057367271229937e-05, 'balanced_loss': True, 'epochs': 91, 'early_stopping_patience': 23, 'plateau_patience': 11, 'plateau_divider': 3}. Best is trial 275 with value: 0.9656322221957822.
CUDA out of memory. Tried to allocate 740.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 66.69 MiB is free. Including non-PyTorch memory, this process has 44.49 GiB memory in use. Of the allocated memory 39.99 GiB is allocated by PyTorch, and 3.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 03:05:35,910] Trial 315 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7759532630423286, 'batch_size': 107, 'attention_heads': 4, 'hidden_dimension': 49, 'number_of_hidden_layers': 3, 'dropout_rate': 0.478601163334934, 'global_pooling': 'max', 'learning_rate': 0.0038297684111000133, 'weight_decay': 2.3080350526693384e-06, 'beta_0': 0.8268729035752268, 'beta_1': 0.9838561938397063, 'epsilon': 1.5855961807985062e-05, 'balanced_loss': True, 'epochs': 90, 'early_stopping_patience': 23, 'plateau_patience': 11, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 03:15:12,594] Trial 316 finished with value: 0.9470500363158665 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7834699114065137, 'batch_size': 102, 'attention_heads': 6, 'hidden_dimension': 44, 'number_of_hidden_layers': 1, 'dropout_rate': 0.48375157999858753, 'global_pooling': 'max', 'learning_rate': 0.0027482367411521815, 'weight_decay': 2.9549260847783606e-06, 'beta_0': 0.8245973409711811, 'beta_1': 0.9834770607505396, 'epsilon': 1.0031253416968832e-05, 'balanced_loss': True, 'epochs': 95, 'early_stopping_patience': 23, 'plateau_patience': 11, 'plateau_divider': 3}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 03:23:40,624] Trial 317 finished with value: 0.9460556689608499 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.810123961860912, 'batch_size': 94, 'attention_heads': 6, 'hidden_dimension': 72, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4729724913802927, 'global_pooling': 'max', 'learning_rate': 0.002294838247763177, 'weight_decay': 3.832921835221603e-05, 'beta_0': 0.8200247309396891, 'beta_1': 0.9841183849258733, 'epsilon': 1.2911047746628768e-05, 'balanced_loss': True, 'epochs': 85, 'early_stopping_patience': 15, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 275 with value: 0.9656322221957822.
CUDA out of memory. Tried to allocate 1.83 GiB. GPU 0 has a total capacity of 44.56 GiB of which 676.69 MiB is free. Including non-PyTorch memory, this process has 43.89 GiB memory in use. Of the allocated memory 41.56 GiB is allocated by PyTorch, and 1.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 03:29:48,835] Trial 318 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7861699993518084, 'batch_size': 103, 'attention_heads': 7, 'hidden_dimension': 67, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4866671468078351, 'global_pooling': 'mean', 'learning_rate': 0.003169283042593557, 'weight_decay': 1.783586312220415e-06, 'beta_0': 0.8293206282013711, 'beta_1': 0.9829480648951475, 'epsilon': 8.291858260551992e-05, 'balanced_loss': True, 'epochs': 91, 'early_stopping_patience': 23, 'plateau_patience': 12, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 03:40:58,809] Trial 319 finished with value: 0.9428935601054331 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7958978183440375, 'batch_size': 96, 'attention_heads': 5, 'hidden_dimension': 54, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5139576197845862, 'global_pooling': 'max', 'learning_rate': 0.001986160479980736, 'weight_decay': 5.289485153470786e-05, 'beta_0': 0.823339198180549, 'beta_1': 0.9823941604654235, 'epsilon': 3.913084398447586e-05, 'balanced_loss': True, 'epochs': 87, 'early_stopping_patience': 24, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 275 with value: 0.9656322221957822.
CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 44.56 GiB of which 464.69 MiB is free. Including non-PyTorch memory, this process has 44.10 GiB memory in use. Of the allocated memory 41.84 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 03:46:54,599] Trial 320 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7727466181415402, 'batch_size': 111, 'attention_heads': 6, 'hidden_dimension': 62, 'number_of_hidden_layers': 1, 'dropout_rate': 0.47839529708538964, 'global_pooling': 'max', 'learning_rate': 0.002672470362853374, 'weight_decay': 7.260423360338024e-05, 'beta_0': 0.8221645888365122, 'beta_1': 0.9839231788753782, 'epsilon': 2.2781292007048625e-05, 'balanced_loss': True, 'epochs': 101, 'early_stopping_patience': 25, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 03:56:56,612] Trial 321 finished with value: 0.9302306166056445 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7901771258019006, 'batch_size': 47, 'attention_heads': 5, 'hidden_dimension': 55, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4944081482324547, 'global_pooling': 'max', 'learning_rate': 0.004121515821634602, 'weight_decay': 1.0079559298069349e-06, 'beta_0': 0.8255976428252135, 'beta_1': 0.9833264151559645, 'epsilon': 2.9588095265406937e-05, 'balanced_loss': True, 'epochs': 81, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
CUDA out of memory. Tried to allocate 1.72 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 43.33 GiB memory in use. Of the allocated memory 40.32 GiB is allocated by PyTorch, and 1.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 04:03:02,754] Trial 322 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8030953756196011, 'batch_size': 105, 'attention_heads': 5, 'hidden_dimension': 123, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4815075771880489, 'global_pooling': 'max', 'learning_rate': 0.0022692539390257406, 'weight_decay': 1.5194975661027047e-06, 'beta_0': 0.83325013507653, 'beta_1': 0.9836588613414057, 'epsilon': 1.7122880288143655e-05, 'balanced_loss': True, 'epochs': 198, 'early_stopping_patience': 10, 'plateau_patience': 10, 'plateau_divider': 6}. Best is trial 275 with value: 0.9656322221957822.
CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacity of 44.56 GiB of which 458.69 MiB is free. Including non-PyTorch memory, this process has 44.11 GiB memory in use. Of the allocated memory 42.58 GiB is allocated by PyTorch, and 385.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 04:09:06,485] Trial 323 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7622454562483606, 'batch_size': 91, 'attention_heads': 7, 'hidden_dimension': 70, 'number_of_hidden_layers': 1, 'dropout_rate': 0.47170545861798135, 'global_pooling': 'max', 'learning_rate': 0.001712431662966785, 'weight_decay': 2.8969372750054667e-06, 'beta_0': 0.816154024617108, 'beta_1': 0.9829190935875842, 'epsilon': 1.93239401763316e-05, 'balanced_loss': True, 'epochs': 195, 'early_stopping_patience': 24, 'plateau_patience': 11, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
CUDA out of memory. Tried to allocate 1.44 GiB. GPU 0 has a total capacity of 44.56 GiB of which 872.69 MiB is free. Including non-PyTorch memory, this process has 43.70 GiB memory in use. Of the allocated memory 41.43 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-21 04:15:24,522] Trial 324 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7813896948108854, 'batch_size': 100, 'attention_heads': 6, 'hidden_dimension': 59, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5043037227487843, 'global_pooling': 'max', 'learning_rate': 0.0063117853452753945, 'weight_decay': 0.0002237374457178827, 'beta_0': 0.8384053224354735, 'beta_1': 0.9842776891544527, 'epsilon': 1.5190141910880637e-05, 'balanced_loss': True, 'epochs': 71, 'early_stopping_patience': 25, 'plateau_patience': 12, 'plateau_divider': 3}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 04:23:56,169] Trial 325 finished with value: 0.9480134732519618 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.775355579786772, 'batch_size': 36, 'attention_heads': 5, 'hidden_dimension': 50, 'number_of_hidden_layers': 1, 'dropout_rate': 0.48951939067092254, 'global_pooling': 'mean', 'learning_rate': 0.003138422263870924, 'weight_decay': 3.1935347626299995e-06, 'beta_0': 0.836891664232982, 'beta_1': 0.9824720870441226, 'epsilon': 2.5306256385673117e-05, 'balanced_loss': True, 'epochs': 93, 'early_stopping_patience': 22, 'plateau_patience': 11, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 04:32:37,461] Trial 326 finished with value: 0.9481317694597536 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7856152198878269, 'batch_size': 52, 'attention_heads': 4, 'hidden_dimension': 64, 'number_of_hidden_layers': 1, 'dropout_rate': 0.47430946519891365, 'global_pooling': 'max', 'learning_rate': 0.0014022159152662556, 'weight_decay': 4.5157578359604384e-05, 'beta_0': 0.8279633452167094, 'beta_1': 0.9834538654557433, 'epsilon': 3.244186890800222e-05, 'balanced_loss': True, 'epochs': 189, 'early_stopping_patience': 22, 'plateau_patience': 10, 'plateau_divider': 6}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 04:43:10,793] Trial 327 finished with value: 0.9556638308331209 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8317434080281222, 'batch_size': 98, 'attention_heads': 6, 'hidden_dimension': 73, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4963897396367712, 'global_pooling': 'max', 'learning_rate': 0.0005023909318292852, 'weight_decay': 3.075852610284756e-05, 'beta_0': 0.8310913099311618, 'beta_1': 0.983130940249673, 'epsilon': 2.2047230387049445e-05, 'balanced_loss': True, 'epochs': 197, 'early_stopping_patience': 23, 'plateau_patience': 11, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 04:57:09,696] Trial 328 finished with value: 0.9523868730077973 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8321425255368484, 'batch_size': 116, 'attention_heads': 6, 'hidden_dimension': 72, 'number_of_hidden_layers': 1, 'dropout_rate': 0.49811916918163224, 'global_pooling': 'max', 'learning_rate': 0.0003367042985910172, 'weight_decay': 3.719696543353445e-06, 'beta_0': 0.831328461570907, 'beta_1': 0.9827936365300535, 'epsilon': 1.9577087812821057e-05, 'balanced_loss': True, 'epochs': 196, 'early_stopping_patience': 23, 'plateau_patience': 15, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 05:09:26,023] Trial 329 finished with value: 0.9391248795036773 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.821130344895623, 'batch_size': 98, 'attention_heads': 6, 'hidden_dimension': 65, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4972287929579294, 'global_pooling': 'max', 'learning_rate': 0.0004498415989032346, 'weight_decay': 2.9713309705429855e-05, 'beta_0': 0.8291512243385579, 'beta_1': 0.9822426773742491, 'epsilon': 1.3985262057779406e-05, 'balanced_loss': True, 'epochs': 198, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 05:21:02,741] Trial 330 finished with value: 0.9483620465296381 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.818294241085619, 'batch_size': 106, 'attention_heads': 6, 'hidden_dimension': 61, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5087337376668252, 'global_pooling': 'max', 'learning_rate': 0.00039884578769735043, 'weight_decay': 3.605438526260962e-05, 'beta_0': 0.8332824618791335, 'beta_1': 0.9831636289221801, 'epsilon': 1.1941846464522196e-05, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 23, 'plateau_patience': 11, 'plateau_divider': 4}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 05:31:43,575] Trial 331 finished with value: 0.9586203014096366 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7950893160116648, 'batch_size': 54, 'attention_heads': 6, 'hidden_dimension': 70, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4662176549075393, 'global_pooling': 'max', 'learning_rate': 0.0005272851239947449, 'weight_decay': 2.986542487519086e-05, 'beta_0': 0.8311074364877751, 'beta_1': 0.9830115432043333, 'epsilon': 2.2299642693094427e-05, 'balanced_loss': True, 'epochs': 192, 'early_stopping_patience': 24, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 275 with value: 0.9656322221957822.
[I 2025-02-21 05:41:52,404] Trial 332 finished with value: 0.9499400133471263 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7990377018904871, 'batch_size': 46, 'attention_heads': 6, 'hidden_dimension': 67, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5041557163553287, 'global_pooling': 'max', 'learning_rate': 0.0005274157704704447, 'weight_decay': 3.2425723032853955e-05, 'beta_0': 0.8315214286158079, 'beta_1': 0.9838669903843404, 'epsilon': 1.8221403782471374e-05, 'balanced_loss': True, 'epochs': 190, 'early_stopping_patience': 24, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 275 with value: 0.9656322221957822.

[TRIAL] 275 [VALIDATION PERFORMANCE] 0.9656322221957822 [TRAINING LOSS] 0.031063333213197715 [VALIDATION LOSS] 0.16324398942473953 

number                                     275
value                                 0.965632
params_threshold                      0.783498
params_attention_heads                       5
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           48
params_dropout_rate                   0.488092
params_early_stopping_patience              14
params_epochs                              192
params_global_pooling                      max
params_hidden_dimension                     57
params_learning_rate                  0.001139
params_number_of_hidden_layers               1
params_plateau_divider                       4
params_plateau_patience                     10
params_weight_decay                   0.000047
params_beta_0                         0.836494
params_beta_1                         0.983377
params_epsilon                        0.000027
user_attrs_epoch                          19.0
user_attrs_training_loss              0.031063
user_attrs_validation_loss            0.163244
params_left_stride                          32
params_right_stride                         32
Name: 275, dtype: object
37 Val: 0.9480689973537831 Test: 0.9410064190575502
38 Val: 0.9472698620058985 Test: 0.9364580923455514
39 Val: 0.9504934502598044 Test: 0.9443215354537234
40 Val: 0.9525592895802333 Test: 0.9451357922105362
41 Val: 0.9384335962450083 Test: 0.9467902889240376
42 Val: 0.9528901390414883 Test: 0.9273788722854638
43 Val: 0.9558094286615705 Test: 0.9315712380454976
44 Val: 0.9536501145177387 Test: 0.9465415090851682
45 Val: 0.9566753191695362 Test: 0.9526629556829733
46 Val: 0.9516149288129088 Test: 0.9528864851908515
Validation performance: 93.84 & 95.07 ± 0.53 & 95.67
Testing performance: 92.74 & 94.25 ± 0.85 & 95.29

[TRIAL] 165 [VALIDATION PERFORMANCE] 0.9646181545012297 [TRAINING LOSS] 0.03016883973674451 [VALIDATION LOSS] 0.17013449168298395 

number                                     165
value                                 0.964618
params_threshold                      0.783399
params_attention_heads                       5
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           45
params_dropout_rate                   0.478308
params_early_stopping_patience              24
params_epochs                               52
params_global_pooling                      max
params_hidden_dimension                     60
params_learning_rate                   0.00141
params_number_of_hidden_layers               1
params_plateau_divider                       6
params_plateau_patience                     11
params_weight_decay                   0.000759
params_beta_0                         0.833909
params_beta_1                         0.983183
params_epsilon                        0.000017
user_attrs_epoch                          19.0
user_attrs_training_loss              0.030169
user_attrs_validation_loss            0.170134
params_left_stride                           0
params_right_stride                         32
Name: 165, dtype: object
37 Val: 0.94704472481922 Test: 0.9426149696235275
38 Val: 0.9461324124464041 Test: 0.9552724848066684
39 Val: 0.952965135230073 Test: 0.9479088507812623
40 Val: 0.9415871649670069 Test: 0.9447463322975976
41 Val: 0.947819921591394 Test: 0.9388616310158121
42 Val: 0.9506417270625586 Test: 0.9458007836696443
43 Val: 0.9589758726306825 Test: 0.9427978380810695
44 Val: 0.945362336542299 Test: 0.9514290523170466
45 Val: 0.9522804369590349 Test: 0.946357214414398
46 Val: 0.9459572385292145 Test: 0.9167506977906206
Validation performance: 94.16 & 94.89 ± 0.49 & 95.9
Testing performance: 91.68 & 94.33 ± 1.04 & 95.53

[TRIAL] 154 [VALIDATION PERFORMANCE] 0.9618278280757855 [TRAINING LOSS] 0.037781199275658844 [VALIDATION LOSS] 0.14090811427343974 

number                                     154
value                                 0.961828
params_threshold                       0.84699
params_attention_heads                       5
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           50
params_dropout_rate                   0.505141
params_early_stopping_patience              25
params_epochs                              193
params_global_pooling                      max
params_hidden_dimension                     50
params_learning_rate                  0.001374
params_number_of_hidden_layers               1
params_plateau_divider                       5
params_plateau_patience                     10
params_weight_decay                   0.000351
params_beta_0                          0.83701
params_beta_1                         0.983567
params_epsilon                        0.000025
user_attrs_epoch                          20.0
user_attrs_training_loss              0.037781
user_attrs_validation_loss            0.140908
params_left_stride                           0
params_right_stride                        128
Name: 154, dtype: object
37 Val: 0.9418087620695688 Test: 0.9487015915773037
38 Val: 0.9314883099057607 Test: 0.9422854033859468
39 Val: 0.9469423449650726 Test: 0.9410947620278234
40 Val: 0.9513754931604614 Test: 0.9454235320430857
41 Val: 0.9486760296545722 Test: 0.9426812702968864
42 Val: 0.9451968295895561 Test: 0.9391069724001153
43 Val: 0.9489044691268554 Test: 0.9480474879529571
44 Val: 0.9533188731944058 Test: 0.9585980681170354
45 Val: 0.9408635227332005 Test: 0.9267731020492787
46 Val: 0.9378990978385149 Test: 0.9434034640394608
Validation performance: 93.15 & 94.46 ± 0.67 & 95.33
Testing performance: 92.68 & 94.36 ± 0.81 & 95.86

[TRIAL] 314 [VALIDATION PERFORMANCE] 0.9613718042653205 [TRAINING LOSS] 0.026447955035363582 [VALIDATION LOSS] 0.18203300373120743 

number                                     314
value                                 0.961372
params_threshold                      0.786255
params_attention_heads                       6
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                          104
params_dropout_rate                   0.483309
params_early_stopping_patience              23
params_epochs                               91
params_global_pooling                      max
params_hidden_dimension                     54
params_learning_rate                  0.002771
params_number_of_hidden_layers               1
params_plateau_divider                       3
params_plateau_patience                     11
params_weight_decay                   0.000003
params_beta_0                         0.824641
params_beta_1                         0.983829
params_epsilon                        0.000016
user_attrs_epoch                          24.0
user_attrs_training_loss              0.026448
user_attrs_validation_loss            0.182033
params_left_stride                           0
params_right_stride                         32
Name: 314, dtype: object
slurmstepd: error: *** JOB 14947748 ON gpu035 CANCELLED AT 2025-02-21T10:28:23 DUE TO TIME LIMIT ***
