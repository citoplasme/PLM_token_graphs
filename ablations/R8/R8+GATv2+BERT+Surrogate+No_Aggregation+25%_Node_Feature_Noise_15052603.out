[I 2025-02-27 18:49:48,356] Using an existing study with name 'R8-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-No_Ablation-1.0-0.25' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors
[I 2025-02-27 19:03:48,562] Trial 178 finished with value: 0.920000144417671 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8591843998091894, 'batch_size': 119, 'attention_heads': 5, 'hidden_dimension': 48, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5385555415304696, 'global_pooling': 'max', 'learning_rate': 0.0019049110999106232, 'weight_decay': 0.00027740064032891795, 'beta_0': 0.8738570673928853, 'beta_1': 0.9942893216610067, 'epsilon': 3.00814156008797e-08, 'balanced_loss': False, 'epochs': 131, 'early_stopping_patience': 24, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
CUDA out of memory. Tried to allocate 458.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 208.69 MiB is free. Including non-PyTorch memory, this process has 44.35 GiB memory in use. Of the allocated memory 42.87 GiB is allocated by PyTorch, and 333.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 19:11:11,669] Trial 179 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.6617547238682159, 'batch_size': 36, 'attention_heads': 4, 'hidden_dimension': 63, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4637628490485892, 'global_pooling': 'max', 'learning_rate': 0.0013602802955812335, 'weight_decay': 0.0003275672301770852, 'beta_0': 0.8452493582659651, 'beta_1': 0.9949450517685602, 'epsilon': 5.9253701500251084e-08, 'balanced_loss': False, 'epochs': 172, 'early_stopping_patience': 25, 'plateau_patience': 14, 'plateau_divider': 4}. Best is trial 14 with value: 0.9451449407066621.
CUDA out of memory. Tried to allocate 1.05 GiB. GPU 0 has a total capacity of 44.56 GiB of which 874.69 MiB is free. Including non-PyTorch memory, this process has 43.70 GiB memory in use. Of the allocated memory 42.06 GiB is allocated by PyTorch, and 496.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 19:17:41,741] Trial 180 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8320989734117393, 'batch_size': 171, 'attention_heads': 5, 'hidden_dimension': 45, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3496759555856476, 'global_pooling': 'mean', 'learning_rate': 0.0007540516064307746, 'weight_decay': 0.0006999082286345293, 'beta_0': 0.8829726132374565, 'beta_1': 0.9815018804913745, 'epsilon': 8.377331446902039e-06, 'balanced_loss': False, 'epochs': 85, 'early_stopping_patience': 22, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
CUDA out of memory. Tried to allocate 1.14 GiB. GPU 0 has a total capacity of 44.56 GiB of which 42.69 MiB is free. Including non-PyTorch memory, this process has 44.51 GiB memory in use. Of the allocated memory 41.93 GiB is allocated by PyTorch, and 1.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 19:25:04,384] Trial 181 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8266023428466747, 'batch_size': 56, 'attention_heads': 4, 'hidden_dimension': 201, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5515551765115503, 'global_pooling': 'max', 'learning_rate': 0.0009569822745077256, 'weight_decay': 0.0004287295784994719, 'beta_0': 0.8648238742786226, 'beta_1': 0.9842967991745736, 'epsilon': 1.7499986076076176e-05, 'balanced_loss': False, 'epochs': 88, 'early_stopping_patience': 21, 'plateau_patience': 14, 'plateau_divider': 3}. Best is trial 14 with value: 0.9451449407066621.
CUDA out of memory. Tried to allocate 1.78 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.65 GiB is free. Including non-PyTorch memory, this process has 42.91 GiB memory in use. Of the allocated memory 41.07 GiB is allocated by PyTorch, and 702.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 19:31:14,952] Trial 182 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8121167690206451, 'batch_size': 45, 'attention_heads': 6, 'hidden_dimension': 210, 'number_of_hidden_layers': 4, 'dropout_rate': 0.44491909563928916, 'global_pooling': 'max', 'learning_rate': 0.001738718720084238, 'weight_decay': 0.00024174960709848548, 'beta_0': 0.8765590157995659, 'beta_1': 0.9803762132812406, 'epsilon': 7.14050528389458e-08, 'balanced_loss': False, 'epochs': 96, 'early_stopping_patience': 23, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
CUDA out of memory. Tried to allocate 1.28 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.26 GiB is free. Including non-PyTorch memory, this process has 43.29 GiB memory in use. Of the allocated memory 41.92 GiB is allocated by PyTorch, and 232.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 19:37:20,882] Trial 183 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8651300695453237, 'batch_size': 78, 'attention_heads': 13, 'hidden_dimension': 68, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5104266252153272, 'global_pooling': 'sum', 'learning_rate': 0.003045178154891665, 'weight_decay': 2.8295658000415127e-05, 'beta_0': 0.8727501479244594, 'beta_1': 0.9817998118822142, 'epsilon': 4.074369319658698e-05, 'balanced_loss': False, 'epochs': 183, 'early_stopping_patience': 23, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 19:51:24,401] Trial 184 finished with value: 0.9199148028617546 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8431160990715403, 'batch_size': 41, 'attention_heads': 4, 'hidden_dimension': 52, 'number_of_hidden_layers': 4, 'dropout_rate': 0.45577597640850437, 'global_pooling': 'max', 'learning_rate': 0.0012321102996349191, 'weight_decay': 0.0005211279704419429, 'beta_0': 0.8626970857198507, 'beta_1': 0.9936576015276483, 'epsilon': 2.0319920681121276e-08, 'balanced_loss': False, 'epochs': 53, 'early_stopping_patience': 20, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 20:02:13,452] Trial 185 finished with value: 0.9289025327830214 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8576865579746739, 'batch_size': 144, 'attention_heads': 5, 'hidden_dimension': 48, 'number_of_hidden_layers': 2, 'dropout_rate': 0.551519351612751, 'global_pooling': 'max', 'learning_rate': 0.0017575095748238944, 'weight_decay': 0.0004940286006718675, 'beta_0': 0.8467968985288469, 'beta_1': 0.9840706458608643, 'epsilon': 9.061252254644802e-06, 'balanced_loss': True, 'epochs': 91, 'early_stopping_patience': 20, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 20:11:22,208] Trial 186 finished with value: 0.9281166651218044 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8534920220488881, 'batch_size': 124, 'attention_heads': 5, 'hidden_dimension': 41, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5593536848546289, 'global_pooling': 'max', 'learning_rate': 0.0016229353083725506, 'weight_decay': 0.00037739959714883526, 'beta_0': 0.854562113049609, 'beta_1': 0.9840314287675427, 'epsilon': 1.0836051506661145e-05, 'balanced_loss': True, 'epochs': 93, 'early_stopping_patience': 20, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 20:20:39,126] Trial 187 finished with value: 0.9239200061438347 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8749028841294851, 'batch_size': 155, 'attention_heads': 5, 'hidden_dimension': 58, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5712380303424978, 'global_pooling': 'max', 'learning_rate': 0.0022420549266354895, 'weight_decay': 0.0006090122390670734, 'beta_0': 0.8417366577452056, 'beta_1': 0.9836318772658815, 'epsilon': 1.403507199957335e-05, 'balanced_loss': True, 'epochs': 83, 'early_stopping_patience': 20, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 20:29:50,921] Trial 188 finished with value: 0.9148407452897729 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.847894849614229, 'batch_size': 141, 'attention_heads': 5, 'hidden_dimension': 46, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5414692513773944, 'global_pooling': 'max', 'learning_rate': 0.0010761607483893685, 'weight_decay': 0.0004437410392842951, 'beta_0': 0.8474507144329786, 'beta_1': 0.9832746618628686, 'epsilon': 5.568024634570335e-06, 'balanced_loss': True, 'epochs': 77, 'early_stopping_patience': 19, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 20:38:38,617] Trial 189 finished with value: 0.9190483771100553 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8591755126293589, 'batch_size': 133, 'attention_heads': 6, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.532305581630444, 'global_pooling': 'max', 'learning_rate': 0.001371112320583454, 'weight_decay': 0.0007619213177391797, 'beta_0': 0.8491288039610722, 'beta_1': 0.9947721245517903, 'epsilon': 1.0440409619141796e-05, 'balanced_loss': True, 'epochs': 91, 'early_stopping_patience': 10, 'plateau_patience': 12, 'plateau_divider': 4}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 20:47:55,840] Trial 190 finished with value: 0.9219448420702753 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8229624880006974, 'batch_size': 115, 'attention_heads': 4, 'hidden_dimension': 38, 'number_of_hidden_layers': 2, 'dropout_rate': 0.547547053185171, 'global_pooling': 'max', 'learning_rate': 0.0008302021702022871, 'weight_decay': 0.0005280636679760007, 'beta_0': 0.8802291106425099, 'beta_1': 0.9828041030803378, 'epsilon': 6.364909446969004e-06, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 21, 'plateau_patience': 13, 'plateau_divider': 4}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 21:01:29,834] Trial 191 finished with value: 0.928718052786076 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8375986258207119, 'batch_size': 48, 'attention_heads': 5, 'hidden_dimension': 53, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5181674861914107, 'global_pooling': 'max', 'learning_rate': 0.00013965440225757582, 'weight_decay': 2.9957567126289117e-06, 'beta_0': 0.8565372019072367, 'beta_1': 0.9837753573582414, 'epsilon': 3.2443407066477495e-06, 'balanced_loss': True, 'epochs': 96, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 21:10:03,383] Trial 192 finished with value: 0.9010988382805928 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8675907536760297, 'batch_size': 148, 'attention_heads': 4, 'hidden_dimension': 46, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3353795604338359, 'global_pooling': 'sum', 'learning_rate': 0.000630605781382273, 'weight_decay': 0.0003025643041160633, 'beta_0': 0.8426307523698632, 'beta_1': 0.9973311929370299, 'epsilon': 2.0181372069740705e-05, 'balanced_loss': False, 'epochs': 88, 'early_stopping_patience': 25, 'plateau_patience': 14, 'plateau_divider': 4}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 21:21:52,276] Trial 193 finished with value: 0.9301134520276402 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8527211566127706, 'batch_size': 129, 'attention_heads': 5, 'hidden_dimension': 57, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5530207682427212, 'global_pooling': 'max', 'learning_rate': 0.0018951208950880247, 'weight_decay': 6.815401863781057e-05, 'beta_0': 0.8441826217271385, 'beta_1': 0.9961659424516814, 'epsilon': 4.08175934537735e-06, 'balanced_loss': False, 'epochs': 101, 'early_stopping_patience': 24, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 21:35:11,571] Trial 194 finished with value: 0.9183018339119697 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.8861932004586631, 'batch_size': 60, 'attention_heads': 6, 'hidden_dimension': 63, 'number_of_hidden_layers': 4, 'dropout_rate': 0.49425474368000333, 'global_pooling': 'mean', 'learning_rate': 0.00105621538716734, 'weight_decay': 0.0001104447886330778, 'beta_0': 0.8671125191890264, 'beta_1': 0.9831663179744485, 'epsilon': 1.4599087181651428e-07, 'balanced_loss': False, 'epochs': 63, 'early_stopping_patience': 19, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 21:44:29,853] Trial 195 finished with value: 0.9212980748444515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.847736919950724, 'batch_size': 123, 'attention_heads': 5, 'hidden_dimension': 49, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5355318832669779, 'global_pooling': 'max', 'learning_rate': 0.0014152504573889918, 'weight_decay': 0.0005591634067562228, 'beta_0': 0.8492485644065492, 'beta_1': 0.9843914170763044, 'epsilon': 1.150054767655989e-06, 'balanced_loss': True, 'epochs': 87, 'early_stopping_patience': 20, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 21:58:19,725] Trial 196 finished with value: 0.9235207953513993 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.84138745798037, 'batch_size': 135, 'attention_heads': 5, 'hidden_dimension': 51, 'number_of_hidden_layers': 2, 'dropout_rate': 0.538364032364609, 'global_pooling': 'max', 'learning_rate': 0.0013094488362148566, 'weight_decay': 0.0006620017562311153, 'beta_0': 0.845662649216561, 'beta_1': 0.9848055685115313, 'epsilon': 1.349604326340405e-06, 'balanced_loss': True, 'epochs': 72, 'early_stopping_patience': 20, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 22:07:22,222] Trial 197 finished with value: 0.9287821160595178 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8599744842079705, 'batch_size': 139, 'attention_heads': 5, 'hidden_dimension': 43, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5292710682380193, 'global_pooling': 'max', 'learning_rate': 0.001488188691071027, 'weight_decay': 0.0004729964020050812, 'beta_0': 0.8525898326701797, 'beta_1': 0.985163877676456, 'epsilon': 6.722169286576446e-07, 'balanced_loss': True, 'epochs': 85, 'early_stopping_patience': 20, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 22:21:11,568] Trial 198 finished with value: 0.9235969863431253 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8501827131358854, 'batch_size': 133, 'attention_heads': 5, 'hidden_dimension': 37, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5635001633554405, 'global_pooling': 'max', 'learning_rate': 0.0009022128442679365, 'weight_decay': 0.0005733885486797091, 'beta_0': 0.8501834049327947, 'beta_1': 0.9847590192697813, 'epsilon': 1.2157385447541928e-06, 'balanced_loss': True, 'epochs': 80, 'early_stopping_patience': 21, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 14 with value: 0.9451449407066621.
CUDA out of memory. Tried to allocate 1.03 GiB. GPU 0 has a total capacity of 44.56 GiB of which 878.69 MiB is free. Including non-PyTorch memory, this process has 43.70 GiB memory in use. Of the allocated memory 41.84 GiB is allocated by PyTorch, and 725.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 22:27:27,226] Trial 199 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8337127195166588, 'batch_size': 230, 'attention_heads': 4, 'hidden_dimension': 51, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5452047464906649, 'global_pooling': 'max', 'learning_rate': 0.0023739514303075435, 'weight_decay': 0.000998042072237917, 'beta_0': 0.8476408850838789, 'beta_1': 0.9941243210518168, 'epsilon': 2.129777403775219e-06, 'balanced_loss': True, 'epochs': 91, 'early_stopping_patience': 23, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 22:41:39,425] Trial 200 finished with value: 0.788813488757609 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8728695714490777, 'batch_size': 126, 'attention_heads': 4, 'hidden_dimension': 41, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5239896809830547, 'global_pooling': 'max', 'learning_rate': 9.374789014551959e-05, 'weight_decay': 5.7103486403499237e-05, 'beta_0': 0.8942210450812421, 'beta_1': 0.9887223917386682, 'epsilon': 9.670141224259697e-07, 'balanced_loss': False, 'epochs': 83, 'early_stopping_patience': 21, 'plateau_patience': 16, 'plateau_divider': 4}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 22:50:47,479] Trial 201 finished with value: 0.3000022319367765 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8442177038974101, 'batch_size': 131, 'attention_heads': 5, 'hidden_dimension': 73, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5371055395474426, 'global_pooling': 'max', 'learning_rate': 0.01797522755588587, 'weight_decay': 8.347545361572476e-05, 'beta_0': 0.8780819995529029, 'beta_1': 0.9957441647062941, 'epsilon': 1.4822725465801874e-05, 'balanced_loss': False, 'epochs': 94, 'early_stopping_patience': 20, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 23:07:32,969] Trial 202 finished with value: 0.9333418676426706 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8214045343576487, 'batch_size': 32, 'attention_heads': 6, 'hidden_dimension': 59, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5315076576161688, 'global_pooling': 'sum', 'learning_rate': 0.0011920744475140545, 'weight_decay': 0.0008519516030352511, 'beta_0': 0.8761861181187139, 'beta_1': 0.9952300862114868, 'epsilon': 1.2279604556746558e-05, 'balanced_loss': True, 'epochs': 50, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 23:22:50,302] Trial 203 finished with value: 0.9192132319059931 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8799692078433814, 'batch_size': 120, 'attention_heads': 5, 'hidden_dimension': 54, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5447914610449216, 'global_pooling': 'max', 'learning_rate': 0.001767744112539259, 'weight_decay': 0.0003815785929207234, 'beta_0': 0.8718246302845485, 'beta_1': 0.9980230581815118, 'epsilon': 1.769264430613625e-06, 'balanced_loss': False, 'epochs': 86, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 4}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 23:35:03,066] Trial 204 finished with value: 0.9091070123928708 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8566726513331921, 'batch_size': 146, 'attention_heads': 4, 'hidden_dimension': 45, 'number_of_hidden_layers': 4, 'dropout_rate': 0.46877574781089826, 'global_pooling': 'max', 'learning_rate': 0.0009771825313998144, 'weight_decay': 0.0004524116838559888, 'beta_0': 0.8390088101061663, 'beta_1': 0.9821103776473473, 'epsilon': 9.662958668958914e-06, 'balanced_loss': False, 'epochs': 90, 'early_stopping_patience': 21, 'plateau_patience': 11, 'plateau_divider': 6}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 23:45:34,790] Trial 205 finished with value: 0.9411645274732611 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8031677383367939, 'batch_size': 122, 'attention_heads': 4, 'hidden_dimension': 34, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5272759657046674, 'global_pooling': 'max', 'learning_rate': 0.0012036747871845578, 'weight_decay': 0.0008249763551534871, 'beta_0': 0.8792101634044337, 'beta_1': 0.9944680081969874, 'epsilon': 2.612337321782565e-05, 'balanced_loss': False, 'epochs': 80, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 4}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-27 23:56:32,765] Trial 206 finished with value: 0.9314041197396022 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.7905459135443449, 'batch_size': 112, 'attention_heads': 4, 'hidden_dimension': 35, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5268519808021563, 'global_pooling': 'max', 'learning_rate': 0.0007737094977177024, 'weight_decay': 0.0007338703672558086, 'beta_0': 0.8822436925780703, 'beta_1': 0.9946887928523248, 'epsilon': 3.2509434031019164e-05, 'balanced_loss': False, 'epochs': 78, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 4}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-28 00:05:57,653] Trial 207 finished with value: 0.9177304971134892 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8072758752415358, 'batch_size': 217, 'attention_heads': 4, 'hidden_dimension': 39, 'number_of_hidden_layers': 2, 'dropout_rate': 0.516284812189754, 'global_pooling': 'max', 'learning_rate': 0.0014941166499998144, 'weight_decay': 0.0006367330383402207, 'beta_0': 0.880646672845908, 'beta_1': 0.994095671207284, 'epsilon': 2.734376087497201e-05, 'balanced_loss': False, 'epochs': 98, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 4}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-28 00:15:35,463] Trial 208 finished with value: 0.9208443600639823 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8276203147715427, 'batch_size': 117, 'attention_heads': 5, 'hidden_dimension': 33, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5397595340673782, 'global_pooling': 'max', 'learning_rate': 0.0011652469155028558, 'weight_decay': 0.0008710806560772743, 'beta_0': 0.8745188039714289, 'beta_1': 0.9902384035115736, 'epsilon': 1.850077162529648e-05, 'balanced_loss': False, 'epochs': 83, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 4}. Best is trial 14 with value: 0.9451449407066621.
The selected strides are greater or equal to the total chunk size.
[I 2025-02-28 00:15:37,214] Trial 209 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8660329735309223, 'batch_size': 123, 'attention_heads': 4, 'hidden_dimension': 49, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4413793280707588, 'global_pooling': 'max', 'learning_rate': 0.0019996518162016842, 'weight_decay': 0.0005607478730172441, 'beta_0': 0.8783198185541323, 'beta_1': 0.9945781319768974, 'epsilon': 2.2744364545585716e-05, 'balanced_loss': False, 'epochs': 118, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-28 00:29:46,489] Trial 210 finished with value: 0.9347730860035007 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8357223508895147, 'batch_size': 74, 'attention_heads': 4, 'hidden_dimension': 43, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5556154480377568, 'global_pooling': 'max', 'learning_rate': 0.0006786140596936484, 'weight_decay': 0.0007920876120250787, 'beta_0': 0.8690606158282002, 'beta_1': 0.984568326997746, 'epsilon': 3.3629201348942114e-07, 'balanced_loss': False, 'epochs': 94, 'early_stopping_patience': 23, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-28 00:42:46,949] Trial 211 finished with value: 0.9319504298167562 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8020569136300323, 'batch_size': 107, 'attention_heads': 5, 'hidden_dimension': 32, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5208755087039143, 'global_pooling': 'max', 'learning_rate': 0.0015912162042022806, 'weight_decay': 0.0001326894259164629, 'beta_0': 0.8856577704238849, 'beta_1': 0.9834524700850691, 'epsilon': 7.3154000181782845e-06, 'balanced_loss': False, 'epochs': 124, 'early_stopping_patience': 20, 'plateau_patience': 13, 'plateau_divider': 3}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-28 00:56:34,283] Trial 212 finished with value: 0.9174351997323509 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8496360184256317, 'batch_size': 129, 'attention_heads': 5, 'hidden_dimension': 39, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5341982843637257, 'global_pooling': 'sum', 'learning_rate': 0.002747714548307707, 'weight_decay': 0.0006813753930727003, 'beta_0': 0.8611859769772309, 'beta_1': 0.9909104976699193, 'epsilon': 1.551613903669946e-05, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 22, 'plateau_patience': 14, 'plateau_divider': 4}. Best is trial 14 with value: 0.9451449407066621.
CUDA out of memory. Tried to allocate 2.49 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.57 GiB is free. Including non-PyTorch memory, this process has 42.98 GiB memory in use. Of the allocated memory 41.45 GiB is allocated by PyTorch, and 390.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 01:02:44,603] Trial 213 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7804086409270811, 'batch_size': 142, 'attention_heads': 4, 'hidden_dimension': 191, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4523024260530518, 'global_pooling': 'max', 'learning_rate': 0.0010618330013380712, 'weight_decay': 0.0004979160652372049, 'beta_0': 0.8510824210738791, 'beta_1': 0.9808939971297365, 'epsilon': 5.224641572719881e-08, 'balanced_loss': False, 'epochs': 86, 'early_stopping_patience': 25, 'plateau_patience': 15, 'plateau_divider': 4}. Best is trial 14 with value: 0.9451449407066621.
CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacity of 44.56 GiB of which 654.69 MiB is free. Including non-PyTorch memory, this process has 43.91 GiB memory in use. Of the allocated memory 42.31 GiB is allocated by PyTorch, and 467.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 01:08:57,180] Trial 214 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8147807571269214, 'batch_size': 85, 'attention_heads': 7, 'hidden_dimension': 103, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3272233587930914, 'global_pooling': 'mean', 'learning_rate': 0.0012913746319756735, 'weight_decay': 0.000394239535633852, 'beta_0': 0.8757857923363382, 'beta_1': 0.9989828689610365, 'epsilon': 3.67275408282636e-08, 'balanced_loss': False, 'epochs': 76, 'early_stopping_patience': 24, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-28 01:20:22,677] Trial 215 finished with value: 0.9333820151175147 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8356222879737499, 'batch_size': 65, 'attention_heads': 4, 'hidden_dimension': 43, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5543832801831812, 'global_pooling': 'max', 'learning_rate': 0.000708345437936494, 'weight_decay': 0.0008071665557310549, 'beta_0': 0.8692014239813137, 'beta_1': 0.9846665699816035, 'epsilon': 2.3815455910348058e-07, 'balanced_loss': False, 'epochs': 93, 'early_stopping_patience': 23, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-28 01:31:43,602] Trial 216 finished with value: 0.920115470191207 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8396685503279353, 'batch_size': 73, 'attention_heads': 4, 'hidden_dimension': 47, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5507347952509253, 'global_pooling': 'max', 'learning_rate': 0.0008564493967306977, 'weight_decay': 0.0007200807495326856, 'beta_0': 0.8647846521513454, 'beta_1': 0.9839765634290237, 'epsilon': 3.6506857661525296e-07, 'balanced_loss': False, 'epochs': 96, 'early_stopping_patience': 23, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-28 01:45:57,372] Trial 217 finished with value: 0.9432675449159171 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8286271817850015, 'batch_size': 72, 'attention_heads': 9, 'hidden_dimension': 43, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5417646093474191, 'global_pooling': 'max', 'learning_rate': 0.0005386063420125788, 'weight_decay': 0.0006001511825112411, 'beta_0': 0.8712391697222912, 'beta_1': 0.9843550103419264, 'epsilon': 5.298153635981355e-07, 'balanced_loss': False, 'epochs': 88, 'early_stopping_patience': 22, 'plateau_patience': 15, 'plateau_divider': 5}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-28 02:01:41,585] Trial 218 finished with value: 0.935632189173308 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8275282984147282, 'batch_size': 80, 'attention_heads': 9, 'hidden_dimension': 52, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5446199617422781, 'global_pooling': 'max', 'learning_rate': 0.0004808173767127106, 'weight_decay': 0.000595732706015408, 'beta_0': 0.8714539703908423, 'beta_1': 0.9856577382083613, 'epsilon': 1.1033348985197544e-07, 'balanced_loss': False, 'epochs': 89, 'early_stopping_patience': 22, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-28 02:15:41,685] Trial 219 finished with value: 0.9158307742008656 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8228712862322648, 'batch_size': 78, 'attention_heads': 9, 'hidden_dimension': 55, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3435489370626125, 'global_pooling': 'max', 'learning_rate': 0.0004230487529247183, 'weight_decay': 0.00010020375770222827, 'beta_0': 0.871563403979073, 'beta_1': 0.9874679490483838, 'epsilon': 9.108129315308428e-08, 'balanced_loss': False, 'epochs': 89, 'early_stopping_patience': 22, 'plateau_patience': 14, 'plateau_divider': 8}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-28 02:30:31,825] Trial 220 finished with value: 0.9365874446033922 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8179195193113385, 'batch_size': 69, 'attention_heads': 8, 'hidden_dimension': 61, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5430160185174249, 'global_pooling': 'max', 'learning_rate': 0.0004734255048922665, 'weight_decay': 0.0005983400565723967, 'beta_0': 0.8754425908152126, 'beta_1': 0.9870491353220627, 'epsilon': 1.221086552973208e-07, 'balanced_loss': False, 'epochs': 91, 'early_stopping_patience': 22, 'plateau_patience': 16, 'plateau_divider': 9}. Best is trial 14 with value: 0.9451449407066621.
CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 368.69 MiB is free. Including non-PyTorch memory, this process has 44.19 GiB memory in use. Of the allocated memory 42.15 GiB is allocated by PyTorch, and 912.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 02:38:08,752] Trial 221 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8149281715156904, 'batch_size': 66, 'attention_heads': 7, 'hidden_dimension': 67, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5420533649187519, 'global_pooling': 'max', 'learning_rate': 0.0005657983629270896, 'weight_decay': 0.0004934296564824041, 'beta_0': 0.8778937214597409, 'beta_1': 0.9870594413412687, 'epsilon': 1.24846748272236e-05, 'balanced_loss': False, 'epochs': 98, 'early_stopping_patience': 22, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 14 with value: 0.9451449407066621.
CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.18 GiB is free. Including non-PyTorch memory, this process has 42.37 GiB memory in use. Of the allocated memory 40.86 GiB is allocated by PyTorch, and 366.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 02:45:41,236] Trial 222 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8045440754272029, 'batch_size': 72, 'attention_heads': 7, 'hidden_dimension': 178, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5265716873089092, 'global_pooling': 'max', 'learning_rate': 0.0005942934412979996, 'weight_decay': 0.000632241429934956, 'beta_0': 0.8735863790816516, 'beta_1': 0.9827366685841994, 'epsilon': 2.0536699234579515e-07, 'balanced_loss': False, 'epochs': 91, 'early_stopping_patience': 21, 'plateau_patience': 18, 'plateau_divider': 10}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-28 03:02:02,065] Trial 223 finished with value: 0.9352059459486213 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8122599821796986, 'batch_size': 69, 'attention_heads': 8, 'hidden_dimension': 61, 'number_of_hidden_layers': 2, 'dropout_rate': 0.548272303268088, 'global_pooling': 'sum', 'learning_rate': 0.0003392714715004254, 'weight_decay': 0.0004152849120211182, 'beta_0': 0.8801051574111619, 'beta_1': 0.9867853328184153, 'epsilon': 5.702371007141022e-07, 'balanced_loss': False, 'epochs': 81, 'early_stopping_patience': 22, 'plateau_patience': 15, 'plateau_divider': 9}. Best is trial 14 with value: 0.9451449407066621.
CUDA out of memory. Tried to allocate 1014.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 898.69 MiB is free. Including non-PyTorch memory, this process has 43.68 GiB memory in use. Of the allocated memory 41.94 GiB is allocated by PyTorch, and 599.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 03:22:32,648] Trial 224 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8214991827760441, 'batch_size': 94, 'attention_heads': 8, 'hidden_dimension': 36, 'number_of_hidden_layers': 4, 'dropout_rate': 0.46217390757745214, 'global_pooling': 'max', 'learning_rate': 0.00019029089748656371, 'weight_decay': 2.2089032058630986e-05, 'beta_0': 0.8745243809851254, 'beta_1': 0.995201429281211, 'epsilon': 1.8786502686529344e-05, 'balanced_loss': False, 'epochs': 87, 'early_stopping_patience': 24, 'plateau_patience': 16, 'plateau_divider': 4}. Best is trial 14 with value: 0.9451449407066621.
[I 2025-02-28 03:39:45,254] Trial 225 finished with value: 0.9507461710473065 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8308630305239748, 'batch_size': 78, 'attention_heads': 9, 'hidden_dimension': 57, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5433928832326027, 'global_pooling': 'max', 'learning_rate': 0.00043582198448212633, 'weight_decay': 0.0005783095498051698, 'beta_0': 0.8713157052797263, 'beta_1': 0.9854876430341758, 'epsilon': 1.0693503942177135e-07, 'balanced_loss': False, 'epochs': 91, 'early_stopping_patience': 22, 'plateau_patience': 14, 'plateau_divider': 4}. Best is trial 225 with value: 0.9507461710473065.
[I 2025-02-28 03:56:39,837] Trial 226 finished with value: 0.9262650521379954 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8291106194454044, 'batch_size': 62, 'attention_heads': 10, 'hidden_dimension': 63, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5332126271696407, 'global_pooling': 'max', 'learning_rate': 0.00027127939381477634, 'weight_decay': 0.0005373075105920906, 'beta_0': 0.8759844607975538, 'beta_1': 0.9873976300874969, 'epsilon': 1.3672886939401101e-07, 'balanced_loss': False, 'epochs': 93, 'early_stopping_patience': 22, 'plateau_patience': 14, 'plateau_divider': 4}. Best is trial 225 with value: 0.9507461710473065.
[I 2025-02-28 04:15:49,199] Trial 227 finished with value: 0.9280418255616982 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8296717098742136, 'batch_size': 74, 'attention_heads': 8, 'hidden_dimension': 58, 'number_of_hidden_layers': 2, 'dropout_rate': 0.540281253486304, 'global_pooling': 'max', 'learning_rate': 0.00039344779019963847, 'weight_decay': 0.00034924088343911365, 'beta_0': 0.870507479843671, 'beta_1': 0.9863043085168196, 'epsilon': 1.1953537118757705e-07, 'balanced_loss': False, 'epochs': 176, 'early_stopping_patience': 22, 'plateau_patience': 16, 'plateau_divider': 4}. Best is trial 225 with value: 0.9507461710473065.
[I 2025-02-28 04:32:12,348] Trial 228 finished with value: 0.9448910474209404 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.817422537532551, 'batch_size': 69, 'attention_heads': 8, 'hidden_dimension': 55, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5580576297855676, 'global_pooling': 'max', 'learning_rate': 0.000517797054773789, 'weight_decay': 0.00046072346364497713, 'beta_0': 0.8669387294734836, 'beta_1': 0.9850541363874161, 'epsilon': 1.821396904592715e-07, 'balanced_loss': False, 'epochs': 91, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 225 with value: 0.9507461710473065.
[I 2025-02-28 04:51:01,093] Trial 229 finished with value: 0.9457508619118524 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8211441253249347, 'batch_size': 68, 'attention_heads': 9, 'hidden_dimension': 56, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5599524781876174, 'global_pooling': 'max', 'learning_rate': 0.0004954258208008021, 'weight_decay': 0.0004322482716185813, 'beta_0': 0.8671129567443281, 'beta_1': 0.9859732852087929, 'epsilon': 1.7406809641223931e-07, 'balanced_loss': False, 'epochs': 95, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 225 with value: 0.9507461710473065.
CUDA out of memory. Tried to allocate 2.30 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.17 GiB is free. Including non-PyTorch memory, this process has 42.38 GiB memory in use. Of the allocated memory 40.85 GiB is allocated by PyTorch, and 392.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 04:58:23,241] Trial 230 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8163706996700111, 'batch_size': 68, 'attention_heads': 9, 'hidden_dimension': 146, 'number_of_hidden_layers': 2, 'dropout_rate': 0.57432172676163, 'global_pooling': 'max', 'learning_rate': 0.0003541689624913711, 'weight_decay': 0.0006857152459095433, 'beta_0': 0.8673393104724347, 'beta_1': 0.986317275287348, 'epsilon': 1.5362104748636304e-07, 'balanced_loss': False, 'epochs': 95, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 3}. Best is trial 225 with value: 0.9507461710473065.
CUDA out of memory. Tried to allocate 1.54 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.16 GiB is free. Including non-PyTorch memory, this process has 43.39 GiB memory in use. Of the allocated memory 41.27 GiB is allocated by PyTorch, and 991.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 05:06:07,771] Trial 231 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8084323240913299, 'batch_size': 77, 'attention_heads': 10, 'hidden_dimension': 55, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5617494641606072, 'global_pooling': 'max', 'learning_rate': 0.0005242082118168125, 'weight_decay': 0.00044680177412876324, 'beta_0': 0.8688562877696994, 'beta_1': 0.9853358301158196, 'epsilon': 8.833566102312185e-08, 'balanced_loss': False, 'epochs': 99, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 225 with value: 0.9507461710473065.
[I 2025-02-28 05:21:58,274] Trial 232 finished with value: 0.9384738800334129 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8187856982305344, 'batch_size': 63, 'attention_heads': 9, 'hidden_dimension': 61, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5592299645906621, 'global_pooling': 'max', 'learning_rate': 0.000469890400383032, 'weight_decay': 0.0005824460881117183, 'beta_0': 0.8672958544310333, 'beta_1': 0.9860758568353146, 'epsilon': 1.0413283211890217e-07, 'balanced_loss': False, 'epochs': 92, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 225 with value: 0.9507461710473065.
[I 2025-02-28 05:38:11,533] Trial 233 finished with value: 0.9335200884998023 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7960241691686872, 'batch_size': 59, 'attention_heads': 10, 'hidden_dimension': 39, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5684221949660824, 'global_pooling': 'max', 'learning_rate': 0.00042353580454055083, 'weight_decay': 0.0008752302221339202, 'beta_0': 0.8626142310634949, 'beta_1': 0.98557442574531, 'epsilon': 5.885215634927806e-08, 'balanced_loss': False, 'epochs': 97, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 225 with value: 0.9507461710473065.
CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.65 GiB is free. Including non-PyTorch memory, this process has 42.91 GiB memory in use. Of the allocated memory 40.99 GiB is allocated by PyTorch, and 788.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 05:48:35,020] Trial 234 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8207889979386096, 'batch_size': 66, 'attention_heads': 9, 'hidden_dimension': 69, 'number_of_hidden_layers': 2, 'dropout_rate': 0.559487157166717, 'global_pooling': 'max', 'learning_rate': 0.00055884515355439, 'weight_decay': 0.0005232255988434776, 'beta_0': 0.8668786283000869, 'beta_1': 0.9850894524707143, 'epsilon': 2.757807977298061e-07, 'balanced_loss': False, 'epochs': 56, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 225 with value: 0.9507461710473065.
[I 2025-02-28 06:06:39,505] Trial 235 finished with value: 0.9394758146969813 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8174857366416874, 'batch_size': 70, 'attention_heads': 9, 'hidden_dimension': 61, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5568914017978707, 'global_pooling': 'max', 'learning_rate': 0.0002832228244373667, 'weight_decay': 0.0005883422571602766, 'beta_0': 0.8663970251872499, 'beta_1': 0.9870399508186216, 'epsilon': 1.0473434135601464e-07, 'balanced_loss': False, 'epochs': 91, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 225 with value: 0.9507461710473065.
CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacity of 44.56 GiB of which 528.69 MiB is free. Including non-PyTorch memory, this process has 44.04 GiB memory in use. Of the allocated memory 41.49 GiB is allocated by PyTorch, and 1.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 06:23:40,908] Trial 236 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8244962261632983, 'batch_size': 82, 'attention_heads': 9, 'hidden_dimension': 58, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5674098972707168, 'global_pooling': 'max', 'learning_rate': 0.00032146492195211544, 'weight_decay': 0.0006670973638934148, 'beta_0': 0.8658575468794931, 'beta_1': 0.9859238946558878, 'epsilon': 1.8140510828776107e-07, 'balanced_loss': False, 'epochs': 88, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 225 with value: 0.9507461710473065.
CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacity of 44.56 GiB of which 362.69 MiB is free. Including non-PyTorch memory, this process has 44.20 GiB memory in use. Of the allocated memory 42.07 GiB is allocated by PyTorch, and 1006.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-28 06:31:29,182] Trial 237 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8069791152180438, 'batch_size': 72, 'attention_heads': 9, 'hidden_dimension': 65, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5582146030331505, 'global_pooling': 'max', 'learning_rate': 0.00023967754600552748, 'weight_decay': 7.870679124809751e-05, 'beta_0': 0.8641367372628714, 'beta_1': 0.9859260640150604, 'epsilon': 2.0980191040404023e-07, 'balanced_loss': False, 'epochs': 93, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 225 with value: 0.9507461710473065.
[I 2025-02-28 06:45:19,036] Trial 238 finished with value: 0.914962915570239 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8301964266273792, 'batch_size': 62, 'attention_heads': 9, 'hidden_dimension': 52, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5632395823131219, 'global_pooling': 'max', 'learning_rate': 0.0003152807488144612, 'weight_decay': 0.0005770848253469292, 'beta_0': 0.8681594541489042, 'beta_1': 0.98644799646594, 'epsilon': 8.581437529060859e-08, 'balanced_loss': False, 'epochs': 85, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 225 with value: 0.9507461710473065.
slurmstepd: error: *** JOB 15052603 ON gpu007 CANCELLED AT 2025-02-28T06:49:53 DUE TO TIME LIMIT ***
