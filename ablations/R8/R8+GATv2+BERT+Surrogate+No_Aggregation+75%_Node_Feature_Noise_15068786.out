[I 2025-03-01 22:24:13,654] Using an existing study with name 'R8-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-No_Ablation-1.0-0.75' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors
[I 2025-03-01 22:34:19,052] Trial 253 finished with value: 0.9207825475098664 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8993002819588347, 'batch_size': 122, 'attention_heads': 7, 'hidden_dimension': 145, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32275474760503947, 'global_pooling': 'max', 'learning_rate': 0.0008152020399224768, 'weight_decay': 7.394108091201311e-05, 'beta_0': 0.808570911588037, 'beta_1': 0.9914133203173263, 'epsilon': 8.154703125721245e-05, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 18, 'plateau_patience': 25, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-01 22:45:38,674] Trial 254 finished with value: 0.9256029770804048 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9072827522594303, 'batch_size': 105, 'attention_heads': 12, 'hidden_dimension': 152, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33963795393634, 'global_pooling': 'max', 'learning_rate': 0.0012555395842962325, 'weight_decay': 3.1198908798129594e-05, 'beta_0': 0.8046942810419149, 'beta_1': 0.986013967868247, 'epsilon': 4.2328982857167464e-05, 'balanced_loss': True, 'epochs': 144, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-01 22:57:34,451] Trial 255 finished with value: 0.9254622200303857 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9218290022294754, 'batch_size': 109, 'attention_heads': 13, 'hidden_dimension': 178, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31774618077596983, 'global_pooling': 'max', 'learning_rate': 0.0017207440661523073, 'weight_decay': 0.0001232626691072652, 'beta_0': 0.8001443751501068, 'beta_1': 0.9886544983215708, 'epsilon': 2.0296533463332624e-05, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-01 23:07:29,361] Trial 256 finished with value: 0.9165979758887587 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9117637371174395, 'batch_size': 93, 'attention_heads': 10, 'hidden_dimension': 156, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3316095938424348, 'global_pooling': 'mean', 'learning_rate': 0.0010365359173123848, 'weight_decay': 5.657252855073836e-05, 'beta_0': 0.8063570336028629, 'beta_1': 0.9894820783637132, 'epsilon': 2.5827371118690756e-05, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-01 23:16:49,620] Trial 257 finished with value: 0.9085560017214922 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8987399725906388, 'batch_size': 115, 'attention_heads': 6, 'hidden_dimension': 139, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3253522253349762, 'global_pooling': 'max', 'learning_rate': 0.0006823582214327598, 'weight_decay': 2.640500614210044e-05, 'beta_0': 0.8019534228144077, 'beta_1': 0.9854352121215196, 'epsilon': 6.804739404523889e-06, 'balanced_loss': True, 'epochs': 106, 'early_stopping_patience': 18, 'plateau_patience': 20, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 3.81 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.80 GiB is free. Including non-PyTorch memory, this process has 40.76 GiB memory in use. Of the allocated memory 36.15 GiB is allocated by PyTorch, and 3.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 23:26:10,236] Trial 258 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8855196374673694, 'batch_size': 83, 'attention_heads': 14, 'hidden_dimension': 146, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3457648235015966, 'global_pooling': 'sum', 'learning_rate': 0.0012659877426844633, 'weight_decay': 0.0001452168254736098, 'beta_0': 0.8089271407094889, 'beta_1': 0.9868216834176764, 'epsilon': 2.95063590060809e-05, 'balanced_loss': False, 'epochs': 153, 'early_stopping_patience': 17, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-01 23:36:13,538] Trial 259 finished with value: 0.9017085245312231 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9122019154840582, 'batch_size': 146, 'attention_heads': 8, 'hidden_dimension': 159, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33486863931642424, 'global_pooling': 'max', 'learning_rate': 0.0008621710882676753, 'weight_decay': 0.00016678137193369425, 'beta_0': 0.8041465223329738, 'beta_1': 0.9863685319994204, 'epsilon': 6.568564421872565e-05, 'balanced_loss': True, 'epochs': 148, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 4.09 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.54 GiB is free. Including non-PyTorch memory, this process has 42.02 GiB memory in use. Of the allocated memory 36.82 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-01 23:45:17,626] Trial 260 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8928300140100308, 'batch_size': 101, 'attention_heads': 12, 'hidden_dimension': 172, 'number_of_hidden_layers': 0, 'dropout_rate': 0.50832887599105, 'global_pooling': 'max', 'learning_rate': 0.0014944605584959853, 'weight_decay': 0.0003088834080177111, 'beta_0': 0.8079195084540451, 'beta_1': 0.9858273364155409, 'epsilon': 1.6457472449620934e-05, 'balanced_loss': True, 'epochs': 93, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-01 23:55:06,346] Trial 261 finished with value: 0.9168043949650881 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9301512954535986, 'batch_size': 88, 'attention_heads': 11, 'hidden_dimension': 151, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3513859076973219, 'global_pooling': 'mean', 'learning_rate': 0.0011115750623175544, 'weight_decay': 4.198067921574523e-05, 'beta_0': 0.802939316813373, 'beta_1': 0.9877473564257363, 'epsilon': 1.3559329883414478e-05, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 00:05:16,945] Trial 262 finished with value: 0.9216359999649468 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9017167640310925, 'batch_size': 105, 'attention_heads': 9, 'hidden_dimension': 164, 'number_of_hidden_layers': 0, 'dropout_rate': 0.36305009944973543, 'global_pooling': 'max', 'learning_rate': 0.0019489494148570996, 'weight_decay': 0.00010550188817216557, 'beta_0': 0.8059405083916777, 'beta_1': 0.9848435558130662, 'epsilon': 4.823139292464214e-05, 'balanced_loss': True, 'epochs': 135, 'early_stopping_patience': 17, 'plateau_patience': 24, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 00:15:32,636] Trial 263 finished with value: 0.9141984957435532 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9173051766921944, 'batch_size': 97, 'attention_heads': 11, 'hidden_dimension': 137, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3124477418005105, 'global_pooling': 'max', 'learning_rate': 0.0010051006370947833, 'weight_decay': 8.605534063286785e-05, 'beta_0': 0.8014489159418358, 'beta_1': 0.9906300002284472, 'epsilon': 8.73032886246034e-05, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 18, 'plateau_patience': 20, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 00:26:23,488] Trial 264 finished with value: 0.9169044522722399 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9064839205879882, 'batch_size': 112, 'attention_heads': 12, 'hidden_dimension': 143, 'number_of_hidden_layers': 0, 'dropout_rate': 0.320226873609912, 'global_pooling': 'max', 'learning_rate': 0.000739528425208494, 'weight_decay': 6.122995430114849e-05, 'beta_0': 0.8049428457564626, 'beta_1': 0.9872593863268383, 'epsilon': 3.8087441076817306e-05, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 16, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 5.21 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.81 GiB is free. Including non-PyTorch memory, this process has 41.75 GiB memory in use. Of the allocated memory 39.51 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 00:32:32,663] Trial 265 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7979771610074435, 'batch_size': 102, 'attention_heads': 12, 'hidden_dimension': 152, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34072217867993454, 'global_pooling': 'mean', 'learning_rate': 0.0013419901652936444, 'weight_decay': 0.00022998146967028132, 'beta_0': 0.8103187881277224, 'beta_1': 0.9864333329529134, 'epsilon': 1.9400582923134842e-05, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 00:41:46,451] Trial 266 finished with value: 0.9187134313005533 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9203215209633118, 'batch_size': 117, 'attention_heads': 12, 'hidden_dimension': 158, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3284797355717741, 'global_pooling': 'max', 'learning_rate': 0.001753418547829703, 'weight_decay': 4.783694432531325e-05, 'beta_0': 0.8068919624481146, 'beta_1': 0.9854755981472982, 'epsilon': 2.3679163118160968e-05, 'balanced_loss': True, 'epochs': 131, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 00:52:47,611] Trial 267 finished with value: 0.9217483835264542 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8961339944447803, 'batch_size': 107, 'attention_heads': 13, 'hidden_dimension': 148, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33431770998952715, 'global_pooling': 'max', 'learning_rate': 0.0022899204303731286, 'weight_decay': 0.0001257383521276914, 'beta_0': 0.8031642367850583, 'beta_1': 0.9859411832860018, 'epsilon': 6.279641168607148e-05, 'balanced_loss': True, 'epochs': 98, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 01:02:28,511] Trial 268 finished with value: 0.9297919392546696 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8806922921033086, 'batch_size': 60, 'attention_heads': 13, 'hidden_dimension': 143, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32489043117790306, 'global_pooling': 'max', 'learning_rate': 0.0009128304190000053, 'weight_decay': 7.080077159415704e-05, 'beta_0': 0.8607800724783692, 'beta_1': 0.9844137154458972, 'epsilon': 2.900258780375283e-05, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 10, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 01:12:53,300] Trial 269 finished with value: 0.9057955676498407 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8752226892416817, 'batch_size': 59, 'attention_heads': 13, 'hidden_dimension': 135, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5298721420781565, 'global_pooling': 'max', 'learning_rate': 0.0011836368876144319, 'weight_decay': 7.253248570885176e-05, 'beta_0': 0.8711251881143734, 'beta_1': 0.9845855486764491, 'epsilon': 8.658527593053043e-06, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 01:22:34,683] Trial 270 finished with value: 0.9212920859865471 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8851399177736129, 'batch_size': 47, 'attention_heads': 13, 'hidden_dimension': 125, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3139928771325949, 'global_pooling': 'max', 'learning_rate': 0.0015336192090158274, 'weight_decay': 6.502682605522987e-05, 'beta_0': 0.860861454196597, 'beta_1': 0.9842582450418076, 'epsilon': 1.1450968316664674e-05, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 11, 'plateau_patience': 25, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 4.11 GiB. GPU 0 has a total capacity of 44.56 GiB of which 262.69 MiB is free. Including non-PyTorch memory, this process has 44.30 GiB memory in use. Of the allocated memory 38.98 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 01:32:20,768] Trial 271 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8721567975017009, 'batch_size': 66, 'attention_heads': 13, 'hidden_dimension': 167, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32176427998248397, 'global_pooling': 'max', 'learning_rate': 0.0005762943225436946, 'weight_decay': 8.218437754422738e-05, 'beta_0': 0.8333097119309992, 'beta_1': 0.9852116534554899, 'epsilon': 1.6710415427240985e-05, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 01:41:51,492] Trial 272 finished with value: 0.9173889483198604 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9407870259127232, 'batch_size': 75, 'attention_heads': 13, 'hidden_dimension': 110, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34662899046075535, 'global_pooling': 'max', 'learning_rate': 0.0030040706249315186, 'weight_decay': 9.354477556596838e-05, 'beta_0': 0.8017105527359757, 'beta_1': 0.9945134299262866, 'epsilon': 2.9745368014716636e-05, 'balanced_loss': True, 'epochs': 130, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 01:52:34,245] Trial 273 finished with value: 0.9201599101469424 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.8795585370721438, 'batch_size': 55, 'attention_heads': 14, 'hidden_dimension': 141, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3384871801430937, 'global_pooling': 'max', 'learning_rate': 0.0008442408038958429, 'weight_decay': 0.00011112541598245992, 'beta_0': 0.876002826179507, 'beta_1': 0.9843919158588517, 'epsilon': 2.0636325164225637e-05, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 19, 'plateau_patience': 25, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 02:04:18,153] Trial 274 finished with value: 0.9251054182141185 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8880097384862757, 'batch_size': 61, 'attention_heads': 11, 'hidden_dimension': 154, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35537541333409545, 'global_pooling': 'max', 'learning_rate': 0.001052993123427486, 'weight_decay': 0.00014429516905729376, 'beta_0': 0.883401908001342, 'beta_1': 0.9861727462522883, 'epsilon': 1.4517341772385861e-05, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.09 GiB is free. Including non-PyTorch memory, this process has 41.46 GiB memory in use. Of the allocated memory 39.30 GiB is allocated by PyTorch, and 1.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 02:11:43,344] Trial 275 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8592668915633824, 'batch_size': 215, 'attention_heads': 8, 'hidden_dimension': 173, 'number_of_hidden_layers': 0, 'dropout_rate': 0.39780078059785823, 'global_pooling': 'max', 'learning_rate': 0.0013008352279866439, 'weight_decay': 7.43049117460941e-05, 'beta_0': 0.8003221446155923, 'beta_1': 0.9856414614577594, 'epsilon': 2.5951322424849775e-05, 'balanced_loss': True, 'epochs': 134, 'early_stopping_patience': 11, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 02:22:28,694] Trial 276 finished with value: 0.9250890220625236 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8932516231788571, 'batch_size': 93, 'attention_heads': 14, 'hidden_dimension': 132, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32414647530902246, 'global_pooling': 'max', 'learning_rate': 0.0007560494963003018, 'weight_decay': 0.0002069505191402915, 'beta_0': 0.8524651898578538, 'beta_1': 0.989796026354716, 'epsilon': 1.738520669122339e-05, 'balanced_loss': True, 'epochs': 169, 'early_stopping_patience': 12, 'plateau_patience': 22, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 02:33:26,412] Trial 277 finished with value: 0.9167915740553473 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9103794795039392, 'batch_size': 96, 'attention_heads': 11, 'hidden_dimension': 162, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3168803775336579, 'global_pooling': 'max', 'learning_rate': 0.0016170148706985538, 'weight_decay': 0.00016445381876648309, 'beta_0': 0.8975062657209482, 'beta_1': 0.9839952037006248, 'epsilon': 9.765797460238786e-05, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 02:43:36,651] Trial 278 finished with value: 0.9207709512589416 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9032352204016482, 'batch_size': 89, 'attention_heads': 12, 'hidden_dimension': 144, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3289183050563676, 'global_pooling': 'max', 'learning_rate': 0.0009504987774132778, 'weight_decay': 9.590730476518263e-05, 'beta_0': 0.8037569751228527, 'beta_1': 0.9849905970103712, 'epsilon': 3.3314101922875074e-05, 'balanced_loss': True, 'epochs': 138, 'early_stopping_patience': 10, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 02:53:48,080] Trial 279 finished with value: 0.9315673046182901 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9249290232049638, 'batch_size': 71, 'attention_heads': 10, 'hidden_dimension': 180, 'number_of_hidden_layers': 0, 'dropout_rate': 0.42683331644206013, 'global_pooling': 'max', 'learning_rate': 0.0012060668265688017, 'weight_decay': 6.715100242835032e-05, 'beta_0': 0.8000522773213219, 'beta_1': 0.9868323351149834, 'epsilon': 2.2656363743660732e-05, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 03:04:05,087] Trial 280 finished with value: 0.9164769456311496 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9252766382312125, 'batch_size': 82, 'attention_heads': 10, 'hidden_dimension': 178, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4292067054999889, 'global_pooling': 'max', 'learning_rate': 0.001162007329184364, 'weight_decay': 5.183520797314693e-05, 'beta_0': 0.8015484153719329, 'beta_1': 0.9867202679248684, 'epsilon': 2.6602909395973182e-05, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 03:14:35,535] Trial 281 finished with value: 0.9162387656610101 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.93244484272263, 'batch_size': 72, 'attention_heads': 10, 'hidden_dimension': 182, 'number_of_hidden_layers': 0, 'dropout_rate': 0.48419638730090403, 'global_pooling': 'max', 'learning_rate': 0.0006426308119709554, 'weight_decay': 6.498426279457869e-05, 'beta_0': 0.800105422539977, 'beta_1': 0.9869798078182856, 'epsilon': 7.309441248245203e-05, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 3.60 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.33 GiB is free. Including non-PyTorch memory, this process has 43.22 GiB memory in use. Of the allocated memory 41.65 GiB is allocated by PyTorch, and 429.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 03:21:52,113] Trial 282 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8266741238491848, 'batch_size': 62, 'attention_heads': 13, 'hidden_dimension': 188, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37482954617688125, 'global_pooling': 'max', 'learning_rate': 0.0009769596775295731, 'weight_decay': 5.767304397710395e-05, 'beta_0': 0.8026781910742509, 'beta_1': 0.9832987635328736, 'epsilon': 2.1967197467071677e-05, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 5}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 03:31:21,480] Trial 283 finished with value: 0.8705261208363387 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9221304586109903, 'batch_size': 70, 'attention_heads': 8, 'hidden_dimension': 178, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3441337889352091, 'global_pooling': 'sum', 'learning_rate': 0.039348461092948, 'weight_decay': 7.698794525649397e-05, 'beta_0': 0.8484352146215216, 'beta_1': 0.9865231218521645, 'epsilon': 8.224885818414417e-05, 'balanced_loss': True, 'epochs': 107, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 03:42:03,495] Trial 284 finished with value: 0.9213114375478968 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.881773843409383, 'batch_size': 79, 'attention_heads': 9, 'hidden_dimension': 175, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3364301724351765, 'global_pooling': 'max', 'learning_rate': 0.0021388068537596524, 'weight_decay': 6.62377373910097e-05, 'beta_0': 0.8673994337011018, 'beta_1': 0.9862343002492687, 'epsilon': 1.2906212322795553e-05, 'balanced_loss': True, 'epochs': 128, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 03:58:47,707] Trial 285 finished with value: 0.9256936116873481 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9382844516188898, 'batch_size': 68, 'attention_heads': 12, 'hidden_dimension': 172, 'number_of_hidden_layers': 2, 'dropout_rate': 0.465383472464152, 'global_pooling': 'max', 'learning_rate': 0.0008149866161228261, 'weight_decay': 8.65911001535532e-05, 'beta_0': 0.892739122232157, 'beta_1': 0.9867447435287088, 'epsilon': 3.419022127068659e-05, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 21, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 04:07:54,097] Trial 286 finished with value: 0.9260075136216868 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8900487903451947, 'batch_size': 73, 'attention_heads': 12, 'hidden_dimension': 166, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3315227879797534, 'global_pooling': 'max', 'learning_rate': 0.0012104569338874996, 'weight_decay': 0.00018722622302885282, 'beta_0': 0.8129504060952712, 'beta_1': 0.9858841569931877, 'epsilon': 2.375450217477622e-05, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 12, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 04:18:13,804] Trial 287 finished with value: 0.9234879676813649 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9156977002223674, 'batch_size': 54, 'attention_heads': 13, 'hidden_dimension': 138, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34149060540046894, 'global_pooling': 'max', 'learning_rate': 0.0014113945875743024, 'weight_decay': 0.0002502410006480892, 'beta_0': 0.8562884279792924, 'beta_1': 0.9909104976699193, 'epsilon': 3.080620561763718e-08, 'balanced_loss': True, 'epochs': 132, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 04:27:10,027] Trial 288 finished with value: 0.9245919424625091 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9479688983346306, 'batch_size': 99, 'attention_heads': 10, 'hidden_dimension': 158, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35198719818356644, 'global_pooling': 'max', 'learning_rate': 0.0019025451192631543, 'weight_decay': 5.424992630709786e-05, 'beta_0': 0.8165899730704458, 'beta_1': 0.9903007137480148, 'epsilon': 1.5882096513046637e-05, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 04:36:46,408] Trial 289 finished with value: 0.920685622509441 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9300503078711425, 'batch_size': 85, 'attention_heads': 12, 'hidden_dimension': 129, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3251649984635405, 'global_pooling': 'max', 'learning_rate': 0.0009917392067690454, 'weight_decay': 7.367348501484586e-05, 'beta_0': 0.8378856460655116, 'beta_1': 0.9870837523244879, 'epsilon': 5.719211456427298e-05, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 14, 'plateau_patience': 24, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 4.60 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.24 GiB is free. Including non-PyTorch memory, this process has 41.31 GiB memory in use. Of the allocated memory 39.27 GiB is allocated by PyTorch, and 908.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 04:44:41,201] Trial 290 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8990460961623116, 'batch_size': 103, 'attention_heads': 12, 'hidden_dimension': 170, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3345746611464374, 'global_pooling': 'max', 'learning_rate': 0.0007510993958496776, 'weight_decay': 4.81535994299996e-05, 'beta_0': 0.8307104291776675, 'beta_1': 0.9862882714296797, 'epsilon': 9.785738779910386e-06, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 5}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 04:55:11,296] Trial 291 finished with value: 0.9105189031122043 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9070923163719217, 'batch_size': 76, 'attention_heads': 13, 'hidden_dimension': 192, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3201084241884389, 'global_pooling': 'max', 'learning_rate': 0.0026182753083264527, 'weight_decay': 0.00010263540282399247, 'beta_0': 0.8000682077387881, 'beta_1': 0.9856015498860133, 'epsilon': 1.9071809843540096e-05, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 05:06:55,762] Trial 292 finished with value: 0.9342030260239873 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8964583169410468, 'batch_size': 91, 'attention_heads': 10, 'hidden_dimension': 183, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32800959646617983, 'global_pooling': 'max', 'learning_rate': 0.0016739205590408587, 'weight_decay': 0.0001296412092077529, 'beta_0': 0.8046724520595107, 'beta_1': 0.9974504929626943, 'epsilon': 2.9442934090546713e-05, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 3.62 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.45 GiB is free. Including non-PyTorch memory, this process has 42.10 GiB memory in use. Of the allocated memory 37.28 GiB is allocated by PyTorch, and 3.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 05:14:17,837] Trial 293 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8659156802860463, 'batch_size': 91, 'attention_heads': 10, 'hidden_dimension': 186, 'number_of_hidden_layers': 0, 'dropout_rate': 0.41654671593414705, 'global_pooling': 'max', 'learning_rate': 0.0016405836784496133, 'weight_decay': 0.0001419019282128171, 'beta_0': 0.8091918330904168, 'beta_1': 0.9987185466546301, 'epsilon': 3.093500605948067e-05, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 05:24:50,698] Trial 294 finished with value: 0.9341850465593842 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9248474908920914, 'batch_size': 64, 'attention_heads': 10, 'hidden_dimension': 182, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3613697767265685, 'global_pooling': 'max', 'learning_rate': 0.0017553507940094553, 'weight_decay': 0.0001255164047677881, 'beta_0': 0.8051558578370408, 'beta_1': 0.9960403931325764, 'epsilon': 4.137082205600356e-05, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 05:34:46,025] Trial 295 finished with value: 0.9289532999978265 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9346057377217036, 'batch_size': 63, 'attention_heads': 10, 'hidden_dimension': 177, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4454467581539779, 'global_pooling': 'max', 'learning_rate': 0.0021066123314083638, 'weight_decay': 0.0001254268586284939, 'beta_0': 0.8053204833383325, 'beta_1': 0.9981141760779337, 'epsilon': 4.2297337014947415e-05, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 05:45:02,659] Trial 296 finished with value: 0.9195280891299942 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9352386311249673, 'batch_size': 66, 'attention_heads': 10, 'hidden_dimension': 182, 'number_of_hidden_layers': 0, 'dropout_rate': 0.38451859220950907, 'global_pooling': 'max', 'learning_rate': 0.0025516352735470674, 'weight_decay': 0.00012406315863089094, 'beta_0': 0.8053089421923291, 'beta_1': 0.9984007480937047, 'epsilon': 4.1196503380184226e-05, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 05:54:38,598] Trial 297 finished with value: 0.905110766946172 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9394292946516203, 'batch_size': 66, 'attention_heads': 10, 'hidden_dimension': 190, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4338067325639927, 'global_pooling': 'max', 'learning_rate': 0.0031989773328268546, 'weight_decay': 0.00016487492968649808, 'beta_0': 0.8030966921063583, 'beta_1': 0.99730311148735, 'epsilon': 5.0201080829818346e-05, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 06:04:59,463] Trial 298 finished with value: 0.9252969699642722 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9272424193305914, 'batch_size': 60, 'attention_heads': 10, 'hidden_dimension': 182, 'number_of_hidden_layers': 0, 'dropout_rate': 0.361829574731196, 'global_pooling': 'max', 'learning_rate': 0.0020904913775469033, 'weight_decay': 0.0001359014280147725, 'beta_0': 0.8071340811422545, 'beta_1': 0.9982010911064749, 'epsilon': 4.038157714523684e-05, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 06:13:06,342] Trial 299 finished with value: 0.9109867348736195 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9493901319503516, 'batch_size': 63, 'attention_heads': 10, 'hidden_dimension': 186, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4521038758563753, 'global_pooling': 'max', 'learning_rate': 0.0018203085085794586, 'weight_decay': 0.0001129087983292285, 'beta_0': 0.8814065493410206, 'beta_1': 0.9943625005494655, 'epsilon': 3.7480973437340196e-05, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 06:23:16,428] Trial 300 finished with value: 0.9170760073175704 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.925060677587113, 'batch_size': 51, 'attention_heads': 10, 'hidden_dimension': 178, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4367255712816919, 'global_pooling': 'max', 'learning_rate': 0.0022785200817726477, 'weight_decay': 0.00015239616142831127, 'beta_0': 0.8025179062625538, 'beta_1': 0.9925295831171533, 'epsilon': 2.7190533814539188e-05, 'balanced_loss': True, 'epochs': 130, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 06:33:30,742] Trial 301 finished with value: 0.9188225074409172 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9353089444620009, 'batch_size': 57, 'attention_heads': 10, 'hidden_dimension': 179, 'number_of_hidden_layers': 0, 'dropout_rate': 0.44600256367077934, 'global_pooling': 'max', 'learning_rate': 0.0018574868274010355, 'weight_decay': 9.15392881432161e-05, 'beta_0': 0.805445035831805, 'beta_1': 0.9982722608990725, 'epsilon': 5.0622551271027095e-05, 'balanced_loss': True, 'epochs': 135, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 06:43:40,673] Trial 302 finished with value: 0.9059002833598939 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9194641996872672, 'batch_size': 71, 'attention_heads': 9, 'hidden_dimension': 181, 'number_of_hidden_layers': 0, 'dropout_rate': 0.44567327166271725, 'global_pooling': 'max', 'learning_rate': 0.0015557984161329622, 'weight_decay': 0.00012852379803226903, 'beta_0': 0.8045064498606704, 'beta_1': 0.9959246794482661, 'epsilon': 3.389134676953608e-05, 'balanced_loss': True, 'epochs': 120, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 06:53:02,415] Trial 303 finished with value: 0.9194592201830425 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9582978709573571, 'batch_size': 64, 'attention_heads': 10, 'hidden_dimension': 193, 'number_of_hidden_layers': 0, 'dropout_rate': 0.36866813437313667, 'global_pooling': 'max', 'learning_rate': 0.0026520709346670155, 'weight_decay': 0.00010325411988764838, 'beta_0': 0.8017580620686056, 'beta_1': 0.9977532280480795, 'epsilon': 2.6550059943140066e-05, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 22, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 07:02:50,197] Trial 304 finished with value: 0.9207420441153329 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.925798960528286, 'batch_size': 78, 'attention_heads': 12, 'hidden_dimension': 175, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35774859198354, 'global_pooling': 'max', 'learning_rate': 0.0016768434635951598, 'weight_decay': 0.00018520192317904028, 'beta_0': 0.8072386645952135, 'beta_1': 0.9963230388031128, 'epsilon': 6.472133359035703e-05, 'balanced_loss': True, 'epochs': 132, 'early_stopping_patience': 10, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 07:13:35,143] Trial 305 finished with value: 0.9290845602711255 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9311174342642743, 'batch_size': 59, 'attention_heads': 11, 'hidden_dimension': 185, 'number_of_hidden_layers': 0, 'dropout_rate': 0.47108061720590466, 'global_pooling': 'max', 'learning_rate': 0.002123956647570029, 'weight_decay': 8.812163460561166e-05, 'beta_0': 0.8036903003651067, 'beta_1': 0.9972917969866146, 'epsilon': 2.2435300856053708e-05, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 07:23:27,123] Trial 306 finished with value: 0.8867552492272393 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9377342677356919, 'batch_size': 57, 'attention_heads': 11, 'hidden_dimension': 186, 'number_of_hidden_layers': 0, 'dropout_rate': 0.46112608643805547, 'global_pooling': 'max', 'learning_rate': 0.0036767284900237943, 'weight_decay': 8.339685986275657e-05, 'beta_0': 0.8035436321253987, 'beta_1': 0.9975516539034017, 'epsilon': 5.740609029024587e-06, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 07:33:13,104] Trial 307 finished with value: 0.8738785271056065 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9324131993215242, 'batch_size': 63, 'attention_heads': 11, 'hidden_dimension': 196, 'number_of_hidden_layers': 0, 'dropout_rate': 0.46982202730929656, 'global_pooling': 'max', 'learning_rate': 0.0154033431805622, 'weight_decay': 8.275757391975636e-05, 'beta_0': 0.8000814303905037, 'beta_1': 0.9933004990856124, 'epsilon': 2.2295432410126256e-05, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 07:41:56,906] Trial 308 finished with value: 0.8905228977980013 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9414974499330792, 'batch_size': 57, 'attention_heads': 11, 'hidden_dimension': 185, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4996742675692636, 'global_pooling': 'max', 'learning_rate': 0.0021582595859818365, 'weight_decay': 9.166898318053326e-05, 'beta_0': 0.8430714485754283, 'beta_1': 0.9970667626323196, 'epsilon': 1.7623001611902462e-05, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 2.78 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.58 GiB is free. Including non-PyTorch memory, this process has 42.97 GiB memory in use. Of the allocated memory 41.50 GiB is allocated by PyTorch, and 329.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 07:49:13,182] Trial 309 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8428970176148111, 'batch_size': 69, 'attention_heads': 10, 'hidden_dimension': 180, 'number_of_hidden_layers': 3, 'dropout_rate': 0.48958318922975314, 'global_pooling': 'max', 'learning_rate': 0.0012596789273733229, 'weight_decay': 6.910538575867898e-05, 'beta_0': 0.8034866671881075, 'beta_1': 0.9982949895974796, 'epsilon': 1.3282097168003e-05, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 07:59:32,507] Trial 310 finished with value: 0.915125200563758 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9302440355297569, 'batch_size': 64, 'attention_heads': 11, 'hidden_dimension': 204, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4767066687284416, 'global_pooling': 'max', 'learning_rate': 0.0014492026048641513, 'weight_decay': 0.00010425234228853346, 'beta_0': 0.8018039797306534, 'beta_1': 0.9970753539874456, 'epsilon': 2.220713670909783e-05, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 4.73 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.53 GiB is free. Including non-PyTorch memory, this process has 42.02 GiB memory in use. Of the allocated memory 37.16 GiB is allocated by PyTorch, and 3.71 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 08:05:49,571] Trial 311 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9186427771226607, 'batch_size': 192, 'attention_heads': 11, 'hidden_dimension': 191, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3481390154618831, 'global_pooling': 'max', 'learning_rate': 0.0011573803279655453, 'weight_decay': 7.922095736336295e-05, 'beta_0': 0.8058038412969638, 'beta_1': 0.997764773197108, 'epsilon': 1.4842199428710502e-05, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 08:15:32,076] Trial 312 finished with value: 0.9169321560710602 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9232364334925376, 'batch_size': 59, 'attention_heads': 11, 'hidden_dimension': 116, 'number_of_hidden_layers': 0, 'dropout_rate': 0.44552232163808214, 'global_pooling': 'max', 'learning_rate': 0.0020585135444897346, 'weight_decay': 6.155984686072906e-06, 'beta_0': 0.8233913039734972, 'beta_1': 0.9977932688946518, 'epsilon': 1.067661080108291e-05, 'balanced_loss': True, 'epochs': 130, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 08:29:22,299] Trial 313 finished with value: 0.8991075488323572 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9167110226227534, 'batch_size': 53, 'attention_heads': 10, 'hidden_dimension': 184, 'number_of_hidden_layers': 1, 'dropout_rate': 0.40427030489517424, 'global_pooling': 'sum', 'learning_rate': 0.0015260439113808002, 'weight_decay': 9.60254374764392e-05, 'beta_0': 0.8042193734781619, 'beta_1': 0.9938958427678959, 'epsilon': 4.514856014078276e-05, 'balanced_loss': True, 'epochs': 140, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
CUDA out of memory. Tried to allocate 240.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 146.69 MiB is free. Including non-PyTorch memory, this process has 44.41 GiB memory in use. Of the allocated memory 42.64 GiB is allocated by PyTorch, and 631.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-03-02 08:36:26,626] Trial 314 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.6536941901394503, 'batch_size': 107, 'attention_heads': 9, 'hidden_dimension': 176, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3612218944784784, 'global_pooling': 'max', 'learning_rate': 0.0029836125464569505, 'weight_decay': 0.00020787747200461346, 'beta_0': 0.8018815931467947, 'beta_1': 0.9963531138721343, 'epsilon': 1.7888069174510526e-05, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 08:46:40,178] Trial 315 finished with value: 0.9275698990623192 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9424095182835021, 'batch_size': 47, 'attention_heads': 11, 'hidden_dimension': 154, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4722453002933209, 'global_pooling': 'max', 'learning_rate': 0.001152491764271183, 'weight_decay': 0.00015659716555727036, 'beta_0': 0.8855490599887967, 'beta_1': 0.996753986865398, 'epsilon': 4.7425955848857464e-07, 'balanced_loss': True, 'epochs': 103, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 08:56:30,983] Trial 316 finished with value: 0.9182646180142449 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.942716817501287, 'batch_size': 45, 'attention_heads': 11, 'hidden_dimension': 148, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4704809835302574, 'global_pooling': 'max', 'learning_rate': 0.0012194475984049229, 'weight_decay': 0.00015546097075488848, 'beta_0': 0.8076324418370293, 'beta_1': 0.9967915671628028, 'epsilon': 9.984573857741273e-05, 'balanced_loss': True, 'epochs': 103, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 09:04:58,159] Trial 317 finished with value: 0.9199355167175536 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9404019929383224, 'batch_size': 49, 'attention_heads': 11, 'hidden_dimension': 153, 'number_of_hidden_layers': 0, 'dropout_rate': 0.46409006860952273, 'global_pooling': 'max', 'learning_rate': 0.0023344388409278073, 'weight_decay': 0.00011640562907336138, 'beta_0': 0.8060369608839175, 'beta_1': 0.9967373675483817, 'epsilon': 2.592191703477973e-07, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 20, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 09:15:02,635] Trial 318 finished with value: 0.923251525731053 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9339097705972886, 'batch_size': 69, 'attention_heads': 11, 'hidden_dimension': 151, 'number_of_hidden_layers': 0, 'dropout_rate': 0.48476255494177367, 'global_pooling': 'max', 'learning_rate': 0.00179120552609937, 'weight_decay': 0.00016454323645779403, 'beta_0': 0.8865313818273418, 'beta_1': 0.9954109637916428, 'epsilon': 1.665782005911741e-07, 'balanced_loss': True, 'epochs': 99, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 09:24:37,188] Trial 319 finished with value: 0.9117370629011536 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.944293887274837, 'batch_size': 44, 'attention_heads': 10, 'hidden_dimension': 141, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4749155696494275, 'global_pooling': 'max', 'learning_rate': 0.0013942131309455203, 'weight_decay': 0.00014234187499310833, 'beta_0': 0.874980214607308, 'beta_1': 0.9962582363031682, 'epsilon': 8.424549232859537e-07, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 09:54:47,827] Trial 320 finished with value: 0.7575341564108604 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9574044441176253, 'batch_size': 61, 'attention_heads': 14, 'hidden_dimension': 190, 'number_of_hidden_layers': 4, 'dropout_rate': 0.47917007709066106, 'global_pooling': 'max', 'learning_rate': 0.0010109713192774973, 'weight_decay': 0.00022999826397343697, 'beta_0': 0.804836266545464, 'beta_1': 0.9971477250510374, 'epsilon': 4.0488278359779275e-07, 'balanced_loss': True, 'epochs': 106, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 10:04:36,496] Trial 321 finished with value: 0.9253093077648178 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9467015470728014, 'batch_size': 73, 'attention_heads': 11, 'hidden_dimension': 147, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4195724441475809, 'global_pooling': 'max', 'learning_rate': 0.0013588577711277563, 'weight_decay': 0.0001927792748591035, 'beta_0': 0.8079914222926023, 'beta_1': 0.9973988969419106, 'epsilon': 6.754784228946469e-05, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 6}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 10:13:26,725] Trial 322 finished with value: 0.9093971534188916 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9527375940358976, 'batch_size': 50, 'attention_heads': 10, 'hidden_dimension': 95, 'number_of_hidden_layers': 0, 'dropout_rate': 0.45925591136813726, 'global_pooling': 'max', 'learning_rate': 0.0016657394258300408, 'weight_decay': 0.0003490619648645305, 'beta_0': 0.8000266985482923, 'beta_1': 0.9974125137561409, 'epsilon': 5.635154272115806e-05, 'balanced_loss': True, 'epochs': 101, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
[I 2025-03-02 10:23:10,103] Trial 323 finished with value: 0.9273466043154028 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9304809245398473, 'batch_size': 36, 'attention_heads': 10, 'hidden_dimension': 155, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35546253051464805, 'global_pooling': 'max', 'learning_rate': 0.0011241003931714312, 'weight_decay': 0.0002772878251177619, 'beta_0': 0.803419861071794, 'beta_1': 0.9976027981033722, 'epsilon': 8.050782793963609e-05, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 228 with value: 0.940926033029364.
slurmstepd: error: *** JOB 15068786 ON gpu049 CANCELLED AT 2025-03-02T10:24:12 DUE TO TIME LIMIT ***
