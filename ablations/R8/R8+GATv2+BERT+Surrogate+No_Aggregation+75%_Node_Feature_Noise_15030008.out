[I 2025-02-27 03:39:00,251] Using an existing study with name 'R8-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation-No_Ablation-1.0-0.75' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors
[I 2025-02-27 03:48:48,564] Trial 113 finished with value: 0.9196297830628513 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8997258174385352, 'batch_size': 196, 'attention_heads': 12, 'hidden_dimension': 98, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32187095800205795, 'global_pooling': 'max', 'learning_rate': 0.001062000239599519, 'weight_decay': 0.00028067965775308956, 'beta_0': 0.8143757744336667, 'beta_1': 0.986642708930525, 'epsilon': 2.169400481565404e-05, 'balanced_loss': True, 'epochs': 137, 'early_stopping_patience': 14, 'plateau_patience': 21, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 03:57:50,050] Trial 114 finished with value: 0.917681003280703 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9293627976901854, 'batch_size': 112, 'attention_heads': 11, 'hidden_dimension': 128, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3406236542487304, 'global_pooling': 'max', 'learning_rate': 0.0019811775255169383, 'weight_decay': 0.00012034247570838079, 'beta_0': 0.8096774990411476, 'beta_1': 0.984886452982726, 'epsilon': 5.7140279169963756e-05, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 04:07:14,442] Trial 115 finished with value: 0.9213560434940803 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9272797574300283, 'batch_size': 106, 'attention_heads': 11, 'hidden_dimension': 105, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3369274498254472, 'global_pooling': 'max', 'learning_rate': 0.0014611614506893887, 'weight_decay': 0.00023421104213088722, 'beta_0': 0.8018122038778991, 'beta_1': 0.9850129288507966, 'epsilon': 7.344050515263015e-05, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 04:17:47,843] Trial 116 finished with value: 0.9222109945916864 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9153340464430275, 'batch_size': 99, 'attention_heads': 11, 'hidden_dimension': 142, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3168029961388279, 'global_pooling': 'max', 'learning_rate': 0.001451926742101279, 'weight_decay': 0.00021449742486139044, 'beta_0': 0.8013225017384539, 'beta_1': 0.9852052028261848, 'epsilon': 8.730527301241329e-05, 'balanced_loss': True, 'epochs': 122, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 04:27:42,411] Trial 117 finished with value: 0.9187902415371418 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9122923391168395, 'batch_size': 105, 'attention_heads': 11, 'hidden_dimension': 106, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31078035882562643, 'global_pooling': 'max', 'learning_rate': 0.0014594709347630023, 'weight_decay': 0.00024174960709848548, 'beta_0': 0.8014654294308914, 'beta_1': 0.9854139114227071, 'epsilon': 6.533098457084308e-05, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 04:38:46,525] Trial 118 finished with value: 0.9351979215114055 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8912428687180156, 'batch_size': 101, 'attention_heads': 10, 'hidden_dimension': 140, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31579884792204416, 'global_pooling': 'max', 'learning_rate': 0.0011446468386151836, 'weight_decay': 7.358563178098008e-05, 'beta_0': 0.8020946683438519, 'beta_1': 0.9862395640504047, 'epsilon': 9.21586490181127e-05, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 04:49:55,930] Trial 119 finished with value: 0.9250311207589754 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8902678037822863, 'batch_size': 99, 'attention_heads': 10, 'hidden_dimension': 141, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31684630782457424, 'global_pooling': 'max', 'learning_rate': 0.0008136548539352906, 'weight_decay': 6.049070306383993e-05, 'beta_0': 0.806102508447635, 'beta_1': 0.9860966764511248, 'epsilon': 8.125595357789761e-05, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 05:00:37,781] Trial 120 finished with value: 0.9216052677051682 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8883772383746564, 'batch_size': 88, 'attention_heads': 9, 'hidden_dimension': 141, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3149928887922314, 'global_pooling': 'max', 'learning_rate': 0.0007821473838980483, 'weight_decay': 3.719865258572425e-05, 'beta_0': 0.8044843632791626, 'beta_1': 0.9859484648985035, 'epsilon': 9.731231812040547e-05, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 05:11:36,519] Trial 121 finished with value: 0.9247354620063198 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.865128009096493, 'batch_size': 99, 'attention_heads': 9, 'hidden_dimension': 142, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31520396712614296, 'global_pooling': 'mean', 'learning_rate': 0.0007720508578632023, 'weight_decay': 3.414512288629647e-05, 'beta_0': 0.8062400802719485, 'beta_1': 0.9859860796282013, 'epsilon': 9.586059158437172e-05, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 05:22:29,395] Trial 122 finished with value: 0.9185475276301487 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.861567061434677, 'batch_size': 99, 'attention_heads': 9, 'hidden_dimension': 152, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3051838273729973, 'global_pooling': 'mean', 'learning_rate': 0.0010093023973536523, 'weight_decay': 5.57958356444448e-05, 'beta_0': 0.8060141691406825, 'beta_1': 0.987078854071131, 'epsilon': 7.866245867537666e-05, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 21, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 05:32:39,481] Trial 123 finished with value: 0.8978474424687146 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8721608724450005, 'batch_size': 124, 'attention_heads': 10, 'hidden_dimension': 131, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3188098650155102, 'global_pooling': 'mean', 'learning_rate': 0.09285939748894982, 'weight_decay': 3.215566425328162e-05, 'beta_0': 0.8094926663165879, 'beta_1': 0.9878926902862211, 'epsilon': 4.772938522231351e-05, 'balanced_loss': True, 'epochs': 99, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 05:43:04,816] Trial 124 finished with value: 0.9190410577487227 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8876279430056759, 'batch_size': 91, 'attention_heads': 9, 'hidden_dimension': 141, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3002009861490431, 'global_pooling': 'mean', 'learning_rate': 0.0007479816249301369, 'weight_decay': 1.3800267186532668e-05, 'beta_0': 0.8066085279252377, 'beta_1': 0.9858373242872477, 'epsilon': 9.855021588050417e-05, 'balanced_loss': True, 'epochs': 107, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 3.25 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.62 GiB is free. Including non-PyTorch memory, this process has 41.93 GiB memory in use. Of the allocated memory 37.54 GiB is allocated by PyTorch, and 3.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 05:50:36,132] Trial 125 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8486206846596582, 'batch_size': 98, 'attention_heads': 10, 'hidden_dimension': 143, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3161701819435174, 'global_pooling': 'mean', 'learning_rate': 0.0005357059659803666, 'weight_decay': 2.782216351470268e-05, 'beta_0': 0.8042368069162192, 'beta_1': 0.9860366358712965, 'epsilon': 8.898913441484248e-05, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 06:00:50,996] Trial 126 finished with value: 0.9265274388911917 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8980197698570818, 'batch_size': 88, 'attention_heads': 10, 'hidden_dimension': 146, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3249965227142663, 'global_pooling': 'mean', 'learning_rate': 0.0008198421702215188, 'weight_decay': 3.9869471496973626e-05, 'beta_0': 0.8116049594852159, 'beta_1': 0.9852186939272372, 'epsilon': 7.957184431502705e-05, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 06:11:15,902] Trial 127 finished with value: 0.9187987462707814 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8958624308330019, 'batch_size': 102, 'attention_heads': 10, 'hidden_dimension': 117, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3287161730157117, 'global_pooling': 'mean', 'learning_rate': 0.000333308619662872, 'weight_decay': 4.420308933412844e-05, 'beta_0': 0.8121020600956824, 'beta_1': 0.9843250019096462, 'epsilon': 3.791687346921866e-05, 'balanced_loss': True, 'epochs': 95, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 06:21:24,108] Trial 128 finished with value: 0.9290983614284849 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8654366390591786, 'batch_size': 114, 'attention_heads': 8, 'hidden_dimension': 149, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3230810205932666, 'global_pooling': 'mean', 'learning_rate': 0.0011635489708838793, 'weight_decay': 3.74093814353546e-05, 'beta_0': 0.8085518922046883, 'beta_1': 0.9852691638974974, 'epsilon': 7.519912834645461e-05, 'balanced_loss': True, 'epochs': 104, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 3.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 984.69 MiB is free. Including non-PyTorch memory, this process has 43.59 GiB memory in use. Of the allocated memory 40.01 GiB is allocated by PyTorch, and 2.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 06:28:56,351] Trial 129 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8385943850761652, 'batch_size': 114, 'attention_heads': 8, 'hidden_dimension': 148, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32627496566900344, 'global_pooling': 'mean', 'learning_rate': 0.001156895586820305, 'weight_decay': 1.946432636447373e-05, 'beta_0': 0.8088318455404877, 'beta_1': 0.9868414107680696, 'epsilon': 5.122790869669872e-05, 'balanced_loss': True, 'epochs': 104, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 06:39:28,901] Trial 130 finished with value: 0.9245621836206489 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8789701797793428, 'batch_size': 94, 'attention_heads': 9, 'hidden_dimension': 162, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32177989888424724, 'global_pooling': 'mean', 'learning_rate': 0.0009505161707721038, 'weight_decay': 3.804876991225489e-05, 'beta_0': 0.8163954680272026, 'beta_1': 0.9856858053229348, 'epsilon': 6.610633655964655e-05, 'balanced_loss': True, 'epochs': 91, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 3.49 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.92 GiB is free. Including non-PyTorch memory, this process has 41.63 GiB memory in use. Of the allocated memory 36.83 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 06:46:53,440] Trial 131 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8708137236395831, 'batch_size': 121, 'attention_heads': 10, 'hidden_dimension': 169, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3463261032565617, 'global_pooling': 'mean', 'learning_rate': 0.0005708719404755173, 'weight_decay': 5.092592723976447e-05, 'beta_0': 0.8110115765227375, 'beta_1': 0.9885844636242958, 'epsilon': 3.437212030710179e-05, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.09 GiB is free. Including non-PyTorch memory, this process has 42.46 GiB memory in use. Of the allocated memory 35.13 GiB is allocated by PyTorch, and 6.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 06:55:19,972] Trial 132 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8671830796542291, 'batch_size': 108, 'attention_heads': 8, 'hidden_dimension': 155, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3057350406117299, 'global_pooling': 'mean', 'learning_rate': 0.0008644724366656432, 'weight_decay': 6.213363717000744e-05, 'beta_0': 0.8074080376764233, 'beta_1': 0.9839744689966127, 'epsilon': 2.6341657129341773e-05, 'balanced_loss': True, 'epochs': 154, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 07:05:01,427] Trial 133 finished with value: 0.9135810967596902 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8962147295987202, 'batch_size': 86, 'attention_heads': 7, 'hidden_dimension': 131, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3442657838569995, 'global_pooling': 'mean', 'learning_rate': 0.00043095571146851047, 'weight_decay': 2.5649124289505755e-05, 'beta_0': 0.8138304953325075, 'beta_1': 0.9852752749795021, 'epsilon': 7.797974827780745e-05, 'balanced_loss': True, 'epochs': 131, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 07:15:34,753] Trial 134 finished with value: 0.9212277794926724 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8784250542284342, 'batch_size': 94, 'attention_heads': 9, 'hidden_dimension': 161, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3227189654847724, 'global_pooling': 'mean', 'learning_rate': 0.0011227748273073144, 'weight_decay': 4.094569975180836e-05, 'beta_0': 0.822974870177479, 'beta_1': 0.9846035208452517, 'epsilon': 6.568540827505414e-05, 'balanced_loss': True, 'epochs': 92, 'early_stopping_patience': 19, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 07:26:46,551] Trial 135 finished with value: 0.9181833727586262 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8810627351136957, 'batch_size': 95, 'attention_heads': 9, 'hidden_dimension': 151, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33007389089471056, 'global_pooling': 'mean', 'learning_rate': 0.0006905333431832588, 'weight_decay': 3.611358699210405e-05, 'beta_0': 0.8159539083037483, 'beta_1': 0.9855625065964768, 'epsilon': 5.6251600264151e-05, 'balanced_loss': True, 'epochs': 86, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 07:37:05,667] Trial 136 finished with value: 0.9263159886584859 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8929833273658291, 'batch_size': 116, 'attention_heads': 8, 'hidden_dimension': 166, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3233454569307454, 'global_pooling': 'mean', 'learning_rate': 0.0009107992501915367, 'weight_decay': 4.713159564277992e-05, 'beta_0': 0.89986087646536, 'beta_1': 0.986548181518308, 'epsilon': 2.0174837471266533e-05, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 17, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 07:46:47,925] Trial 137 finished with value: 0.9189057718719196 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8907673206849415, 'batch_size': 119, 'attention_heads': 8, 'hidden_dimension': 167, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3115028137691287, 'global_pooling': 'mean', 'learning_rate': 0.0012383528007176758, 'weight_decay': 5.169085423083491e-05, 'beta_0': 0.8882685599814263, 'beta_1': 0.9867213370458134, 'epsilon': 1.9054037059253264e-05, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 17, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 07:56:19,316] Trial 138 finished with value: 0.9260852068219201 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8999994748097738, 'batch_size': 115, 'attention_heads': 7, 'hidden_dimension': 147, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3287610822901571, 'global_pooling': 'mean', 'learning_rate': 0.0009146440918425792, 'weight_decay': 3.0545674888636614e-05, 'beta_0': 0.8063941145950523, 'beta_1': 0.9873834887980782, 'epsilon': 4.370188295384713e-05, 'balanced_loss': True, 'epochs': 100, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 08:05:10,799] Trial 139 finished with value: 0.9232625150466184 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9032082979250066, 'batch_size': 114, 'attention_heads': 6, 'hidden_dimension': 148, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3527804531217091, 'global_pooling': 'mean', 'learning_rate': 0.0018233640834062913, 'weight_decay': 4.474037938310807e-05, 'beta_0': 0.8087786704597563, 'beta_1': 0.9873914892251973, 'epsilon': 4.441393480369227e-05, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 08:14:25,178] Trial 140 finished with value: 0.9154066918372166 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.910190493574854, 'batch_size': 108, 'attention_heads': 7, 'hidden_dimension': 137, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3313319867536479, 'global_pooling': 'mean', 'learning_rate': 0.0009302046045267863, 'weight_decay': 2.008759118856948e-05, 'beta_0': 0.8026403033146658, 'beta_1': 0.9864756237232075, 'epsilon': 1.4631058223627979e-05, 'balanced_loss': True, 'epochs': 98, 'early_stopping_patience': 17, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 08:24:05,918] Trial 141 finished with value: 0.9248646689130796 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8991738147813158, 'batch_size': 124, 'attention_heads': 7, 'hidden_dimension': 155, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3397742937479609, 'global_pooling': 'mean', 'learning_rate': 0.0005714965411430279, 'weight_decay': 2.9613281146306715e-05, 'beta_0': 0.8404920839550495, 'beta_1': 0.9871201507073183, 'epsilon': 2.466642151907216e-05, 'balanced_loss': True, 'epochs': 101, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 08:33:49,262] Trial 142 finished with value: 0.9151529253657311 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9184184225442156, 'batch_size': 133, 'attention_heads': 12, 'hidden_dimension': 124, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3271872550250859, 'global_pooling': 'mean', 'learning_rate': 0.00117028494722547, 'weight_decay': 6.043442683243526e-05, 'beta_0': 0.8779119637690382, 'beta_1': 0.9876620346716753, 'epsilon': 3.583202143082598e-05, 'balanced_loss': True, 'epochs': 134, 'early_stopping_patience': 17, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 08:43:58,962] Trial 143 finished with value: 0.9214788258903366 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.892801051432858, 'batch_size': 143, 'attention_heads': 8, 'hidden_dimension': 159, 'number_of_hidden_layers': 0, 'dropout_rate': 0.36162753192710945, 'global_pooling': 'mean', 'learning_rate': 0.0005092846175720466, 'weight_decay': 9.397295315710232e-05, 'beta_0': 0.8053195677521267, 'beta_1': 0.9861399784594602, 'epsilon': 2.1011965070624157e-08, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 08:53:59,815] Trial 144 finished with value: 0.9186122238948258 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.90019158351097, 'batch_size': 137, 'attention_heads': 7, 'hidden_dimension': 154, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34081579280547425, 'global_pooling': 'mean', 'learning_rate': 0.000617036297995391, 'weight_decay': 2.9122373820897987e-05, 'beta_0': 0.8448196109126486, 'beta_1': 0.987156711876006, 'epsilon': 1.9639716243513737e-05, 'balanced_loss': True, 'epochs': 104, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 09:03:50,057] Trial 145 finished with value: 0.9159887641461719 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8853751265574431, 'batch_size': 124, 'attention_heads': 7, 'hidden_dimension': 146, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33611501069098076, 'global_pooling': 'mean', 'learning_rate': 0.0007619563685570133, 'weight_decay': 1.5706343770905492e-05, 'beta_0': 0.8664243797500168, 'beta_1': 0.9867694240363775, 'epsilon': 2.31526631260785e-05, 'balanced_loss': True, 'epochs': 97, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 09:12:46,604] Trial 146 finished with value: 0.9104721923084231 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.907586108372538, 'batch_size': 128, 'attention_heads': 6, 'hidden_dimension': 167, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34655734208280436, 'global_pooling': 'mean', 'learning_rate': 0.0010019619006743992, 'weight_decay': 7.505623245056704e-05, 'beta_0': 0.8350322345928076, 'beta_1': 0.9850910676800629, 'epsilon': 2.78282569037832e-05, 'balanced_loss': True, 'epochs': 103, 'early_stopping_patience': 17, 'plateau_patience': 10, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 09:22:52,776] Trial 147 finished with value: 0.9227946563074017 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9006515835728983, 'batch_size': 117, 'attention_heads': 10, 'hidden_dimension': 152, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3225338840438824, 'global_pooling': 'mean', 'learning_rate': 0.0013352959993853748, 'weight_decay': 4.867988395700239e-05, 'beta_0': 0.8407884064124124, 'beta_1': 0.9883123824940168, 'epsilon': 1.0993166800210339e-05, 'balanced_loss': True, 'epochs': 100, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 09:32:19,013] Trial 148 finished with value: 0.9066627898244939 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9221677390125784, 'batch_size': 112, 'attention_heads': 7, 'hidden_dimension': 163, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3326910435227476, 'global_pooling': 'mean', 'learning_rate': 0.0008448499176212808, 'weight_decay': 2.3226205163873514e-05, 'beta_0': 0.8036367648051967, 'beta_1': 0.9863107038510586, 'epsilon': 1.697138893427202e-05, 'balanced_loss': True, 'epochs': 137, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 09:43:35,890] Trial 149 finished with value: 0.911011376917821 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.911457526841693, 'batch_size': 103, 'attention_heads': 12, 'hidden_dimension': 157, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3556325156614351, 'global_pooling': 'max', 'learning_rate': 0.0003683551347818754, 'weight_decay': 3.146715770385286e-05, 'beta_0': 0.8574640064632809, 'beta_1': 0.9855562845761134, 'epsilon': 1.2890589981993127e-05, 'balanced_loss': True, 'epochs': 145, 'early_stopping_patience': 18, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 09:56:35,857] Trial 150 finished with value: 0.9050437855165372 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8938053672204317, 'batch_size': 127, 'attention_heads': 10, 'hidden_dimension': 135, 'number_of_hidden_layers': 0, 'dropout_rate': 0.308528500702533, 'global_pooling': 'sum', 'learning_rate': 0.0005991733308440585, 'weight_decay': 6.722349792968291e-05, 'beta_0': 0.8071802958175622, 'beta_1': 0.9847655763098601, 'epsilon': 2.2779722390485023e-05, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 17, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 10:09:14,466] Trial 151 finished with value: 0.935518809662129 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9041111514645287, 'batch_size': 107, 'attention_heads': 11, 'hidden_dimension': 176, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32511777367946726, 'global_pooling': 'max', 'learning_rate': 0.0016197610138454115, 'weight_decay': 0.00010303509845745622, 'beta_0': 0.8103184521924727, 'beta_1': 0.9891339435604477, 'epsilon': 3.101230791887617e-05, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 4.40 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.65 GiB is free. Including non-PyTorch memory, this process has 41.90 GiB memory in use. Of the allocated memory 39.82 GiB is allocated by PyTorch, and 954.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 10:16:58,771] Trial 152 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8862013049547435, 'batch_size': 107, 'attention_heads': 11, 'hidden_dimension': 175, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3204606344094874, 'global_pooling': 'max', 'learning_rate': 0.0022770383016177836, 'weight_decay': 0.00010562530731464745, 'beta_0': 0.8107549297620069, 'beta_1': 0.988929600137629, 'epsilon': 4.041913336078497e-05, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 10:28:27,878] Trial 153 finished with value: 0.9268014669548945 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9061401823716464, 'batch_size': 89, 'attention_heads': 12, 'hidden_dimension': 169, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3251222957560291, 'global_pooling': 'max', 'learning_rate': 0.001797116330076493, 'weight_decay': 0.00013063505875551538, 'beta_0': 0.8125132759779421, 'beta_1': 0.990050897544653, 'epsilon': 3.0952593348699016e-05, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 10:40:53,715] Trial 154 finished with value: 0.9260716259330091 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9068500969857086, 'batch_size': 90, 'attention_heads': 12, 'hidden_dimension': 169, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3256996192080933, 'global_pooling': 'max', 'learning_rate': 0.001657116143366717, 'weight_decay': 0.0001385986618196212, 'beta_0': 0.8121969114241366, 'beta_1': 0.9901742114669558, 'epsilon': 3.17285010342474e-05, 'balanced_loss': True, 'epochs': 128, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 10:51:35,621] Trial 155 finished with value: 0.9189904322744586 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9340917874246621, 'batch_size': 89, 'attention_heads': 12, 'hidden_dimension': 181, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32663149476076897, 'global_pooling': 'max', 'learning_rate': 0.0016941974231889216, 'weight_decay': 0.0001388198798071924, 'beta_0': 0.8131820214822595, 'beta_1': 0.9902061049179326, 'epsilon': 3.0056385439094854e-05, 'balanced_loss': True, 'epochs': 128, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 11:03:02,194] Trial 156 finished with value: 0.9097719778703854 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9160585836664877, 'batch_size': 85, 'attention_heads': 12, 'hidden_dimension': 169, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33272590649843936, 'global_pooling': 'max', 'learning_rate': 0.001470006078760481, 'weight_decay': 0.00011963308267772331, 'beta_0': 0.8121374999607491, 'beta_1': 0.9909101455291653, 'epsilon': 1.6378850374063858e-05, 'balanced_loss': True, 'epochs': 124, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 11:14:09,974] Trial 157 finished with value: 0.9148390640174979 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9224251543167692, 'batch_size': 83, 'attention_heads': 12, 'hidden_dimension': 164, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3242893529938815, 'global_pooling': 'max', 'learning_rate': 0.001796335080046046, 'weight_decay': 0.00014255966274807398, 'beta_0': 0.8084559522446154, 'beta_1': 0.9891692232198116, 'epsilon': 3.337311714126815e-05, 'balanced_loss': True, 'epochs': 131, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 4.70 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.58 GiB is free. Including non-PyTorch memory, this process has 40.97 GiB memory in use. Of the allocated memory 38.90 GiB is allocated by PyTorch, and 947.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 11:23:30,430] Trial 158 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9063948671250166, 'batch_size': 105, 'attention_heads': 13, 'hidden_dimension': 175, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30076509342031293, 'global_pooling': 'max', 'learning_rate': 0.001201492051699931, 'weight_decay': 8.766024670475646e-05, 'beta_0': 0.8101166323455559, 'beta_1': 0.9904799944826683, 'epsilon': 2.0786410592812636e-05, 'balanced_loss': True, 'epochs': 149, 'early_stopping_patience': 21, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 11:33:55,521] Trial 159 finished with value: 0.9206038297903767 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9111146091982094, 'batch_size': 116, 'attention_heads': 11, 'hidden_dimension': 169, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30912668744000293, 'global_pooling': 'max', 'learning_rate': 0.002532522738339767, 'weight_decay': 9.934828880807938e-05, 'beta_0': 0.8149778768030113, 'beta_1': 0.9896117262687271, 'epsilon': 4.857716145379679e-05, 'balanced_loss': True, 'epochs': 138, 'early_stopping_patience': 17, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 11:45:10,153] Trial 160 finished with value: 0.9233498652914278 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9032010200630477, 'batch_size': 91, 'attention_heads': 12, 'hidden_dimension': 176, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3446974483397776, 'global_pooling': 'max', 'learning_rate': 0.0020011870767287147, 'weight_decay': 0.00016649690159172432, 'beta_0': 0.8941096787927508, 'beta_1': 0.9900410027907313, 'epsilon': 7.705012891161401e-06, 'balanced_loss': True, 'epochs': 133, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 11:56:28,816] Trial 161 finished with value: 0.9292996861019829 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9298641479879586, 'batch_size': 110, 'attention_heads': 12, 'hidden_dimension': 159, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33700978276609456, 'global_pooling': 'max', 'learning_rate': 0.0015581081646843414, 'weight_decay': 0.00012410765242182792, 'beta_0': 0.8018197297918347, 'beta_1': 0.9910731039004874, 'epsilon': 2.671964583639796e-05, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 12:07:30,556] Trial 162 finished with value: 0.9122577066995481 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9333923248542695, 'batch_size': 109, 'attention_heads': 13, 'hidden_dimension': 159, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3374854990617306, 'global_pooling': 'max', 'learning_rate': 0.0014787275101246493, 'weight_decay': 0.00011675942924320433, 'beta_0': 0.817630653042832, 'beta_1': 0.99186655958944, 'epsilon': 2.8303156879880817e-05, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 19, 'plateau_patience': 20, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 12:18:39,059] Trial 163 finished with value: 0.9181039956553604 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9224079676183801, 'batch_size': 112, 'attention_heads': 11, 'hidden_dimension': 149, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32933470110533597, 'global_pooling': 'max', 'learning_rate': 0.001042663085324094, 'weight_decay': 0.0001302289588001657, 'beta_0': 0.8037623332789205, 'beta_1': 0.9906002467244206, 'epsilon': 3.976986964455678e-05, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 12:30:19,880] Trial 164 finished with value: 0.9163602113949911 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.912857913373143, 'batch_size': 103, 'attention_heads': 12, 'hidden_dimension': 164, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34890058117741, 'global_pooling': 'max', 'learning_rate': 0.001212723898760739, 'weight_decay': 8.22265541947034e-05, 'beta_0': 0.8016693337083506, 'beta_1': 0.9894851348899948, 'epsilon': 1.4679806436122885e-05, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 12:40:34,686] Trial 165 finished with value: 0.9212669050889946 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.944347451313205, 'batch_size': 96, 'attention_heads': 12, 'hidden_dimension': 151, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32072710822550793, 'global_pooling': 'max', 'learning_rate': 0.0016687688082180053, 'weight_decay': 0.0001479757570742734, 'beta_0': 0.8050655097469783, 'beta_1': 0.9925717898956609, 'epsilon': 1.0495923263966614e-05, 'balanced_loss': True, 'epochs': 141, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 76.69 MiB is free. Including non-PyTorch memory, this process has 44.48 GiB memory in use. Of the allocated memory 42.78 GiB is allocated by PyTorch, and 566.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 12:48:01,667] Trial 166 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.6808517021899901, 'batch_size': 101, 'attention_heads': 12, 'hidden_dimension': 170, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3346159339862418, 'global_pooling': 'max', 'learning_rate': 0.002289135764183897, 'weight_decay': 0.00010759360788419278, 'beta_0': 0.8076080554329657, 'beta_1': 0.9910671094642324, 'epsilon': 1.924578818537111e-05, 'balanced_loss': True, 'epochs': 154, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 12:58:57,804] Trial 167 finished with value: 0.9210945976668136 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9267595274952846, 'batch_size': 81, 'attention_heads': 11, 'hidden_dimension': 159, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3140963740648354, 'global_pooling': 'max', 'learning_rate': 0.000992946959565496, 'weight_decay': 9.385324568688496e-05, 'beta_0': 0.8000506758638887, 'beta_1': 0.9912521516751014, 'epsilon': 2.403766863661065e-05, 'balanced_loss': True, 'epochs': 134, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 13:09:24,654] Trial 168 finished with value: 0.9182994801558029 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9062120726069632, 'batch_size': 120, 'attention_heads': 12, 'hidden_dimension': 146, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3411202196730272, 'global_pooling': 'max', 'learning_rate': 0.003451336929159024, 'weight_decay': 4.362520323498244e-06, 'beta_0': 0.802228938318154, 'beta_1': 0.990641235963265, 'epsilon': 3.3833248617958834e-05, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 17, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 4.42 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.27 GiB is free. Including non-PyTorch memory, this process has 41.29 GiB memory in use. Of the allocated memory 39.06 GiB is allocated by PyTorch, and 1.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 13:17:17,778] Trial 169 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8957353547611965, 'batch_size': 108, 'attention_heads': 13, 'hidden_dimension': 177, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32663219235989693, 'global_pooling': 'max', 'learning_rate': 0.0014827669982987117, 'weight_decay': 0.00012383832865660522, 'beta_0': 0.8100905935733345, 'beta_1': 0.9915188857002715, 'epsilon': 1.3045150834586721e-05, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 13:27:10,947] Trial 170 finished with value: 0.9117067386027846 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9163672796273288, 'batch_size': 92, 'attention_heads': 12, 'hidden_dimension': 164, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32099194174882895, 'global_pooling': 'max', 'learning_rate': 0.002001397939486512, 'weight_decay': 0.00017542523515596604, 'beta_0': 0.8045571229906121, 'beta_1': 0.9852116459478191, 'epsilon': 1.6934283951211215e-05, 'balanced_loss': True, 'epochs': 120, 'early_stopping_patience': 16, 'plateau_patience': 21, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 4.17 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.49 GiB is free. Including non-PyTorch memory, this process has 42.06 GiB memory in use. Of the allocated memory 37.18 GiB is allocated by PyTorch, and 3.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 13:35:00,458] Trial 171 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8983728491931383, 'batch_size': 116, 'attention_heads': 11, 'hidden_dimension': 153, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3061616855326319, 'global_pooling': 'max', 'learning_rate': 0.0012936806262550924, 'weight_decay': 7.475866353400626e-05, 'beta_0': 0.8069737485663607, 'beta_1': 0.9901146971485495, 'epsilon': 5.5621278779826875e-05, 'balanced_loss': True, 'epochs': 159, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 13:45:59,118] Trial 172 finished with value: 0.9148088535731651 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9293442558643519, 'batch_size': 104, 'attention_heads': 11, 'hidden_dimension': 180, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3134422309218492, 'global_pooling': 'max', 'learning_rate': 0.0008885083121611066, 'weight_decay': 9.720097936531147e-05, 'beta_0': 0.8088218153573608, 'beta_1': 0.9897804536543634, 'epsilon': 2.7300548246748516e-05, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 21, 'plateau_patience': 20, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 4.44 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.58 GiB is free. Including non-PyTorch memory, this process has 40.97 GiB memory in use. Of the allocated memory 35.16 GiB is allocated by PyTorch, and 4.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 13:53:17,804] Trial 173 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8839569464979036, 'batch_size': 152, 'attention_heads': 13, 'hidden_dimension': 172, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3313622860725371, 'global_pooling': 'max', 'learning_rate': 0.0010918376008272964, 'weight_decay': 0.00013650354938022204, 'beta_0': 0.8118977277971502, 'beta_1': 0.9856224432059847, 'epsilon': 4.6484339977309296e-05, 'balanced_loss': True, 'epochs': 142, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 14:04:24,236] Trial 174 finished with value: 0.9096319415966053 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8932257093998417, 'batch_size': 100, 'attention_heads': 10, 'hidden_dimension': 139, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3187540021634986, 'global_pooling': 'max', 'learning_rate': 0.0007919863760036407, 'weight_decay': 5.777442784134851e-05, 'beta_0': 0.805703432718308, 'beta_1': 0.9861539763184933, 'epsilon': 6.837786951415554e-05, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 14:15:35,989] Trial 175 finished with value: 0.9328119454529646 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8904085261682367, 'batch_size': 96, 'attention_heads': 10, 'hidden_dimension': 145, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3165170727226454, 'global_pooling': 'max', 'learning_rate': 0.0008325410722049773, 'weight_decay': 8.323191247428864e-05, 'beta_0': 0.8031496318009974, 'beta_1': 0.9866077103780299, 'epsilon': 7.433995251546573e-05, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 3.96 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.15 GiB is free. Including non-PyTorch memory, this process has 43.41 GiB memory in use. Of the allocated memory 41.35 GiB is allocated by PyTorch, and 931.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 14:22:54,062] Trial 176 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8116380891798518, 'batch_size': 88, 'attention_heads': 12, 'hidden_dimension': 147, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32496251790431036, 'global_pooling': 'max', 'learning_rate': 0.0007306663415671483, 'weight_decay': 8.452763243799733e-05, 'beta_0': 0.8023441639369253, 'beta_1': 0.9867269091762011, 'epsilon': 7.540304026409719e-05, 'balanced_loss': True, 'epochs': 130, 'early_stopping_patience': 21, 'plateau_patience': 24, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 3.71 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.52 GiB is free. Including non-PyTorch memory, this process has 41.03 GiB memory in use. Of the allocated memory 36.63 GiB is allocated by PyTorch, and 3.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 14:30:13,156] Trial 177 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8769773083889526, 'batch_size': 111, 'attention_heads': 11, 'hidden_dimension': 160, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33753306706958575, 'global_pooling': 'max', 'learning_rate': 0.0016316150882087562, 'weight_decay': 0.00010748606933278616, 'beta_0': 0.8472582538989946, 'beta_1': 0.9878195906499042, 'epsilon': 2.0268240374436044e-05, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 14:41:56,410] Trial 178 finished with value: 0.9093116113504264 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9055092027137973, 'batch_size': 97, 'attention_heads': 12, 'hidden_dimension': 157, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31342920075301844, 'global_pooling': 'max', 'learning_rate': 0.0012886015976151732, 'weight_decay': 7.678747460380857e-05, 'beta_0': 0.8031787660019688, 'beta_1': 0.9864803989005398, 'epsilon': 3.626532049935118e-05, 'balanced_loss': True, 'epochs': 136, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 14:53:10,796] Trial 179 finished with value: 0.9196045130483068 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9186797303425677, 'batch_size': 77, 'attention_heads': 11, 'hidden_dimension': 166, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32987567713096777, 'global_pooling': 'max', 'learning_rate': 0.0009530345657483088, 'weight_decay': 0.00011671847928910732, 'beta_0': 0.8041171478706542, 'beta_1': 0.9857836025650691, 'epsilon': 9.44368303875517e-06, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 15:02:29,579] Trial 180 finished with value: 0.9114696611816957 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9391458446238024, 'batch_size': 93, 'attention_heads': 8, 'hidden_dimension': 145, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3428625682265973, 'global_pooling': 'max', 'learning_rate': 0.0012058627321036672, 'weight_decay': 0.00015992799289839407, 'beta_0': 0.8008102953092846, 'beta_1': 0.9886498134455391, 'epsilon': 5.592659920943545e-05, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 7}. Best is trial 95 with value: 0.9399421522615483.
CUDA out of memory. Tried to allocate 4.14 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.99 GiB is free. Including non-PyTorch memory, this process has 40.56 GiB memory in use. Of the allocated memory 36.07 GiB is allocated by PyTorch, and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2025-02-27 15:10:58,639] Trial 181 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9021936955852687, 'batch_size': 172, 'attention_heads': 13, 'hidden_dimension': 129, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3500806020141708, 'global_pooling': 'max', 'learning_rate': 0.0026754791585935165, 'weight_decay': 6.835057387875708e-05, 'beta_0': 0.8992551500670428, 'beta_1': 0.9892025105408953, 'epsilon': 2.4509790534530194e-05, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 17, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 15:22:09,285] Trial 182 finished with value: 0.9260280645523837 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9088955567120598, 'batch_size': 105, 'attention_heads': 10, 'hidden_dimension': 152, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3063577863769752, 'global_pooling': 'max', 'learning_rate': 0.0006665828917864705, 'weight_decay': 8.999365224003953e-05, 'beta_0': 0.8071965777757211, 'beta_1': 0.9854048634227018, 'epsilon': 2.9808300213665332e-05, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
[I 2025-02-27 15:33:18,187] Trial 183 finished with value: 0.9149020593957045 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.910390854324332, 'batch_size': 87, 'attention_heads': 10, 'hidden_dimension': 150, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30048068122033383, 'global_pooling': 'max', 'learning_rate': 0.00045724482292727265, 'weight_decay': 1.6584162895917853e-06, 'beta_0': 0.8081681721227956, 'beta_1': 0.9848346417069979, 'epsilon': 4.445220277571782e-05, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 9}. Best is trial 95 with value: 0.9399421522615483.
slurmstepd: error: *** JOB 15030008 ON gpu039 CANCELLED AT 2025-02-27T15:38:57 DUE TO TIME LIMIT ***
