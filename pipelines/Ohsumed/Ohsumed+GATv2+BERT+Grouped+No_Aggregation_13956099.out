[I 2024-11-18 06:22:58,475] Using an existing study with name 'Ohsumed-GATv2-google-bert-bert-base-uncased-Grouped-No_Aggregation' instead of creating a new one.
Optimization already completed.

[TRIAL] 291 [VALIDATION PERFORMANCE] 0.6575659225668925 [TRAINING LOSS] 0.05042202492682811 [VALIDATION LOSS] 1.5264910179025986 

number                                     291
value                                 0.657566
params_threshold                      0.864514
params_attention_heads                      14
params_balanced_loss                     False
params_embedding_pooling_operation        mean
params_attention_pooling_operation         max
params_batch_size                           40
params_dropout_rate                   0.397687
params_early_stopping_patience              18
params_epochs                              171
params_global_pooling                      max
params_hidden_dimension                    241
params_learning_rate                  0.000142
params_number_of_hidden_layers               2
params_plateau_divider                       9
params_plateau_patience                     10
params_weight_decay                   0.000218
params_beta_0                         0.821612
params_beta_1                         0.985736
params_epsilon                        0.000007
user_attrs_epoch                          26.0
user_attrs_training_loss              0.050422
user_attrs_validation_loss            1.526491
params_left_stride                           0
params_right_stride                         64
Name: 291, dtype: object
37 Val: 0.6246356373418134 Test: 0.6063936468579104
Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors
38 Val: 0.6263165246144936 Test: 0.6146079767534726
39 Val: 0.6326137982866441 Test: 0.6183453828881647
40 Val: 0.6301038300640592 Test: 0.6110237788155483
41 Val: 0.6362406296260685 Test: 0.6137971353003046
42 Val: 0.6521416898459519 Test: 0.6109667927761385
43 Val: 0.6445423262333728 Test: 0.6210495936989129
44 Val: 0.6490912898970213 Test: 0.620116641594276
45 Val: 0.6416695394262252 Test: 0.6099580100099529
46 Val: 0.6077114667469676 Test: 0.6135938481214472
Validation performance: 60.77 & 63.45 ± 1.33 & 65.21
Testing performance: 60.64 & 61.4 ± 0.47 & 62.1

[TRIAL] 281 [VALIDATION PERFORMANCE] 0.6557486637302313 [TRAINING LOSS] 0.07297712089358896 [VALIDATION LOSS] 1.424754308329688 

number                                     281
value                                 0.655749
params_threshold                       0.86489
params_attention_heads                      14
params_balanced_loss                     False
params_embedding_pooling_operation        mean
params_attention_pooling_operation         max
params_batch_size                           39
params_dropout_rate                   0.415757
params_early_stopping_patience              19
params_epochs                              168
params_global_pooling                      max
params_hidden_dimension                    234
params_learning_rate                  0.000103
params_number_of_hidden_layers               2
params_plateau_divider                       9
params_plateau_patience                     11
params_weight_decay                   0.000385
params_beta_0                         0.827269
params_beta_1                         0.985075
params_epsilon                         0.00001
user_attrs_epoch                          29.0
user_attrs_training_loss              0.072977
user_attrs_validation_loss            1.424754
params_left_stride                           0
params_right_stride                         64
Name: 281, dtype: object
37 Val: 0.6301201170361614 Test: 0.5963750624727269
38 Val: 0.6164170549452314 Test: 0.597010558043172
39 Val: 0.639517274914288 Test: 0.6028215127473882
40 Val: 0.6277934154225661 Test: 0.5994197856521212
41 Val: 0.6453013082898186 Test: 0.6176957536342923
42 Val: 0.6543158821859957 Test: 0.6124054078235343
43 Val: 0.631906701341002 Test: 0.6012606065631152
44 Val: 0.6329138205515962 Test: 0.6183368065570551
45 Val: 0.6306501726178502 Test: 0.6031766513274563
46 Val: 0.6162452534269587 Test: 0.6097386718223806
Validation performance: 61.62 & 63.25 ± 1.18 & 65.43
Testing performance: 59.64 & 60.58 ± 0.82 & 61.83

[TRIAL] 231 [VALIDATION PERFORMANCE] 0.6544151158172802 [TRAINING LOSS] 0.08214596154935219 [VALIDATION LOSS] 1.3894364833831787 

number                                     231
value                                 0.654415
params_threshold                      0.859005
params_attention_heads                      13
params_balanced_loss                     False
params_embedding_pooling_operation        mean
params_attention_pooling_operation         max
params_batch_size                           40
params_dropout_rate                   0.434616
params_early_stopping_patience              22
params_epochs                              192
params_global_pooling                      max
params_hidden_dimension                    244
params_learning_rate                  0.000158
params_number_of_hidden_layers               2
params_plateau_divider                      10
params_plateau_patience                     11
params_weight_decay                   0.000111
params_beta_0                         0.807414
params_beta_1                         0.985976
params_epsilon                         0.00001
user_attrs_epoch                          23.0
user_attrs_training_loss              0.082146
user_attrs_validation_loss            1.389436
params_left_stride                          64
params_right_stride                         64
Name: 231, dtype: object
37 Val: 0.6388288828082122 Test: 0.6107216271937486
38 Val: 0.6033641513248691 Test: 0.6111458179809335
39 Val: 0.6272622558320338 Test: 0.6151220802619654
40 Val: 0.6428135792568211 Test: 0.6242740280223911
41 Val: 0.6372587388995808 Test: 0.6107353352916504
42 Val: 0.6475147827980701 Test: 0.6215915531166111
43 Val: 0.6395296265247693 Test: 0.6138149077133594
44 Val: 0.6344026796548151 Test: 0.6161060399318602
slurmstepd: error: *** JOB 13956099 ON gpu046 CANCELLED AT 2024-11-18T18:23:09 DUE TO TIME LIMIT ***
