Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2024-12-22 06:19:11,036] Using an existing study with name 'Ohsumed-GATv2-FacebookAI-roberta-large-Surrogate-No_Aggregation' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors
[I 2024-12-22 06:43:09,462] Trial 268 finished with value: 0.6086346711780882 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9908598697938067, 'batch_size': 90, 'attention_heads': 7, 'hidden_dimension': 238, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3184485450121524, 'global_pooling': 'max', 'learning_rate': 0.0011013798780815924, 'weight_decay': 0.0003171106712292484, 'beta_0': 0.8729085328672652, 'beta_1': 0.9856971418681292, 'epsilon': 6.192821024576196e-08, 'balanced_loss': True, 'epochs': 70, 'early_stopping_patience': 24, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 07:06:59,635] Trial 269 finished with value: 0.5550785601529801 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9862853517599394, 'batch_size': 85, 'attention_heads': 6, 'hidden_dimension': 232, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31209730789623596, 'global_pooling': 'sum', 'learning_rate': 0.0023257753604832014, 'weight_decay': 3.6652332337103924e-06, 'beta_0': 0.8681750003456002, 'beta_1': 0.9929852133403209, 'epsilon': 3.810410443943547e-08, 'balanced_loss': True, 'epochs': 131, 'early_stopping_patience': 22, 'plateau_patience': 17, 'plateau_divider': 7}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 07:31:01,059] Trial 270 finished with value: 0.6206600619746055 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9828134147263415, 'batch_size': 81, 'attention_heads': 6, 'hidden_dimension': 252, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33076997183872825, 'global_pooling': 'max', 'learning_rate': 0.001518169266899622, 'weight_decay': 2.2908516188898616e-05, 'beta_0': 0.8703912196797895, 'beta_1': 0.9922879138188438, 'epsilon': 7.938312524113852e-08, 'balanced_loss': True, 'epochs': 77, 'early_stopping_patience': 25, 'plateau_patience': 15, 'plateau_divider': 8}. Best is trial 225 with value: 0.6511418625796105.
CUDA out of memory. Tried to allocate 954.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 554.69 MiB is free. Including non-PyTorch memory, this process has 44.01 GiB memory in use. Of the allocated memory 41.43 GiB is allocated by PyTorch, and 1.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-22 07:52:55,647] Trial 271 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9740102265683132, 'batch_size': 76, 'attention_heads': 6, 'hidden_dimension': 244, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3243707030181865, 'global_pooling': 'max', 'learning_rate': 0.0012646041915275053, 'weight_decay': 6.444132027706825e-06, 'beta_0': 0.8638032323754443, 'beta_1': 0.9938848510042457, 'epsilon': 1.2510283849206062e-08, 'balanced_loss': False, 'epochs': 68, 'early_stopping_patience': 23, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 08:24:01,117] Trial 272 finished with value: 0.024176883418978525 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9942771213651118, 'batch_size': 83, 'attention_heads': 5, 'hidden_dimension': 222, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3088226050987324, 'global_pooling': 'max', 'learning_rate': 0.04111834324236489, 'weight_decay': 1.3391597789152644e-05, 'beta_0': 0.8672150673795641, 'beta_1': 0.9931994238229035, 'epsilon': 2.2130172021307412e-07, 'balanced_loss': True, 'epochs': 73, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 08:47:18,106] Trial 273 finished with value: 0.6192557613518701 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9885873335642962, 'batch_size': 87, 'attention_heads': 5, 'hidden_dimension': 256, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3190163351775977, 'global_pooling': 'max', 'learning_rate': 0.0009558531602051221, 'weight_decay': 2.8568672488521753e-05, 'beta_0': 0.8745329214728691, 'beta_1': 0.9924074805323501, 'epsilon': 2.730720512462228e-08, 'balanced_loss': False, 'epochs': 81, 'early_stopping_patience': 25, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 09:10:59,280] Trial 274 finished with value: 0.6125039611090773 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9774905195531746, 'batch_size': 85, 'attention_heads': 6, 'hidden_dimension': 240, 'number_of_hidden_layers': 0, 'dropout_rate': 0.303866530275238, 'global_pooling': 'max', 'learning_rate': 0.001956209563212774, 'weight_decay': 3.571739735856684e-05, 'beta_0': 0.8701133342384808, 'beta_1': 0.9934213783567168, 'epsilon': 1.9513161928783322e-08, 'balanced_loss': True, 'epochs': 76, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 225 with value: 0.6511418625796105.
CUDA out of memory. Tried to allocate 1.39 GiB. GPU 0 has a total capacity of 44.56 GiB of which 198.69 MiB is free. Including non-PyTorch memory, this process has 44.36 GiB memory in use. Of the allocated memory 41.56 GiB is allocated by PyTorch, and 1.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-22 09:32:53,285] Trial 275 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9712407440988163, 'batch_size': 107, 'attention_heads': 7, 'hidden_dimension': 202, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3116754672093413, 'global_pooling': 'max', 'learning_rate': 0.0031789242159041705, 'weight_decay': 0.0003863925719437061, 'beta_0': 0.8650081647413742, 'beta_1': 0.9927137999813761, 'epsilon': 4.975141823181128e-08, 'balanced_loss': False, 'epochs': 88, 'early_stopping_patience': 24, 'plateau_patience': 16, 'plateau_divider': 6}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 09:56:00,262] Trial 276 finished with value: 0.6151120687833288 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9846009686376965, 'batch_size': 79, 'attention_heads': 4, 'hidden_dimension': 247, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32863123381817827, 'global_pooling': 'max', 'learning_rate': 0.001673574561789911, 'weight_decay': 0.000283311355845283, 'beta_0': 0.868200952446545, 'beta_1': 0.9941518534837932, 'epsilon': 3.766960745319647e-08, 'balanced_loss': True, 'epochs': 84, 'early_stopping_patience': 25, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 10:19:35,596] Trial 277 finished with value: 0.620633736897785 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9802216530045202, 'batch_size': 82, 'attention_heads': 5, 'hidden_dimension': 226, 'number_of_hidden_layers': 0, 'dropout_rate': 0.36433156061080646, 'global_pooling': 'max', 'learning_rate': 0.001225619265111112, 'weight_decay': 8.359316603110569e-06, 'beta_0': 0.861431008691314, 'beta_1': 0.9915119073293922, 'epsilon': 6.188302452458623e-08, 'balanced_loss': False, 'epochs': 67, 'early_stopping_patience': 24, 'plateau_patience': 17, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 10:42:33,726] Trial 278 finished with value: 0.6016294840046095 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9906101450207971, 'batch_size': 89, 'attention_heads': 6, 'hidden_dimension': 235, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3212033288067871, 'global_pooling': 'max', 'learning_rate': 0.0022929883546467566, 'weight_decay': 5.1533543262244444e-06, 'beta_0': 0.8730880315486496, 'beta_1': 0.99362818892344, 'epsilon': 3.107518840002144e-08, 'balanced_loss': True, 'epochs': 79, 'early_stopping_patience': 23, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 11:05:23,272] Trial 279 finished with value: 0.6097994948986663 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9962869964638159, 'batch_size': 80, 'attention_heads': 6, 'hidden_dimension': 241, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3157643240398844, 'global_pooling': 'max', 'learning_rate': 0.0008039175425276671, 'weight_decay': 0.0002141607753452977, 'beta_0': 0.8761146650920709, 'beta_1': 0.993013452456057, 'epsilon': 1.0197184680047499e-05, 'balanced_loss': False, 'epochs': 74, 'early_stopping_patience': 21, 'plateau_patience': 14, 'plateau_divider': 6}. Best is trial 225 with value: 0.6511418625796105.
CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 90.69 MiB is free. Including non-PyTorch memory, this process has 44.46 GiB memory in use. Of the allocated memory 42.33 GiB is allocated by PyTorch, and 1005.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-22 11:12:31,983] Trial 280 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8845565657015305, 'batch_size': 54, 'attention_heads': 7, 'hidden_dimension': 250, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3392946869945149, 'global_pooling': 'max', 'learning_rate': 0.0014973941163005284, 'weight_decay': 1.9205272025785476e-05, 'beta_0': 0.8803031155461427, 'beta_1': 0.9920904855358037, 'epsilon': 4.4779079799892965e-08, 'balanced_loss': True, 'epochs': 70, 'early_stopping_patience': 24, 'plateau_patience': 15, 'plateau_divider': 4}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 11:35:45,404] Trial 281 finished with value: 0.6371112208638877 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9866443448738963, 'batch_size': 77, 'attention_heads': 5, 'hidden_dimension': 245, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3059971160791137, 'global_pooling': 'max', 'learning_rate': 0.001025577519660706, 'weight_decay': 4.4309766083400525e-05, 'beta_0': 0.8713900750478966, 'beta_1': 0.9925932712541502, 'epsilon': 5.853572277249868e-08, 'balanced_loss': False, 'epochs': 115, 'early_stopping_patience': 25, 'plateau_patience': 12, 'plateau_divider': 6}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 12:09:48,106] Trial 282 finished with value: 0.3008820536651618 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9998248131221513, 'batch_size': 74, 'attention_heads': 6, 'hidden_dimension': 80, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3021085587447499, 'global_pooling': 'max', 'learning_rate': 0.0009867981427203094, 'weight_decay': 3.224789665667081e-05, 'beta_0': 0.8712180517239944, 'beta_1': 0.9926068686555071, 'epsilon': 5.531063129519373e-08, 'balanced_loss': False, 'epochs': 107, 'early_stopping_patience': 25, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 12:39:25,526] Trial 283 finished with value: 0.5947600854067003 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9874498218844713, 'batch_size': 78, 'attention_heads': 6, 'hidden_dimension': 245, 'number_of_hidden_layers': 3, 'dropout_rate': 0.3096478043187674, 'global_pooling': 'max', 'learning_rate': 0.0010660742510931937, 'weight_decay': 4.070450248213903e-05, 'beta_0': 0.8777175982156867, 'beta_1': 0.9945045787334648, 'epsilon': 7.073038205568242e-08, 'balanced_loss': False, 'epochs': 117, 'early_stopping_patience': 25, 'plateau_patience': 12, 'plateau_divider': 8}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 13:02:37,607] Trial 284 finished with value: 0.6275612451250706 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9890045427992299, 'batch_size': 78, 'attention_heads': 5, 'hidden_dimension': 238, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30746476861818955, 'global_pooling': 'max', 'learning_rate': 0.0007624365251242664, 'weight_decay': 4.916923337480279e-05, 'beta_0': 0.8735025701379557, 'beta_1': 0.9932425491446931, 'epsilon': 1.0427326253370448e-07, 'balanced_loss': False, 'epochs': 63, 'early_stopping_patience': 25, 'plateau_patience': 12, 'plateau_divider': 6}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 13:25:49,679] Trial 285 finished with value: 0.6303326732258284 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9925843485243092, 'batch_size': 76, 'attention_heads': 7, 'hidden_dimension': 251, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3009881572974803, 'global_pooling': 'max', 'learning_rate': 0.0018423393933408448, 'weight_decay': 2.684793996669488e-05, 'beta_0': 0.8696186853723749, 'beta_1': 0.993817040750538, 'epsilon': 8.508628957311812e-08, 'balanced_loss': False, 'epochs': 85, 'early_stopping_patience': 25, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 13:49:00,471] Trial 286 finished with value: 0.6174143389767521 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9932362856597005, 'batch_size': 75, 'attention_heads': 7, 'hidden_dimension': 253, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3032983075210012, 'global_pooling': 'max', 'learning_rate': 0.0019883869604405955, 'weight_decay': 2.652503320432585e-05, 'beta_0': 0.8709835047638838, 'beta_1': 0.9939722122357935, 'epsilon': 9.139011958339428e-08, 'balanced_loss': False, 'epochs': 84, 'early_stopping_patience': 25, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 14:12:03,525] Trial 287 finished with value: 0.6333729762544799 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9967996709781988, 'batch_size': 72, 'attention_heads': 7, 'hidden_dimension': 249, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4114522203528189, 'global_pooling': 'max', 'learning_rate': 0.0024442529152437806, 'weight_decay': 3.527934826900732e-05, 'beta_0': 0.8746207483777312, 'beta_1': 0.9936425987060689, 'epsilon': 8.348893883317477e-08, 'balanced_loss': False, 'epochs': 91, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 14:35:03,588] Trial 288 finished with value: 0.608162420057012 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9973017945098406, 'batch_size': 73, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37141710417571117, 'global_pooling': 'max', 'learning_rate': 0.004053187597420538, 'weight_decay': 4.615926264475118e-05, 'beta_0': 0.8747262332238042, 'beta_1': 0.9948628814178343, 'epsilon': 1.0273745157497306e-07, 'balanced_loss': False, 'epochs': 88, 'early_stopping_patience': 25, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 14:57:58,999] Trial 289 finished with value: 0.4044097836839914 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9939942214030724, 'batch_size': 70, 'attention_heads': 7, 'hidden_dimension': 249, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4200044669434798, 'global_pooling': 'mean', 'learning_rate': 0.002776495285683351, 'weight_decay': 3.0476645278322167e-05, 'beta_0': 0.8822857001250697, 'beta_1': 0.9937584695074896, 'epsilon': 8.163841033900127e-08, 'balanced_loss': False, 'epochs': 91, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 15:20:39,340] Trial 290 finished with value: 0.6048509130128628 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9982438516318592, 'batch_size': 77, 'attention_heads': 8, 'hidden_dimension': 108, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34822181188526025, 'global_pooling': 'max', 'learning_rate': 0.0020495569211000744, 'weight_decay': 3.290828917807885e-05, 'beta_0': 0.8763221465398396, 'beta_1': 0.9943332227301915, 'epsilon': 7.793102926229076e-08, 'balanced_loss': False, 'epochs': 110, 'early_stopping_patience': 25, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 15:43:59,999] Trial 291 finished with value: 0.6322550444817707 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9929972620812892, 'batch_size': 76, 'attention_heads': 7, 'hidden_dimension': 249, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3005193283943391, 'global_pooling': 'max', 'learning_rate': 0.002498131858211561, 'weight_decay': 2.6385837163965204e-05, 'beta_0': 0.8789095625001435, 'beta_1': 0.9939880017435673, 'epsilon': 1.2995140655449647e-07, 'balanced_loss': False, 'epochs': 95, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 16:07:29,092] Trial 292 finished with value: 0.579294418748177 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9938695931130793, 'batch_size': 78, 'attention_heads': 7, 'hidden_dimension': 251, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3025106521588201, 'global_pooling': 'sum', 'learning_rate': 0.002827929070614518, 'weight_decay': 3.6588186851762195e-05, 'beta_0': 0.8786168711928111, 'beta_1': 0.993653509259345, 'epsilon': 6.646594145481309e-08, 'balanced_loss': False, 'epochs': 96, 'early_stopping_patience': 24, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 16:32:50,330] Trial 293 finished with value: 0.5479452765308416 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9977825651456635, 'batch_size': 73, 'attention_heads': 7, 'hidden_dimension': 252, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30072338652689956, 'global_pooling': 'max', 'learning_rate': 7.975270775105055e-05, 'weight_decay': 3.504921616989393e-05, 'beta_0': 0.8801450387655697, 'beta_1': 0.9945451162894823, 'epsilon': 1.265834938059141e-07, 'balanced_loss': False, 'epochs': 88, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 16:56:15,655] Trial 294 finished with value: 0.5852651362791707 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9928984348697617, 'batch_size': 77, 'attention_heads': 8, 'hidden_dimension': 247, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3001660759326763, 'global_pooling': 'max', 'learning_rate': 0.0033146671341070487, 'weight_decay': 3.936771033157173e-05, 'beta_0': 0.8697978148903655, 'beta_1': 0.9942018787360007, 'epsilon': 6.193133676411601e-08, 'balanced_loss': False, 'epochs': 89, 'early_stopping_patience': 23, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 17:19:38,979] Trial 295 finished with value: 0.6143713719180007 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9917792464344133, 'batch_size': 75, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30785526247298295, 'global_pooling': 'max', 'learning_rate': 0.002508134527926112, 'weight_decay': 0.0004292928511735277, 'beta_0': 0.8166456350614111, 'beta_1': 0.9940244723441878, 'epsilon': 1.4750924845019534e-07, 'balanced_loss': False, 'epochs': 85, 'early_stopping_patience': 23, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 17:42:55,082] Trial 296 finished with value: 0.6119581977934686 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9959744668899726, 'batch_size': 76, 'attention_heads': 7, 'hidden_dimension': 244, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4107642740435997, 'global_pooling': 'max', 'learning_rate': 0.0023597684813683865, 'weight_decay': 6.507579780183532e-05, 'beta_0': 0.8784198733075829, 'beta_1': 0.9863096767429185, 'epsilon': 3.66882924262707e-08, 'balanced_loss': False, 'epochs': 82, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 18:06:30,790] Trial 297 finished with value: 0.6274928828254311 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9901087924393673, 'batch_size': 68, 'attention_heads': 7, 'hidden_dimension': 249, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33372164394352094, 'global_pooling': 'max', 'learning_rate': 0.0019610663133358026, 'weight_decay': 2.9827727008627745e-05, 'beta_0': 0.8853587016914034, 'beta_1': 0.9928751850551504, 'epsilon': 5.008375620486694e-07, 'balanced_loss': False, 'epochs': 99, 'early_stopping_patience': 24, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 18:29:34,926] Trial 298 finished with value: 0.6229271603847432 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9991493738926088, 'batch_size': 71, 'attention_heads': 7, 'hidden_dimension': 252, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31131857135056246, 'global_pooling': 'max', 'learning_rate': 0.00309758969842205, 'weight_decay': 2.6793273786985517e-05, 'beta_0': 0.8754332300022943, 'beta_1': 0.9925417652684019, 'epsilon': 7.793886534283612e-08, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 20, 'plateau_patience': 13, 'plateau_divider': 4}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 18:53:17,432] Trial 299 finished with value: 0.6314537422947862 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9898015764621171, 'batch_size': 74, 'attention_heads': 8, 'hidden_dimension': 244, 'number_of_hidden_layers': 0, 'dropout_rate': 0.39931998483188114, 'global_pooling': 'max', 'learning_rate': 0.0017745925111068556, 'weight_decay': 2.905177968086029e-06, 'beta_0': 0.8723801906338533, 'beta_1': 0.9890667657395396, 'epsilon': 4.718774244908399e-08, 'balanced_loss': False, 'epochs': 93, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 19:16:49,113] Trial 300 finished with value: 0.6488463979603859 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9920358371775453, 'batch_size': 72, 'attention_heads': 8, 'hidden_dimension': 242, 'number_of_hidden_layers': 0, 'dropout_rate': 0.39043573028114475, 'global_pooling': 'max', 'learning_rate': 0.0017707769373791521, 'weight_decay': 2.547867536550399e-06, 'beta_0': 0.8730765360517537, 'beta_1': 0.9906482674876188, 'epsilon': 5.110445317987339e-08, 'balanced_loss': False, 'epochs': 93, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 19:45:16,397] Trial 301 finished with value: 0.6024377468786518 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9896143909347298, 'batch_size': 72, 'attention_heads': 8, 'hidden_dimension': 242, 'number_of_hidden_layers': 2, 'dropout_rate': 0.381998145346396, 'global_pooling': 'max', 'learning_rate': 0.0017323751773953204, 'weight_decay': 1.4780989577245808e-06, 'beta_0': 0.8727324570855703, 'beta_1': 0.9903456298860206, 'epsilon': 5.169951759310373e-08, 'balanced_loss': False, 'epochs': 94, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 20:08:36,014] Trial 302 finished with value: 0.5925175068734105 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.994962380386028, 'batch_size': 67, 'attention_heads': 8, 'hidden_dimension': 240, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3909377257936363, 'global_pooling': 'max', 'learning_rate': 0.004848239771095661, 'weight_decay': 2.5372238482609045e-06, 'beta_0': 0.8768224004415736, 'beta_1': 0.9907068874789329, 'epsilon': 4.8574675347163616e-08, 'balanced_loss': False, 'epochs': 102, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 20:32:22,783] Trial 303 finished with value: 0.6261535724867047 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9886133405665933, 'batch_size': 72, 'attention_heads': 8, 'hidden_dimension': 244, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4153323134973329, 'global_pooling': 'max', 'learning_rate': 0.0017069878381905236, 'weight_decay': 3.159960415501967e-06, 'beta_0': 0.8826654445407922, 'beta_1': 0.9888890299567399, 'epsilon': 5.6956974372105084e-08, 'balanced_loss': False, 'epochs': 94, 'early_stopping_patience': 24, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 20:56:57,798] Trial 304 finished with value: 0.6235149838746341 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9863010907763244, 'batch_size': 111, 'attention_heads': 8, 'hidden_dimension': 238, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3858587229198035, 'global_pooling': 'max', 'learning_rate': 0.0012644572145798262, 'weight_decay': 2.736566332916308e-06, 'beta_0': 0.8747286075640872, 'beta_1': 0.9915985649136213, 'epsilon': 4.397974203337953e-08, 'balanced_loss': False, 'epochs': 93, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
CUDA out of memory. Tried to allocate 344.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 82.69 MiB is free. Including non-PyTorch memory, this process has 44.47 GiB memory in use. Of the allocated memory 40.15 GiB is allocated by PyTorch, and 3.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-22 21:10:34,933] Trial 305 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9477083941379746, 'batch_size': 93, 'attention_heads': 9, 'hidden_dimension': 245, 'number_of_hidden_layers': 0, 'dropout_rate': 0.40133551234876835, 'global_pooling': 'max', 'learning_rate': 0.0023048066036978035, 'weight_decay': 2.385201200658213e-06, 'beta_0': 0.8724808537222931, 'beta_1': 0.9818355754988661, 'epsilon': 1.7328858854688505e-07, 'balanced_loss': False, 'epochs': 91, 'early_stopping_patience': 24, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 21:46:29,804] Trial 306 finished with value: 0.5820555421921614 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9899266844384942, 'batch_size': 74, 'attention_heads': 8, 'hidden_dimension': 243, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4049224678577068, 'global_pooling': 'max', 'learning_rate': 0.0015262994209424656, 'weight_decay': 0.00011462785262170894, 'beta_0': 0.8774986912879221, 'beta_1': 0.9891339435604477, 'epsilon': 7.589310241157183e-06, 'balanced_loss': False, 'epochs': 92, 'early_stopping_patience': 24, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 22:09:35,986] Trial 307 finished with value: 0.6052746326043569 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9998252411733234, 'batch_size': 74, 'attention_heads': 7, 'hidden_dimension': 247, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3599443431641218, 'global_pooling': 'max', 'learning_rate': 0.001910737422079792, 'weight_decay': 3.4785284856192494e-06, 'beta_0': 0.8751691900450889, 'beta_1': 0.9974504929626943, 'epsilon': 2.5675965890589453e-08, 'balanced_loss': False, 'epochs': 97, 'early_stopping_patience': 24, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 280.69 MiB is free. Including non-PyTorch memory, this process has 44.28 GiB memory in use. Of the allocated memory 40.83 GiB is allocated by PyTorch, and 2.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-22 22:15:09,123] Trial 308 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8524577705593, 'batch_size': 70, 'attention_heads': 8, 'hidden_dimension': 239, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3969435678977908, 'global_pooling': 'max', 'learning_rate': 0.0012861018958951935, 'weight_decay': 2.9428093112678073e-06, 'beta_0': 0.872021598472504, 'beta_1': 0.990050897544653, 'epsilon': 6.399816782569347e-08, 'balanced_loss': False, 'epochs': 99, 'early_stopping_patience': 20, 'plateau_patience': 12, 'plateau_divider': 4}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 22:38:32,427] Trial 309 finished with value: 0.6059060652383128 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9934267672149681, 'batch_size': 76, 'attention_heads': 8, 'hidden_dimension': 247, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4081314720615005, 'global_pooling': 'max', 'learning_rate': 0.002726390100964862, 'weight_decay': 1.98075365969148e-06, 'beta_0': 0.8589706328534217, 'beta_1': 0.9851118421797127, 'epsilon': 3.522492378841265e-08, 'balanced_loss': False, 'epochs': 95, 'early_stopping_patience': 21, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 23:02:23,832] Trial 310 finished with value: 0.6154635420421701 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9863210723515685, 'batch_size': 47, 'attention_heads': 7, 'hidden_dimension': 236, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34407939425222156, 'global_pooling': 'max', 'learning_rate': 0.0016601104796759518, 'weight_decay': 0.00048017745125121763, 'beta_0': 0.8740642264116214, 'beta_1': 0.9910387110948966, 'epsilon': 5.374448097609866e-08, 'balanced_loss': False, 'epochs': 105, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 7}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 23:25:24,264] Trial 311 finished with value: 0.38710790261972816 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9960835178224974, 'batch_size': 120, 'attention_heads': 8, 'hidden_dimension': 242, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3913450546919822, 'global_pooling': 'max', 'learning_rate': 0.002144854479219513, 'weight_decay': 1.1338946189091506e-05, 'beta_0': 0.8812853201375186, 'beta_1': 0.9935260304924075, 'epsilon': 3.067982031640747e-08, 'balanced_loss': False, 'epochs': 90, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-22 23:49:44,071] Trial 312 finished with value: 0.5750644093988881 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9845550624006388, 'batch_size': 79, 'attention_heads': 7, 'hidden_dimension': 252, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32723950975904903, 'global_pooling': 'mean', 'learning_rate': 0.001396054232297248, 'weight_decay': 2.1260959867392233e-06, 'beta_0': 0.8698267939884446, 'beta_1': 0.9931441670618644, 'epsilon': 4.508591974320346e-08, 'balanced_loss': False, 'epochs': 86, 'early_stopping_patience': 21, 'plateau_patience': 12, 'plateau_divider': 8}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 00:13:36,857] Trial 313 finished with value: 0.6055726496613684 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9907550252598234, 'batch_size': 91, 'attention_heads': 7, 'hidden_dimension': 241, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3220406559567672, 'global_pooling': 'max', 'learning_rate': 0.001137948757284793, 'weight_decay': 2.2085547434118445e-06, 'beta_0': 0.8718170030757197, 'beta_1': 0.9884853045668178, 'epsilon': 1.3856821676881289e-08, 'balanced_loss': False, 'epochs': 135, 'early_stopping_patience': 23, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 00:36:31,010] Trial 314 finished with value: 0.6257146210843605 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9881140746534357, 'batch_size': 80, 'attention_heads': 9, 'hidden_dimension': 62, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35562111545999286, 'global_pooling': 'max', 'learning_rate': 0.0016739526548076135, 'weight_decay': 0.00025233383735387356, 'beta_0': 0.8796053281385368, 'beta_1': 0.9917877865606808, 'epsilon': 6.825369506647228e-08, 'balanced_loss': False, 'epochs': 81, 'early_stopping_patience': 24, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 01:00:07,148] Trial 315 finished with value: 0.5718884259335757 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9821833911974237, 'batch_size': 77, 'attention_heads': 4, 'hidden_dimension': 157, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4248025720211348, 'global_pooling': 'sum', 'learning_rate': 0.0022724453614553293, 'weight_decay': 0.00039300815555685963, 'beta_0': 0.8684458330568412, 'beta_1': 0.9873622220073444, 'epsilon': 4.148275657391459e-08, 'balanced_loss': False, 'epochs': 89, 'early_stopping_patience': 24, 'plateau_patience': 13, 'plateau_divider': 4}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 01:23:32,097] Trial 316 finished with value: 0.6431545588115045 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9927471322509659, 'batch_size': 73, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3950493244029248, 'global_pooling': 'max', 'learning_rate': 0.0019663615503709144, 'weight_decay': 0.00033849902099269887, 'beta_0': 0.8767158728334192, 'beta_1': 0.9922305404610489, 'epsilon': 2.285275210201295e-08, 'balanced_loss': False, 'epochs': 82, 'early_stopping_patience': 21, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 01:46:27,978] Trial 317 finished with value: 0.6075583806055392 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9949338261054524, 'batch_size': 72, 'attention_heads': 5, 'hidden_dimension': 256, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3951845394159634, 'global_pooling': 'max', 'learning_rate': 0.0026646554769130205, 'weight_decay': 3.919583724343289e-06, 'beta_0': 0.8775296264378631, 'beta_1': 0.9913367643469881, 'epsilon': 2.3171137148830578e-08, 'balanced_loss': False, 'epochs': 128, 'early_stopping_patience': 24, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 02:09:55,483] Trial 318 finished with value: 0.6116290847680215 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9922475583739137, 'batch_size': 66, 'attention_heads': 7, 'hidden_dimension': 256, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3818004122188813, 'global_pooling': 'max', 'learning_rate': 0.0019239319790476481, 'weight_decay': 1.6865539222853843e-06, 'beta_0': 0.8752287017123903, 'beta_1': 0.9922300948323495, 'epsilon': 3.444287936227954e-08, 'balanced_loss': False, 'epochs': 100, 'early_stopping_patience': 25, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 02:32:46,999] Trial 319 finished with value: 0.6224581886055612 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9967405598452079, 'batch_size': 69, 'attention_heads': 5, 'hidden_dimension': 232, 'number_of_hidden_layers': 0, 'dropout_rate': 0.39677148181856137, 'global_pooling': 'max', 'learning_rate': 0.0020888234495570488, 'weight_decay': 0.00029100171002642566, 'beta_0': 0.8659896855541905, 'beta_1': 0.9928570366854381, 'epsilon': 2.3958855007574123e-06, 'balanced_loss': False, 'epochs': 86, 'early_stopping_patience': 20, 'plateau_patience': 12, 'plateau_divider': 8}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 02:56:27,618] Trial 320 finished with value: 0.623747996007502 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9900293062800238, 'batch_size': 74, 'attention_heads': 8, 'hidden_dimension': 246, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3871181672439317, 'global_pooling': 'max', 'learning_rate': 0.0013479998557149122, 'weight_decay': 2.908250691079621e-06, 'beta_0': 0.8632664641412479, 'beta_1': 0.9922707488054039, 'epsilon': 5.12993581448703e-08, 'balanced_loss': False, 'epochs': 96, 'early_stopping_patience': 23, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 03:20:05,581] Trial 321 finished with value: 0.6024721133103187 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9860394908040533, 'batch_size': 73, 'attention_heads': 7, 'hidden_dimension': 252, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4030571917749843, 'global_pooling': 'max', 'learning_rate': 0.0037435251066496185, 'weight_decay': 0.0003418198888542092, 'beta_0': 0.8782139458686036, 'beta_1': 0.9907911930522981, 'epsilon': 3.1110725604865316e-08, 'balanced_loss': False, 'epochs': 170, 'early_stopping_patience': 21, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 03:42:21,703] Trial 322 finished with value: 0.559914182713874 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9928048749542484, 'batch_size': 76, 'attention_heads': 6, 'hidden_dimension': 32, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3332098719296265, 'global_pooling': 'max', 'learning_rate': 0.0154033431805622, 'weight_decay': 0.0004478008915609125, 'beta_0': 0.87145675772956, 'beta_1': 0.9919174045881133, 'epsilon': 2.4935750425754456e-08, 'balanced_loss': False, 'epochs': 59, 'early_stopping_patience': 23, 'plateau_patience': 12, 'plateau_divider': 7}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 04:05:39,991] Trial 323 finished with value: 0.6163887650104009 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9995452298497558, 'batch_size': 75, 'attention_heads': 6, 'hidden_dimension': 236, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33760373464492105, 'global_pooling': 'max', 'learning_rate': 0.003098952184416519, 'weight_decay': 4.362520323498244e-06, 'beta_0': 0.87624886994958, 'beta_1': 0.9954027789753288, 'epsilon': 6.382305923141613e-08, 'balanced_loss': False, 'epochs': 83, 'early_stopping_patience': 25, 'plateau_patience': 12, 'plateau_divider': 8}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 04:29:10,631] Trial 324 finished with value: 0.6103417977905025 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9878068216940209, 'batch_size': 59, 'attention_heads': 5, 'hidden_dimension': 247, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32551140967750747, 'global_pooling': 'max', 'learning_rate': 0.0024431073240409424, 'weight_decay': 0.0005464566314384275, 'beta_0': 0.8683712309349224, 'beta_1': 0.9933626160395739, 'epsilon': 5.28863858914186e-08, 'balanced_loss': False, 'epochs': 79, 'early_stopping_patience': 24, 'plateau_patience': 13, 'plateau_divider': 8}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 04:52:29,480] Trial 325 finished with value: 0.6128119741723779 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9933393283064214, 'batch_size': 78, 'attention_heads': 7, 'hidden_dimension': 241, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3167105689278485, 'global_pooling': 'max', 'learning_rate': 0.001138458428308743, 'weight_decay': 3.250487744482861e-06, 'beta_0': 0.8604780405247761, 'beta_1': 0.9925792023339451, 'epsilon': 4.147046806975519e-08, 'balanced_loss': False, 'epochs': 81, 'early_stopping_patience': 24, 'plateau_patience': 17, 'plateau_divider': 7}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 05:18:25,029] Trial 326 finished with value: 0.6245233284105123 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9841699175847872, 'batch_size': 81, 'attention_heads': 6, 'hidden_dimension': 250, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41159849104593105, 'global_pooling': 'max', 'learning_rate': 0.001760616501019205, 'weight_decay': 5.467791964332045e-05, 'beta_0': 0.8807161161775462, 'beta_1': 0.9896436545339758, 'epsilon': 9.989653906152947e-05, 'balanced_loss': False, 'epochs': 92, 'early_stopping_patience': 22, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 05:42:49,656] Trial 327 finished with value: 0.618637268745364 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9901287712888145, 'batch_size': 80, 'attention_heads': 9, 'hidden_dimension': 244, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37630445243782085, 'global_pooling': 'max', 'learning_rate': 0.001471321460866599, 'weight_decay': 7.384175063048738e-06, 'beta_0': 0.8732425964208973, 'beta_1': 0.9948724007695807, 'epsilon': 6.985332325406189e-08, 'balanced_loss': False, 'epochs': 87, 'early_stopping_patience': 24, 'plateau_patience': 12, 'plateau_divider': 7}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 06:18:30,341] Trial 328 finished with value: 0.5683464283724224 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9778151336246451, 'batch_size': 71, 'attention_heads': 5, 'hidden_dimension': 230, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3077306250339266, 'global_pooling': 'max', 'learning_rate': 0.001980544955120468, 'weight_decay': 0.0005021675351637653, 'beta_0': 0.8666441563676662, 'beta_1': 0.9928277449131514, 'epsilon': 2.9170562571924838e-08, 'balanced_loss': False, 'epochs': 143, 'early_stopping_patience': 20, 'plateau_patience': 14, 'plateau_divider': 4}. Best is trial 225 with value: 0.6511418625796105.
CUDA out of memory. Tried to allocate 1020.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 380.69 MiB is free. Including non-PyTorch memory, this process has 44.18 GiB memory in use. Of the allocated memory 41.19 GiB is allocated by PyTorch, and 1.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 06:27:30,225] Trial 329 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9124430547679729, 'batch_size': 104, 'attention_heads': 4, 'hidden_dimension': 238, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3138564215199952, 'global_pooling': 'max', 'learning_rate': 1.5302351530815115e-05, 'weight_decay': 2.6683804629870545e-06, 'beta_0': 0.8702599098550917, 'beta_1': 0.9938881012700734, 'epsilon': 4.755271726275971e-08, 'balanced_loss': False, 'epochs': 74, 'early_stopping_patience': 25, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 06:51:19,661] Trial 330 finished with value: 0.6325311962946093 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9843546929194933, 'batch_size': 92, 'attention_heads': 8, 'hidden_dimension': 256, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3200774173717483, 'global_pooling': 'max', 'learning_rate': 0.0012286785620330373, 'weight_decay': 0.00032165971583228745, 'beta_0': 0.864375663899525, 'beta_1': 0.9931390827454444, 'epsilon': 8.594546715128315e-07, 'balanced_loss': False, 'epochs': 79, 'early_stopping_patience': 12, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
CUDA out of memory. Tried to allocate 1.25 GiB. GPU 0 has a total capacity of 44.56 GiB of which 340.69 MiB is free. Including non-PyTorch memory, this process has 44.22 GiB memory in use. Of the allocated memory 41.53 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 07:13:33,466] Trial 331 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9835598066135993, 'batch_size': 95, 'attention_heads': 8, 'hidden_dimension': 256, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3296325281337831, 'global_pooling': 'max', 'learning_rate': 0.002590814694449851, 'weight_decay': 0.0003166570951778183, 'beta_0': 0.8647221113609498, 'beta_1': 0.9923725311204321, 'epsilon': 8.015428282137654e-07, 'balanced_loss': False, 'epochs': 79, 'early_stopping_patience': 10, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
CUDA out of memory. Tried to allocate 1.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.23 GiB is free. Including non-PyTorch memory, this process has 43.32 GiB memory in use. Of the allocated memory 40.30 GiB is allocated by PyTorch, and 1.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 07:35:39,287] Trial 332 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.975128546610271, 'batch_size': 91, 'attention_heads': 8, 'hidden_dimension': 252, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32032116554458706, 'global_pooling': 'max', 'learning_rate': 0.0014629760330653718, 'weight_decay': 0.0002201495274508101, 'beta_0': 0.8350741587535646, 'beta_1': 0.9931233665719553, 'epsilon': 3.667446430308358e-08, 'balanced_loss': False, 'epochs': 81, 'early_stopping_patience': 14, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 08:00:24,584] Trial 333 finished with value: 0.622841743901668 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9821947736738899, 'batch_size': 93, 'attention_heads': 8, 'hidden_dimension': 256, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5046713856668286, 'global_pooling': 'max', 'learning_rate': 0.0016886501814449366, 'weight_decay': 0.0003493522176310137, 'beta_0': 0.862549803279687, 'beta_1': 0.9929648274875899, 'epsilon': 1.5895469272414078e-06, 'balanced_loss': False, 'epochs': 84, 'early_stopping_patience': 19, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 08:25:07,967] Trial 334 finished with value: 0.43596878764518915 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9863417376432321, 'batch_size': 92, 'attention_heads': 10, 'hidden_dimension': 250, 'number_of_hidden_layers': 0, 'dropout_rate': 0.39107724979075154, 'global_pooling': 'max', 'learning_rate': 0.002114733971879323, 'weight_decay': 0.00026443077438129597, 'beta_0': 0.8638539422061446, 'beta_1': 0.9866484313676499, 'epsilon': 4.0398420218862486e-07, 'balanced_loss': False, 'epochs': 77, 'early_stopping_patience': 25, 'plateau_patience': 17, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 08:50:14,807] Trial 335 finished with value: 0.5845736073155671 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9800385320290205, 'batch_size': 97, 'attention_heads': 8, 'hidden_dimension': 247, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32972533519176855, 'global_pooling': 'mean', 'learning_rate': 0.0010118012204455107, 'weight_decay': 0.00039159209719468065, 'beta_0': 0.8612180476893483, 'beta_1': 0.9913862312224008, 'epsilon': 1.1762241441631519e-06, 'balanced_loss': False, 'epochs': 153, 'early_stopping_patience': 21, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 09:13:18,651] Trial 336 finished with value: 0.6016685634102564 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9961336087262542, 'batch_size': 89, 'attention_heads': 7, 'hidden_dimension': 252, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3418714341349728, 'global_pooling': 'max', 'learning_rate': 0.001259940306320498, 'weight_decay': 8.128066800935021e-05, 'beta_0': 0.8672365669994598, 'beta_1': 0.9919818963856821, 'epsilon': 1.754431249801093e-07, 'balanced_loss': False, 'epochs': 83, 'early_stopping_patience': 11, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 09:35:54,752] Trial 337 finished with value: 0.6189198574602396 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.987045885700417, 'batch_size': 94, 'attention_heads': 8, 'hidden_dimension': 95, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32328584312663705, 'global_pooling': 'max', 'learning_rate': 0.0018478476283762056, 'weight_decay': 0.00029494267890339094, 'beta_0': 0.8648347323565355, 'beta_1': 0.9934201677792827, 'epsilon': 5.884974041968233e-06, 'balanced_loss': False, 'epochs': 88, 'early_stopping_patience': 13, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 09:59:39,465] Trial 338 finished with value: 0.5746961670456477 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9927245215734893, 'batch_size': 75, 'attention_heads': 9, 'hidden_dimension': 245, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30856387773474464, 'global_pooling': 'sum', 'learning_rate': 0.0030469337441119187, 'weight_decay': 0.0005846838164814603, 'beta_0': 0.8789934394338845, 'beta_1': 0.9925155158310062, 'epsilon': 6.175945691963052e-07, 'balanced_loss': False, 'epochs': 74, 'early_stopping_patience': 22, 'plateau_patience': 12, 'plateau_divider': 8}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 10:24:17,202] Trial 339 finished with value: 0.6173777799061899 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9780958548956936, 'batch_size': 90, 'attention_heads': 7, 'hidden_dimension': 249, 'number_of_hidden_layers': 0, 'dropout_rate': 0.40381494448183447, 'global_pooling': 'max', 'learning_rate': 0.002337721018961128, 'weight_decay': 0.00041102550925121566, 'beta_0': 0.8842480211528035, 'beta_1': 0.9940914712041179, 'epsilon': 1.9740554395409195e-08, 'balanced_loss': False, 'epochs': 79, 'early_stopping_patience': 25, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 10:48:13,821] Trial 340 finished with value: 0.6245885583012595 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9843698563058846, 'batch_size': 77, 'attention_heads': 5, 'hidden_dimension': 256, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3116081192258999, 'global_pooling': 'max', 'learning_rate': 0.0015371830572353969, 'weight_decay': 0.00018611818172717905, 'beta_0': 0.8745661593696099, 'beta_1': 0.9928399199905711, 'epsilon': 3.0100039135225707e-07, 'balanced_loss': False, 'epochs': 92, 'early_stopping_patience': 23, 'plateau_patience': 11, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
CUDA out of memory. Tried to allocate 1.13 GiB. GPU 0 has a total capacity of 44.56 GiB of which 338.69 MiB is free. Including non-PyTorch memory, this process has 44.22 GiB memory in use. Of the allocated memory 40.93 GiB is allocated by PyTorch, and 2.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 11:10:41,806] Trial 341 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9713603777310261, 'batch_size': 73, 'attention_heads': 7, 'hidden_dimension': 242, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3204949299682865, 'global_pooling': 'max', 'learning_rate': 0.0017759179581255476, 'weight_decay': 8.685778552214904e-06, 'beta_0': 0.869142832615814, 'beta_1': 0.9934805997368206, 'epsilon': 2.6263191324008373e-08, 'balanced_loss': False, 'epochs': 85, 'early_stopping_patience': 20, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 11:34:44,260] Trial 342 finished with value: 0.5799445112399142 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9902080796140997, 'batch_size': 79, 'attention_heads': 8, 'hidden_dimension': 248, 'number_of_hidden_layers': 0, 'dropout_rate': 0.36916930081477106, 'global_pooling': 'max', 'learning_rate': 0.003771886578418514, 'weight_decay': 0.0004578946525152748, 'beta_0': 0.8663996929726725, 'beta_1': 0.9944597809908159, 'epsilon': 4.7224368857694126e-08, 'balanced_loss': False, 'epochs': 80, 'early_stopping_patience': 25, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 225 with value: 0.6511418625796105.
CUDA out of memory. Tried to allocate 354.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 298.69 MiB is free. Including non-PyTorch memory, this process has 44.26 GiB memory in use. Of the allocated memory 41.62 GiB is allocated by PyTorch, and 1.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 11:39:49,099] Trial 343 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8327552232898947, 'batch_size': 78, 'attention_heads': 7, 'hidden_dimension': 239, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3052307260573246, 'global_pooling': 'max', 'learning_rate': 0.0012782084929879884, 'weight_decay': 0.0001303323706866686, 'beta_0': 0.8579575038819889, 'beta_1': 0.9924190113707565, 'epsilon': 3.906975142639905e-08, 'balanced_loss': False, 'epochs': 120, 'early_stopping_patience': 15, 'plateau_patience': 24, 'plateau_divider': 4}. Best is trial 225 with value: 0.6511418625796105.
CUDA out of memory. Tried to allocate 374.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 374.69 MiB is free. Including non-PyTorch memory, this process has 44.19 GiB memory in use. Of the allocated memory 39.23 GiB is allocated by PyTorch, and 3.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 11:50:50,796] Trial 344 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9328261305902266, 'batch_size': 40, 'attention_heads': 5, 'hidden_dimension': 253, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31493756584620225, 'global_pooling': 'max', 'learning_rate': 0.0009216580643900982, 'weight_decay': 0.00034981969978165365, 'beta_0': 0.8621041890809671, 'beta_1': 0.9917928510107032, 'epsilon': 5.924416885969707e-08, 'balanced_loss': False, 'epochs': 97, 'early_stopping_patience': 24, 'plateau_patience': 16, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 12:15:27,453] Trial 345 finished with value: 0.6030222720132844 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9807785889641213, 'batch_size': 70, 'attention_heads': 8, 'hidden_dimension': 246, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3340724043435414, 'global_pooling': 'max', 'learning_rate': 0.0021851961232283246, 'weight_decay': 3.677589738024363e-06, 'beta_0': 0.8724780213700694, 'beta_1': 0.9900922152053739, 'epsilon': 3.371553217751876e-08, 'balanced_loss': False, 'epochs': 77, 'early_stopping_patience': 18, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 12:39:07,479] Trial 346 finished with value: 0.628554114919822 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9967822259970438, 'batch_size': 92, 'attention_heads': 7, 'hidden_dimension': 243, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31091395123260807, 'global_pooling': 'max', 'learning_rate': 0.0010698327329239008, 'weight_decay': 0.0005371935584769026, 'beta_0': 0.8548341118214206, 'beta_1': 0.9931813984299257, 'epsilon': 2.3056204744853083e-08, 'balanced_loss': False, 'epochs': 112, 'early_stopping_patience': 21, 'plateau_patience': 14, 'plateau_divider': 4}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 13:02:20,257] Trial 347 finished with value: 0.6117840179956291 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9871523952597951, 'batch_size': 89, 'attention_heads': 6, 'hidden_dimension': 236, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32690899726055167, 'global_pooling': 'max', 'learning_rate': 0.0014831003609093723, 'weight_decay': 2.290805181786488e-06, 'beta_0': 0.876675360637485, 'beta_1': 0.9928243229579424, 'epsilon': 5.8208592341767766e-08, 'balanced_loss': False, 'epochs': 73, 'early_stopping_patience': 12, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
CUDA out of memory. Tried to allocate 1.22 GiB. GPU 0 has a total capacity of 44.56 GiB of which 996.69 MiB is free. Including non-PyTorch memory, this process has 43.58 GiB memory in use. Of the allocated memory 41.18 GiB is allocated by PyTorch, and 1.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 13:24:30,715] Trial 348 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.976114042420693, 'batch_size': 109, 'attention_heads': 5, 'hidden_dimension': 252, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34966719291712456, 'global_pooling': 'max', 'learning_rate': 0.0026856889018680007, 'weight_decay': 0.0002556908921626605, 'beta_0': 0.8685936242529009, 'beta_1': 0.9937971138019657, 'epsilon': 8.596570250623973e-07, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 13:47:34,026] Trial 349 finished with value: 0.6149318705187901 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9937343567038684, 'batch_size': 75, 'attention_heads': 4, 'hidden_dimension': 248, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32049505723207694, 'global_pooling': 'max', 'learning_rate': 0.0017249615721534226, 'weight_decay': 4.500495088872416e-05, 'beta_0': 0.8642685465962109, 'beta_1': 0.9855400465756086, 'epsilon': 4.5555892870941464e-08, 'balanced_loss': False, 'epochs': 83, 'early_stopping_patience': 25, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 14:10:30,184] Trial 350 finished with value: 0.6074678238192233 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.999954587470799, 'batch_size': 82, 'attention_heads': 6, 'hidden_dimension': 129, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3058262107148298, 'global_pooling': 'max', 'learning_rate': 0.0013085778649906022, 'weight_decay': 4.793178761724798e-06, 'beta_0': 0.873802573587449, 'beta_1': 0.9921163614973837, 'epsilon': 4.067262066210209e-06, 'balanced_loss': False, 'epochs': 89, 'early_stopping_patience': 24, 'plateau_patience': 17, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 14:46:38,340] Trial 351 finished with value: 0.5761087610222073 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9839570602886425, 'batch_size': 77, 'attention_heads': 7, 'hidden_dimension': 241, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3163553265647975, 'global_pooling': 'max', 'learning_rate': 0.002021365334791147, 'weight_decay': 0.00029904717759886973, 'beta_0': 0.8669175095758882, 'beta_1': 0.9936620585424064, 'epsilon': 2.5147006181838886e-07, 'balanced_loss': False, 'epochs': 76, 'early_stopping_patience': 16, 'plateau_patience': 12, 'plateau_divider': 5}. Best is trial 225 with value: 0.6511418625796105.
CUDA out of memory. Tried to allocate 382.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 70.69 MiB is free. Including non-PyTorch memory, this process has 44.48 GiB memory in use. Of the allocated memory 41.19 GiB is allocated by PyTorch, and 2.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 14:55:09,197] Trial 352 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9053451553734797, 'batch_size': 80, 'attention_heads': 5, 'hidden_dimension': 256, 'number_of_hidden_layers': 0, 'dropout_rate': 0.43263511303545016, 'global_pooling': 'max', 'learning_rate': 0.0011547829919118747, 'weight_decay': 0.0005995245843726548, 'beta_0': 0.8709927675363924, 'beta_1': 0.9931858976803687, 'epsilon': 4.081792550223168e-08, 'balanced_loss': False, 'epochs': 79, 'early_stopping_patience': 11, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 225 with value: 0.6511418625796105.
[I 2024-12-23 15:19:22,441] Trial 353 finished with value: 0.6147142757469023 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9897753439118822, 'batch_size': 94, 'attention_heads': 11, 'hidden_dimension': 235, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3375805176525096, 'global_pooling': 'max', 'learning_rate': 0.0024044966729669932, 'weight_decay': 7.59146138303207e-06, 'beta_0': 0.8755640144580263, 'beta_1': 0.9926708073917362, 'epsilon': 2.897132845360604e-08, 'balanced_loss': False, 'epochs': 71, 'early_stopping_patience': 21, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 225 with value: 0.6511418625796105.

[TRIAL] 225 [VALIDATION PERFORMANCE] 0.6511418625796105 [TRAINING LOSS] 0.007661715519669301 [VALIDATION LOSS] 1.6871564388275146 

number                                     225
value                                 0.651142
params_threshold                       0.98208
params_attention_heads                       5
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           80
params_dropout_rate                    0.32243
params_early_stopping_patience              24
params_epochs                              135
params_global_pooling                      max
params_hidden_dimension                    236
params_learning_rate                  0.001723
params_number_of_hidden_layers               0
params_plateau_divider                       8
params_plateau_patience                     15
params_weight_decay                   0.000032
params_beta_0                         0.867354
params_beta_1                         0.992777
params_epsilon                             0.0
user_attrs_epoch                          28.0
user_attrs_training_loss              0.007662
user_attrs_validation_loss            1.687156
params_left_stride                         128
params_right_stride                        128
Name: 225, dtype: object
37 Val: 0.6251837102742159 Test: 0.6417889437586688
38 Val: 0.6221071342289273 Test: 0.6427387285542165
39 Val: 0.6100320848969245 Test: 0.6318042108668704
40 Val: 0.6114929049294769 Test: 0.644366129433182
41 Val: 0.6269919516869139 Test: 0.6441465843683679
42 Val: 0.6291159858794548 Test: 0.6581026625635443
43 Val: 0.625095011465374 Test: 0.6459551592700561
44 Val: 0.6322907918610532 Test: 0.6490450540357259
45 Val: 0.6174196007024375 Test: 0.63711391075049
46 Val: 0.6291713106504117 Test: 0.6609020739827519
Validation performance: 61.0 & 62.29 ± 0.76 & 63.23
Testing performance: 63.18 & 64.56 ± 0.88 & 66.09

[TRIAL] 300 [VALIDATION PERFORMANCE] 0.6488463979603859 [TRAINING LOSS] 0.003538012391225876 [VALIDATION LOSS] 1.3474257349967957 

number                                     300
value                                 0.648846
params_threshold                      0.992036
params_attention_heads                       8
params_balanced_loss                     False
params_embedding_pooling_operation         max
params_attention_pooling_operation         max
params_batch_size                           72
params_dropout_rate                   0.390436
params_early_stopping_patience              24
params_epochs                               93
params_global_pooling                      max
params_hidden_dimension                    242
params_learning_rate                  0.001771
params_number_of_hidden_layers               0
params_plateau_divider                       5
params_plateau_patience                     12
params_weight_decay                   0.000003
params_beta_0                         0.873077
params_beta_1                         0.990648
params_epsilon                             0.0
user_attrs_epoch                          24.0
user_attrs_training_loss              0.003538
user_attrs_validation_loss            1.347426
params_left_stride                         128
params_right_stride                         32
Name: 300, dtype: object
37 Val: 0.6399298117643678 Test: 0.6321907525899839
38 Val: 0.6193660416524421 Test: 0.6495025517190706
39 Val: 0.6328797302713032 Test: 0.6318561007836535
40 Val: 0.6123666149151784 Test: 0.6602841476652028
41 Val: 0.6085631218932688 Test: 0.6385394201517627
42 Val: 0.6488108968772698 Test: 0.6443839882230185
43 Val: 0.5987163931974929 Test: 0.6541641573816693
44 Val: 0.6096259280858249 Test: 0.6406754257682588
45 Val: 0.6382747754352931 Test: 0.6508596559537275
46 Val: 0.6330149698173237 Test: 0.6320714223513937
Validation performance: 59.87 & 62.42 ± 1.66 & 64.88
Testing performance: 63.19 & 64.35 ± 1.01 & 66.03

[TRIAL] 237 [VALIDATION PERFORMANCE] 0.6479819511082777 [TRAINING LOSS] 0.003154695652483497 [VALIDATION LOSS] 1.8531288653612137 

number                                     237
value                                 0.647982
params_threshold                      0.983468
params_attention_heads                       5
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation         max
params_batch_size                           84
params_dropout_rate                   0.329549
params_early_stopping_patience              23
params_epochs                               78
params_global_pooling                      max
params_hidden_dimension                    173
params_learning_rate                  0.002332
params_number_of_hidden_layers               0
params_plateau_divider                       6
params_plateau_patience                     15
params_weight_decay                   0.000007
params_beta_0                         0.863206
params_beta_1                         0.992491
params_epsilon                             0.0
user_attrs_epoch                          20.0
user_attrs_training_loss              0.003155
user_attrs_validation_loss            1.853129
params_left_stride                          32
params_right_stride                          0
Name: 237, dtype: object
37 Val: 0.6163455537444541 Test: 0.642665402553317
38 Val: 0.6219237495742451 Test: 0.6445598392696713
39 Val: 0.6072601615577042 Test: 0.6147248598762312
40 Val: 0.6224800167381447 Test: 0.6373113117275876
41 Val: 0.5962714458595211 Test: 0.6197932068594175
42 Val: 0.6371605707659748 Test: 0.6316666566410837
43 Val: 0.6208925737903669 Test: 0.6529946718488732
44 Val: 0.6238323691157501 Test: 0.6363987289446644
45 Val: 0.6296451779915067 Test: 0.6335904473989867
46 Val: 0.6291213686821883 Test: 0.6407488011571999
Validation performance: 59.63 & 62.05 ± 1.17 & 63.72
Testing performance: 61.47 & 63.54 ± 1.14 & 65.3

[TRIAL] 316 [VALIDATION PERFORMANCE] 0.6431545588115045 [TRAINING LOSS] 0.003707627347368445 [VALIDATION LOSS] 1.2955186903476714 

number                                     316
value                                 0.643155
params_threshold                      0.992747
params_attention_heads                       7
params_balanced_loss                     False
params_embedding_pooling_operation         max
params_attention_pooling_operation         max
params_batch_size                           73
params_dropout_rate                   0.395049
params_early_stopping_patience              21
params_epochs                               82
params_global_pooling                      max
params_hidden_dimension                    256
params_learning_rate                  0.001966
params_number_of_hidden_layers               0
params_plateau_divider                       8
params_plateau_patience                     13
params_weight_decay                   0.000338
params_beta_0                         0.876716
params_beta_1                         0.992231
params_epsilon                             0.0
user_attrs_epoch                          23.0
user_attrs_training_loss              0.003708
user_attrs_validation_loss            1.295519
params_left_stride                           0
params_right_stride                        128
Name: 316, dtype: object
37 Val: 0.6186737300887755 Test: 0.645100974623545
38 Val: 0.6108106902851438 Test: 0.6421775085091018
39 Val: 0.6335546378387878 Test: 0.6241372441945164
40 Val: 0.608527707730023 Test: 0.6334572921162377
41 Val: 0.5996217464533113 Test: 0.6351587910067586
42 Val: 0.625757080481393 Test: 0.633920091539806
43 Val: 0.6027621931577493 Test: 0.6322053442925658
44 Val: 0.6081314650998081 Test: 0.636639653667537
slurmstepd: error: *** JOB 14134231 ON gpu039 CANCELLED AT 2024-12-24T06:19:19 DUE TO TIME LIMIT ***
