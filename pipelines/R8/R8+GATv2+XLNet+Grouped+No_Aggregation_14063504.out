[I 2024-12-05 16:50:07,258] Using an existing study with name 'R8-GATv2-xlnet-xlnet-base-cased-Grouped-No_Aggregation' instead of creating a new one.
Optimization already completed.

[TRIAL] 125 [VALIDATION PERFORMANCE] 0.9564763717525835 [TRAINING LOSS] 0.02372874446666321 [VALIDATION LOSS] 0.13412006869912146 

number                                     125
value                                 0.956476
params_threshold                      0.780541
params_attention_heads                       6
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation        mean
params_batch_size                          120
params_dropout_rate                   0.330269
params_early_stopping_patience              20
params_epochs                               77
params_global_pooling                      max
params_hidden_dimension                    124
params_learning_rate                  0.000188
params_number_of_hidden_layers               0
params_plateau_divider                       3
params_plateau_patience                     16
params_weight_decay                   0.000001
params_beta_0                         0.853204
params_beta_1                         0.987658
params_epsilon                             0.0
user_attrs_epoch                          37.0
user_attrs_training_loss              0.023729
user_attrs_validation_loss             0.13412
Name: 125, dtype: object
37 Val: 0.9529258302194643 Test: 0.9077301464579972
38 Val: 0.9447163038667121 Test: 0.9081371222285337
39 Val: 0.9449014502480745 Test: 0.9078403806294533
40 Val: 0.9382052700835943 Test: 0.9055468432771927
41 Val: 0.9462193289179972 Test: 0.934212992536798
42 Val: 0.9377491110396258 Test: 0.9125748227263697
43 Val: 0.9389013649560931 Test: 0.9108114479929772
44 Val: 0.9452712575809956 Test: 0.904718212372486
45 Val: 0.9454967300951309 Test: 0.9067913472059843
46 Val: 0.9283798009457285 Test: 0.8989117029680251
Validation performance: 92.84 & 94.23 ± 0.67 & 95.29
Testing performance: 89.89 & 90.97 ± 0.94 & 93.42

[TRIAL] 118 [VALIDATION PERFORMANCE] 0.955876017992461 [TRAINING LOSS] 0.00886115394410138 [VALIDATION LOSS] 0.13300553299486637 

number                                     118
value                                 0.955876
params_threshold                      0.800338
params_attention_heads                       6
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation        mean
params_batch_size                          116
params_dropout_rate                   0.317175
params_early_stopping_patience              21
params_epochs                               61
params_global_pooling                      max
params_hidden_dimension                    122
params_learning_rate                   0.00033
params_number_of_hidden_layers               0
params_plateau_divider                       3
params_plateau_patience                     16
params_weight_decay                   0.000002
params_beta_0                         0.852254
params_beta_1                         0.987794
params_epsilon                             0.0
user_attrs_epoch                          32.0
user_attrs_training_loss              0.008861
user_attrs_validation_loss            0.133006
Name: 118, dtype: object
37 Val: 0.943498429292018 Test: 0.9104346853193548
38 Val: 0.9253607680091112 Test: 0.9195351909578212
39 Val: 0.9451475608620028 Test: 0.9208820509582316
40 Val: 0.9494221508585927 Test: 0.9099366042286652
41 Val: 0.9280831797545442 Test: 0.9121623233001356
42 Val: 0.9561086529475926 Test: 0.9114169837743
43 Val: 0.9343853672771305 Test: 0.9025607001193023
44 Val: 0.9444820492914854 Test: 0.9188905959679197
45 Val: 0.9383629384727916 Test: 0.8854440683514375
46 Val: 0.930194102219644 Test: 0.9037413306871342
Validation performance: 92.54 & 93.95 ± 1.0 & 95.61
Testing performance: 88.54 & 90.95 ± 1.05 & 92.09

[TRIAL] 210 [VALIDATION PERFORMANCE] 0.9555249103311603 [TRAINING LOSS] 0.0029309920294455128 [VALIDATION LOSS] 0.15545100884305108 

number                                     210
value                                 0.955525
params_threshold                      0.752188
params_attention_heads                       8
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation        mean
params_batch_size                          131
params_dropout_rate                   0.315683
params_early_stopping_patience              25
params_epochs                              117
params_global_pooling                      max
params_hidden_dimension                    172
params_learning_rate                  0.000916
params_number_of_hidden_layers               0
params_plateau_divider                       5
params_plateau_patience                     14
params_weight_decay                   0.000083
params_beta_0                         0.845184
params_beta_1                         0.986699
params_epsilon                             0.0
user_attrs_epoch                          38.0
user_attrs_training_loss              0.002931
user_attrs_validation_loss            0.155451
Name: 210, dtype: object
37 Val: 0.9231133604409808 Test: 0.8897246617645982
38 Val: 0.9281112647232183 Test: 0.9078513892867088
39 Val: 0.938052502154578 Test: 0.907492541898806
40 Val: 0.9407017811838401 Test: 0.9375816613947578
41 Val: 0.9364836534940607 Test: 0.938979314600197
42 Val: 0.9423388680694449 Test: 0.9269492188079578
43 Val: 0.9339966925440243 Test: 0.928751765451431
44 Val: 0.9398752019093537 Test: 0.9015806418133647
45 Val: 0.9316460899183783 Test: 0.9213547540459288
46 Val: 0.9431345990299791 Test: 0.9155004492011551
Validation performance: 92.31 & 93.57 ± 0.65 & 94.31
Testing performance: 88.97 & 91.76 ± 1.6 & 93.9

[TRIAL] 203 [VALIDATION PERFORMANCE] 0.9514055067750185 [TRAINING LOSS] 0.008321199256566946 [VALIDATION LOSS] 0.14044252617491615 

number                                     203
value                                 0.951406
params_threshold                      0.742935
params_attention_heads                       8
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation        mean
params_batch_size                          134
params_dropout_rate                   0.305338
params_early_stopping_patience              25
params_epochs                              121
params_global_pooling                      max
params_hidden_dimension                    184
params_learning_rate                  0.000814
params_number_of_hidden_layers               0
params_plateau_divider                       5
params_plateau_patience                     14
params_weight_decay                   0.000036
params_beta_0                         0.847816
params_beta_1                         0.988155
params_epsilon                             0.0
user_attrs_epoch                          29.0
user_attrs_training_loss              0.008321
user_attrs_validation_loss            0.140443
Name: 203, dtype: object
37 Val: 0.9343565137842231 Test: 0.9293407055536773
38 Val: 0.9288201385119745 Test: 0.9024996826559393
39 Val: 0.9372024815033041 Test: 0.9140384532291868
40 Val: 0.930812709968261 Test: 0.9213289187087108
41 Val: 0.9372812975751771 Test: 0.9134837875114254
42 Val: 0.941451385204375 Test: 0.9321529897381213
43 Val: 0.9413415671622267 Test: 0.9190222061937698
44 Val: 0.9229075206905304 Test: 0.8854395129356668
45 Val: 0.9297015116546307 Test: 0.9231214778066931
46 Val: 0.9401056806228538 Test: 0.904187720922226
Validation performance: 92.29 & 93.44 ± 0.62 & 94.15
Testing performance: 88.54 & 91.45 ± 1.4 & 93.22

[TRIAL] 232 [VALIDATION PERFORMANCE] 0.9511814504830296 [TRAINING LOSS] 0.019593811318786306 [VALIDATION LOSS] 0.11576948987527026 

number                                     232
value                                 0.951181
params_threshold                      0.758454
params_attention_heads                       7
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation        mean
params_batch_size                          135
params_dropout_rate                   0.328574
params_early_stopping_patience              25
params_epochs                              120
params_global_pooling                      max
params_hidden_dimension                    175
params_learning_rate                   0.00046
params_number_of_hidden_layers               0
params_plateau_divider                       4
params_plateau_patience                     16
params_weight_decay                   0.000014
params_beta_0                         0.855749
params_beta_1                         0.984934
params_epsilon                             0.0
user_attrs_epoch                          25.0
user_attrs_training_loss              0.019594
user_attrs_validation_loss            0.115769
Name: 232, dtype: object
37 Val: 0.9419788658735033 Test: 0.9144880513157534
38 Val: 0.9406730396502622 Test: 0.9089508347924948
39 Val: 0.9395573644443094 Test: 0.9172551707677653
40 Val: 0.9305396189577047 Test: 0.8877006118036526
41 Val: 0.9516095055591263 Test: 0.917368713781151
42 Val: 0.9457937671533589 Test: 0.9098295855397571
43 Val: 0.9204464608067628 Test: 0.9244344879167303
44 Val: 0.9436015064694447 Test: 0.9181637032179113
45 Val: 0.924526733654987 Test: 0.9084434181778663
46 Val: 0.9384551297996111 Test: 0.9204260260410555
Validation performance: 92.04 & 93.77 ± 0.97 & 95.16
Testing performance: 88.77 & 91.27 ± 1.02 & 92.44

[R8] Elapsed time: 68.5395148475965 minutes.
