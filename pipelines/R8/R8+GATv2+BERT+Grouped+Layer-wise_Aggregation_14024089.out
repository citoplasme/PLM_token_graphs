[I 2024-11-28 06:10:40,056] A new study created in RDB with name: R8-GATv2-google-bert-bert-base-uncased-Grouped-Layer-wise_Aggregation
Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors
[I 2024-11-28 06:21:03,412] Trial 0 finished with value: 0.3281535770931543 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7564817426134086, 'batch_size': 150, 'attention_heads': 9, 'hidden_dimension': 97, 'number_of_hidden_layers': 3, 'dropout_rate': 0.34184815819561254, 'global_pooling': 'max', 'learning_rate': 0.013826232179369865, 'weight_decay': 3.972110727381911e-06, 'beta_0': 0.849951952030185, 'beta_1': 0.9912118037965686, 'epsilon': 1.5339162591163588e-08, 'balanced_loss': True, 'epochs': 59, 'early_stopping_patience': 25, 'plateau_patience': 25, 'plateau_divider': 9}. Best is trial 0 with value: 0.3281535770931543.
[I 2024-11-28 06:27:19,849] Trial 1 finished with value: 0.9289204680530407 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9788152345580505, 'batch_size': 233, 'attention_heads': 11, 'hidden_dimension': 239, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35879485872574357, 'global_pooling': 'max', 'learning_rate': 0.00012172958098369953, 'weight_decay': 0.0003063462210622083, 'beta_0': 0.834331843801655, 'beta_1': 0.9853009566677808, 'epsilon': 1.4817820606039087e-06, 'balanced_loss': False, 'epochs': 61, 'early_stopping_patience': 25, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 1 with value: 0.9289204680530407.
[I 2024-11-28 06:33:13,495] Trial 2 finished with value: 0.8999984154935967 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9605155877742886, 'batch_size': 138, 'attention_heads': 5, 'hidden_dimension': 192, 'number_of_hidden_layers': 3, 'dropout_rate': 0.46838315927084884, 'global_pooling': 'mean', 'learning_rate': 0.0005130551760589835, 'weight_decay': 1.1919481947918734e-06, 'beta_0': 0.8102310933924105, 'beta_1': 0.98059161803998, 'epsilon': 3.512704726270843e-06, 'balanced_loss': False, 'epochs': 187, 'early_stopping_patience': 13, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 1 with value: 0.9289204680530407.
[I 2024-11-28 06:42:32,342] Trial 3 finished with value: 0.9294521139388473 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.7297750275380542, 'batch_size': 128, 'attention_heads': 14, 'hidden_dimension': 225, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4532241907732697, 'global_pooling': 'mean', 'learning_rate': 0.00022410971619109496, 'weight_decay': 0.0006741074265640696, 'beta_0': 0.8310413476654125, 'beta_1': 0.9898114758541204, 'epsilon': 6.487477066058673e-06, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 14, 'plateau_patience': 17, 'plateau_divider': 4}. Best is trial 3 with value: 0.9294521139388473.
[I 2024-11-28 06:49:43,285] Trial 4 finished with value: 0.9274765760587935 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.7787204186204115, 'batch_size': 174, 'attention_heads': 12, 'hidden_dimension': 152, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5505907486767714, 'global_pooling': 'mean', 'learning_rate': 0.002309786149269356, 'weight_decay': 0.00010781845035122267, 'beta_0': 0.8015645397505602, 'beta_1': 0.9896841863656863, 'epsilon': 8.053471030316087e-08, 'balanced_loss': True, 'epochs': 154, 'early_stopping_patience': 16, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 3 with value: 0.9294521139388473.
CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.58 GiB is free. Including non-PyTorch memory, this process has 41.97 GiB memory in use. Of the allocated memory 40.18 GiB is allocated by PyTorch, and 654.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-28 06:55:01,469] Trial 5 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9040772280477951, 'batch_size': 233, 'attention_heads': 15, 'hidden_dimension': 207, 'number_of_hidden_layers': 3, 'dropout_rate': 0.3252419894985146, 'global_pooling': 'sum', 'learning_rate': 1.0883991813938131e-05, 'weight_decay': 2.015647705936503e-06, 'beta_0': 0.8650272248026284, 'beta_1': 0.9800952543380481, 'epsilon': 4.397766894483953e-08, 'balanced_loss': False, 'epochs': 148, 'early_stopping_patience': 13, 'plateau_patience': 21, 'plateau_divider': 4}. Best is trial 3 with value: 0.9294521139388473.
[I 2024-11-28 07:02:10,131] Trial 6 finished with value: 0.29300338039282897 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.8519105905803794, 'batch_size': 142, 'attention_heads': 6, 'hidden_dimension': 194, 'number_of_hidden_layers': 1, 'dropout_rate': 0.30729478992943615, 'global_pooling': 'max', 'learning_rate': 0.06542056762893128, 'weight_decay': 0.0005553837526912237, 'beta_0': 0.8356502322469728, 'beta_1': 0.9802909082956842, 'epsilon': 5.167425813322413e-05, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 23, 'plateau_patience': 14, 'plateau_divider': 5}. Best is trial 3 with value: 0.9294521139388473.
The selected strides are greater or equal to the total chunk size.
[I 2024-11-28 07:02:11,222] Trial 7 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7758183080154022, 'batch_size': 98, 'attention_heads': 14, 'hidden_dimension': 214, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5739721657669414, 'global_pooling': 'max', 'learning_rate': 0.0039797493741031125, 'weight_decay': 0.0001276146788173022, 'beta_0': 0.8786113098385785, 'beta_1': 0.996892198716152, 'epsilon': 2.248954284391446e-07, 'balanced_loss': True, 'epochs': 137, 'early_stopping_patience': 10, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 3 with value: 0.9294521139388473.
[I 2024-11-28 07:09:12,134] Trial 8 finished with value: 0.24485591292510855 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9041247058895944, 'batch_size': 251, 'attention_heads': 10, 'hidden_dimension': 104, 'number_of_hidden_layers': 3, 'dropout_rate': 0.38124967537862225, 'global_pooling': 'mean', 'learning_rate': 0.07089141723796885, 'weight_decay': 0.0003220626495993124, 'beta_0': 0.8683420313684149, 'beta_1': 0.9877260389162159, 'epsilon': 4.933751600448336e-08, 'balanced_loss': False, 'epochs': 132, 'early_stopping_patience': 21, 'plateau_patience': 20, 'plateau_divider': 4}. Best is trial 3 with value: 0.9294521139388473.
[I 2024-11-28 07:15:31,610] Trial 9 finished with value: 0.933418466651645 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8220606401321402, 'batch_size': 138, 'attention_heads': 6, 'hidden_dimension': 129, 'number_of_hidden_layers': 1, 'dropout_rate': 0.48475502941566495, 'global_pooling': 'mean', 'learning_rate': 0.003187422711813414, 'weight_decay': 3.2315343430749745e-05, 'beta_0': 0.8849150937783302, 'beta_1': 0.9924741264147013, 'epsilon': 4.484744524732786e-08, 'balanced_loss': False, 'epochs': 54, 'early_stopping_patience': 19, 'plateau_patience': 25, 'plateau_divider': 7}. Best is trial 9 with value: 0.933418466651645.
[I 2024-11-28 07:23:17,093] Trial 10 finished with value: 0.913518424958751 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.6664949826483579, 'batch_size': 40, 'attention_heads': 7, 'hidden_dimension': 38, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5215216634175063, 'global_pooling': 'sum', 'learning_rate': 3.669591461834728e-05, 'weight_decay': 1.61082897385271e-05, 'beta_0': 0.8991067401494276, 'beta_1': 0.9956078490330983, 'epsilon': 3.326182875246256e-07, 'balanced_loss': True, 'epochs': 92, 'early_stopping_patience': 19, 'plateau_patience': 10, 'plateau_divider': 7}. Best is trial 9 with value: 0.933418466651645.
[I 2024-11-28 07:35:18,477] Trial 11 finished with value: 0.9516171797725637 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6924528270578993, 'batch_size': 94, 'attention_heads': 16, 'hidden_dimension': 147, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4473632477367198, 'global_pooling': 'mean', 'learning_rate': 0.00036651279837326777, 'weight_decay': 2.005846062309342e-05, 'beta_0': 0.8230765289451137, 'beta_1': 0.9929852133403209, 'epsilon': 1.297420372982077e-05, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 11 with value: 0.9516171797725637.
[I 2024-11-28 07:41:57,884] Trial 12 finished with value: 0.9485758189903638 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6702225534677031, 'batch_size': 76, 'attention_heads': 4, 'hidden_dimension': 137, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4074839016298433, 'global_pooling': 'mean', 'learning_rate': 0.0012153133644180927, 'weight_decay': 2.4482753574523875e-05, 'beta_0': 0.8189848834723071, 'beta_1': 0.9935869883571339, 'epsilon': 2.2094860255768444e-05, 'balanced_loss': False, 'epochs': 100, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 10}. Best is trial 11 with value: 0.9516171797725637.
[I 2024-11-28 08:04:04,161] Trial 13 finished with value: 0.951782072677531 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6524067293870226, 'batch_size': 60, 'attention_heads': 16, 'hidden_dimension': 154, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3888849316808096, 'global_pooling': 'mean', 'learning_rate': 0.00040209332609098707, 'weight_decay': 1.1752003418812842e-05, 'beta_0': 0.8172660649220073, 'beta_1': 0.9941420202127368, 'epsilon': 5.097670010864778e-05, 'balanced_loss': False, 'epochs': 102, 'early_stopping_patience': 17, 'plateau_patience': 10, 'plateau_divider': 10}. Best is trial 13 with value: 0.951782072677531.
[I 2024-11-28 08:24:46,954] Trial 14 finished with value: 0.9429298922751425 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.7093518394704191, 'batch_size': 40, 'attention_heads': 16, 'hidden_dimension': 166, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4167968571557064, 'global_pooling': 'mean', 'learning_rate': 0.0001171729060679583, 'weight_decay': 6.894223619870373e-06, 'beta_0': 0.819384629213966, 'beta_1': 0.998881893098348, 'epsilon': 7.347697597716605e-05, 'balanced_loss': False, 'epochs': 101, 'early_stopping_patience': 16, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 13 with value: 0.951782072677531.
[I 2024-11-28 08:34:25,854] Trial 15 finished with value: 0.9521323589494136 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6561210755349065, 'batch_size': 76, 'attention_heads': 13, 'hidden_dimension': 63, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4226321539063549, 'global_pooling': 'mean', 'learning_rate': 0.00037739862451563797, 'weight_decay': 1.1428850680838979e-05, 'beta_0': 0.8210060493076966, 'beta_1': 0.9946506297224307, 'epsilon': 1.4081206827145327e-05, 'balanced_loss': False, 'epochs': 112, 'early_stopping_patience': 21, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 15 with value: 0.9521323589494136.
[I 2024-11-28 08:44:10,155] Trial 16 finished with value: 0.9109032415737204 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7333464675485333, 'batch_size': 68, 'attention_heads': 13, 'hidden_dimension': 38, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3751032123853982, 'global_pooling': 'sum', 'learning_rate': 4.090407934216512e-05, 'weight_decay': 7.424720792898314e-06, 'beta_0': 0.8441994959093083, 'beta_1': 0.9957286903556802, 'epsilon': 2.255962464437519e-05, 'balanced_loss': False, 'epochs': 81, 'early_stopping_patience': 21, 'plateau_patience': 11, 'plateau_divider': 8}. Best is trial 15 with value: 0.9521323589494136.
[I 2024-11-28 08:54:07,344] Trial 17 finished with value: 0.7007995261291002 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6560051325322812, 'batch_size': 64, 'attention_heads': 13, 'hidden_dimension': 73, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4143438862152962, 'global_pooling': 'mean', 'learning_rate': 0.009373415816671718, 'weight_decay': 4.7598027423803544e-05, 'beta_0': 0.8003744182467128, 'beta_1': 0.9873097231261093, 'epsilon': 2.269126510581792e-06, 'balanced_loss': False, 'epochs': 169, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 9}. Best is trial 15 with value: 0.9521323589494136.
[I 2024-11-28 09:06:06,451] Trial 18 finished with value: 0.9304438988517052 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8157311633624432, 'batch_size': 112, 'attention_heads': 9, 'hidden_dimension': 73, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5003955324817476, 'global_pooling': 'mean', 'learning_rate': 0.0008266409901576564, 'weight_decay': 6.98564244420247e-06, 'beta_0': 0.8111003415592093, 'beta_1': 0.9985726468542088, 'epsilon': 9.53249166480919e-05, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 23, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 15 with value: 0.9521323589494136.
CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacity of 44.56 GiB of which 684.69 MiB is free. Including non-PyTorch memory, this process has 43.88 GiB memory in use. Of the allocated memory 42.37 GiB is allocated by PyTorch, and 377.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-28 09:10:49,008] Trial 19 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.7011726127843165, 'batch_size': 182, 'attention_heads': 15, 'hidden_dimension': 171, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3948324515619607, 'global_pooling': 'sum', 'learning_rate': 4.8095953711900794e-05, 'weight_decay': 3.163325874640673e-06, 'beta_0': 0.8469953998841874, 'beta_1': 0.9943885047958471, 'epsilon': 7.747798107137818e-06, 'balanced_loss': False, 'epochs': 81, 'early_stopping_patience': 15, 'plateau_patience': 10, 'plateau_divider': 8}. Best is trial 15 with value: 0.9521323589494136.
CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.62 GiB is free. Including non-PyTorch memory, this process has 42.94 GiB memory in use. Of the allocated memory 39.09 GiB is allocated by PyTorch, and 2.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-28 09:26:25,960] Trial 20 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.6560015538042706, 'batch_size': 32, 'attention_heads': 12, 'hidden_dimension': 255, 'number_of_hidden_layers': 3, 'dropout_rate': 0.4377533399594111, 'global_pooling': 'mean', 'learning_rate': 0.00020778435287418024, 'weight_decay': 1.2202614472399117e-05, 'beta_0': 0.8566587105450952, 'beta_1': 0.9913897145012956, 'epsilon': 7.763487007055997e-07, 'balanced_loss': False, 'epochs': 117, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 15 with value: 0.9521323589494136.
[I 2024-11-28 09:40:29,451] Trial 21 finished with value: 0.9440450837509722 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6945484652465223, 'batch_size': 93, 'attention_heads': 16, 'hidden_dimension': 117, 'number_of_hidden_layers': 2, 'dropout_rate': 0.43611150219950257, 'global_pooling': 'mean', 'learning_rate': 0.0005626011089242127, 'weight_decay': 5.05669820333934e-05, 'beta_0': 0.8247099646868926, 'beta_1': 0.9934215078742809, 'epsilon': 1.677656011990728e-05, 'balanced_loss': False, 'epochs': 113, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 15 with value: 0.9521323589494136.
[I 2024-11-28 09:54:49,775] Trial 22 finished with value: 0.9535029686382479 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6907459868659754, 'batch_size': 86, 'attention_heads': 16, 'hidden_dimension': 159, 'number_of_hidden_layers': 1, 'dropout_rate': 0.46451042499896716, 'global_pooling': 'mean', 'learning_rate': 0.00032516049555187716, 'weight_decay': 1.4827991698121976e-05, 'beta_0': 0.8137109402525361, 'beta_1': 0.9967953015475355, 'epsilon': 1.1898949141494236e-05, 'balanced_loss': False, 'epochs': 83, 'early_stopping_patience': 17, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 22 with value: 0.9535029686382479.
[I 2024-11-28 10:08:42,804] Trial 23 finished with value: 0.9504830069527637 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7326943020417505, 'batch_size': 58, 'attention_heads': 14, 'hidden_dimension': 175, 'number_of_hidden_layers': 1, 'dropout_rate': 0.509246202469824, 'global_pooling': 'mean', 'learning_rate': 8.089304518316203e-05, 'weight_decay': 1.1518531702029378e-05, 'beta_0': 0.811110138537064, 'beta_1': 0.9975498296563354, 'epsilon': 3.4030251040541746e-05, 'balanced_loss': False, 'epochs': 73, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 10}. Best is trial 22 with value: 0.9535029686382479.
[I 2024-11-28 10:19:55,982] Trial 24 finished with value: 0.9333912426880236 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6818248782308146, 'batch_size': 52, 'attention_heads': 15, 'hidden_dimension': 77, 'number_of_hidden_layers': 2, 'dropout_rate': 0.46863586340391133, 'global_pooling': 'mean', 'learning_rate': 0.0014052653207299853, 'weight_decay': 4.044737203809066e-06, 'beta_0': 0.8096398863419266, 'beta_1': 0.9954811522739413, 'epsilon': 4.143522771528647e-06, 'balanced_loss': False, 'epochs': 97, 'early_stopping_patience': 23, 'plateau_patience': 11, 'plateau_divider': 9}. Best is trial 22 with value: 0.9535029686382479.
[I 2024-11-28 10:28:42,637] Trial 25 finished with value: 0.942443654596632 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6507240505486379, 'batch_size': 82, 'attention_heads': 13, 'hidden_dimension': 119, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3638148609676825, 'global_pooling': 'mean', 'learning_rate': 0.00038045653979465016, 'weight_decay': 7.995134429592054e-05, 'beta_0': 0.8280171470132046, 'beta_1': 0.9963612504042094, 'epsilon': 1.0206031556352829e-05, 'balanced_loss': False, 'epochs': 75, 'early_stopping_patience': 10, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 22 with value: 0.9535029686382479.
CUDA out of memory. Tried to allocate 3.04 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 41.69 GiB memory in use. Of the allocated memory 37.23 GiB is allocated by PyTorch, and 3.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-28 10:33:46,003] Trial 26 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.722454965496136, 'batch_size': 118, 'attention_heads': 16, 'hidden_dimension': 152, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5995589723505277, 'global_pooling': 'mean', 'learning_rate': 0.00019585474879423514, 'weight_decay': 3.61340514493979e-05, 'beta_0': 0.8163153296309146, 'beta_1': 0.9945917208872982, 'epsilon': 4.36699472711372e-05, 'balanced_loss': True, 'epochs': 93, 'early_stopping_patience': 15, 'plateau_patience': 10, 'plateau_divider': 8}. Best is trial 22 with value: 0.9535029686382479.
[I 2024-11-28 11:00:59,310] Trial 27 finished with value: 0.92702839239667 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7732919466063646, 'batch_size': 107, 'attention_heads': 15, 'hidden_dimension': 95, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5323525696698727, 'global_pooling': 'mean', 'learning_rate': 1.5164810588267804e-05, 'weight_decay': 9.07080741597528e-06, 'beta_0': 0.8426269316364442, 'beta_1': 0.9974268620103036, 'epsilon': 3.099025207990564e-05, 'balanced_loss': False, 'epochs': 107, 'early_stopping_patience': 12, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 22 with value: 0.9535029686382479.
[I 2024-11-28 11:06:48,452] Trial 28 finished with value: 0.9317600333581979 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.684454492810486, 'batch_size': 83, 'attention_heads': 12, 'hidden_dimension': 57, 'number_of_hidden_layers': 0, 'dropout_rate': 0.423248666782322, 'global_pooling': 'max', 'learning_rate': 0.006029308911410843, 'weight_decay': 1.498194200155489e-05, 'beta_0': 0.8049634869883668, 'beta_1': 0.9918359618477869, 'epsilon': 8.157616343286037e-07, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 18, 'plateau_patience': 12, 'plateau_divider': 6}. Best is trial 22 with value: 0.9535029686382479.
CUDA out of memory. Tried to allocate 2.52 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.76 GiB is free. Including non-PyTorch memory, this process has 42.79 GiB memory in use. Of the allocated memory 39.29 GiB is allocated by PyTorch, and 2.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-28 11:11:48,589] Trial 29 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7528096672675558, 'batch_size': 167, 'attention_heads': 11, 'hidden_dimension': 184, 'number_of_hidden_layers': 3, 'dropout_rate': 0.34455469437800923, 'global_pooling': 'sum', 'learning_rate': 0.0010283145276928413, 'weight_decay': 4.357058538330659e-06, 'beta_0': 0.8357856439200851, 'beta_1': 0.9902898548655753, 'epsilon': 3.6480541699160957e-06, 'balanced_loss': True, 'epochs': 85, 'early_stopping_patience': 16, 'plateau_patience': 18, 'plateau_divider': 9}. Best is trial 22 with value: 0.9535029686382479.
[I 2024-11-28 11:25:34,213] Trial 30 finished with value: 0.9439991774648293 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7516404076095506, 'batch_size': 55, 'attention_heads': 14, 'hidden_dimension': 163, 'number_of_hidden_layers': 1, 'dropout_rate': 0.39249882008934434, 'global_pooling': 'max', 'learning_rate': 0.0016340279280289281, 'weight_decay': 2.3329802119740234e-06, 'beta_0': 0.8541763877967351, 'beta_1': 0.9881587998931927, 'epsilon': 9.772691345244706e-05, 'balanced_loss': False, 'epochs': 67, 'early_stopping_patience': 22, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 22 with value: 0.9535029686382479.
[I 2024-11-28 11:37:51,099] Trial 31 finished with value: 0.9581793419336566 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6968014016022918, 'batch_size': 93, 'attention_heads': 16, 'hidden_dimension': 146, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4596762216609653, 'global_pooling': 'mean', 'learning_rate': 0.00034564670954856906, 'weight_decay': 2.1564799532171242e-05, 'beta_0': 0.8236810383102886, 'beta_1': 0.992887864203629, 'epsilon': 1.3656906380695237e-05, 'balanced_loss': False, 'epochs': 107, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 31 with value: 0.9581793419336566.
[I 2024-11-28 11:47:09,632] Trial 32 finished with value: 0.9374795170279393 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7056526406385841, 'batch_size': 76, 'attention_heads': 16, 'hidden_dimension': 132, 'number_of_hidden_layers': 0, 'dropout_rate': 0.46165773889521244, 'global_pooling': 'mean', 'learning_rate': 0.0002936454181535246, 'weight_decay': 2.298232040753806e-05, 'beta_0': 0.8162321884124899, 'beta_1': 0.9943901885709627, 'epsilon': 1.1768226854149206e-05, 'balanced_loss': False, 'epochs': 122, 'early_stopping_patience': 25, 'plateau_patience': 11, 'plateau_divider': 9}. Best is trial 31 with value: 0.9581793419336566.
CUDA out of memory. Tried to allocate 4.01 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.35 GiB is free. Including non-PyTorch memory, this process has 41.21 GiB memory in use. Of the allocated memory 35.77 GiB is allocated by PyTorch, and 4.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-28 12:00:05,542] Trial 33 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6785602225921247, 'batch_size': 194, 'attention_heads': 15, 'hidden_dimension': 100, 'number_of_hidden_layers': 1, 'dropout_rate': 0.485403678704555, 'global_pooling': 'mean', 'learning_rate': 0.0001050953918605468, 'weight_decay': 5.2047417454736105e-06, 'beta_0': 0.8270600055776132, 'beta_1': 0.9908763039711044, 'epsilon': 1.793179638162192e-06, 'balanced_loss': False, 'epochs': 105, 'early_stopping_patience': 18, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 31 with value: 0.9581793419336566.
CUDA out of memory. Tried to allocate 3.26 GiB. GPU 0 has a total capacity of 44.56 GiB of which 650.69 MiB is free. Including non-PyTorch memory, this process has 43.92 GiB memory in use. Of the allocated memory 39.78 GiB is allocated by PyTorch, and 2.98 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-28 12:05:31,286] Trial 34 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7156912130834749, 'batch_size': 121, 'attention_heads': 14, 'hidden_dimension': 158, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4314984467384817, 'global_pooling': 'mean', 'learning_rate': 0.0005871739113159435, 'weight_decay': 6.27496915270814e-05, 'beta_0': 0.8395914518514389, 'beta_1': 0.9947352432325894, 'epsilon': 5.553041132909102e-06, 'balanced_loss': False, 'epochs': 88, 'early_stopping_patience': 15, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 31 with value: 0.9581793419336566.
[I 2024-11-28 12:17:57,375] Trial 35 finished with value: 0.932252485194198 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.6512479094046091, 'batch_size': 103, 'attention_heads': 16, 'hidden_dimension': 116, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4861383308132497, 'global_pooling': 'mean', 'learning_rate': 0.00018445829234325518, 'weight_decay': 1.0931030764639093e-06, 'beta_0': 0.806107545176858, 'beta_1': 0.9850240871558807, 'epsilon': 4.9064217472310894e-05, 'balanced_loss': False, 'epochs': 65, 'early_stopping_patience': 17, 'plateau_patience': 10, 'plateau_divider': 8}. Best is trial 31 with value: 0.9581793419336566.
[I 2024-11-28 12:27:36,590] Trial 36 finished with value: 0.9382403981444407 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7909639162835103, 'batch_size': 51, 'attention_heads': 11, 'hidden_dimension': 192, 'number_of_hidden_layers': 1, 'dropout_rate': 0.45413846513253736, 'global_pooling': 'mean', 'learning_rate': 0.0006519084413574708, 'weight_decay': 1.2416367374449744e-05, 'beta_0': 0.8307518859783598, 'beta_1': 0.9924873942203929, 'epsilon': 2.311359522901346e-05, 'balanced_loss': False, 'epochs': 140, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 31 with value: 0.9581793419336566.
[I 2024-11-28 12:36:24,870] Trial 37 finished with value: 0.2918789554565671 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8567168622558521, 'batch_size': 157, 'attention_heads': 15, 'hidden_dimension': 140, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40025202346284916, 'global_pooling': 'max', 'learning_rate': 0.017838803196435552, 'weight_decay': 2.833754368995207e-05, 'beta_0': 0.8218727190237963, 'beta_1': 0.9977456914521796, 'epsilon': 7.548437208054952e-06, 'balanced_loss': False, 'epochs': 109, 'early_stopping_patience': 14, 'plateau_patience': 13, 'plateau_divider': 9}. Best is trial 31 with value: 0.9581793419336566.
[I 2024-11-28 12:43:47,774] Trial 38 finished with value: 0.8553432765667957 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.980841755916128, 'batch_size': 131, 'attention_heads': 13, 'hidden_dimension': 179, 'number_of_hidden_layers': 3, 'dropout_rate': 0.3442842167007799, 'global_pooling': 'mean', 'learning_rate': 7.753807521578601e-05, 'weight_decay': 0.00011208420333791353, 'beta_0': 0.8144974991592094, 'beta_1': 0.9830181316508826, 'epsilon': 2.2901040902164395e-06, 'balanced_loss': True, 'epochs': 147, 'early_stopping_patience': 16, 'plateau_patience': 11, 'plateau_divider': 8}. Best is trial 31 with value: 0.9581793419336566.
[I 2024-11-28 12:49:38,406] Trial 39 finished with value: 0.9261517019286718 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9246933000862712, 'batch_size': 87, 'attention_heads': 8, 'hidden_dimension': 223, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4730024917528698, 'global_pooling': 'mean', 'learning_rate': 0.0003580379134246348, 'weight_decay': 1.7296757135218553e-06, 'beta_0': 0.832925248652842, 'beta_1': 0.9891750274700728, 'epsilon': 1.213965801256414e-08, 'balanced_loss': False, 'epochs': 170, 'early_stopping_patience': 13, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 31 with value: 0.9581793419336566.
[I 2024-11-28 13:07:53,279] Trial 40 finished with value: 0.9345580681461254 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.6712497951294526, 'batch_size': 72, 'attention_heads': 15, 'hidden_dimension': 204, 'number_of_hidden_layers': 1, 'dropout_rate': 0.38062404410000295, 'global_pooling': 'max', 'learning_rate': 0.0023304990182382557, 'weight_decay': 0.0001983255502409713, 'beta_0': 0.8052605907755268, 'beta_1': 0.9966852645685891, 'epsilon': 6.005616662598009e-05, 'balanced_loss': False, 'epochs': 130, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 5}. Best is trial 31 with value: 0.9581793419336566.
[I 2024-11-28 13:21:40,406] Trial 41 finished with value: 0.9629554078946512 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6949712480539552, 'batch_size': 96, 'attention_heads': 16, 'hidden_dimension': 144, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4425932896871607, 'global_pooling': 'mean', 'learning_rate': 0.0003787161402989896, 'weight_decay': 1.9067176378992048e-05, 'beta_0': 0.8141583937549629, 'beta_1': 0.9930738893046038, 'epsilon': 1.4063707361804423e-05, 'balanced_loss': False, 'epochs': 122, 'early_stopping_patience': 17, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 13:33:28,365] Trial 42 finished with value: 0.9436548471060375 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7404577695443292, 'batch_size': 99, 'attention_heads': 16, 'hidden_dimension': 152, 'number_of_hidden_layers': 1, 'dropout_rate': 0.45306950079116376, 'global_pooling': 'mean', 'learning_rate': 0.0001710101556934719, 'weight_decay': 1.7547823130617533e-05, 'beta_0': 0.8134982417800276, 'beta_1': 0.9938321063490495, 'epsilon': 1.7180652801124292e-05, 'balanced_loss': False, 'epochs': 124, 'early_stopping_patience': 17, 'plateau_patience': 12, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 13:44:16,870] Trial 43 finished with value: 0.9455051959203122 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6853500707186683, 'batch_size': 66, 'attention_heads': 14, 'hidden_dimension': 127, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41725937422741954, 'global_pooling': 'mean', 'learning_rate': 0.00028076552535730257, 'weight_decay': 9.391484784513302e-06, 'beta_0': 0.8216321652437818, 'beta_1': 0.9919221784740221, 'epsilon': 5.227931107600362e-06, 'balanced_loss': False, 'epochs': 96, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 13:50:48,419] Trial 44 finished with value: 0.9345684041823664 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7152324261716604, 'batch_size': 87, 'attention_heads': 15, 'hidden_dimension': 53, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4373149929764327, 'global_pooling': 'mean', 'learning_rate': 0.0005048515626538936, 'weight_decay': 3.800802641290848e-05, 'beta_0': 0.8273985682351187, 'beta_1': 0.995756804391991, 'epsilon': 3.3719348795187144e-05, 'balanced_loss': False, 'epochs': 138, 'early_stopping_patience': 18, 'plateau_patience': 13, 'plateau_divider': 9}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 14:08:31,726] Trial 45 finished with value: 0.9594006707728875 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6677847056096962, 'batch_size': 43, 'attention_heads': 16, 'hidden_dimension': 142, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3187568110137412, 'global_pooling': 'mean', 'learning_rate': 0.0008564116362671991, 'weight_decay': 1.9917677690829224e-05, 'beta_0': 0.8067292605329559, 'beta_1': 0.9928293030924101, 'epsilon': 1.2772877334474378e-05, 'balanced_loss': False, 'epochs': 105, 'early_stopping_patience': 20, 'plateau_patience': 10, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 14:17:28,001] Trial 46 finished with value: 0.9333893709934595 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.670178825082145, 'batch_size': 45, 'attention_heads': 14, 'hidden_dimension': 86, 'number_of_hidden_layers': 1, 'dropout_rate': 0.32175765512986654, 'global_pooling': 'mean', 'learning_rate': 0.0007822077085536022, 'weight_decay': 2.1029170426803422e-05, 'beta_0': 0.807722897332843, 'beta_1': 0.9928668656373437, 'epsilon': 1.3051104472526517e-05, 'balanced_loss': False, 'epochs': 110, 'early_stopping_patience': 20, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 41 with value: 0.9629554078946512.
CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacity of 44.56 GiB of which 326.69 MiB is free. Including non-PyTorch memory, this process has 44.23 GiB memory in use. Of the allocated memory 40.44 GiB is allocated by PyTorch, and 2.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-28 14:22:53,323] Trial 47 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.697830228005001, 'batch_size': 123, 'attention_heads': 16, 'hidden_dimension': 105, 'number_of_hidden_layers': 3, 'dropout_rate': 0.30987149415247367, 'global_pooling': 'sum', 'learning_rate': 0.002164336195180849, 'weight_decay': 1.6081603983644583e-05, 'beta_0': 0.8035351480569444, 'beta_1': 0.9906645090442997, 'epsilon': 1.2658663854952383e-06, 'balanced_loss': True, 'epochs': 120, 'early_stopping_patience': 21, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 14:32:09,192] Trial 48 finished with value: 0.9428014010576948 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.861435531287595, 'batch_size': 149, 'attention_heads': 12, 'hidden_dimension': 145, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5454769990835228, 'global_pooling': 'mean', 'learning_rate': 0.0001414499353881992, 'weight_decay': 2.7175039469194135e-05, 'beta_0': 0.8007159752103736, 'beta_1': 0.9891339435604477, 'epsilon': 2.803433699614594e-06, 'balanced_loss': False, 'epochs': 89, 'early_stopping_patience': 22, 'plateau_patience': 11, 'plateau_divider': 7}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 14:41:00,429] Trial 49 finished with value: 0.915107955507223 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9500910471589477, 'batch_size': 212, 'attention_heads': 15, 'hidden_dimension': 124, 'number_of_hidden_layers': 3, 'dropout_rate': 0.4978614076015099, 'global_pooling': 'mean', 'learning_rate': 0.00432811833805297, 'weight_decay': 5.693457485004966e-06, 'beta_0': 0.8125430440435077, 'beta_1': 0.995367105543475, 'epsilon': 4.651295628841895e-07, 'balanced_loss': False, 'epochs': 134, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 14:49:25,884] Trial 50 finished with value: 0.9461832780100584 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.765117267000643, 'batch_size': 108, 'attention_heads': 10, 'hidden_dimension': 110, 'number_of_hidden_layers': 1, 'dropout_rate': 0.47226469756501877, 'global_pooling': 'mean', 'learning_rate': 0.0009736313074714723, 'weight_decay': 7.41351553482321e-05, 'beta_0': 0.8202785052024398, 'beta_1': 0.9928793945005351, 'epsilon': 1.4139267304824216e-07, 'balanced_loss': False, 'epochs': 102, 'early_stopping_patience': 22, 'plateau_patience': 10, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 15:04:52,787] Trial 51 finished with value: 0.9534500619440955 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6711591912336599, 'batch_size': 33, 'attention_heads': 16, 'hidden_dimension': 139, 'number_of_hidden_layers': 2, 'dropout_rate': 0.35965468574630605, 'global_pooling': 'mean', 'learning_rate': 0.0004448068548776598, 'weight_decay': 9.193603124007676e-06, 'beta_0': 0.8161277586333953, 'beta_1': 0.9938367968927161, 'epsilon': 9.327977190028697e-06, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 17, 'plateau_patience': 10, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 15:21:17,790] Trial 52 finished with value: 0.9431087849569281 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6662214695949885, 'batch_size': 32, 'attention_heads': 16, 'hidden_dimension': 143, 'number_of_hidden_layers': 2, 'dropout_rate': 0.33073214524746974, 'global_pooling': 'mean', 'learning_rate': 0.0002994854949432972, 'weight_decay': 9.033828194597823e-06, 'beta_0': 0.8174099497760492, 'beta_1': 0.9918441375961445, 'epsilon': 8.659201876412105e-06, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 18, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 15:36:23,154] Trial 53 finished with value: 0.957670475278058 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6931926185775601, 'batch_size': 38, 'attention_heads': 15, 'hidden_dimension': 164, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3669089244716371, 'global_pooling': 'mean', 'learning_rate': 0.0004555966584501084, 'weight_decay': 1.4827961167608031e-05, 'beta_0': 0.8081771979807619, 'beta_1': 0.9935260304924075, 'epsilon': 1.564794351501303e-05, 'balanced_loss': False, 'epochs': 50, 'early_stopping_patience': 16, 'plateau_patience': 11, 'plateau_divider': 9}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 15:51:25,777] Trial 54 finished with value: 0.9404148891122767 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6972150555783154, 'batch_size': 40, 'attention_heads': 15, 'hidden_dimension': 166, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3585201592967986, 'global_pooling': 'mean', 'learning_rate': 0.0016008314348627626, 'weight_decay': 1.907251279299925e-05, 'beta_0': 0.8083636454668689, 'beta_1': 0.9933661350399029, 'epsilon': 2.1415142418251455e-05, 'balanced_loss': False, 'epochs': 73, 'early_stopping_patience': 14, 'plateau_patience': 11, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 16:01:10,937] Trial 55 finished with value: 0.9345247833589403 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7986140096143208, 'batch_size': 48, 'attention_heads': 16, 'hidden_dimension': 133, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3005068983956064, 'global_pooling': 'sum', 'learning_rate': 0.00048589715367682306, 'weight_decay': 4.681351673886799e-05, 'beta_0': 0.8111016732063547, 'beta_1': 0.9901100022936916, 'epsilon': 6.092030973495595e-06, 'balanced_loss': False, 'epochs': 50, 'early_stopping_patience': 16, 'plateau_patience': 10, 'plateau_divider': 9}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 16:17:51,648] Trial 56 finished with value: 0.9477158171718453 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.742325976713112, 'batch_size': 34, 'attention_heads': 16, 'hidden_dimension': 161, 'number_of_hidden_layers': 2, 'dropout_rate': 0.35924361345113487, 'global_pooling': 'mean', 'learning_rate': 0.00024067770529121962, 'weight_decay': 1.4070945651392115e-05, 'beta_0': 0.8031938843191936, 'beta_1': 0.9951549567662272, 'epsilon': 1.1151133488493597e-05, 'balanced_loss': False, 'epochs': 54, 'early_stopping_patience': 15, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 16:34:49,190] Trial 57 finished with value: 0.9480815649454482 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7222048890042225, 'batch_size': 64, 'attention_heads': 15, 'hidden_dimension': 186, 'number_of_hidden_layers': 2, 'dropout_rate': 0.33257595114276745, 'global_pooling': 'mean', 'learning_rate': 0.0009473678528125541, 'weight_decay': 3.367086278812263e-05, 'beta_0': 0.8240274864552622, 'beta_1': 0.9913431297565206, 'epsilon': 2.563159245360725e-05, 'balanced_loss': False, 'epochs': 61, 'early_stopping_patience': 17, 'plateau_patience': 11, 'plateau_divider': 9}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 16:52:38,153] Trial 58 finished with value: 0.9330511451424766 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6853078559407161, 'batch_size': 43, 'attention_heads': 16, 'hidden_dimension': 138, 'number_of_hidden_layers': 3, 'dropout_rate': 0.37106798416053544, 'global_pooling': 'mean', 'learning_rate': 0.0007031108675081818, 'weight_decay': 2.3399874141942784e-05, 'beta_0': 0.869036425542072, 'beta_1': 0.9962371444642201, 'epsilon': 1.608445963730859e-05, 'balanced_loss': True, 'epochs': 81, 'early_stopping_patience': 16, 'plateau_patience': 10, 'plateau_divider': 5}. Best is trial 41 with value: 0.9629554078946512.
CUDA out of memory. Tried to allocate 2.05 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.02 GiB is free. Including non-PyTorch memory, this process has 42.53 GiB memory in use. Of the allocated memory 39.26 GiB is allocated by PyTorch, and 2.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-28 16:58:02,523] Trial 59 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7078031202456804, 'batch_size': 57, 'attention_heads': 14, 'hidden_dimension': 200, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3541836705935131, 'global_pooling': 'mean', 'learning_rate': 0.0001305407493642559, 'weight_decay': 7.009997644259149e-06, 'beta_0': 0.8091141716017733, 'beta_1': 0.9981800595091048, 'epsilon': 4.548093381219007e-06, 'balanced_loss': False, 'epochs': 97, 'early_stopping_patience': 14, 'plateau_patience': 11, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 17:08:50,494] Trial 60 finished with value: 0.9505755418871145 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6668294670794055, 'batch_size': 95, 'attention_heads': 4, 'hidden_dimension': 149, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3189801325698632, 'global_pooling': 'max', 'learning_rate': 5.9117137970123136e-05, 'weight_decay': 9.50541675275242e-06, 'beta_0': 0.8990457552445458, 'beta_1': 0.9923255383379883, 'epsilon': 8.191466447092707e-06, 'balanced_loss': False, 'epochs': 119, 'early_stopping_patience': 17, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 41 with value: 0.9629554078946512.
CUDA out of memory. Tried to allocate 3.53 GiB. GPU 0 has a total capacity of 44.56 GiB of which 316.69 MiB is free. Including non-PyTorch memory, this process has 44.24 GiB memory in use. Of the allocated memory 42.81 GiB is allocated by PyTorch, and 285.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-28 17:19:12,761] Trial 61 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6619478930665915, 'batch_size': 74, 'attention_heads': 15, 'hidden_dimension': 169, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4437804246209094, 'global_pooling': 'mean', 'learning_rate': 0.00038361463456184676, 'weight_decay': 1.1307109784014215e-05, 'beta_0': 0.8150484775264176, 'beta_1': 0.9940350174024782, 'epsilon': 1.542288485018329e-05, 'balanced_loss': False, 'epochs': 106, 'early_stopping_patience': 20, 'plateau_patience': 12, 'plateau_divider': 9}. Best is trial 41 with value: 0.9629554078946512.
CUDA out of memory. Tried to allocate 3.34 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.68 GiB is free. Including non-PyTorch memory, this process has 41.88 GiB memory in use. Of the allocated memory 37.40 GiB is allocated by PyTorch, and 3.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-28 17:29:46,285] Trial 62 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.690480349350659, 'batch_size': 82, 'attention_heads': 16, 'hidden_dimension': 158, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4576886148618465, 'global_pooling': 'mean', 'learning_rate': 0.000467340274667288, 'weight_decay': 1.8574584374910036e-05, 'beta_0': 0.8187765672767686, 'beta_1': 0.9932165133785115, 'epsilon': 3.712578253744414e-05, 'balanced_loss': False, 'epochs': 112, 'early_stopping_patience': 18, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 17:36:58,993] Trial 63 finished with value: 0.9449470493700939 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6772146047379215, 'batch_size': 114, 'attention_heads': 14, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40645960497728273, 'global_pooling': 'mean', 'learning_rate': 0.0012272860412565947, 'weight_decay': 0.0008433870920184607, 'beta_0': 0.8125221432954507, 'beta_1': 0.9948527281655353, 'epsilon': 1.0429858018887954e-05, 'balanced_loss': False, 'epochs': 129, 'early_stopping_patience': 19, 'plateau_patience': 10, 'plateau_divider': 9}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 17:51:14,350] Trial 64 finished with value: 0.9436268347384485 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7281513793239192, 'batch_size': 59, 'attention_heads': 13, 'hidden_dimension': 175, 'number_of_hidden_layers': 2, 'dropout_rate': 0.42154883425556633, 'global_pooling': 'mean', 'learning_rate': 0.00023156679597433904, 'weight_decay': 5.499900073891577e-06, 'beta_0': 0.8237911907321525, 'beta_1': 0.9972466369616131, 'epsilon': 2.2267757216975642e-08, 'balanced_loss': False, 'epochs': 92, 'early_stopping_patience': 16, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
[I 2024-11-28 18:01:12,382] Trial 65 finished with value: 0.9377856681986956 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.6985415939812099, 'batch_size': 39, 'attention_heads': 15, 'hidden_dimension': 123, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3730088380519651, 'global_pooling': 'mean', 'learning_rate': 0.0007114248258653751, 'weight_decay': 1.35431319705197e-05, 'beta_0': 0.8067056613758824, 'beta_1': 0.9938021528914354, 'epsilon': 2.0042812426237144e-05, 'balanced_loss': False, 'epochs': 102, 'early_stopping_patience': 17, 'plateau_patience': 15, 'plateau_divider': 8}. Best is trial 41 with value: 0.9629554078946512.
CUDA out of memory. Tried to allocate 3.26 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.07 GiB is free. Including non-PyTorch memory, this process has 41.49 GiB memory in use. Of the allocated memory 40.14 GiB is allocated by PyTorch, and 200.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-28 18:06:48,069] Trial 66 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.6603844691682856, 'batch_size': 69, 'attention_heads': 16, 'hidden_dimension': 214, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4293352706783437, 'global_pooling': 'sum', 'learning_rate': 0.00031937821680146626, 'weight_decay': 2.682284075732479e-05, 'beta_0': 0.8290172791312936, 'beta_1': 0.9924965221794029, 'epsilon': 2.8499811488247854e-05, 'balanced_loss': False, 'epochs': 125, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 10}. Best is trial 41 with value: 0.9629554078946512.
slurmstepd: error: *** JOB 14024089 ON gpu046 CANCELLED AT 2024-11-28T18:10:40 DUE TO TIME LIMIT ***
