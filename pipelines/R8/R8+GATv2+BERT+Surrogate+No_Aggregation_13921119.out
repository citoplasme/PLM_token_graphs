[I 2024-11-13 18:19:19,979] Using an existing study with name 'R8-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors
[I 2024-11-13 18:33:45,863] Trial 260 finished with value: 0.938812488567635 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8094879163120907, 'batch_size': 118, 'attention_heads': 8, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3159520487129637, 'global_pooling': 'max', 'learning_rate': 8.141722359568465e-05, 'weight_decay': 9.168028992355123e-05, 'beta_0': 0.8365817504782849, 'beta_1': 0.9986735319914057, 'epsilon': 1.6171568864348225e-06, 'balanced_loss': False, 'epochs': 56, 'early_stopping_patience': 22, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 18:46:20,185] Trial 261 finished with value: 0.9468496849920055 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8373918363243911, 'batch_size': 114, 'attention_heads': 8, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3437820084806569, 'global_pooling': 'max', 'learning_rate': 9.269099444396649e-05, 'weight_decay': 8.157469226890979e-05, 'beta_0': 0.8468086926893108, 'beta_1': 0.9964665317444142, 'epsilon': 1.9042544196150821e-06, 'balanced_loss': False, 'epochs': 67, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.04 GiB. GPU 0 has a total capacity of 44.56 GiB of which 240.69 MiB is free. Including non-PyTorch memory, this process has 44.32 GiB memory in use. Of the allocated memory 42.96 GiB is allocated by PyTorch, and 217.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-13 18:52:33,361] Trial 262 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.81747677682621, 'batch_size': 106, 'attention_heads': 8, 'hidden_dimension': 45, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3239574831133998, 'global_pooling': 'max', 'learning_rate': 4.102757183935305e-05, 'weight_decay': 0.00010122823114717535, 'beta_0': 0.8386731713994503, 'beta_1': 0.9976663928009041, 'epsilon': 1.068298664266548e-06, 'balanced_loss': False, 'epochs': 77, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.26 GiB. GPU 0 has a total capacity of 44.56 GiB of which 474.69 MiB is free. Including non-PyTorch memory, this process has 44.09 GiB memory in use. Of the allocated memory 42.36 GiB is allocated by PyTorch, and 593.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-13 18:58:54,562] Trial 263 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.788792069403849, 'batch_size': 99, 'attention_heads': 9, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.33696701966364134, 'global_pooling': 'max', 'learning_rate': 6.601697154519657e-05, 'weight_decay': 6.9886705091307e-05, 'beta_0': 0.8607949013945763, 'beta_1': 0.9970216484995934, 'epsilon': 1.9059975509201129e-06, 'balanced_loss': False, 'epochs': 73, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 19:07:33,219] Trial 264 finished with value: 0.20548819703494225 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8375997171352194, 'batch_size': 111, 'attention_heads': 7, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.30864703030424556, 'global_pooling': 'max', 'learning_rate': 0.04111834324236489, 'weight_decay': 0.0003748843625785422, 'beta_0': 0.8427919862708313, 'beta_1': 0.9983665154603709, 'epsilon': 1.5424003382715012e-06, 'balanced_loss': False, 'epochs': 70, 'early_stopping_patience': 22, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 19:20:40,984] Trial 265 finished with value: 0.9526355828217526 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8255835613232224, 'batch_size': 104, 'attention_heads': 8, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3291124854858747, 'global_pooling': 'max', 'learning_rate': 0.00010731517589800898, 'weight_decay': 0.00011803301796123955, 'beta_0': 0.8488385584555861, 'beta_1': 0.9979227654715744, 'epsilon': 1.3669556309143115e-06, 'balanced_loss': False, 'epochs': 87, 'early_stopping_patience': 22, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 19:33:38,196] Trial 266 finished with value: 0.9084922741003071 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8272477843213263, 'batch_size': 85, 'attention_heads': 8, 'hidden_dimension': 51, 'number_of_hidden_layers': 2, 'dropout_rate': 0.42044549627393435, 'global_pooling': 'sum', 'learning_rate': 0.0001125494439558472, 'weight_decay': 0.00013387225939768705, 'beta_0': 0.8461727340103075, 'beta_1': 0.9974713597089221, 'epsilon': 7.748585155616675e-07, 'balanced_loss': False, 'epochs': 86, 'early_stopping_patience': 22, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 19:47:46,347] Trial 267 finished with value: 0.9504318631099831 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8316929706292148, 'batch_size': 91, 'attention_heads': 8, 'hidden_dimension': 43, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3409721996304461, 'global_pooling': 'max', 'learning_rate': 9.94270437546828e-05, 'weight_decay': 9.792563678765116e-05, 'beta_0': 0.8428347229547465, 'beta_1': 0.9978275581715071, 'epsilon': 1.28723402357864e-06, 'balanced_loss': False, 'epochs': 63, 'early_stopping_patience': 21, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 20:01:23,469] Trial 268 finished with value: 0.9483521344976424 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8347695086726289, 'batch_size': 90, 'attention_heads': 8, 'hidden_dimension': 43, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3433834017305052, 'global_pooling': 'max', 'learning_rate': 0.00010707208705721866, 'weight_decay': 5.185408459751566e-05, 'beta_0': 0.8439162593670514, 'beta_1': 0.9968969239481964, 'epsilon': 1.3344446829385754e-06, 'balanced_loss': False, 'epochs': 63, 'early_stopping_patience': 20, 'plateau_patience': 17, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 20:14:24,797] Trial 269 finished with value: 0.9457983000026723 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8253701730833859, 'batch_size': 100, 'attention_heads': 7, 'hidden_dimension': 41, 'number_of_hidden_layers': 2, 'dropout_rate': 0.33277169008550683, 'global_pooling': 'max', 'learning_rate': 0.00013006114519405304, 'weight_decay': 0.00010204069325368817, 'beta_0': 0.8402900165966327, 'beta_1': 0.997855302508526, 'epsilon': 9.64116534026434e-07, 'balanced_loss': False, 'epochs': 69, 'early_stopping_patience': 21, 'plateau_patience': 18, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.33 GiB. GPU 0 has a total capacity of 44.56 GiB of which 56.69 MiB is free. Including non-PyTorch memory, this process has 44.50 GiB memory in use. Of the allocated memory 42.22 GiB is allocated by PyTorch, and 1.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-13 20:20:52,898] Trial 270 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8036730610682077, 'batch_size': 120, 'attention_heads': 8, 'hidden_dimension': 47, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3382323651207572, 'global_pooling': 'max', 'learning_rate': 9.442893819768088e-05, 'weight_decay': 7.894089015495859e-05, 'beta_0': 0.842239704744357, 'beta_1': 0.9978473298593717, 'epsilon': 1.244133581199446e-06, 'balanced_loss': False, 'epochs': 75, 'early_stopping_patience': 22, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 20:33:44,457] Trial 271 finished with value: 0.9310936804784918 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8413619582193566, 'batch_size': 94, 'attention_heads': 8, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3181503303686927, 'global_pooling': 'max', 'learning_rate': 4.852954271704332e-05, 'weight_decay': 0.00034501518845249, 'beta_0': 0.8451145373885485, 'beta_1': 0.9972061015215622, 'epsilon': 1.4574831439914825e-06, 'balanced_loss': False, 'epochs': 56, 'early_stopping_patience': 21, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 20:50:08,995] Trial 272 finished with value: 0.9417033930333896 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8311210275693024, 'batch_size': 115, 'attention_heads': 8, 'hidden_dimension': 39, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3476080013306977, 'global_pooling': 'max', 'learning_rate': 5.6552535594728666e-05, 'weight_decay': 0.0001507554655979043, 'beta_0': 0.8337810596614755, 'beta_1': 0.9965236714404402, 'epsilon': 1.048322601425135e-06, 'balanced_loss': False, 'epochs': 78, 'early_stopping_patience': 21, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 21:05:17,337] Trial 273 finished with value: 0.9487589540456496 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8124095937957696, 'batch_size': 103, 'attention_heads': 8, 'hidden_dimension': 44, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32982166290731324, 'global_pooling': 'max', 'learning_rate': 8.842334854463092e-05, 'weight_decay': 0.00011051382204465975, 'beta_0': 0.8551013458018368, 'beta_1': 0.9974981057210962, 'epsilon': 1.5393821542370143e-06, 'balanced_loss': False, 'epochs': 72, 'early_stopping_patience': 22, 'plateau_patience': 17, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 21:18:26,390] Trial 274 finished with value: 0.9528279524027372 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8210712086701124, 'batch_size': 90, 'attention_heads': 8, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3404777672988805, 'global_pooling': 'max', 'learning_rate': 0.00012169812041641924, 'weight_decay': 0.00010115725458354936, 'beta_0': 0.8498921631733914, 'beta_1': 0.9962838252038494, 'epsilon': 2.1600078805292654e-06, 'balanced_loss': False, 'epochs': 67, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 21:31:52,595] Trial 275 finished with value: 0.9471262058899513 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8238708717656539, 'batch_size': 89, 'attention_heads': 8, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.34239548832523586, 'global_pooling': 'max', 'learning_rate': 0.00012793569683590745, 'weight_decay': 9.249026683636202e-05, 'beta_0': 0.8379716573572229, 'beta_1': 0.9961817721193184, 'epsilon': 2.3251842118699755e-06, 'balanced_loss': False, 'epochs': 58, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 3.71 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.98 GiB is free. Including non-PyTorch memory, this process has 42.57 GiB memory in use. Of the allocated memory 40.91 GiB is allocated by PyTorch, and 523.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-13 21:37:54,660] Trial 276 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8393928947789688, 'batch_size': 111, 'attention_heads': 8, 'hidden_dimension': 228, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3480713952612815, 'global_pooling': 'mean', 'learning_rate': 0.00010503253745667737, 'weight_decay': 7.64593950078644e-05, 'beta_0': 0.8502286425951604, 'beta_1': 0.9967755181156486, 'epsilon': 1.1553655521474148e-06, 'balanced_loss': False, 'epochs': 67, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 21:51:34,164] Trial 277 finished with value: 0.9549200074517479 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.831778147630701, 'batch_size': 117, 'attention_heads': 8, 'hidden_dimension': 50, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3179781477652654, 'global_pooling': 'max', 'learning_rate': 0.0001297652202916487, 'weight_decay': 9.290767670916067e-05, 'beta_0': 0.8483428871428962, 'beta_1': 0.9962534817722066, 'epsilon': 2.0827074728572575e-06, 'balanced_loss': False, 'epochs': 62, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 22:06:52,190] Trial 278 finished with value: 0.9516186779377168 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8229171335686148, 'batch_size': 118, 'attention_heads': 8, 'hidden_dimension': 51, 'number_of_hidden_layers': 2, 'dropout_rate': 0.31087047378809074, 'global_pooling': 'max', 'learning_rate': 0.00013348473399365534, 'weight_decay': 6.721575779985921e-05, 'beta_0': 0.8478965973395672, 'beta_1': 0.9961568714209019, 'epsilon': 2.1707639951798983e-06, 'balanced_loss': False, 'epochs': 67, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacity of 44.56 GiB of which 320.69 MiB is free. Including non-PyTorch memory, this process has 44.24 GiB memory in use. Of the allocated memory 42.16 GiB is allocated by PyTorch, and 953.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-13 22:19:47,394] Trial 279 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8202952331497737, 'batch_size': 120, 'attention_heads': 7, 'hidden_dimension': 56, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3110555041258889, 'global_pooling': 'max', 'learning_rate': 0.00013278494702267195, 'weight_decay': 7.128132193181437e-05, 'beta_0': 0.8530393161133533, 'beta_1': 0.996328642256222, 'epsilon': 2.9971326422508383e-06, 'balanced_loss': False, 'epochs': 66, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 4.37 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.85 GiB is free. Including non-PyTorch memory, this process has 42.71 GiB memory in use. Of the allocated memory 41.29 GiB is allocated by PyTorch, and 271.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-13 22:25:49,815] Trial 280 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8274092733756956, 'batch_size': 117, 'attention_heads': 8, 'hidden_dimension': 248, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3159353602690237, 'global_pooling': 'max', 'learning_rate': 0.0001300816265109518, 'weight_decay': 6.20892700200063e-05, 'beta_0': 0.8494912480172906, 'beta_1': 0.9969609593488274, 'epsilon': 2.4178073357108288e-06, 'balanced_loss': False, 'epochs': 62, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.42 GiB is free. Including non-PyTorch memory, this process has 43.13 GiB memory in use. Of the allocated memory 41.19 GiB is allocated by PyTorch, and 804.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-13 22:39:23,029] Trial 281 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8222806694924311, 'batch_size': 113, 'attention_heads': 8, 'hidden_dimension': 49, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3056513872191604, 'global_pooling': 'max', 'learning_rate': 0.00011184339961850295, 'weight_decay': 8.55733125715078e-05, 'beta_0': 0.8497293968463647, 'beta_1': 0.9962135004823405, 'epsilon': 2.108729654682864e-06, 'balanced_loss': False, 'epochs': 69, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 22:51:13,134] Trial 282 finished with value: 0.940450423578574 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8429853346396163, 'batch_size': 80, 'attention_heads': 7, 'hidden_dimension': 50, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3007284139179117, 'global_pooling': 'max', 'learning_rate': 0.00014464544913088046, 'weight_decay': 4.481828489967862e-05, 'beta_0': 0.8480305621196991, 'beta_1': 0.99671428536684, 'epsilon': 2.655667883395027e-06, 'balanced_loss': False, 'epochs': 72, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.76 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.40 GiB is free. Including non-PyTorch memory, this process has 43.15 GiB memory in use. Of the allocated memory 41.07 GiB is allocated by PyTorch, and 955.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-13 23:04:57,509] Trial 283 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8340457125254047, 'batch_size': 123, 'attention_heads': 9, 'hidden_dimension': 53, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3213054500752208, 'global_pooling': 'max', 'learning_rate': 0.00013339742467299476, 'weight_decay': 0.00010305746077586276, 'beta_0': 0.8472083253169272, 'beta_1': 0.9971797487599345, 'epsilon': 3.4691877400834655e-06, 'balanced_loss': False, 'epochs': 75, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 23:19:08,905] Trial 284 finished with value: 0.943208605267829 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8073664158296662, 'batch_size': 107, 'attention_heads': 8, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.31147077404892004, 'global_pooling': 'max', 'learning_rate': 0.00010916644969950102, 'weight_decay': 0.00021544501557740518, 'beta_0': 0.8484738635109005, 'beta_1': 0.9963576794602748, 'epsilon': 2.285798366104865e-06, 'balanced_loss': False, 'epochs': 67, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.11 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.09 GiB is free. Including non-PyTorch memory, this process has 43.46 GiB memory in use. Of the allocated memory 37.00 GiB is allocated by PyTorch, and 5.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-13 23:26:00,675] Trial 285 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8200511333815786, 'batch_size': 116, 'attention_heads': 8, 'hidden_dimension': 46, 'number_of_hidden_layers': 2, 'dropout_rate': 0.31851647863390287, 'global_pooling': 'max', 'learning_rate': 8.314870433725563e-05, 'weight_decay': 0.0001320578967120017, 'beta_0': 0.8672925337672506, 'beta_1': 0.9973858418559837, 'epsilon': 2.018149396848423e-06, 'balanced_loss': False, 'epochs': 71, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-13 23:40:22,970] Trial 286 finished with value: 0.9525642170278059 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7991848331876996, 'batch_size': 111, 'attention_heads': 8, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32459797706852483, 'global_pooling': 'max', 'learning_rate': 0.00011273198001490327, 'weight_decay': 6.669761621954058e-05, 'beta_0': 0.8206561052329566, 'beta_1': 0.9966351133385613, 'epsilon': 1.9918341949475392e-06, 'balanced_loss': False, 'epochs': 74, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.15 GiB. GPU 0 has a total capacity of 44.56 GiB of which 362.69 MiB is free. Including non-PyTorch memory, this process has 44.20 GiB memory in use. Of the allocated memory 42.21 GiB is allocated by PyTorch, and 854.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-13 23:46:28,765] Trial 287 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7813041686391938, 'batch_size': 109, 'attention_heads': 8, 'hidden_dimension': 41, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3250375926469355, 'global_pooling': 'max', 'learning_rate': 0.00011712531208586818, 'weight_decay': 5.604858052878653e-05, 'beta_0': 0.856026879839586, 'beta_1': 0.9960068582139228, 'epsilon': 2.7655120391284447e-06, 'balanced_loss': False, 'epochs': 64, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.02 GiB. GPU 0 has a total capacity of 44.56 GiB of which 770.69 MiB is free. Including non-PyTorch memory, this process has 43.80 GiB memory in use. Of the allocated memory 42.07 GiB is allocated by PyTorch, and 590.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-13 23:52:30,634] Trial 288 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7679910402053991, 'batch_size': 120, 'attention_heads': 9, 'hidden_dimension': 35, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3166704016167552, 'global_pooling': 'max', 'learning_rate': 0.0001415968836836038, 'weight_decay': 6.599224599910244e-05, 'beta_0': 0.823057956567827, 'beta_1': 0.9965049223835772, 'epsilon': 4.244144138658812e-06, 'balanced_loss': False, 'epochs': 70, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 00:06:42,026] Trial 289 finished with value: 0.917916584044446 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7980740904468425, 'batch_size': 113, 'attention_heads': 8, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32734555900249795, 'global_pooling': 'sum', 'learning_rate': 7.21784041348167e-05, 'weight_decay': 7.608557777367314e-05, 'beta_0': 0.8195874540274309, 'beta_1': 0.9988408657545736, 'epsilon': 1.969744063186186e-06, 'balanced_loss': False, 'epochs': 74, 'early_stopping_patience': 24, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.38 GiB. GPU 0 has a total capacity of 44.56 GiB of which 644.69 MiB is free. Including non-PyTorch memory, this process has 43.92 GiB memory in use. Of the allocated memory 41.23 GiB is allocated by PyTorch, and 1.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-14 00:12:46,602] Trial 290 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8093946056332182, 'batch_size': 110, 'attention_heads': 14, 'hidden_dimension': 41, 'number_of_hidden_layers': 2, 'dropout_rate': 0.30790075325744176, 'global_pooling': 'max', 'learning_rate': 0.00011736513145043077, 'weight_decay': 8.642673743335199e-05, 'beta_0': 0.8638372599797138, 'beta_1': 0.9971139594058689, 'epsilon': 1.4983075050532116e-06, 'balanced_loss': False, 'epochs': 66, 'early_stopping_patience': 25, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.24 GiB. GPU 0 has a total capacity of 44.56 GiB of which 836.69 MiB is free. Including non-PyTorch memory, this process has 43.74 GiB memory in use. Of the allocated memory 41.69 GiB is allocated by PyTorch, and 912.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-14 00:19:52,891] Trial 291 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7936399154055345, 'batch_size': 124, 'attention_heads': 8, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3217127740655007, 'global_pooling': 'max', 'learning_rate': 8.5832590063793e-05, 'weight_decay': 3.519343823011086e-05, 'beta_0': 0.8529900218468676, 'beta_1': 0.997606508041988, 'epsilon': 2.429524762936386e-06, 'balanced_loss': False, 'epochs': 69, 'early_stopping_patience': 23, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 00:37:10,592] Trial 292 finished with value: 0.9463247696026352 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8148489006871513, 'batch_size': 117, 'attention_heads': 7, 'hidden_dimension': 46, 'number_of_hidden_layers': 2, 'dropout_rate': 0.31434755957341964, 'global_pooling': 'max', 'learning_rate': 5.5908340986823664e-05, 'weight_decay': 5.056092211066853e-05, 'beta_0': 0.8452558569985951, 'beta_1': 0.998294376217754, 'epsilon': 3.054739721007896e-06, 'balanced_loss': False, 'epochs': 118, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 00:51:33,660] Trial 293 finished with value: 0.9417904389950956 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8166065751589762, 'batch_size': 105, 'attention_heads': 8, 'hidden_dimension': 39, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3312846144838632, 'global_pooling': 'max', 'learning_rate': 0.00010065963484927252, 'weight_decay': 0.00011412586071249602, 'beta_0': 0.8468458463461539, 'beta_1': 0.9959862540326926, 'epsilon': 7.390085666864849e-06, 'balanced_loss': False, 'epochs': 58, 'early_stopping_patience': 24, 'plateau_patience': 21, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 01:04:47,304] Trial 294 finished with value: 0.9543790012640193 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8364996400522698, 'batch_size': 113, 'attention_heads': 9, 'hidden_dimension': 44, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32355743007587406, 'global_pooling': 'max', 'learning_rate': 0.00014969881726486296, 'weight_decay': 6.403842127074749e-05, 'beta_0': 0.8213083747186338, 'beta_1': 0.9965876880345994, 'epsilon': 7.568566026247945e-07, 'balanced_loss': False, 'epochs': 73, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.29 GiB. GPU 0 has a total capacity of 44.56 GiB of which 978.69 MiB is free. Including non-PyTorch memory, this process has 43.60 GiB memory in use. Of the allocated memory 41.49 GiB is allocated by PyTorch, and 976.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-14 01:10:52,908] Trial 295 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8055513375673956, 'batch_size': 115, 'attention_heads': 9, 'hidden_dimension': 49, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3246072735582265, 'global_pooling': 'max', 'learning_rate': 0.0001448502284313361, 'weight_decay': 0.00015815776723068802, 'beta_0': 0.8209504293287639, 'beta_1': 0.9965840803818388, 'epsilon': 5.3056651699623455e-06, 'balanced_loss': True, 'epochs': 73, 'early_stopping_patience': 24, 'plateau_patience': 16, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 01:22:00,563] Trial 296 finished with value: 0.9486481868723854 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.841387041297622, 'batch_size': 109, 'attention_heads': 9, 'hidden_dimension': 44, 'number_of_hidden_layers': 2, 'dropout_rate': 0.33564771275415556, 'global_pooling': 'max', 'learning_rate': 0.00016525078298639355, 'weight_decay': 8.901717456698613e-05, 'beta_0': 0.821040130368962, 'beta_1': 0.996425827809416, 'epsilon': 5.669826787318896e-07, 'balanced_loss': False, 'epochs': 78, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacity of 44.56 GiB of which 440.69 MiB is free. Including non-PyTorch memory, this process has 44.12 GiB memory in use. Of the allocated memory 42.49 GiB is allocated by PyTorch, and 497.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-14 01:28:01,680] Trial 297 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.697830228005001, 'batch_size': 120, 'attention_heads': 9, 'hidden_dimension': 54, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3287794883366459, 'global_pooling': 'max', 'learning_rate': 0.00019327121765721364, 'weight_decay': 9.924394977490735e-05, 'beta_0': 0.818862412789572, 'beta_1': 0.9961114406903683, 'epsilon': 3.6571449028324493e-06, 'balanced_loss': False, 'epochs': 75, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.39 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.06 GiB is free. Including non-PyTorch memory, this process has 43.49 GiB memory in use. Of the allocated memory 41.30 GiB is allocated by PyTorch, and 1.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-14 01:40:47,913] Trial 298 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8218361523140272, 'batch_size': 110, 'attention_heads': 8, 'hidden_dimension': 42, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32272421366518284, 'global_pooling': 'max', 'learning_rate': 0.00012322086942528456, 'weight_decay': 7.443467206803677e-05, 'beta_0': 0.822361876507049, 'beta_1': 0.9968959270591901, 'epsilon': 2.1305193746321987e-06, 'balanced_loss': False, 'epochs': 71, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 01:51:46,593] Trial 299 finished with value: 0.9459910958497464 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8299507076534461, 'batch_size': 114, 'attention_heads': 7, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.33520225557018885, 'global_pooling': 'mean', 'learning_rate': 0.00014577129050526004, 'weight_decay': 0.00012878469652208903, 'beta_0': 0.8519914709896033, 'beta_1': 0.9957026117894178, 'epsilon': 2.5679521696599855e-06, 'balanced_loss': False, 'epochs': 74, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 02:06:09,307] Trial 300 finished with value: 0.9513423278392041 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7996680364819437, 'batch_size': 124, 'attention_heads': 8, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3279048778773864, 'global_pooling': 'max', 'learning_rate': 0.00011392642107007817, 'weight_decay': 0.0002941357069561744, 'beta_0': 0.849152060294655, 'beta_1': 0.9970095937608543, 'epsilon': 1.762539584745445e-06, 'balanced_loss': False, 'epochs': 87, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 4}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.35 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1020.69 MiB is free. Including non-PyTorch memory, this process has 43.56 GiB memory in use. Of the allocated memory 41.73 GiB is allocated by PyTorch, and 692.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-14 02:12:35,539] Trial 301 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8035628428972201, 'batch_size': 125, 'attention_heads': 8, 'hidden_dimension': 45, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3179813030360641, 'global_pooling': 'max', 'learning_rate': 0.00012433727142283966, 'weight_decay': 0.00011401601922363015, 'beta_0': 0.8492468445282354, 'beta_1': 0.9973379517884938, 'epsilon': 1.7084213187587986e-06, 'balanced_loss': False, 'epochs': 86, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.04 GiB. GPU 0 has a total capacity of 44.56 GiB of which 980.69 MiB is free. Including non-PyTorch memory, this process has 43.60 GiB memory in use. Of the allocated memory 39.53 GiB is allocated by PyTorch, and 2.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-14 02:19:12,187] Trial 302 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7927716831972031, 'batch_size': 121, 'attention_heads': 7, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32730038387079236, 'global_pooling': 'max', 'learning_rate': 8.033892097276763e-05, 'weight_decay': 0.0004091397058912483, 'beta_0': 0.8490799121200316, 'beta_1': 0.9962609476538035, 'epsilon': 2.040799860993183e-06, 'balanced_loss': False, 'epochs': 90, 'early_stopping_patience': 17, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 02:30:40,489] Trial 303 finished with value: 0.9548704469311556 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8119380136143795, 'batch_size': 125, 'attention_heads': 8, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3207458130868618, 'global_pooling': 'max', 'learning_rate': 0.00018095006727042375, 'weight_decay': 0.00028414050621936916, 'beta_0': 0.8467742358491396, 'beta_1': 0.9971066736429017, 'epsilon': 8.136334928909087e-07, 'balanced_loss': False, 'epochs': 81, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 4}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 02:42:02,283] Trial 304 finished with value: 0.9516924173228187 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.81153581288935, 'batch_size': 116, 'attention_heads': 8, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.31455109053265473, 'global_pooling': 'max', 'learning_rate': 0.0002121835535091278, 'weight_decay': 0.00023708508660652192, 'beta_0': 0.8462817212647368, 'beta_1': 0.9986180587609571, 'epsilon': 9.936022036370289e-07, 'balanced_loss': False, 'epochs': 81, 'early_stopping_patience': 22, 'plateau_patience': 22, 'plateau_divider': 4}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 02:53:20,175] Trial 305 finished with value: 0.9496304419658446 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8107206832609011, 'batch_size': 118, 'attention_heads': 8, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3215086551190861, 'global_pooling': 'max', 'learning_rate': 0.0002454357297023617, 'weight_decay': 0.00026018413509767654, 'beta_0': 0.847460470414316, 'beta_1': 0.9986077646149703, 'epsilon': 7.256153913769254e-07, 'balanced_loss': True, 'epochs': 78, 'early_stopping_patience': 22, 'plateau_patience': 22, 'plateau_divider': 5}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 03:05:33,055] Trial 306 finished with value: 0.9477743860525195 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8106712091709956, 'batch_size': 114, 'attention_heads': 9, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.468277409150846, 'global_pooling': 'max', 'learning_rate': 0.00017763985671280177, 'weight_decay': 0.00021638411667756322, 'beta_0': 0.845019173506977, 'beta_1': 0.9989186479711478, 'epsilon': 1.0119137804759874e-06, 'balanced_loss': False, 'epochs': 79, 'early_stopping_patience': 22, 'plateau_patience': 21, 'plateau_divider': 4}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 03:18:16,766] Trial 307 finished with value: 0.9383684593538734 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.8206549514758736, 'batch_size': 103, 'attention_heads': 8, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.31128619617872555, 'global_pooling': 'max', 'learning_rate': 0.00014244580009828352, 'weight_decay': 9.135578259034231e-05, 'beta_0': 0.8509875293263761, 'beta_1': 0.9982018725314641, 'epsilon': 5.441671877525014e-07, 'balanced_loss': False, 'epochs': 82, 'early_stopping_patience': 22, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 03:29:37,747] Trial 308 finished with value: 0.9482431748829518 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8155142203097039, 'batch_size': 118, 'attention_heads': 7, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3152206648176728, 'global_pooling': 'max', 'learning_rate': 0.00016994337573977448, 'weight_decay': 0.00024973374262144766, 'beta_0': 0.8464649019812691, 'beta_1': 0.9980341027464272, 'epsilon': 3.837469801515795e-07, 'balanced_loss': False, 'epochs': 80, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 4}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.35 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.05 GiB is free. Including non-PyTorch memory, this process has 43.51 GiB memory in use. Of the allocated memory 41.85 GiB is allocated by PyTorch, and 521.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-14 03:35:47,244] Trial 309 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8018044064353916, 'batch_size': 112, 'attention_heads': 8, 'hidden_dimension': 50, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3310265641444588, 'global_pooling': 'max', 'learning_rate': 9.415899068163188e-05, 'weight_decay': 0.0001832319645063215, 'beta_0': 0.8460962347422153, 'beta_1': 0.9985308413416237, 'epsilon': 7.391124851366027e-07, 'balanced_loss': False, 'epochs': 83, 'early_stopping_patience': 22, 'plateau_patience': 22, 'plateau_divider': 4}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 03:50:35,235] Trial 310 finished with value: 0.9407511128025425 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8251893444960628, 'batch_size': 126, 'attention_heads': 9, 'hidden_dimension': 44, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32172397515647083, 'global_pooling': 'max', 'learning_rate': 7.150371956542745e-05, 'weight_decay': 0.00034072463974691445, 'beta_0': 0.841172973093282, 'beta_1': 0.9954857672192371, 'epsilon': 9.823330209859333e-07, 'balanced_loss': False, 'epochs': 76, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 4}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 04:05:14,489] Trial 311 finished with value: 0.7604359698525291 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8159961582607722, 'batch_size': 106, 'attention_heads': 8, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.30544385446936767, 'global_pooling': 'max', 'learning_rate': 1.0942290680543605e-05, 'weight_decay': 0.0002819408561282874, 'beta_0': 0.8435127102131331, 'beta_1': 0.9977768994334704, 'epsilon': 8.742717958748341e-07, 'balanced_loss': False, 'epochs': 73, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 04:20:21,159] Trial 312 finished with value: 0.9425256515132189 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8267841082232616, 'batch_size': 122, 'attention_heads': 8, 'hidden_dimension': 39, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3405686181468403, 'global_pooling': 'sum', 'learning_rate': 0.00015246257013233616, 'weight_decay': 6.775720462187437e-05, 'beta_0': 0.8443312988803932, 'beta_1': 0.997412915764124, 'epsilon': 1.127529625757954e-06, 'balanced_loss': False, 'epochs': 68, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 04:34:37,563] Trial 313 finished with value: 0.9398425756355568 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8098121488077354, 'batch_size': 117, 'attention_heads': 8, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3271687251901445, 'global_pooling': 'max', 'learning_rate': 9.993030483111747e-05, 'weight_decay': 0.0003145335187999141, 'beta_0': 0.8708900685846687, 'beta_1': 0.9984679158504022, 'epsilon': 8.353186711212454e-07, 'balanced_loss': False, 'epochs': 77, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 04:46:27,760] Trial 314 finished with value: 0.9519229628091017 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8189775998123355, 'batch_size': 111, 'attention_heads': 8, 'hidden_dimension': 35, 'number_of_hidden_layers': 2, 'dropout_rate': 0.356463807807607, 'global_pooling': 'max', 'learning_rate': 0.00020194221428238696, 'weight_decay': 0.0004338580632585227, 'beta_0': 0.8244321994601078, 'beta_1': 0.995869389015758, 'epsilon': 1.4342111443290576e-06, 'balanced_loss': False, 'epochs': 80, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 1.26 GiB. GPU 0 has a total capacity of 44.56 GiB of which 32.69 MiB is free. Including non-PyTorch memory, this process has 44.52 GiB memory in use. Of the allocated memory 42.69 GiB is allocated by PyTorch, and 697.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-14 04:52:42,814] Trial 315 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7871847363461703, 'batch_size': 111, 'attention_heads': 9, 'hidden_dimension': 35, 'number_of_hidden_layers': 2, 'dropout_rate': 0.35634434062424203, 'global_pooling': 'max', 'learning_rate': 0.000222483858271093, 'weight_decay': 0.0004197748967360234, 'beta_0': 0.821844787877239, 'beta_1': 0.9982436532591874, 'epsilon': 1.4139548474449336e-06, 'balanced_loss': False, 'epochs': 84, 'early_stopping_patience': 22, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 05:04:05,270] Trial 316 finished with value: 0.9428900713318622 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8064455144204392, 'batch_size': 104, 'attention_heads': 8, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.36615977504260655, 'global_pooling': 'max', 'learning_rate': 0.000259209333880747, 'weight_decay': 0.0001114352298369173, 'beta_0': 0.8241500973278489, 'beta_1': 0.9978894070627417, 'epsilon': 1.1802703309486467e-06, 'balanced_loss': True, 'epochs': 79, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 05:16:06,809] Trial 317 finished with value: 0.951058029700253 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8180834265262633, 'batch_size': 113, 'attention_heads': 8, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3548296723929642, 'global_pooling': 'max', 'learning_rate': 0.00021115450503405347, 'weight_decay': 0.00044099745090507564, 'beta_0': 0.8196675390986559, 'beta_1': 0.9955049935039582, 'epsilon': 1.5051131302146358e-06, 'balanced_loss': False, 'epochs': 80, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 5}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 05:26:46,566] Trial 318 finished with value: 0.9505859823262315 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8337212684279701, 'batch_size': 107, 'attention_heads': 7, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3437905863278046, 'global_pooling': 'max', 'learning_rate': 0.00018812170320305305, 'weight_decay': 0.0006670973638934148, 'beta_0': 0.8248655061341607, 'beta_1': 0.9989408098035133, 'epsilon': 8.529947267948311e-07, 'balanced_loss': False, 'epochs': 75, 'early_stopping_patience': 22, 'plateau_patience': 23, 'plateau_divider': 4}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 05:41:24,279] Trial 319 finished with value: 0.940477340481498 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8145210992353128, 'batch_size': 103, 'attention_heads': 8, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3589957574810471, 'global_pooling': 'max', 'learning_rate': 4.5862141494872347e-05, 'weight_decay': 0.00032633109491311547, 'beta_0': 0.818420327211517, 'beta_1': 0.9958773071881082, 'epsilon': 6.08537998530806e-07, 'balanced_loss': False, 'epochs': 72, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 2.25 GiB. GPU 0 has a total capacity of 44.56 GiB of which 274.69 MiB is free. Including non-PyTorch memory, this process has 44.29 GiB memory in use. Of the allocated memory 42.68 GiB is allocated by PyTorch, and 468.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-14 05:47:28,203] Trial 320 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.798772085739616, 'batch_size': 58, 'attention_heads': 8, 'hidden_dimension': 181, 'number_of_hidden_layers': 2, 'dropout_rate': 0.34988289098731534, 'global_pooling': 'max', 'learning_rate': 7.783477060148552e-05, 'weight_decay': 0.0001363742500820045, 'beta_0': 0.8805075911475208, 'beta_1': 0.9973869814854677, 'epsilon': 1.2287144253466123e-06, 'balanced_loss': False, 'epochs': 81, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 70.69 MiB is free. Including non-PyTorch memory, this process has 44.48 GiB memory in use. Of the allocated memory 42.97 GiB is allocated by PyTorch, and 375.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-14 05:53:26,928] Trial 321 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.6536941901394503, 'batch_size': 111, 'attention_heads': 8, 'hidden_dimension': 44, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3356218082306097, 'global_pooling': 'max', 'learning_rate': 0.0003075652415646769, 'weight_decay': 0.00019851504991525261, 'beta_0': 0.8211698871311855, 'beta_1': 0.9966019850301462, 'epsilon': 1.0110602117094872e-06, 'balanced_loss': False, 'epochs': 84, 'early_stopping_patience': 22, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
[I 2024-11-14 06:10:01,599] Trial 322 finished with value: 0.9311775447487872 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8280218307701306, 'batch_size': 107, 'attention_heads': 8, 'hidden_dimension': 37, 'number_of_hidden_layers': 2, 'dropout_rate': 0.33908548780457815, 'global_pooling': 'mean', 'learning_rate': 6.092175024958116e-05, 'weight_decay': 0.00016642149356329864, 'beta_0': 0.8232194441352558, 'beta_1': 0.9980329710597295, 'epsilon': 1.6086880609186204e-06, 'balanced_loss': False, 'epochs': 75, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 215 with value: 0.9575083408077356.
slurmstepd: error: *** JOB 13921119 ON gpu008 CANCELLED AT 2024-11-14T06:19:21 DUE TO TIME LIMIT ***
