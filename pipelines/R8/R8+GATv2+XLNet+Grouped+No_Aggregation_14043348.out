[I 2024-12-02 10:47:09,778] A new study created in RDB with name: R8-GATv2-xlnet-xlnet-base-cased-Grouped-No_Aggregation
CUDA out of memory. Tried to allocate 4.63 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.99 GiB is free. Including non-PyTorch memory, this process has 40.56 GiB memory in use. Of the allocated memory 37.43 GiB is allocated by PyTorch, and 1.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 10:55:23,530] Trial 0 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.6703286834227482, 'batch_size': 226, 'attention_heads': 11, 'hidden_dimension': 191, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5909729556485983, 'global_pooling': 'mean', 'learning_rate': 5.415244119402538e-05, 'weight_decay': 8.179499475211674e-06, 'beta_0': 0.8510059609290175, 'beta_1': 0.9881622148267181, 'epsilon': 1.4618962793704927e-07, 'balanced_loss': True, 'epochs': 94, 'early_stopping_patience': 15, 'plateau_patience': 17, 'plateau_divider': 9}. Best is trial 0 with value: -1.0.
CUDA out of memory. Tried to allocate 8.42 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.14 GiB is free. Including non-PyTorch memory, this process has 42.41 GiB memory in use. Of the allocated memory 39.77 GiB is allocated by PyTorch, and 1.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 11:03:18,069] Trial 1 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.672767407028918, 'batch_size': 245, 'attention_heads': 16, 'hidden_dimension': 213, 'number_of_hidden_layers': 1, 'dropout_rate': 0.32930163420191516, 'global_pooling': 'mean', 'learning_rate': 0.0009565499215943821, 'weight_decay': 1.2681352169084602e-06, 'beta_0': 0.8904386843107996, 'beta_1': 0.9848818831861611, 'epsilon': 4.467752817973898e-06, 'balanced_loss': False, 'epochs': 132, 'early_stopping_patience': 12, 'plateau_patience': 25, 'plateau_divider': 8}. Best is trial 0 with value: -1.0.
CUDA out of memory. Tried to allocate 1.57 GiB. GPU 0 has a total capacity of 44.56 GiB of which 900.69 MiB is free. Including non-PyTorch memory, this process has 43.67 GiB memory in use. Of the allocated memory 41.43 GiB is allocated by PyTorch, and 1.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 11:12:56,928] Trial 2 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.6658290988457992, 'batch_size': 105, 'attention_heads': 9, 'hidden_dimension': 93, 'number_of_hidden_layers': 4, 'dropout_rate': 0.40702599800807676, 'global_pooling': 'sum', 'learning_rate': 0.016172900811143146, 'weight_decay': 1.6736010167825795e-06, 'beta_0': 0.8986110261361376, 'beta_1': 0.9946405101730994, 'epsilon': 6.235377135673148e-08, 'balanced_loss': False, 'epochs': 156, 'early_stopping_patience': 21, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 0 with value: -1.0.
CUDA out of memory. Tried to allocate 2.01 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.46 GiB is free. Including non-PyTorch memory, this process has 43.10 GiB memory in use. Of the allocated memory 39.60 GiB is allocated by PyTorch, and 2.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 11:20:44,373] Trial 3 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7588407027772647, 'batch_size': 105, 'attention_heads': 13, 'hidden_dimension': 175, 'number_of_hidden_layers': 4, 'dropout_rate': 0.44166447754858473, 'global_pooling': 'max', 'learning_rate': 0.0017583640270008513, 'weight_decay': 0.00020554245520150764, 'beta_0': 0.8479082820660899, 'beta_1': 0.9898864065152503, 'epsilon': 5.130551760589827e-07, 'balanced_loss': False, 'epochs': 54, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 0 with value: -1.0.
CUDA out of memory. Tried to allocate 2.26 GiB. GPU 0 has a total capacity of 44.56 GiB of which 344.69 MiB is free. Including non-PyTorch memory, this process has 44.22 GiB memory in use. Of the allocated memory 41.21 GiB is allocated by PyTorch, and 1.86 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 11:28:31,461] Trial 4 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.7514101110052898, 'batch_size': 68, 'attention_heads': 16, 'hidden_dimension': 213, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5614381770563153, 'global_pooling': 'max', 'learning_rate': 0.0014367095138664223, 'weight_decay': 0.00026443593078398644, 'beta_0': 0.889052315352582, 'beta_1': 0.9860025494147586, 'epsilon': 2.755546207779655e-08, 'balanced_loss': False, 'epochs': 173, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 6}. Best is trial 0 with value: -1.0.
CUDA out of memory. Tried to allocate 2.03 GiB. GPU 0 has a total capacity of 44.56 GiB of which 372.69 MiB is free. Including non-PyTorch memory, this process has 44.19 GiB memory in use. Of the allocated memory 41.82 GiB is allocated by PyTorch, and 1.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 11:36:18,518] Trial 5 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.8315715297039608, 'batch_size': 190, 'attention_heads': 8, 'hidden_dimension': 250, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3755346887476092, 'global_pooling': 'mean', 'learning_rate': 1.4045842344024695e-05, 'weight_decay': 6.740513796374044e-05, 'beta_0': 0.8487959271998592, 'beta_1': 0.9809692144821089, 'epsilon': 1.3019246714361555e-07, 'balanced_loss': True, 'epochs': 71, 'early_stopping_patience': 17, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 0 with value: -1.0.
[I 2024-12-02 11:54:41,165] Trial 6 finished with value: 0.7945124558919967 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.8717290634692055, 'batch_size': 152, 'attention_heads': 5, 'hidden_dimension': 219, 'number_of_hidden_layers': 1, 'dropout_rate': 0.35595555311995625, 'global_pooling': 'max', 'learning_rate': 1.1650681118986128e-05, 'weight_decay': 3.4377886617795816e-05, 'beta_0': 0.8216291089982651, 'beta_1': 0.9922164838130152, 'epsilon': 4.9827112000811335e-08, 'balanced_loss': True, 'epochs': 191, 'early_stopping_patience': 12, 'plateau_patience': 15, 'plateau_divider': 3}. Best is trial 6 with value: 0.7945124558919967.
[I 2024-12-02 12:06:23,595] Trial 7 finished with value: 0.10283915422372412 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.8353724059188188, 'batch_size': 86, 'attention_heads': 5, 'hidden_dimension': 233, 'number_of_hidden_layers': 4, 'dropout_rate': 0.48993043718198037, 'global_pooling': 'max', 'learning_rate': 0.0387651117091163, 'weight_decay': 0.00045841547801363794, 'beta_0': 0.8769656613172253, 'beta_1': 0.9921566381933148, 'epsilon': 2.1705003488711103e-08, 'balanced_loss': False, 'epochs': 141, 'early_stopping_patience': 10, 'plateau_patience': 11, 'plateau_divider': 7}. Best is trial 6 with value: 0.7945124558919967.
[I 2024-12-02 12:34:48,680] Trial 8 finished with value: 0.9130425749400618 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8992556056794241, 'batch_size': 85, 'attention_heads': 8, 'hidden_dimension': 199, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5547670231482533, 'global_pooling': 'mean', 'learning_rate': 0.0002957080941494348, 'weight_decay': 6.24607368131809e-06, 'beta_0': 0.8233238054292655, 'beta_1': 0.9984823954805346, 'epsilon': 3.7358626308127487e-07, 'balanced_loss': True, 'epochs': 170, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 6}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 12:43:39,530] Trial 9 finished with value: 0.8868261116261489 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9791510999376765, 'batch_size': 246, 'attention_heads': 15, 'hidden_dimension': 115, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5784955687763176, 'global_pooling': 'sum', 'learning_rate': 0.025824850844906145, 'weight_decay': 7.644457600399742e-06, 'beta_0': 0.8371219067759552, 'beta_1': 0.9961484316107455, 'epsilon': 1.8522006003174358e-07, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 21, 'plateau_patience': 19, 'plateau_divider': 2}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 12:54:26,507] Trial 10 finished with value: 0.9005580229223977 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9481200763539988, 'batch_size': 36, 'attention_heads': 7, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5069924419974332, 'global_pooling': 'mean', 'learning_rate': 0.00011015753215781712, 'weight_decay': 6.954771451368797e-06, 'beta_0': 0.8011183479951905, 'beta_1': 0.997553073267282, 'epsilon': 6.646086576758891e-05, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 25, 'plateau_patience': 20, 'plateau_divider': 5}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 13:04:54,745] Trial 11 finished with value: 0.9117495927669154 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9520624768930392, 'batch_size': 36, 'attention_heads': 7, 'hidden_dimension': 38, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5084585346377367, 'global_pooling': 'mean', 'learning_rate': 0.00013857943411927569, 'weight_decay': 7.679738601475693e-06, 'beta_0': 0.8001766262431174, 'beta_1': 0.9984899547570018, 'epsilon': 4.710988347881894e-05, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 25, 'plateau_patience': 21, 'plateau_divider': 5}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 13:25:04,837] Trial 12 finished with value: 0.9128712924263174 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9091345116218185, 'batch_size': 36, 'attention_heads': 11, 'hidden_dimension': 146, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5207556792136036, 'global_pooling': 'mean', 'learning_rate': 0.000216434273146025, 'weight_decay': 3.431767241750914e-06, 'beta_0': 0.800756177553919, 'beta_1': 0.9986679236675332, 'epsilon': 5.365959793633865e-06, 'balanced_loss': True, 'epochs': 101, 'early_stopping_patience': 25, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 13:58:50,524] Trial 13 finished with value: 0.9041886515830894 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9032596522073935, 'batch_size': 144, 'attention_heads': 11, 'hidden_dimension': 155, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5418473188867232, 'global_pooling': 'mean', 'learning_rate': 0.000369473181069473, 'weight_decay': 2.792058480411356e-06, 'beta_0': 0.8186765843345989, 'beta_1': 0.9942537412396695, 'epsilon': 3.3390500650132797e-06, 'balanced_loss': True, 'epochs': 160, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 14:10:10,719] Trial 14 finished with value: 0.28233950076070813 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9015875733817061, 'batch_size': 63, 'attention_heads': 13, 'hidden_dimension': 124, 'number_of_hidden_layers': 3, 'dropout_rate': 0.4643119547121601, 'global_pooling': 'mean', 'learning_rate': 0.005608861684564817, 'weight_decay': 2.182559164603337e-05, 'beta_0': 0.8157251761306415, 'beta_1': 0.9989856940487221, 'epsilon': 6.615284303702148e-06, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 16, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 8 with value: 0.9130425749400618.
CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.73 GiB is free. Including non-PyTorch memory, this process has 42.83 GiB memory in use. Of the allocated memory 39.86 GiB is allocated by PyTorch, and 1.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 14:21:03,565] Trial 15 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.7768692399133191, 'batch_size': 132, 'attention_heads': 10, 'hidden_dimension': 173, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5384051614323463, 'global_pooling': 'sum', 'learning_rate': 0.00034453498599641046, 'weight_decay': 3.1579488167215517e-06, 'beta_0': 0.8311631958808916, 'beta_1': 0.9955874848849253, 'epsilon': 7.659967028801853e-07, 'balanced_loss': True, 'epochs': 85, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 10}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 14:35:20,624] Trial 16 finished with value: 0.8911022048697379 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8830320426413976, 'batch_size': 61, 'attention_heads': 13, 'hidden_dimension': 138, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4398157646545306, 'global_pooling': 'mean', 'learning_rate': 4.131098050701256e-05, 'weight_decay': 1.7892179812052506e-05, 'beta_0': 0.8101761635869574, 'beta_1': 0.9923856631952251, 'epsilon': 1.498080961015864e-05, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 14:46:09,428] Trial 17 finished with value: 0.35636616998192994 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9994572594907505, 'batch_size': 32, 'attention_heads': 4, 'hidden_dimension': 87, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5998702167467967, 'global_pooling': 'mean', 'learning_rate': 0.0004766916451540554, 'weight_decay': 3.0875006959653776e-06, 'beta_0': 0.8320528401539766, 'beta_1': 0.9965337242200029, 'epsilon': 1.2724930220974975e-06, 'balanced_loss': True, 'epochs': 150, 'early_stopping_patience': 14, 'plateau_patience': 14, 'plateau_divider': 8}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 14:58:33,862] Trial 18 finished with value: 0.565499309127629 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9272785959686469, 'batch_size': 109, 'attention_heads': 11, 'hidden_dimension': 188, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5373406098785114, 'global_pooling': 'mean', 'learning_rate': 0.005259558263777717, 'weight_decay': 6.319575385630166e-05, 'beta_0': 0.8092130524464185, 'beta_1': 0.9802132222965287, 'epsilon': 1.6322008074993785e-06, 'balanced_loss': True, 'epochs': 177, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 15:15:01,300] Trial 19 finished with value: 0.5915739565866617 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.8433083204161141, 'batch_size': 81, 'attention_heads': 9, 'hidden_dimension': 147, 'number_of_hidden_layers': 3, 'dropout_rate': 0.4804507900101209, 'global_pooling': 'sum', 'learning_rate': 0.0001313104316933973, 'weight_decay': 1.4813788376226796e-05, 'beta_0': 0.8240081234465583, 'beta_1': 0.9899243543256632, 'epsilon': 2.2682093594933003e-05, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 13, 'plateau_patience': 21, 'plateau_divider': 9}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 15:30:00,910] Trial 20 finished with value: 0.7159196429851329 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8025757887846198, 'batch_size': 186, 'attention_heads': 7, 'hidden_dimension': 84, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5177977580026261, 'global_pooling': 'mean', 'learning_rate': 3.462126015715643e-05, 'weight_decay': 1.1230610996945843e-06, 'beta_0': 0.8666213275077617, 'beta_1': 0.9938041059305591, 'epsilon': 3.8692941423321504e-07, 'balanced_loss': True, 'epochs': 79, 'early_stopping_patience': 10, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 15:40:43,100] Trial 21 finished with value: 0.8985653301275536 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9519545971385953, 'batch_size': 44, 'attention_heads': 7, 'hidden_dimension': 43, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5144643607330329, 'global_pooling': 'mean', 'learning_rate': 0.0001328680467064642, 'weight_decay': 4.9962295345942685e-06, 'beta_0': 0.8040152104608119, 'beta_1': 0.9988457127520581, 'epsilon': 9.364675548109354e-05, 'balanced_loss': True, 'epochs': 97, 'early_stopping_patience': 25, 'plateau_patience': 21, 'plateau_divider': 5}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 15:50:02,554] Trial 22 finished with value: 0.910154424063061 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9313434517736423, 'batch_size': 52, 'attention_heads': 6, 'hidden_dimension': 63, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5470028686210135, 'global_pooling': 'mean', 'learning_rate': 0.0002238701424797329, 'weight_decay': 1.0638029235890273e-05, 'beta_0': 0.8010013747757445, 'beta_1': 0.9973246283225183, 'epsilon': 2.0662007199915207e-05, 'balanced_loss': True, 'epochs': 104, 'early_stopping_patience': 25, 'plateau_patience': 20, 'plateau_divider': 5}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 16:00:28,227] Trial 23 finished with value: 0.8794868994029462 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9753574820276341, 'batch_size': 83, 'attention_heads': 9, 'hidden_dimension': 120, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5676170448451646, 'global_pooling': 'mean', 'learning_rate': 0.0006538562894346984, 'weight_decay': 4.205949647904194e-06, 'beta_0': 0.8116593175944523, 'beta_1': 0.9988867305237984, 'epsilon': 8.735208309416768e-06, 'balanced_loss': True, 'epochs': 66, 'early_stopping_patience': 22, 'plateau_patience': 22, 'plateau_divider': 6}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 16:19:03,096] Trial 24 finished with value: 0.8364953130969041 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.860856099607312, 'batch_size': 49, 'attention_heads': 8, 'hidden_dimension': 164, 'number_of_hidden_layers': 3, 'dropout_rate': 0.4827354948672147, 'global_pooling': 'mean', 'learning_rate': 7.014828930084426e-05, 'weight_decay': 3.6516962971051506e-05, 'beta_0': 0.8258697905155243, 'beta_1': 0.996992308015039, 'epsilon': 4.513773752401256e-05, 'balanced_loss': True, 'epochs': 134, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 16:33:17,443] Trial 25 finished with value: 0.7744273742467976 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9150008265953625, 'batch_size': 73, 'attention_heads': 12, 'hidden_dimension': 189, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5156962632395353, 'global_pooling': 'mean', 'learning_rate': 0.002491917369993057, 'weight_decay': 2.0627165720264792e-06, 'beta_0': 0.8398530480697087, 'beta_1': 0.9951299454990271, 'epsilon': 2.2939234010926013e-06, 'balanced_loss': True, 'epochs': 90, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 6}. Best is trial 8 with value: 0.9130425749400618.
[I 2024-12-02 16:42:29,800] Trial 26 finished with value: 0.9284165874949324 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9560987069047631, 'batch_size': 33, 'attention_heads': 10, 'hidden_dimension': 61, 'number_of_hidden_layers': 1, 'dropout_rate': 0.41780052693001674, 'global_pooling': 'mean', 'learning_rate': 0.00021313844768471843, 'weight_decay': 5.682990458210509e-06, 'beta_0': 0.8087605143520812, 'beta_1': 0.9977772643920662, 'epsilon': 3.126244833993872e-05, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 22, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 26 with value: 0.9284165874949324.
[I 2024-12-02 16:52:20,416] Trial 27 finished with value: 0.9338915596118125 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8946951335565203, 'batch_size': 123, 'attention_heads': 10, 'hidden_dimension': 65, 'number_of_hidden_layers': 1, 'dropout_rate': 0.39591976165170173, 'global_pooling': 'mean', 'learning_rate': 0.00029037876546255363, 'weight_decay': 4.858793655537738e-06, 'beta_0': 0.8091560563204497, 'beta_1': 0.9931790346613278, 'epsilon': 6.974102007270628e-06, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 21, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 27 with value: 0.9338915596118125.
[I 2024-12-02 17:02:09,893] Trial 28 finished with value: 0.9143424591268263 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8874232610442441, 'batch_size': 130, 'attention_heads': 10, 'hidden_dimension': 100, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4121004603428353, 'global_pooling': 'sum', 'learning_rate': 0.0008204083238737424, 'weight_decay': 1.2901512409711959e-05, 'beta_0': 0.8164824540972547, 'beta_1': 0.9930593467432327, 'epsilon': 1.3994685140017229e-05, 'balanced_loss': True, 'epochs': 199, 'early_stopping_patience': 20, 'plateau_patience': 13, 'plateau_divider': 3}. Best is trial 27 with value: 0.9338915596118125.
[I 2024-12-02 17:12:07,976] Trial 29 finished with value: 0.9017332140790538 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8024062310885327, 'batch_size': 181, 'attention_heads': 10, 'hidden_dimension': 67, 'number_of_hidden_layers': 0, 'dropout_rate': 0.40227455138816076, 'global_pooling': 'sum', 'learning_rate': 0.004099846083454181, 'weight_decay': 1.2041833315387818e-05, 'beta_0': 0.8660319973731965, 'beta_1': 0.9877617627338583, 'epsilon': 1.4670872987120637e-05, 'balanced_loss': True, 'epochs': 197, 'early_stopping_patience': 21, 'plateau_patience': 13, 'plateau_divider': 3}. Best is trial 27 with value: 0.9338915596118125.
[I 2024-12-02 17:21:21,672] Trial 30 finished with value: 0.8548703776449478 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.8649397868826127, 'batch_size': 165, 'attention_heads': 12, 'hidden_dimension': 61, 'number_of_hidden_layers': 0, 'dropout_rate': 0.421013818213909, 'global_pooling': 'sum', 'learning_rate': 0.0009732381705096811, 'weight_decay': 6.879934104470709e-05, 'beta_0': 0.8146396615645303, 'beta_1': 0.9910206906260257, 'epsilon': 3.7442358969096234e-05, 'balanced_loss': True, 'epochs': 181, 'early_stopping_patience': 20, 'plateau_patience': 12, 'plateau_divider': 3}. Best is trial 27 with value: 0.9338915596118125.
[I 2024-12-02 17:31:08,190] Trial 31 finished with value: 0.8905008647467009 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.884971575675163, 'batch_size': 121, 'attention_heads': 10, 'hidden_dimension': 103, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3870538096148154, 'global_pooling': 'sum', 'learning_rate': 0.0006430861912189, 'weight_decay': 5.160674654573651e-06, 'beta_0': 0.8073439563802696, 'beta_1': 0.9933183970078799, 'epsilon': 9.199747220722652e-06, 'balanced_loss': True, 'epochs': 171, 'early_stopping_patience': 18, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 27 with value: 0.9338915596118125.
[I 2024-12-02 17:41:25,336] Trial 32 finished with value: 0.8714788197146164 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9378792353815072, 'batch_size': 125, 'attention_heads': 8, 'hidden_dimension': 74, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3051595827288166, 'global_pooling': 'sum', 'learning_rate': 0.0002876746453409895, 'weight_decay': 2.488336029548453e-05, 'beta_0': 0.8271457493166803, 'beta_1': 0.9872043192880285, 'epsilon': 2.6127746673025503e-06, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 16, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 27 with value: 0.9338915596118125.
[I 2024-12-02 17:50:32,553] Trial 33 finished with value: 0.8125042322616469 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9674735146755625, 'batch_size': 94, 'attention_heads': 10, 'hidden_dimension': 54, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3604073546455249, 'global_pooling': 'sum', 'learning_rate': 6.142127454384262e-05, 'weight_decay': 2.0442760416736913e-06, 'beta_0': 0.818275972915222, 'beta_1': 0.9836170911400609, 'epsilon': 2.9844921585507415e-05, 'balanced_loss': True, 'epochs': 185, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 4}. Best is trial 27 with value: 0.9338915596118125.
[I 2024-12-02 17:59:20,719] Trial 34 finished with value: 0.8937331924364911 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.888981872018415, 'batch_size': 226, 'attention_heads': 9, 'hidden_dimension': 102, 'number_of_hidden_layers': 0, 'dropout_rate': 0.42461715807667433, 'global_pooling': 'max', 'learning_rate': 0.08844241319717973, 'weight_decay': 1.0354413443950294e-05, 'beta_0': 0.8399904030753856, 'beta_1': 0.9910576898998944, 'epsilon': 1.1149700292540624e-08, 'balanced_loss': False, 'epochs': 163, 'early_stopping_patience': 22, 'plateau_patience': 13, 'plateau_divider': 2}. Best is trial 27 with value: 0.9338915596118125.
[I 2024-12-02 18:16:02,793] Trial 35 finished with value: 0.9246480798714296 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.7119534144683031, 'batch_size': 102, 'attention_heads': 12, 'hidden_dimension': 80, 'number_of_hidden_layers': 1, 'dropout_rate': 0.455450563647987, 'global_pooling': 'mean', 'learning_rate': 0.0014318536980668201, 'weight_decay': 5.296469780671821e-06, 'beta_0': 0.8069233774869998, 'beta_1': 0.9949675499009365, 'epsilon': 3.452640604126396e-07, 'balanced_loss': False, 'epochs': 148, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 27 with value: 0.9338915596118125.
[I 2024-12-02 18:30:08,846] Trial 36 finished with value: 0.9048868445118389 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.7124493703026782, 'batch_size': 112, 'attention_heads': 14, 'hidden_dimension': 78, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4537791372026806, 'global_pooling': 'mean', 'learning_rate': 0.001853496781893653, 'weight_decay': 1.3488823229189694e-05, 'beta_0': 0.813643115082292, 'beta_1': 0.9948227235629536, 'epsilon': 2.1792122471241554e-07, 'balanced_loss': False, 'epochs': 141, 'early_stopping_patience': 21, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 27 with value: 0.9338915596118125.
[I 2024-12-02 18:43:37,441] Trial 37 finished with value: 0.940717230209263 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.678748089619553, 'batch_size': 144, 'attention_heads': 12, 'hidden_dimension': 51, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3972923478727474, 'global_pooling': 'max', 'learning_rate': 0.0009859583947606607, 'weight_decay': 1.8330608032854385e-06, 'beta_0': 0.8058248032105225, 'beta_1': 0.9934262792565957, 'epsilon': 8.432979757640161e-07, 'balanced_loss': False, 'epochs': 148, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 18:54:01,050] Trial 38 finished with value: 0.8209835766123752 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.688425314286848, 'batch_size': 151, 'attention_heads': 12, 'hidden_dimension': 50, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3462688960845038, 'global_pooling': 'max', 'learning_rate': 0.009975941269859777, 'weight_decay': 1.5203393708988813e-06, 'beta_0': 0.8084684496041138, 'beta_1': 0.9908788833685956, 'epsilon': 7.039279471752671e-07, 'balanced_loss': False, 'epochs': 150, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 19:09:13,731] Trial 39 finished with value: 0.9180315075844088 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.7256895782649071, 'batch_size': 168, 'attention_heads': 14, 'hidden_dimension': 71, 'number_of_hidden_layers': 1, 'dropout_rate': 0.38534100224606066, 'global_pooling': 'max', 'learning_rate': 0.001256873539436903, 'weight_decay': 1.9697262705301115e-06, 'beta_0': 0.8588984754171649, 'beta_1': 0.9887746221244362, 'epsilon': 7.958442314265826e-08, 'balanced_loss': False, 'epochs': 117, 'early_stopping_patience': 17, 'plateau_patience': 17, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 19:22:45,037] Trial 40 finished with value: 0.92250794517147 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.659284935069998, 'batch_size': 215, 'attention_heads': 13, 'hidden_dimension': 34, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4366303575764173, 'global_pooling': 'max', 'learning_rate': 0.002943270953978423, 'weight_decay': 1.2143919556628585e-06, 'beta_0': 0.8056280317329612, 'beta_1': 0.9958818630010293, 'epsilon': 2.9178757410929614e-07, 'balanced_loss': False, 'epochs': 132, 'early_stopping_patience': 22, 'plateau_patience': 14, 'plateau_divider': 4}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 19:36:45,776] Trial 41 finished with value: 0.922389375148059 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.6657966114934842, 'batch_size': 220, 'attention_heads': 13, 'hidden_dimension': 34, 'number_of_hidden_layers': 1, 'dropout_rate': 0.43692242891495386, 'global_pooling': 'max', 'learning_rate': 0.002463931549225419, 'weight_decay': 1.3517921394716664e-06, 'beta_0': 0.8054853213183926, 'beta_1': 0.9959802945104265, 'epsilon': 3.302583774813674e-07, 'balanced_loss': False, 'epochs': 131, 'early_stopping_patience': 22, 'plateau_patience': 14, 'plateau_divider': 4}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 19:50:52,245] Trial 42 finished with value: 0.9329477783957223 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.6529471286659353, 'batch_size': 210, 'attention_heads': 12, 'hidden_dimension': 52, 'number_of_hidden_layers': 1, 'dropout_rate': 0.39308535665954913, 'global_pooling': 'max', 'learning_rate': 0.0033145905713408245, 'weight_decay': 2.6244809081985905e-06, 'beta_0': 0.8060816072236205, 'beta_1': 0.9945087949637649, 'epsilon': 1.2058224164373018e-07, 'balanced_loss': False, 'epochs': 142, 'early_stopping_patience': 22, 'plateau_patience': 15, 'plateau_divider': 3}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 20:01:33,256] Trial 43 finished with value: 0.6618666981762205 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.6873057690281387, 'batch_size': 98, 'attention_heads': 11, 'hidden_dimension': 49, 'number_of_hidden_layers': 1, 'dropout_rate': 0.39682994218888507, 'global_pooling': 'max', 'learning_rate': 0.012593489468465242, 'weight_decay': 2.439941978250843e-06, 'beta_0': 0.812421543387039, 'beta_1': 0.9943384691284863, 'epsilon': 1.173483910382977e-07, 'balanced_loss': False, 'epochs': 143, 'early_stopping_patience': 23, 'plateau_patience': 15, 'plateau_divider': 3}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 20:15:37,455] Trial 44 finished with value: 0.9392853660453881 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.6516680932361318, 'batch_size': 204, 'attention_heads': 12, 'hidden_dimension': 57, 'number_of_hidden_layers': 1, 'dropout_rate': 0.36997923789713283, 'global_pooling': 'max', 'learning_rate': 0.001422834288959211, 'weight_decay': 4.100182451177798e-06, 'beta_0': 0.8211003305466603, 'beta_1': 0.9927869853035283, 'epsilon': 4.034070908722778e-08, 'balanced_loss': False, 'epochs': 154, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 20:35:03,933] Trial 45 finished with value: 0.893058807296141 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.6525069895422422, 'batch_size': 206, 'attention_heads': 14, 'hidden_dimension': 57, 'number_of_hidden_layers': 0, 'dropout_rate': 0.36959138874926567, 'global_pooling': 'max', 'learning_rate': 2.1088873844465228e-05, 'weight_decay': 0.0008148369756045082, 'beta_0': 0.8198292425895314, 'beta_1': 0.992321326798288, 'epsilon': 3.6067554093994676e-08, 'balanced_loss': False, 'epochs': 159, 'early_stopping_patience': 21, 'plateau_patience': 11, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 20:47:07,730] Trial 46 finished with value: 0.8961556993973419 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.6794664092386803, 'batch_size': 203, 'attention_heads': 11, 'hidden_dimension': 47, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3390764633192721, 'global_pooling': 'max', 'learning_rate': 0.0073379489343407215, 'weight_decay': 4.267544122445948e-06, 'beta_0': 0.8967491963615756, 'beta_1': 0.9931767915438197, 'epsilon': 1.49557714528149e-08, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
CUDA out of memory. Tried to allocate 3.29 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.23 GiB is free. Including non-PyTorch memory, this process has 42.33 GiB memory in use. Of the allocated memory 39.88 GiB is allocated by PyTorch, and 1.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 20:55:19,984] Trial 47 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.6976499507532478, 'batch_size': 254, 'attention_heads': 15, 'hidden_dimension': 94, 'number_of_hidden_layers': 1, 'dropout_rate': 0.32496876124960244, 'global_pooling': 'max', 'learning_rate': 0.00044740447121309273, 'weight_decay': 8.318726113945528e-06, 'beta_0': 0.8451963663347762, 'beta_1': 0.9916262699825779, 'epsilon': 6.831220111340183e-08, 'balanced_loss': False, 'epochs': 166, 'early_stopping_patience': 21, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 21:08:33,430] Trial 48 finished with value: 0.937849303801992 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7570640909563915, 'batch_size': 231, 'attention_heads': 12, 'hidden_dimension': 64, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3784784859183235, 'global_pooling': 'max', 'learning_rate': 0.0006553373969662039, 'weight_decay': 3.4415972285737144e-06, 'beta_0': 0.831475818893227, 'beta_1': 0.9894979177022853, 'epsilon': 3.7825479227239286e-08, 'balanced_loss': False, 'epochs': 125, 'early_stopping_patience': 20, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 21:18:19,297] Trial 49 finished with value: 0.9296537901785773 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7605093093458011, 'batch_size': 236, 'attention_heads': 12, 'hidden_dimension': 70, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37601060011363224, 'global_pooling': 'max', 'learning_rate': 0.0034553215594512084, 'weight_decay': 1.0011429973564669e-06, 'beta_0': 0.8284494118473217, 'beta_1': 0.9886360960312468, 'epsilon': 3.780775784794628e-08, 'balanced_loss': False, 'epochs': 125, 'early_stopping_patience': 20, 'plateau_patience': 17, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
CUDA out of memory. Tried to allocate 3.18 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.67 GiB is free. Including non-PyTorch memory, this process has 42.89 GiB memory in use. Of the allocated memory 38.20 GiB is allocated by PyTorch, and 3.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 21:26:50,885] Trial 50 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7215323697499519, 'batch_size': 197, 'attention_heads': 15, 'hidden_dimension': 91, 'number_of_hidden_layers': 1, 'dropout_rate': 0.36093196957691914, 'global_pooling': 'max', 'learning_rate': 0.001771772371582559, 'weight_decay': 1.6716113928098694e-06, 'beta_0': 0.8349338107326929, 'beta_1': 0.9899159180507439, 'epsilon': 2.7965580260241402e-08, 'balanced_loss': False, 'epochs': 137, 'early_stopping_patience': 17, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 21:36:52,251] Trial 51 finished with value: 0.9363105226979876 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7529813685436143, 'batch_size': 235, 'attention_heads': 12, 'hidden_dimension': 70, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3803037495779357, 'global_pooling': 'max', 'learning_rate': 0.0034250955871167597, 'weight_decay': 1.103503542531456e-06, 'beta_0': 0.828145479198253, 'beta_1': 0.9889884858993756, 'epsilon': 4.559283575582992e-08, 'balanced_loss': False, 'epochs': 124, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 21:46:21,629] Trial 52 finished with value: 0.9090811662228508 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7350082802874984, 'batch_size': 238, 'attention_heads': 13, 'hidden_dimension': 41, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3888512090118281, 'global_pooling': 'max', 'learning_rate': 0.021596918455361498, 'weight_decay': 3.6039920693517703e-06, 'beta_0': 0.8214365540693326, 'beta_1': 0.9837238179602442, 'epsilon': 5.328216056983683e-08, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 18, 'plateau_patience': 16, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 21:56:22,779] Trial 53 finished with value: 0.9384514296637415 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7452514982150233, 'batch_size': 233, 'attention_heads': 11, 'hidden_dimension': 52, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37335923636487683, 'global_pooling': 'max', 'learning_rate': 0.0006777829566408611, 'weight_decay': 2.6098078065887177e-06, 'beta_0': 0.830401626043553, 'beta_1': 0.9855524436388731, 'epsilon': 1.1300758282362051e-07, 'balanced_loss': False, 'epochs': 149, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
CUDA out of memory. Tried to allocate 5.40 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.79 GiB is free. Including non-PyTorch memory, this process has 39.76 GiB memory in use. Of the allocated memory 37.55 GiB is allocated by PyTorch, and 1.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 22:04:36,697] Trial 54 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7809792591239626, 'batch_size': 229, 'attention_heads': 11, 'hidden_dimension': 255, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37626253366364104, 'global_pooling': 'max', 'learning_rate': 0.0005731334022598216, 'weight_decay': 1.5829201846809631e-06, 'beta_0': 0.8321064965784788, 'beta_1': 0.9859742946157102, 'epsilon': 1.8261400726067106e-08, 'balanced_loss': False, 'epochs': 157, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 22:15:39,354] Trial 55 finished with value: 0.9388109492448187 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7461889303620558, 'batch_size': 254, 'attention_heads': 11, 'hidden_dimension': 112, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3470784915317329, 'global_pooling': 'max', 'learning_rate': 0.0008692117639392974, 'weight_decay': 2.3951924911525578e-06, 'beta_0': 0.8446851369737487, 'beta_1': 0.9870921967090936, 'epsilon': 1.753398157210305e-07, 'balanced_loss': False, 'epochs': 153, 'early_stopping_patience': 20, 'plateau_patience': 17, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 22:26:43,444] Trial 56 finished with value: 0.9406545193421223 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7490611344510425, 'batch_size': 256, 'attention_heads': 11, 'hidden_dimension': 134, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32286792970437084, 'global_pooling': 'max', 'learning_rate': 0.0010910303148115622, 'weight_decay': 2.3372976276908426e-06, 'beta_0': 0.8526451212110241, 'beta_1': 0.9864096366967817, 'epsilon': 8.534672879056901e-08, 'balanced_loss': False, 'epochs': 152, 'early_stopping_patience': 20, 'plateau_patience': 18, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
[I 2024-12-02 22:38:33,769] Trial 57 finished with value: 0.9290078800279027 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7399614993161127, 'batch_size': 251, 'attention_heads': 11, 'hidden_dimension': 129, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32825206761166503, 'global_pooling': 'max', 'learning_rate': 0.001102258204314504, 'weight_decay': 2.543615826065953e-06, 'beta_0': 0.8526392900195584, 'beta_1': 0.985853812523202, 'epsilon': 9.026136158877017e-08, 'balanced_loss': False, 'epochs': 152, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 2}. Best is trial 37 with value: 0.940717230209263.
slurmstepd: error: *** JOB 14043348 ON gpu055 CANCELLED AT 2024-12-02T22:47:20 DUE TO TIME LIMIT ***
