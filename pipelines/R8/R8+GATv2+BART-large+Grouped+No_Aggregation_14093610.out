[I 2024-12-13 03:36:47,917] Using an existing study with name 'R8-GATv2-facebook-bart-large-Grouped-No_Aggregation' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors
[I 2024-12-13 04:29:20,006] Trial 157 finished with value: 0.9731955490254465 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.731328311995955, 'batch_size': 45, 'attention_heads': 16, 'hidden_dimension': 87, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5018809362025403, 'global_pooling': 'max', 'learning_rate': 2.4168344948366003e-05, 'weight_decay': 0.0003376765818509857, 'beta_0': 0.8810583119571513, 'beta_1': 0.9830714288439099, 'epsilon': 5.593125643643233e-05, 'balanced_loss': True, 'epochs': 131, 'early_stopping_patience': 21, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 05:21:55,153] Trial 158 finished with value: 0.9558562974359028 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7287452004519488, 'batch_size': 32, 'attention_heads': 16, 'hidden_dimension': 86, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5026415458243065, 'global_pooling': 'max', 'learning_rate': 1.5198350937197841e-05, 'weight_decay': 5.01466913683294e-06, 'beta_0': 0.8795504996801968, 'beta_1': 0.9829880087017271, 'epsilon': 7.715772819528068e-05, 'balanced_loss': True, 'epochs': 131, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 06:07:42,104] Trial 159 finished with value: 0.9594538087096989 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7561204397098111, 'batch_size': 45, 'attention_heads': 16, 'hidden_dimension': 92, 'number_of_hidden_layers': 3, 'dropout_rate': 0.51719710069565, 'global_pooling': 'max', 'learning_rate': 2.5197501794078494e-05, 'weight_decay': 0.0005216669923731372, 'beta_0': 0.8831224251261586, 'beta_1': 0.9831867169565033, 'epsilon': 3.084219777985862e-05, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 21, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 06:41:51,850] Trial 160 finished with value: 0.9677654556171902 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7337937911645874, 'batch_size': 50, 'attention_heads': 16, 'hidden_dimension': 78, 'number_of_hidden_layers': 3, 'dropout_rate': 0.4984665509048571, 'global_pooling': 'max', 'learning_rate': 3.517185041783741e-05, 'weight_decay': 0.0003947969186174462, 'beta_0': 0.8805863463806045, 'beta_1': 0.9826550504195215, 'epsilon': 5.978547306171671e-05, 'balanced_loss': True, 'epochs': 134, 'early_stopping_patience': 21, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 07:35:05,634] Trial 161 finished with value: 0.9703486052335285 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.723218465620431, 'batch_size': 39, 'attention_heads': 16, 'hidden_dimension': 87, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5122512714964786, 'global_pooling': 'max', 'learning_rate': 2.0901721423085176e-05, 'weight_decay': 0.00024174960709848548, 'beta_0': 0.8895105046878622, 'beta_1': 0.982326319781738, 'epsilon': 5.339122880566654e-05, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 21, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.05 GiB is free. Including non-PyTorch memory, this process has 43.50 GiB memory in use. Of the allocated memory 40.55 GiB is allocated by PyTorch, and 1.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-13 07:58:45,060] Trial 162 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7217280878717227, 'batch_size': 38, 'attention_heads': 16, 'hidden_dimension': 105, 'number_of_hidden_layers': 3, 'dropout_rate': 0.4897600308443242, 'global_pooling': 'max', 'learning_rate': 2.1314826572061105e-05, 'weight_decay': 0.00025024598762270244, 'beta_0': 0.8959012300320476, 'beta_1': 0.9822158360729343, 'epsilon': 5.187817093851914e-05, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 21, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 08:28:15,160] Trial 163 finished with value: 0.9196184900443225 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7416432516391221, 'batch_size': 36, 'attention_heads': 16, 'hidden_dimension': 90, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5086831320888018, 'global_pooling': 'sum', 'learning_rate': 2.9612905853291615e-05, 'weight_decay': 0.0004720115458831066, 'beta_0': 0.8894479091729104, 'beta_1': 0.9818637752892607, 'epsilon': 3.9543163932738346e-05, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
CUDA out of memory. Tried to allocate 1.48 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.36 GiB is free. Including non-PyTorch memory, this process has 43.20 GiB memory in use. Of the allocated memory 38.64 GiB is allocated by PyTorch, and 3.41 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-13 08:57:32,036] Trial 164 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7270029097809396, 'batch_size': 48, 'attention_heads': 16, 'hidden_dimension': 80, 'number_of_hidden_layers': 3, 'dropout_rate': 0.512259539211085, 'global_pooling': 'max', 'learning_rate': 1.797270667931637e-05, 'weight_decay': 0.0008055077002341198, 'beta_0': 0.8847415687613666, 'beta_1': 0.9807589747611501, 'epsilon': 6.60424023357005e-05, 'balanced_loss': False, 'epochs': 110, 'early_stopping_patience': 20, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 09:51:41,175] Trial 165 finished with value: 0.9680342321651483 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7353545099949452, 'batch_size': 41, 'attention_heads': 16, 'hidden_dimension': 87, 'number_of_hidden_layers': 3, 'dropout_rate': 0.520458924744511, 'global_pooling': 'max', 'learning_rate': 1.2792890036794696e-05, 'weight_decay': 0.00035829935764186867, 'beta_0': 0.8898119061794438, 'beta_1': 0.9828060590119151, 'epsilon': 3.319009823849422e-05, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 22, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 10:42:53,299] Trial 166 finished with value: 0.9641400617739181 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.749979644282567, 'batch_size': 41, 'attention_heads': 16, 'hidden_dimension': 96, 'number_of_hidden_layers': 3, 'dropout_rate': 0.528887749004224, 'global_pooling': 'max', 'learning_rate': 2.237330672137634e-05, 'weight_decay': 0.0004371928228538706, 'beta_0': 0.8861952601804858, 'beta_1': 0.9833245342143049, 'epsilon': 2.5999236618883388e-05, 'balanced_loss': True, 'epochs': 128, 'early_stopping_patience': 21, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 11:28:49,100] Trial 167 finished with value: 0.9676066275782451 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7195525403130558, 'batch_size': 32, 'attention_heads': 15, 'hidden_dimension': 84, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5248687373668788, 'global_pooling': 'max', 'learning_rate': 1.589080717468357e-05, 'weight_decay': 0.0003241612287219038, 'beta_0': 0.8929491104239211, 'beta_1': 0.9823231447431888, 'epsilon': 5.2487172316927445e-05, 'balanced_loss': True, 'epochs': 106, 'early_stopping_patience': 22, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 12:12:55,297] Trial 168 finished with value: 0.9725340542621326 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7264627241361429, 'batch_size': 46, 'attention_heads': 16, 'hidden_dimension': 72, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5393307310534049, 'global_pooling': 'max', 'learning_rate': 2.649454173130447e-05, 'weight_decay': 0.0002342264312421746, 'beta_0': 0.882288808700663, 'beta_1': 0.9829154756969366, 'epsilon': 8.062140762303657e-05, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 21, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 12:46:21,063] Trial 169 finished with value: 0.9620183801013551 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7267509932415033, 'batch_size': 53, 'attention_heads': 16, 'hidden_dimension': 73, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5374253456969618, 'global_pooling': 'max', 'learning_rate': 3.856170271455447e-05, 'weight_decay': 0.00023243291317572108, 'beta_0': 0.8823488307583951, 'beta_1': 0.9813688388199665, 'epsilon': 7.822067457316627e-05, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 21, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 13:31:10,720] Trial 170 finished with value: 0.9680026508621737 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7423412016189542, 'batch_size': 47, 'attention_heads': 16, 'hidden_dimension': 76, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5071522531915337, 'global_pooling': 'max', 'learning_rate': 2.7072718931305107e-05, 'weight_decay': 0.00022103119695273752, 'beta_0': 0.8841288467272427, 'beta_1': 0.9825535381957529, 'epsilon': 4.112043455661176e-05, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 22, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 14:19:21,805] Trial 171 finished with value: 0.9720300407958298 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7341368888534119, 'batch_size': 38, 'attention_heads': 16, 'hidden_dimension': 83, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5505316846142411, 'global_pooling': 'max', 'learning_rate': 2.2218713365280085e-05, 'weight_decay': 0.0003479498311284227, 'beta_0': 0.8762988624913958, 'beta_1': 0.9818561690447255, 'epsilon': 6.178933333846046e-05, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 21, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 15:01:00,836] Trial 172 finished with value: 0.9576279277645297 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7178014207683767, 'batch_size': 59, 'attention_heads': 16, 'hidden_dimension': 68, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5510731502374154, 'global_pooling': 'max', 'learning_rate': 3.0519674324799006e-05, 'weight_decay': 0.0003061642231699742, 'beta_0': 0.8796930694500932, 'beta_1': 0.9818221269047632, 'epsilon': 8.760381275300497e-05, 'balanced_loss': True, 'epochs': 109, 'early_stopping_patience': 21, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 15:50:38,218] Trial 173 finished with value: 0.9672776506917252 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7351666604315634, 'batch_size': 45, 'attention_heads': 15, 'hidden_dimension': 90, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5450575240312585, 'global_pooling': 'max', 'learning_rate': 2.42203690012286e-05, 'weight_decay': 0.00027495262203196984, 'beta_0': 0.8758125654465966, 'beta_1': 0.9829880154381924, 'epsilon': 6.020824733236881e-05, 'balanced_loss': True, 'epochs': 130, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 16:20:48,756] Trial 174 finished with value: 0.9617429559774329 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7219753838265963, 'batch_size': 36, 'attention_heads': 16, 'hidden_dimension': 81, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5005498249700105, 'global_pooling': 'max', 'learning_rate': 4.232915942167887e-05, 'weight_decay': 0.0001570581483768154, 'beta_0': 0.8769650398757325, 'beta_1': 0.9811392639523036, 'epsilon': 6.927991993809496e-05, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 17:07:50,569] Trial 175 finished with value: 0.9721544045249723 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7285060825037419, 'batch_size': 39, 'attention_heads': 16, 'hidden_dimension': 83, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5374138653693026, 'global_pooling': 'max', 'learning_rate': 1.914673973634674e-05, 'weight_decay': 0.0002144301473645164, 'beta_0': 0.8883528263353817, 'beta_1': 0.9822273629067506, 'epsilon': 4.883741484407919e-05, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 21, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 17:54:31,167] Trial 176 finished with value: 0.9635857949350056 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7311322638819701, 'batch_size': 40, 'attention_heads': 16, 'hidden_dimension': 74, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5501532378890178, 'global_pooling': 'max', 'learning_rate': 1.7379180951177095e-05, 'weight_decay': 0.0002249878503294487, 'beta_0': 0.8876432791949838, 'beta_1': 0.9815160565425488, 'epsilon': 4.912111130867846e-05, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 21, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 18:32:49,488] Trial 177 finished with value: 0.9676748751884032 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7392485948596379, 'batch_size': 32, 'attention_heads': 16, 'hidden_dimension': 87, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5403764648682916, 'global_pooling': 'max', 'learning_rate': 2.486886199840295e-05, 'weight_decay': 0.0003496857412116781, 'beta_0': 0.8852005140715571, 'beta_1': 0.9825948313240422, 'epsilon': 9.51751269952345e-05, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 21, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 19:20:50,572] Trial 178 finished with value: 0.9730700877712943 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7085177395699387, 'batch_size': 45, 'attention_heads': 16, 'hidden_dimension': 79, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5578754081100565, 'global_pooling': 'max', 'learning_rate': 2.2175312032854826e-05, 'weight_decay': 0.00020593787357474095, 'beta_0': 0.8835361131646496, 'beta_1': 0.9840085463227763, 'epsilon': 3.9248277295306143e-05, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
CUDA out of memory. Tried to allocate 1.58 GiB. GPU 0 has a total capacity of 44.56 GiB of which 322.69 MiB is free. Including non-PyTorch memory, this process has 44.24 GiB memory in use. Of the allocated memory 40.85 GiB is allocated by PyTorch, and 2.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-13 19:31:24,643] Trial 179 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.7086910006734918, 'batch_size': 52, 'attention_heads': 16, 'hidden_dimension': 78, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5585896624498353, 'global_pooling': 'max', 'learning_rate': 1.007271824809071e-05, 'weight_decay': 0.00020092771153395236, 'beta_0': 0.8825306199205031, 'beta_1': 0.9819188084691525, 'epsilon': 5.6555676242935885e-05, 'balanced_loss': True, 'epochs': 122, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 19:59:46,648] Trial 180 finished with value: 0.9630430635503832 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7170201411878443, 'batch_size': 48, 'attention_heads': 15, 'hidden_dimension': 71, 'number_of_hidden_layers': 3, 'dropout_rate': 0.3567462754747118, 'global_pooling': 'max', 'learning_rate': 3.430377042811315e-05, 'weight_decay': 0.00016792289945301094, 'beta_0': 0.8802226463988689, 'beta_1': 0.9825193116756661, 'epsilon': 4.347615383003542e-05, 'balanced_loss': True, 'epochs': 106, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 20:51:02,542] Trial 181 finished with value: 0.9716165540548679 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7102745752861851, 'batch_size': 44, 'attention_heads': 15, 'hidden_dimension': 93, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5565560606929593, 'global_pooling': 'max', 'learning_rate': 2.227895362241311e-05, 'weight_decay': 0.0004700622060393157, 'beta_0': 0.8838826008550401, 'beta_1': 0.994985148398215, 'epsilon': 7.257570743855903e-05, 'balanced_loss': True, 'epochs': 136, 'early_stopping_patience': 21, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.32 GiB is free. Including non-PyTorch memory, this process has 43.24 GiB memory in use. Of the allocated memory 39.33 GiB is allocated by PyTorch, and 2.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-13 21:02:43,506] Trial 182 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7099576300968303, 'batch_size': 43, 'attention_heads': 15, 'hidden_dimension': 96, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5723554152015183, 'global_pooling': 'max', 'learning_rate': 2.1617106338125137e-05, 'weight_decay': 0.000288623918454437, 'beta_0': 0.8869478131151565, 'beta_1': 0.9938691354178746, 'epsilon': 8.136195791646011e-05, 'balanced_loss': True, 'epochs': 134, 'early_stopping_patience': 21, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
CUDA out of memory. Tried to allocate 1.68 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.23 GiB is free. Including non-PyTorch memory, this process has 43.33 GiB memory in use. Of the allocated memory 40.87 GiB is allocated by PyTorch, and 1.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-13 21:10:38,422] Trial 183 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7052313273703964, 'batch_size': 53, 'attention_heads': 15, 'hidden_dimension': 93, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5653444670276446, 'global_pooling': 'max', 'learning_rate': 2.7478137659502406e-05, 'weight_decay': 0.0002109087688712119, 'beta_0': 0.8837022161047055, 'beta_1': 0.9964151233669423, 'epsilon': 6.967851667483525e-05, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
CUDA out of memory. Tried to allocate 1.60 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.25 GiB is free. Including non-PyTorch memory, this process has 43.30 GiB memory in use. Of the allocated memory 39.37 GiB is allocated by PyTorch, and 2.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-13 21:18:33,267] Trial 184 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.714985176681864, 'batch_size': 47, 'attention_heads': 15, 'hidden_dimension': 100, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5561261815564397, 'global_pooling': 'max', 'learning_rate': 1.3576760781954707e-05, 'weight_decay': 0.00046923419148221866, 'beta_0': 0.891292298470179, 'beta_1': 0.9919461778161456, 'epsilon': 5.4651579102547724e-05, 'balanced_loss': True, 'epochs': 100, 'early_stopping_patience': 21, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 22:05:34,290] Trial 185 finished with value: 0.9755479559761673 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.730974840714392, 'batch_size': 39, 'attention_heads': 16, 'hidden_dimension': 82, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5477473510094332, 'global_pooling': 'max', 'learning_rate': 2.1383915286852286e-05, 'weight_decay': 0.00036694556871829867, 'beta_0': 0.8816658661005183, 'beta_1': 0.9829225305482986, 'epsilon': 3.755259499020424e-05, 'balanced_loss': True, 'epochs': 138, 'early_stopping_patience': 21, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 22:48:52,869] Trial 186 finished with value: 0.9669504581239674 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7306390395342399, 'batch_size': 44, 'attention_heads': 16, 'hidden_dimension': 76, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5464607314104334, 'global_pooling': 'max', 'learning_rate': 2.5415155349973885e-05, 'weight_decay': 0.0003470883578314261, 'beta_0': 0.8779119637690382, 'beta_1': 0.9839933528010181, 'epsilon': 4.754226619207631e-05, 'balanced_loss': True, 'epochs': 139, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
CUDA out of memory. Tried to allocate 1.44 GiB. GPU 0 has a total capacity of 44.56 GiB of which 940.69 MiB is free. Including non-PyTorch memory, this process has 43.63 GiB memory in use. Of the allocated memory 38.26 GiB is allocated by PyTorch, and 4.22 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-13 23:00:30,646] Trial 187 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7220991438882396, 'batch_size': 40, 'attention_heads': 16, 'hidden_dimension': 88, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5525508049455583, 'global_pooling': 'max', 'learning_rate': 2.2244475508534917e-05, 'weight_decay': 0.0002940981474114286, 'beta_0': 0.8841998811912588, 'beta_1': 0.9954318872288241, 'epsilon': 3.575368330353594e-05, 'balanced_loss': True, 'epochs': 137, 'early_stopping_patience': 21, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-13 23:46:34,573] Trial 188 finished with value: 0.9742127654270223 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7238456787164255, 'batch_size': 44, 'attention_heads': 16, 'hidden_dimension': 79, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5597760266300238, 'global_pooling': 'max', 'learning_rate': 3.255068557049466e-05, 'weight_decay': 0.00020000248535011441, 'beta_0': 0.8818521374204087, 'beta_1': 0.9890667657395396, 'epsilon': 7.123671195969581e-05, 'balanced_loss': True, 'epochs': 118, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 00:32:12,732] Trial 189 finished with value: 0.9710039160739197 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7272070699516647, 'batch_size': 44, 'attention_heads': 16, 'hidden_dimension': 79, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5625472735603942, 'global_pooling': 'max', 'learning_rate': 3.0166683905569162e-05, 'weight_decay': 0.00018918666877501048, 'beta_0': 0.8816072087760112, 'beta_1': 0.9943679086805135, 'epsilon': 7.507829707971066e-05, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 01:17:41,135] Trial 190 finished with value: 0.974650628932271 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7251655068327295, 'batch_size': 49, 'attention_heads': 16, 'hidden_dimension': 79, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5799167559363197, 'global_pooling': 'max', 'learning_rate': 3.425839348409593e-05, 'weight_decay': 0.00017595612643332877, 'beta_0': 0.8826196819869356, 'beta_1': 0.9945620645200743, 'epsilon': 8.02068218293312e-05, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
CUDA out of memory. Tried to allocate 1.49 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 43.47 GiB memory in use. Of the allocated memory 39.33 GiB is allocated by PyTorch, and 2.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-14 01:25:43,735] Trial 191 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7149828777726206, 'batch_size': 51, 'attention_heads': 16, 'hidden_dimension': 79, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5786305568084826, 'global_pooling': 'max', 'learning_rate': 3.897221707315747e-05, 'weight_decay': 0.00017408457254452944, 'beta_0': 0.8825348708764433, 'beta_1': 0.9946672554829827, 'epsilon': 9.40753666410515e-05, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 17, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 01:52:12,714] Trial 192 finished with value: 0.9252480998654129 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7274438663094904, 'batch_size': 55, 'attention_heads': 16, 'hidden_dimension': 69, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5646408161705065, 'global_pooling': 'sum', 'learning_rate': 4.825798544739619e-05, 'weight_decay': 0.00020688585439769227, 'beta_0': 0.8816821616734274, 'beta_1': 0.9946783324861423, 'epsilon': 7.01683705549155e-05, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 02:25:11,398] Trial 193 finished with value: 0.9589479291417341 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7028119415205375, 'batch_size': 46, 'attention_heads': 16, 'hidden_dimension': 74, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5664427800673928, 'global_pooling': 'max', 'learning_rate': 5.56175564228132e-05, 'weight_decay': 0.0005076250218308926, 'beta_0': 0.8857599833296147, 'beta_1': 0.9955188797664429, 'epsilon': 7.754369432575217e-05, 'balanced_loss': True, 'epochs': 107, 'early_stopping_patience': 19, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 02:56:12,474] Trial 194 finished with value: 0.9150427205176481 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.733934814322116, 'batch_size': 36, 'attention_heads': 16, 'hidden_dimension': 79, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5739066467467334, 'global_pooling': 'max', 'learning_rate': 3.481057726024592e-05, 'weight_decay': 0.0002643662774813254, 'beta_0': 0.8782876576998673, 'beta_1': 0.9930279843954859, 'epsilon': 6.212352581095196e-05, 'balanced_loss': False, 'epochs': 133, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 03:36:10,977] Trial 195 finished with value: 0.9701033574050868 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7214881097944491, 'batch_size': 40, 'attention_heads': 16, 'hidden_dimension': 82, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5902369645289595, 'global_pooling': 'max', 'learning_rate': 3.1318774466232004e-05, 'weight_decay': 0.00019853183831633402, 'beta_0': 0.8881065893344157, 'beta_1': 0.9960430422778725, 'epsilon': 9.819061105019123e-05, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 04:18:59,370] Trial 196 finished with value: 0.9679175461647725 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7279393931387964, 'batch_size': 44, 'attention_heads': 16, 'hidden_dimension': 73, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5592519808227366, 'global_pooling': 'max', 'learning_rate': 2.2196275045595317e-05, 'weight_decay': 0.00012966590993180002, 'beta_0': 0.8865010995012398, 'beta_1': 0.9974504929626943, 'epsilon': 7.704709286022402e-05, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 05:03:03,290] Trial 197 finished with value: 0.9687939782619341 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7214491222227489, 'batch_size': 37, 'attention_heads': 16, 'hidden_dimension': 68, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5604554901102304, 'global_pooling': 'max', 'learning_rate': 1.9209505877802578e-05, 'weight_decay': 0.00023897109674664752, 'beta_0': 0.8812521339637458, 'beta_1': 0.9932745805150178, 'epsilon': 5.5534425731471866e-05, 'balanced_loss': True, 'epochs': 125, 'early_stopping_patience': 20, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 05:49:44,726] Trial 198 finished with value: 0.9541587147884797 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7449718257058694, 'batch_size': 48, 'attention_heads': 16, 'hidden_dimension': 77, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5696823102886401, 'global_pooling': 'max', 'learning_rate': 1.4922093456287941e-05, 'weight_decay': 0.00027234759062837324, 'beta_0': 0.8838621446472222, 'beta_1': 0.9904218376957353, 'epsilon': 6.76805784700026e-05, 'balanced_loss': True, 'epochs': 119, 'early_stopping_patience': 18, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
CUDA out of memory. Tried to allocate 3.24 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.55 GiB is free. Including non-PyTorch memory, this process has 42.00 GiB memory in use. Of the allocated memory 38.43 GiB is allocated by PyTorch, and 2.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-14 05:57:09,997] Trial 199 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7109894286970195, 'batch_size': 240, 'attention_heads': 16, 'hidden_dimension': 88, 'number_of_hidden_layers': 3, 'dropout_rate': 0.584824897996306, 'global_pooling': 'max', 'learning_rate': 1.7663207160752985e-05, 'weight_decay': 0.00018079500958811427, 'beta_0': 0.8877760053575519, 'beta_1': 0.9942091840747348, 'epsilon': 4.7047914629426394e-05, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 17, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 06:35:27,637] Trial 200 finished with value: 0.970166580630673 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7371732888877287, 'batch_size': 40, 'attention_heads': 16, 'hidden_dimension': 82, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5994772425662815, 'global_pooling': 'max', 'learning_rate': 2.9567741171564853e-05, 'weight_decay': 0.0007261401607380839, 'beta_0': 0.8927484545605479, 'beta_1': 0.9944295765415443, 'epsilon': 6.182588595811496e-05, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 07:17:18,092] Trial 201 finished with value: 0.9684187686805105 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7240648647746595, 'batch_size': 35, 'attention_heads': 16, 'hidden_dimension': 93, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5519322641676544, 'global_pooling': 'max', 'learning_rate': 4.167760381939079e-05, 'weight_decay': 0.00015385781075790114, 'beta_0': 0.8755104216883577, 'beta_1': 0.9891100922620251, 'epsilon': 8.308657333819926e-05, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 07:59:37,550] Trial 202 finished with value: 0.97007938286872 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7161287486143115, 'batch_size': 44, 'attention_heads': 15, 'hidden_dimension': 76, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5557812565882784, 'global_pooling': 'max', 'learning_rate': 2.0836606078036342e-05, 'weight_decay': 4.230089090395511e-06, 'beta_0': 0.8953511195606239, 'beta_1': 0.995020925811664, 'epsilon': 9.99698878129993e-05, 'balanced_loss': True, 'epochs': 104, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 08:44:01,035] Trial 203 finished with value: 0.9161204446311237 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7314170627747719, 'batch_size': 49, 'attention_heads': 16, 'hidden_dimension': 71, 'number_of_hidden_layers': 3, 'dropout_rate': 0.54752769409328, 'global_pooling': 'max', 'learning_rate': 1.2433612936574156e-05, 'weight_decay': 0.0003733473277712548, 'beta_0': 0.8810033131196238, 'beta_1': 0.9950622318733902, 'epsilon': 3.913016444884644e-05, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 19, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 09:32:52,422] Trial 204 finished with value: 0.9740453328582659 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7079757412856322, 'batch_size': 38, 'attention_heads': 16, 'hidden_dimension': 85, 'number_of_hidden_layers': 3, 'dropout_rate': 0.563436917818749, 'global_pooling': 'max', 'learning_rate': 2.73542633237722e-05, 'weight_decay': 0.00033711487172411375, 'beta_0': 0.8902507695190381, 'beta_1': 0.9914223984213939, 'epsilon': 3.7748227138171897e-08, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 20, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 10:25:09,389] Trial 205 finished with value: 0.970004832367076 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7104338135148495, 'batch_size': 38, 'attention_heads': 16, 'hidden_dimension': 86, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5654124803654195, 'global_pooling': 'max', 'learning_rate': 2.626632379388264e-05, 'weight_decay': 0.00031237001246663647, 'beta_0': 0.8912466293965311, 'beta_1': 0.9901119674234446, 'epsilon': 5.4062861183258194e-05, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 20, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 11:02:44,293] Trial 206 finished with value: 0.9722332742320928 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7038381857659648, 'batch_size': 32, 'attention_heads': 16, 'hidden_dimension': 81, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5598127294385323, 'global_pooling': 'max', 'learning_rate': 3.333463756872118e-05, 'weight_decay': 0.0003247514672439838, 'beta_0': 0.885391849358691, 'beta_1': 0.9883465885043661, 'epsilon': 7.414406714888755e-05, 'balanced_loss': True, 'epochs': 113, 'early_stopping_patience': 20, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 11:35:38,032] Trial 207 finished with value: 0.9691612035359917 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7046146685733568, 'batch_size': 34, 'attention_heads': 16, 'hidden_dimension': 79, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5601490907834923, 'global_pooling': 'max', 'learning_rate': 3.36115685595987e-05, 'weight_decay': 0.00033410357120382397, 'beta_0': 0.8851460004488684, 'beta_1': 0.9876630687329855, 'epsilon': 7.18063977816796e-05, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 20, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 12:15:39,952] Trial 208 finished with value: 0.968398123387329 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7048305513116906, 'batch_size': 32, 'attention_heads': 16, 'hidden_dimension': 83, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5741633416782639, 'global_pooling': 'max', 'learning_rate': 2.909390709224086e-05, 'weight_decay': 0.00040602314299270604, 'beta_0': 0.8835242999065858, 'beta_1': 0.9914043066984303, 'epsilon': 1.2664114292780513e-08, 'balanced_loss': True, 'epochs': 115, 'early_stopping_patience': 20, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 12:49:20,562] Trial 209 finished with value: 0.969868797847923 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7139405948425604, 'batch_size': 43, 'attention_heads': 16, 'hidden_dimension': 65, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5548932875249606, 'global_pooling': 'max', 'learning_rate': 3.767572513071803e-05, 'weight_decay': 0.00055965136582977, 'beta_0': 0.8865345666165306, 'beta_1': 0.9885907264963051, 'epsilon': 7.972046098520844e-05, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 19, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 13:24:06,264] Trial 210 finished with value: 0.9366510363899239 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.6892414226451682, 'batch_size': 39, 'attention_heads': 16, 'hidden_dimension': 73, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5704113271788637, 'global_pooling': 'max', 'learning_rate': 2.3710089369387628e-05, 'weight_decay': 0.0002989638359977181, 'beta_0': 0.8792306789118727, 'beta_1': 0.9893195378483014, 'epsilon': 7.661891010122419e-08, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 14:06:27,055] Trial 211 finished with value: 0.9663574588844488 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7296902787895319, 'batch_size': 45, 'attention_heads': 15, 'hidden_dimension': 78, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5482000552777325, 'global_pooling': 'max', 'learning_rate': 1.6768095452257297e-05, 'weight_decay': 0.0003585683660473462, 'beta_0': 0.8886250251881667, 'beta_1': 0.9934314845278315, 'epsilon': 2.3180465848269636e-05, 'balanced_loss': True, 'epochs': 127, 'early_stopping_patience': 18, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 14:37:14,529] Trial 212 finished with value: 0.9703133601073863 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7466569641637343, 'batch_size': 32, 'attention_heads': 16, 'hidden_dimension': 82, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5627767173538304, 'global_pooling': 'max', 'learning_rate': 3.3200618810765664e-05, 'weight_decay': 0.00043956487505416854, 'beta_0': 0.8833068986781959, 'beta_1': 0.9926611762468116, 'epsilon': 2.552662851395353e-08, 'balanced_loss': True, 'epochs': 135, 'early_stopping_patience': 20, 'plateau_patience': 10, 'plateau_divider': 7}. Best is trial 136 with value: 0.9776229738062259.
[I 2024-12-14 15:08:21,993] Trial 213 finished with value: 0.9803273479163068 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7190071819077849, 'batch_size': 37, 'attention_heads': 16, 'hidden_dimension': 91, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5803912567130826, 'global_pooling': 'max', 'learning_rate': 4.578712605717444e-05, 'weight_decay': 0.0001941669082036612, 'beta_0': 0.8857446053515984, 'beta_1': 0.9896061067375477, 'epsilon': 4.328100669809577e-05, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 20, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
CUDA out of memory. Tried to allocate 2.05 GiB. GPU 0 has a total capacity of 44.56 GiB of which 314.69 MiB is free. Including non-PyTorch memory, this process has 44.25 GiB memory in use. Of the allocated memory 41.01 GiB is allocated by PyTorch, and 2.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-14 15:15:34,478] Trial 214 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7183801657983788, 'batch_size': 36, 'attention_heads': 16, 'hidden_dimension': 254, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5792157766504215, 'global_pooling': 'max', 'learning_rate': 5.810709729601438e-05, 'weight_decay': 6.502414714004183e-06, 'beta_0': 0.8867815703407639, 'beta_1': 0.9881945294887364, 'epsilon': 4.317435075481698e-05, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-14 15:47:12,360] Trial 215 finished with value: 0.9652165434757936 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.737313691734676, 'batch_size': 41, 'attention_heads': 16, 'hidden_dimension': 91, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5898342773907117, 'global_pooling': 'max', 'learning_rate': 4.898097847624566e-05, 'weight_decay': 0.00021385310611398212, 'beta_0': 0.8845694323659952, 'beta_1': 0.9888983636231795, 'epsilon': 6.130587519685234e-05, 'balanced_loss': True, 'epochs': 111, 'early_stopping_patience': 20, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-14 16:24:09,281] Trial 216 finished with value: 0.9727646254910345 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7242799718528705, 'batch_size': 36, 'attention_heads': 16, 'hidden_dimension': 84, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5556370490212847, 'global_pooling': 'max', 'learning_rate': 4.317075705942609e-05, 'weight_decay': 0.00019566105345144433, 'beta_0': 0.8815655216580399, 'beta_1': 0.9906513254947622, 'epsilon': 2.9034698093548937e-05, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 16, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-14 16:56:58,193] Trial 217 finished with value: 0.9627576096667538 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7092101027553975, 'batch_size': 36, 'attention_heads': 16, 'hidden_dimension': 85, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5502977286493199, 'global_pooling': 'max', 'learning_rate': 4.558423928060309e-05, 'weight_decay': 0.0009844381126498404, 'beta_0': 0.891434743490847, 'beta_1': 0.9894236099259004, 'epsilon': 3.52685097515155e-05, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 16, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-14 17:26:18,839] Trial 218 finished with value: 0.9670494518765945 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7000182278103093, 'batch_size': 32, 'attention_heads': 15, 'hidden_dimension': 92, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5573399803576333, 'global_pooling': 'max', 'learning_rate': 3.9319683299420064e-05, 'weight_decay': 0.0002830126882880878, 'beta_0': 0.8858224987368665, 'beta_1': 0.9907760048339731, 'epsilon': 2.604993774902115e-05, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 16, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-14 18:02:15,527] Trial 219 finished with value: 0.9641812594647308 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7179127535958515, 'batch_size': 40, 'attention_heads': 16, 'hidden_dimension': 74, 'number_of_hidden_layers': 3, 'dropout_rate': 0.544045537152964, 'global_pooling': 'max', 'learning_rate': 2.4984301913673654e-05, 'weight_decay': 0.000252947316462586, 'beta_0': 0.88838329770871, 'beta_1': 0.9897573033199561, 'epsilon': 2.8844489502050226e-05, 'balanced_loss': True, 'epochs': 112, 'early_stopping_patience': 17, 'plateau_patience': 20, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-14 18:48:25,749] Trial 220 finished with value: 0.9723622292029004 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7231577696104248, 'batch_size': 37, 'attention_heads': 16, 'hidden_dimension': 83, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5359135986557547, 'global_pooling': 'max', 'learning_rate': 1.9793182992697223e-05, 'weight_decay': 5.389845869790738e-06, 'beta_0': 0.8777122358573697, 'beta_1': 0.9909453018453074, 'epsilon': 3.740136040269894e-05, 'balanced_loss': True, 'epochs': 132, 'early_stopping_patience': 14, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
CUDA out of memory. Tried to allocate 1.56 GiB. GPU 0 has a total capacity of 44.56 GiB of which 698.69 MiB is free. Including non-PyTorch memory, this process has 43.87 GiB memory in use. Of the allocated memory 40.04 GiB is allocated by PyTorch, and 2.68 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-14 19:19:06,328] Trial 221 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7210740766974014, 'batch_size': 48, 'attention_heads': 15, 'hidden_dimension': 88, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5346407648516138, 'global_pooling': 'max', 'learning_rate': 2.1333769037381913e-05, 'weight_decay': 5.336027328881711e-06, 'beta_0': 0.877980369154796, 'beta_1': 0.9909276602231089, 'epsilon': 4.5916753360873724e-05, 'balanced_loss': True, 'epochs': 141, 'early_stopping_patience': 14, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-14 20:12:29,672] Trial 222 finished with value: 0.9746759007124359 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7102762757805066, 'batch_size': 37, 'attention_heads': 16, 'hidden_dimension': 83, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5515937649242035, 'global_pooling': 'max', 'learning_rate': 1.507105010468602e-05, 'weight_decay': 4.557191686880772e-06, 'beta_0': 0.8802285509050221, 'beta_1': 0.9918826456168011, 'epsilon': 3.623898857884215e-05, 'balanced_loss': True, 'epochs': 139, 'early_stopping_patience': 15, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-14 20:57:27,008] Trial 223 finished with value: 0.9626275312906372 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7336423813214792, 'batch_size': 37, 'attention_heads': 16, 'hidden_dimension': 83, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5381875761524947, 'global_pooling': 'max', 'learning_rate': 1.4059694348648851e-05, 'weight_decay': 3.6557584235921098e-06, 'beta_0': 0.8736327222301942, 'beta_1': 0.991840566048427, 'epsilon': 3.553243470570697e-05, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 13, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-14 21:10:51,791] Trial 224 finished with value: 0.08862858842778522 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7271460037800723, 'batch_size': 39, 'attention_heads': 16, 'hidden_dimension': 81, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5449259918491147, 'global_pooling': 'sum', 'learning_rate': 0.04440540239698851, 'weight_decay': 4.3222044306152425e-06, 'beta_0': 0.8763166731180022, 'beta_1': 0.9912389941943144, 'epsilon': 3.924776060270106e-05, 'balanced_loss': True, 'epochs': 144, 'early_stopping_patience': 14, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
CUDA out of memory. Tried to allocate 1.51 GiB. GPU 0 has a total capacity of 44.56 GiB of which 828.69 MiB is free. Including non-PyTorch memory, this process has 43.74 GiB memory in use. Of the allocated memory 39.96 GiB is allocated by PyTorch, and 2.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-14 21:36:07,788] Trial 225 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7093177259991023, 'batch_size': 43, 'attention_heads': 16, 'hidden_dimension': 89, 'number_of_hidden_layers': 3, 'dropout_rate': 0.552859533082132, 'global_pooling': 'max', 'learning_rate': 1.619851156820447e-05, 'weight_decay': 5.044169873633895e-06, 'beta_0': 0.8823904977015898, 'beta_1': 0.9899495820975995, 'epsilon': 4.655039173681495e-05, 'balanced_loss': True, 'epochs': 138, 'early_stopping_patience': 15, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-14 22:17:32,705] Trial 226 finished with value: 0.9740125452083093 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7158714664860398, 'batch_size': 36, 'attention_heads': 16, 'hidden_dimension': 95, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5535126757093127, 'global_pooling': 'max', 'learning_rate': 2.5797475153727362e-05, 'weight_decay': 5.843790550921147e-06, 'beta_0': 0.8801164378724097, 'beta_1': 0.9906490628752723, 'epsilon': 2.656110599686055e-05, 'balanced_loss': True, 'epochs': 137, 'early_stopping_patience': 15, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-14 22:54:33,770] Trial 227 finished with value: 0.963329897497077 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7169077802988687, 'batch_size': 36, 'attention_heads': 16, 'hidden_dimension': 84, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5504356789504136, 'global_pooling': 'max', 'learning_rate': 2.7183576203365732e-05, 'weight_decay': 5.997355744796594e-06, 'beta_0': 0.8797561066113937, 'beta_1': 0.9905563715667502, 'epsilon': 2.3063879063063053e-05, 'balanced_loss': True, 'epochs': 133, 'early_stopping_patience': 14, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-14 23:38:24,257] Trial 228 finished with value: 0.9607913334019234 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7236839943917166, 'batch_size': 36, 'attention_heads': 16, 'hidden_dimension': 78, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5324551633793211, 'global_pooling': 'max', 'learning_rate': 1.9239017659530505e-05, 'weight_decay': 4.63108098350473e-06, 'beta_0': 0.8805261053496316, 'beta_1': 0.9910053888456065, 'epsilon': 2.8680279021411387e-05, 'balanced_loss': True, 'epochs': 139, 'early_stopping_patience': 16, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacity of 44.56 GiB of which 914.69 MiB is free. Including non-PyTorch memory, this process has 43.66 GiB memory in use. Of the allocated memory 40.18 GiB is allocated by PyTorch, and 2.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-14 23:45:35,813] Trial 229 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.6991889914437661, 'batch_size': 117, 'attention_heads': 16, 'hidden_dimension': 98, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5418850413805374, 'global_pooling': 'max', 'learning_rate': 3.482455072248264e-05, 'weight_decay': 6.120882034412597e-06, 'beta_0': 0.8777859671485828, 'beta_1': 0.9922061022064756, 'epsilon': 2.0509753737738534e-05, 'balanced_loss': True, 'epochs': 131, 'early_stopping_patience': 15, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-15 00:25:38,715] Trial 230 finished with value: 0.9669872130052353 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.7158773813455738, 'batch_size': 40, 'attention_heads': 16, 'hidden_dimension': 87, 'number_of_hidden_layers': 3, 'dropout_rate': 0.570212031573333, 'global_pooling': 'max', 'learning_rate': 2.6336815943315534e-05, 'weight_decay': 6.928204607372849e-06, 'beta_0': 0.8977049915843757, 'beta_1': 0.9901824784787768, 'epsilon': 3.552412192362031e-05, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 15, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-15 01:09:41,609] Trial 231 finished with value: 0.9414562514176159 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7328024805126861, 'batch_size': 32, 'attention_heads': 16, 'hidden_dimension': 69, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5471188305009721, 'global_pooling': 'max', 'learning_rate': 1.5334686395804834e-05, 'weight_decay': 5.340356107260447e-06, 'beta_0': 0.8811588413527185, 'beta_1': 0.9917292750266986, 'epsilon': 3.403465427373641e-08, 'balanced_loss': False, 'epochs': 130, 'early_stopping_patience': 15, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-15 01:36:05,824] Trial 232 finished with value: 0.9701934916306005 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7393905651059277, 'batch_size': 40, 'attention_heads': 16, 'hidden_dimension': 81, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5553669085563415, 'global_pooling': 'max', 'learning_rate': 4.208576003994605e-05, 'weight_decay': 0.00016526021242771143, 'beta_0': 0.8756164651245981, 'beta_1': 0.9909712482666319, 'epsilon': 2.5851234247849054e-05, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 14, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-15 02:07:32,972] Trial 233 finished with value: 0.958068143271537 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7244766989916721, 'batch_size': 48, 'attention_heads': 16, 'hidden_dimension': 76, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5384861860571214, 'global_pooling': 'max', 'learning_rate': 3.0629889094758565e-05, 'weight_decay': 4.722032932335393e-06, 'beta_0': 0.8789294015682477, 'beta_1': 0.9905963262212124, 'epsilon': 3.948116156228427e-05, 'balanced_loss': True, 'epochs': 70, 'early_stopping_patience': 13, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 44.56 GiB of which 388.69 MiB is free. Including non-PyTorch memory, this process has 44.17 GiB memory in use. Of the allocated memory 39.86 GiB is allocated by PyTorch, and 3.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-15 02:40:03,971] Trial 234 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7060193260328912, 'batch_size': 37, 'attention_heads': 16, 'hidden_dimension': 85, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5619166385200983, 'global_pooling': 'max', 'learning_rate': 1.9378042501736664e-05, 'weight_decay': 5.850015466362903e-06, 'beta_0': 0.8898992028282802, 'beta_1': 0.9914559444989337, 'epsilon': 3.184418246508886e-05, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 16, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
[I 2024-12-15 03:33:53,210] Trial 235 finished with value: 0.9639201895260672 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.7137819572047871, 'batch_size': 44, 'attention_heads': 16, 'hidden_dimension': 90, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5556623688263376, 'global_pooling': 'max', 'learning_rate': 2.309360227900823e-05, 'weight_decay': 0.00037395401537091696, 'beta_0': 0.8829695453025651, 'beta_1': 0.9903869247056161, 'epsilon': 6.131324411043778e-05, 'balanced_loss': True, 'epochs': 137, 'early_stopping_patience': 21, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 213 with value: 0.9803273479163068.
slurmstepd: error: *** JOB 14093610 ON gpu012 CANCELLED AT 2024-12-15T03:36:37 DUE TO TIME LIMIT ***
