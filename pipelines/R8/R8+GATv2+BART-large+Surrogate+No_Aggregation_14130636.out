[I 2024-12-21 04:09:21,640] Using an existing study with name 'R8-GATv2-facebook-bart-large-Surrogate-No_Aggregation' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (1136 > 1024). Running this sequence through the model will result in indexing errors
[I 2024-12-21 04:22:09,612] Trial 224 finished with value: 0.9594481920146734 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9605580233637971, 'batch_size': 91, 'attention_heads': 15, 'hidden_dimension': 170, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34710668884330764, 'global_pooling': 'max', 'learning_rate': 0.0002399088127417038, 'weight_decay': 0.0002230352854377548, 'beta_0': 0.8674623723013233, 'beta_1': 0.9824968725531757, 'epsilon': 8.362991962902412e-05, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 12, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 04:35:56,553] Trial 225 finished with value: 0.9669637825617922 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9667055990101546, 'batch_size': 87, 'attention_heads': 15, 'hidden_dimension': 167, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3435825275236242, 'global_pooling': 'max', 'learning_rate': 0.00019012552670506978, 'weight_decay': 0.00027092241773662935, 'beta_0': 0.8702434403322831, 'beta_1': 0.9827023376629564, 'epsilon': 6.87183519831326e-05, 'balanced_loss': False, 'epochs': 133, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
CUDA out of memory. Tried to allocate 1.63 GiB. GPU 0 has a total capacity of 44.56 GiB of which 878.69 MiB is free. Including non-PyTorch memory, this process has 43.70 GiB memory in use. Of the allocated memory 41.28 GiB is allocated by PyTorch, and 1.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 04:45:48,007] Trial 226 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9709297271302156, 'batch_size': 85, 'attention_heads': 15, 'hidden_dimension': 178, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3554201255866841, 'global_pooling': 'max', 'learning_rate': 0.0002094229522551689, 'weight_decay': 0.0003268553023596775, 'beta_0': 0.8694100550534518, 'beta_1': 0.9827878919295604, 'epsilon': 6.628702132939837e-05, 'balanced_loss': False, 'epochs': 139, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 05:00:25,172] Trial 227 finished with value: 0.9641333410294208 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9666903407783638, 'batch_size': 155, 'attention_heads': 15, 'hidden_dimension': 165, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33907896046209457, 'global_pooling': 'max', 'learning_rate': 0.00018061594892685443, 'weight_decay': 0.0001520871998490153, 'beta_0': 0.870435475948212, 'beta_1': 0.9832624369105583, 'epsilon': 4.5991648994308145e-05, 'balanced_loss': False, 'epochs': 134, 'early_stopping_patience': 25, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 05:13:18,630] Trial 228 finished with value: 0.962712293073055 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9672937822858032, 'batch_size': 157, 'attention_heads': 15, 'hidden_dimension': 164, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32831137866734705, 'global_pooling': 'max', 'learning_rate': 0.00032030940994600353, 'weight_decay': 0.0001673591695548354, 'beta_0': 0.8705663680973033, 'beta_1': 0.9832273893412699, 'epsilon': 1.2265395921393952e-05, 'balanced_loss': False, 'epochs': 134, 'early_stopping_patience': 25, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 05:26:42,345] Trial 229 finished with value: 0.9587412731882702 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9761049741266575, 'batch_size': 154, 'attention_heads': 15, 'hidden_dimension': 169, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3418967434988184, 'global_pooling': 'max', 'learning_rate': 0.0001943317450630054, 'weight_decay': 0.00014995887738999413, 'beta_0': 0.8640426805439048, 'beta_1': 0.984123460470705, 'epsilon': 4.1918067313268594e-05, 'balanced_loss': False, 'epochs': 136, 'early_stopping_patience': 25, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 05:40:21,903] Trial 230 finished with value: 0.9465779453507277 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9544677115307957, 'batch_size': 151, 'attention_heads': 10, 'hidden_dimension': 174, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4906479036377837, 'global_pooling': 'sum', 'learning_rate': 0.00027376737719469595, 'weight_decay': 0.00019187720705280924, 'beta_0': 0.8723730619703037, 'beta_1': 0.9834277212735589, 'epsilon': 3.281607661430016e-05, 'balanced_loss': False, 'epochs': 140, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 05:57:21,377] Trial 231 finished with value: 0.9581309279229564 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9721953927130746, 'batch_size': 166, 'attention_heads': 15, 'hidden_dimension': 163, 'number_of_hidden_layers': 0, 'dropout_rate': 0.50832887599105, 'global_pooling': 'max', 'learning_rate': 0.0001297100034062583, 'weight_decay': 0.0002714159888207682, 'beta_0': 0.8689522003840705, 'beta_1': 0.982920897676864, 'epsilon': 4.51190677117805e-05, 'balanced_loss': False, 'epochs': 132, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 06:13:27,746] Trial 232 finished with value: 0.9612131331053941 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9653109987146676, 'batch_size': 162, 'attention_heads': 15, 'hidden_dimension': 185, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3366350362168697, 'global_pooling': 'max', 'learning_rate': 0.00016212819247833938, 'weight_decay': 0.00036946353336470266, 'beta_0': 0.8659496214896886, 'beta_1': 0.9823566018310468, 'epsilon': 2.582337781316478e-05, 'balanced_loss': False, 'epochs': 160, 'early_stopping_patience': 25, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 06:26:44,455] Trial 233 finished with value: 0.9362640391807486 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9837275976473602, 'batch_size': 148, 'attention_heads': 16, 'hidden_dimension': 179, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34602082189806066, 'global_pooling': 'max', 'learning_rate': 0.00018079073048708267, 'weight_decay': 0.0002931107063097739, 'beta_0': 0.8621254670881189, 'beta_1': 0.9806344525579074, 'epsilon': 9.2020157733376e-05, 'balanced_loss': False, 'epochs': 134, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 06:40:10,664] Trial 234 finished with value: 0.9687473403973186 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.958456223649188, 'batch_size': 115, 'attention_heads': 15, 'hidden_dimension': 160, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3494060463149361, 'global_pooling': 'max', 'learning_rate': 0.0001925853355574372, 'weight_decay': 0.0005207290258669812, 'beta_0': 0.8746534231531922, 'beta_1': 0.9819817540269122, 'epsilon': 5.819924663789596e-05, 'balanced_loss': False, 'epochs': 120, 'early_stopping_patience': 11, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 06:52:51,738] Trial 235 finished with value: 0.9584545471576722 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9581883642675382, 'batch_size': 110, 'attention_heads': 15, 'hidden_dimension': 167, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3405584353533831, 'global_pooling': 'max', 'learning_rate': 0.00026001187751713067, 'weight_decay': 0.00047765719593964606, 'beta_0': 0.8708244523059165, 'beta_1': 0.9817567845200202, 'epsilon': 6.759810442496749e-05, 'balanced_loss': False, 'epochs': 143, 'early_stopping_patience': 11, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 07:06:14,274] Trial 236 finished with value: 0.9609894124263894 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9664540195305077, 'batch_size': 96, 'attention_heads': 15, 'hidden_dimension': 160, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34892115571706245, 'global_pooling': 'max', 'learning_rate': 0.00014349291500557784, 'weight_decay': 0.0003968939205730786, 'beta_0': 0.8730993629685818, 'beta_1': 0.9822657124435489, 'epsilon': 5.197794029628683e-05, 'balanced_loss': False, 'epochs': 120, 'early_stopping_patience': 17, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 07:18:55,655] Trial 237 finished with value: 0.9689765262759155 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9587725654426094, 'batch_size': 102, 'attention_heads': 15, 'hidden_dimension': 166, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3339297097194933, 'global_pooling': 'max', 'learning_rate': 0.000195369164324367, 'weight_decay': 0.0005344264967399627, 'beta_0': 0.8750248018382375, 'beta_1': 0.9813026957250539, 'epsilon': 3.7910345017897676e-05, 'balanced_loss': False, 'epochs': 128, 'early_stopping_patience': 11, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 07:32:16,080] Trial 238 finished with value: 0.958374452742699 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9478374408469852, 'batch_size': 102, 'attention_heads': 15, 'hidden_dimension': 166, 'number_of_hidden_layers': 0, 'dropout_rate': 0.333057282128876, 'global_pooling': 'max', 'learning_rate': 0.000209960259922477, 'weight_decay': 0.0005371803437301516, 'beta_0': 0.8776221079179937, 'beta_1': 0.9813489160276238, 'epsilon': 3.814140884655878e-05, 'balanced_loss': False, 'epochs': 128, 'early_stopping_patience': 10, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 07:45:58,242] Trial 239 finished with value: 0.957710575282158 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9570907129674868, 'batch_size': 88, 'attention_heads': 15, 'hidden_dimension': 171, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32951937704761214, 'global_pooling': 'max', 'learning_rate': 0.0003064415003455304, 'weight_decay': 0.00014235778783999056, 'beta_0': 0.874539767463727, 'beta_1': 0.9810374818738076, 'epsilon': 4.556251826469858e-05, 'balanced_loss': False, 'epochs': 131, 'early_stopping_patience': 25, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 204 with value: 0.9699340812748718.
[I 2024-12-21 08:01:07,297] Trial 240 finished with value: 0.9721836830431988 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9615898122261908, 'batch_size': 117, 'attention_heads': 15, 'hidden_dimension': 175, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3379046475923544, 'global_pooling': 'max', 'learning_rate': 0.0001937919409164918, 'weight_decay': 0.000546201982885613, 'beta_0': 0.875911370118661, 'beta_1': 0.9819817691527395, 'epsilon': 5.75847561376166e-05, 'balanced_loss': False, 'epochs': 116, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 08:15:44,191] Trial 241 finished with value: 0.957400175791088 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9524590547267368, 'batch_size': 116, 'attention_heads': 15, 'hidden_dimension': 175, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3209473700520175, 'global_pooling': 'max', 'learning_rate': 0.00024043695684474025, 'weight_decay': 0.0005562677933424046, 'beta_0': 0.8788357734325035, 'beta_1': 0.9818546351838875, 'epsilon': 7.192494677774527e-05, 'balanced_loss': False, 'epochs': 116, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 08:29:58,931] Trial 242 finished with value: 0.9619666747984417 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.960707943769489, 'batch_size': 121, 'attention_heads': 15, 'hidden_dimension': 171, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3356065939911848, 'global_pooling': 'max', 'learning_rate': 0.00034585582205487074, 'weight_decay': 1.029904476432445e-06, 'beta_0': 0.8760098296079619, 'beta_1': 0.9815589757463535, 'epsilon': 6.0693819876837445e-05, 'balanced_loss': False, 'epochs': 126, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 240 with value: 0.9721836830431988.
CUDA out of memory. Tried to allocate 3.98 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.89 GiB is free. Including non-PyTorch memory, this process has 40.66 GiB memory in use. Of the allocated memory 37.52 GiB is allocated by PyTorch, and 1.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 08:39:06,526] Trial 243 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9394151431097234, 'batch_size': 127, 'attention_heads': 14, 'hidden_dimension': 178, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31515066898807254, 'global_pooling': 'mean', 'learning_rate': 0.0002072129747515503, 'weight_decay': 0.0006419888013187344, 'beta_0': 0.8764965868904026, 'beta_1': 0.9807208852900902, 'epsilon': 8.054186271552329e-05, 'balanced_loss': False, 'epochs': 119, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 08:53:39,225] Trial 244 finished with value: 0.9704377646334139 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9627700428367267, 'batch_size': 112, 'attention_heads': 15, 'hidden_dimension': 164, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33891655804616416, 'global_pooling': 'max', 'learning_rate': 0.00017982023231192273, 'weight_decay': 0.000474557050164047, 'beta_0': 0.8749338662902637, 'beta_1': 0.98200976601224, 'epsilon': 5.072728970106271e-05, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 09:07:45,959] Trial 245 finished with value: 0.962564798577004 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9586231058226706, 'batch_size': 112, 'attention_heads': 15, 'hidden_dimension': 162, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3448638795557526, 'global_pooling': 'max', 'learning_rate': 0.00027151185762331074, 'weight_decay': 0.00047275477041703814, 'beta_0': 0.8754055155634043, 'beta_1': 0.9813414234870179, 'epsilon': 5.5481590303104255e-05, 'balanced_loss': False, 'epochs': 110, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 09:22:28,518] Trial 246 finished with value: 0.9640216301670254 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9625514149826956, 'batch_size': 114, 'attention_heads': 15, 'hidden_dimension': 168, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34229352049488276, 'global_pooling': 'max', 'learning_rate': 0.00016561086712720867, 'weight_decay': 0.0005281677792913481, 'beta_0': 0.873297091928089, 'beta_1': 0.9820659884938107, 'epsilon': 3.640141079094619e-05, 'balanced_loss': False, 'epochs': 115, 'early_stopping_patience': 24, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 09:36:03,221] Trial 247 finished with value: 0.9645280691415672 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9744742215713028, 'batch_size': 118, 'attention_heads': 15, 'hidden_dimension': 173, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3356897296708723, 'global_pooling': 'max', 'learning_rate': 0.00019387410994166286, 'weight_decay': 0.0004159324259988952, 'beta_0': 0.8812573876168772, 'beta_1': 0.9817540928551413, 'epsilon': 6.294344002947581e-05, 'balanced_loss': False, 'epochs': 122, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 09:50:51,170] Trial 248 finished with value: 0.9579577642782482 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9524407777160757, 'batch_size': 102, 'attention_heads': 15, 'hidden_dimension': 163, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3284566696611771, 'global_pooling': 'max', 'learning_rate': 0.00023422404678690524, 'weight_decay': 0.0007205983261340768, 'beta_0': 0.8784026177818345, 'beta_1': 0.9825561930120316, 'epsilon': 5.286625669049549e-05, 'balanced_loss': False, 'epochs': 120, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 10:03:41,843] Trial 249 finished with value: 0.9605179681780074 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9647208448904614, 'batch_size': 110, 'attention_heads': 15, 'hidden_dimension': 169, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3561182085024344, 'global_pooling': 'max', 'learning_rate': 0.00029291682160310364, 'weight_decay': 0.0006191960271198959, 'beta_0': 0.8752688275847622, 'beta_1': 0.9820667384179965, 'epsilon': 7.284592168078935e-05, 'balanced_loss': True, 'epochs': 117, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 10:16:12,336] Trial 250 finished with value: 0.9552820850659514 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9737052350349605, 'batch_size': 97, 'attention_heads': 15, 'hidden_dimension': 156, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3469886709750405, 'global_pooling': 'max', 'learning_rate': 0.00015870811185334085, 'weight_decay': 0.00046954974416442934, 'beta_0': 0.8726741474486329, 'beta_1': 0.9813329303421712, 'epsilon': 4.3880972965116244e-05, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 10:34:05,884] Trial 251 finished with value: 0.9576019142048987 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9556393324072875, 'batch_size': 105, 'attention_heads': 16, 'hidden_dimension': 174, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34267501163644914, 'global_pooling': 'max', 'learning_rate': 0.00010901484739926638, 'weight_decay': 0.0005728232662476401, 'beta_0': 0.8637537038067459, 'beta_1': 0.9823440745194476, 'epsilon': 5.8328645564747975e-05, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
CUDA out of memory. Tried to allocate 4.25 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.84 GiB is free. Including non-PyTorch memory, this process has 40.71 GiB memory in use. Of the allocated memory 37.62 GiB is allocated by PyTorch, and 1.94 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 10:43:14,200] Trial 252 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9459679673247746, 'batch_size': 122, 'attention_heads': 15, 'hidden_dimension': 166, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35975414165944686, 'global_pooling': 'sum', 'learning_rate': 0.00020357750771367005, 'weight_decay': 0.00038190514322726635, 'beta_0': 0.877504781411663, 'beta_1': 0.981793171866532, 'epsilon': 3.934084212183309e-05, 'balanced_loss': False, 'epochs': 125, 'early_stopping_patience': 11, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 10:57:07,513] Trial 253 finished with value: 0.9641981010142098 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9633803043264966, 'batch_size': 94, 'attention_heads': 15, 'hidden_dimension': 160, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34965140259189553, 'global_pooling': 'max', 'learning_rate': 0.0002408742221547282, 'weight_decay': 0.0005158503963796914, 'beta_0': 0.8716966793485765, 'beta_1': 0.9809997433379513, 'epsilon': 8.988155416829327e-05, 'balanced_loss': False, 'epochs': 155, 'early_stopping_patience': 24, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 11:09:48,470] Trial 254 finished with value: 0.9550377306530138 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9696923107998189, 'batch_size': 83, 'attention_heads': 15, 'hidden_dimension': 180, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33809454166615344, 'global_pooling': 'max', 'learning_rate': 0.0003576586506020494, 'weight_decay': 0.00022595228177715057, 'beta_0': 0.8599846270522986, 'beta_1': 0.9814870574664027, 'epsilon': 5.293009574495299e-05, 'balanced_loss': False, 'epochs': 129, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 11:22:19,799] Trial 255 finished with value: 0.9433796088620093 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.981464830862372, 'batch_size': 117, 'attention_heads': 15, 'hidden_dimension': 171, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33156905242239354, 'global_pooling': 'max', 'learning_rate': 0.00014495830552775584, 'weight_decay': 0.0004338939229562642, 'beta_0': 0.8342920578998595, 'beta_1': 0.9826622408828213, 'epsilon': 3.108634987349941e-05, 'balanced_loss': False, 'epochs': 122, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 11:37:22,679] Trial 256 finished with value: 0.9676854247612656 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9582692565706854, 'batch_size': 111, 'attention_heads': 15, 'hidden_dimension': 162, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35386287101090796, 'global_pooling': 'max', 'learning_rate': 0.00017954456975696463, 'weight_decay': 0.0006797876296971063, 'beta_0': 0.8752507904939953, 'beta_1': 0.9802185248418737, 'epsilon': 7.361321817314114e-05, 'balanced_loss': False, 'epochs': 131, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 11:50:50,174] Trial 257 finished with value: 0.9547029671065905 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9495563355960015, 'batch_size': 72, 'attention_heads': 15, 'hidden_dimension': 166, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3637973094768405, 'global_pooling': 'max', 'learning_rate': 0.000449328184661686, 'weight_decay': 0.0003344008120746383, 'beta_0': 0.873869148456066, 'beta_1': 0.980308643450761, 'epsilon': 4.877678570370358e-05, 'balanced_loss': False, 'epochs': 131, 'early_stopping_patience': 23, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 12:05:09,172] Trial 258 finished with value: 0.95786847321024 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9576877980351373, 'batch_size': 107, 'attention_heads': 16, 'hidden_dimension': 175, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3547782222205137, 'global_pooling': 'max', 'learning_rate': 0.0001871677309753567, 'weight_decay': 0.0002627086923962398, 'beta_0': 0.8793822476890638, 'beta_1': 0.9804688342557951, 'epsilon': 3.080620561763718e-08, 'balanced_loss': False, 'epochs': 137, 'early_stopping_patience': 24, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 12:18:47,447] Trial 259 finished with value: 0.9587498737723774 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.961178531856749, 'batch_size': 101, 'attention_heads': 14, 'hidden_dimension': 155, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34426135401511426, 'global_pooling': 'max', 'learning_rate': 0.00030245919615621447, 'weight_decay': 0.0006338788005464465, 'beta_0': 0.8764132461920726, 'beta_1': 0.9807775888281812, 'epsilon': 9.825430726919742e-05, 'balanced_loss': False, 'epochs': 125, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 12:33:14,794] Trial 260 finished with value: 0.955140681825975 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9537731564760782, 'batch_size': 89, 'attention_heads': 15, 'hidden_dimension': 170, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3544342996156874, 'global_pooling': 'max', 'learning_rate': 0.00023171161034117016, 'weight_decay': 0.0005179415524051257, 'beta_0': 0.8827626746620951, 'beta_1': 0.9801763627706476, 'epsilon': 3.9349424072630404e-05, 'balanced_loss': False, 'epochs': 129, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 12:44:34,984] Trial 261 finished with value: 0.959220631219276 and parameters: {'left_stride': 64, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9745651858828177, 'batch_size': 223, 'attention_heads': 9, 'hidden_dimension': 162, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3225020390960683, 'global_pooling': 'max', 'learning_rate': 0.0002630239877648736, 'weight_decay': 0.000449129449874663, 'beta_0': 0.8745149633759802, 'beta_1': 0.981116752604702, 'epsilon': 5.625706644569213e-08, 'balanced_loss': False, 'epochs': 119, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 12:57:28,902] Trial 262 finished with value: 0.9564374948888467 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9626759325085605, 'batch_size': 108, 'attention_heads': 15, 'hidden_dimension': 189, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3379630613576694, 'global_pooling': 'max', 'learning_rate': 0.0010351614248038914, 'weight_decay': 0.0002912928263508161, 'beta_0': 0.8656944104781574, 'beta_1': 0.9808829187294582, 'epsilon': 6.919457101905984e-05, 'balanced_loss': False, 'epochs': 132, 'early_stopping_patience': 25, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 13:13:33,180] Trial 263 finished with value: 0.957710575282158 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.945779486720029, 'batch_size': 98, 'attention_heads': 15, 'hidden_dimension': 165, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3605682326421464, 'global_pooling': 'max', 'learning_rate': 0.0001805350383244582, 'weight_decay': 0.00019397721189816353, 'beta_0': 0.8577372057936093, 'beta_1': 0.9800101594284123, 'epsilon': 6.239101201963125e-05, 'balanced_loss': False, 'epochs': 171, 'early_stopping_patience': 23, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
CUDA out of memory. Tried to allocate 700.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 204.69 MiB is free. Including non-PyTorch memory, this process has 44.35 GiB memory in use. Of the allocated memory 42.61 GiB is allocated by PyTorch, and 604.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 13:19:40,555] Trial 264 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.7418030657435342, 'batch_size': 112, 'attention_heads': 14, 'hidden_dimension': 168, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3491012916776305, 'global_pooling': 'sum', 'learning_rate': 0.00012188794707692087, 'weight_decay': 9.95258107842154e-06, 'beta_0': 0.8613458205083598, 'beta_1': 0.9816817117534221, 'epsilon': 4.958169936487195e-05, 'balanced_loss': False, 'epochs': 123, 'early_stopping_patience': 25, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 13:31:24,634] Trial 265 finished with value: 0.9586841808994218 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.978422513526482, 'batch_size': 125, 'attention_heads': 15, 'hidden_dimension': 178, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3329512654990333, 'global_pooling': 'max', 'learning_rate': 0.000544065830634981, 'weight_decay': 2.0970096833953142e-05, 'beta_0': 0.8629468153876118, 'beta_1': 0.9812609682985184, 'epsilon': 3.291410154009046e-05, 'balanced_loss': False, 'epochs': 134, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 13:44:20,311] Trial 266 finished with value: 0.96726743687185 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9690189274905816, 'batch_size': 104, 'attention_heads': 16, 'hidden_dimension': 184, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3416193349222191, 'global_pooling': 'max', 'learning_rate': 0.0003269008956025703, 'weight_decay': 0.00038930196558080075, 'beta_0': 0.8761348027916328, 'beta_1': 0.9805247891132939, 'epsilon': 7.648666880928837e-05, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 16, 'plateau_patience': 25, 'plateau_divider': 8}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 13:56:35,222] Trial 267 finished with value: 0.961134945414517 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9703770404428536, 'batch_size': 104, 'attention_heads': 16, 'hidden_dimension': 193, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34044383520062155, 'global_pooling': 'max', 'learning_rate': 0.0003959588784975884, 'weight_decay': 0.0005746732787286905, 'beta_0': 0.8724203687149527, 'beta_1': 0.9804373631835991, 'epsilon': 8.736185723579184e-05, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 15, 'plateau_patience': 23, 'plateau_divider': 8}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 14:11:18,599] Trial 268 finished with value: 0.938863764954982 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9560081040183973, 'batch_size': 100, 'attention_heads': 16, 'hidden_dimension': 184, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32809579516147613, 'global_pooling': 'mean', 'learning_rate': 0.00031554626743068187, 'weight_decay': 0.00039721302160006965, 'beta_0': 0.8753232027144524, 'beta_1': 0.9806598964626427, 'epsilon': 7.498051166799509e-05, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 16, 'plateau_patience': 24, 'plateau_divider': 7}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 14:23:24,689] Trial 269 finished with value: 0.9510427714344605 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9790602007694429, 'batch_size': 94, 'attention_heads': 16, 'hidden_dimension': 182, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3670652475934699, 'global_pooling': 'max', 'learning_rate': 0.00022184849374595427, 'weight_decay': 0.00011627630271269251, 'beta_0': 0.8680398687699884, 'beta_1': 0.9800137182302255, 'epsilon': 1.3856821676881289e-08, 'balanced_loss': False, 'epochs': 117, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 14:37:33,793] Trial 270 finished with value: 0.9609768532795078 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9678342709997471, 'batch_size': 117, 'attention_heads': 16, 'hidden_dimension': 172, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35288295738234216, 'global_pooling': 'max', 'learning_rate': 0.00035628931549143227, 'weight_decay': 0.0002360544838028459, 'beta_0': 0.8653421627465876, 'beta_1': 0.9823673464857211, 'epsilon': 6.059443813733342e-05, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 25, 'plateau_patience': 25, 'plateau_divider': 7}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 14:50:34,348] Trial 271 finished with value: 0.959143713138469 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9597285285141934, 'batch_size': 110, 'attention_heads': 14, 'hidden_dimension': 157, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34376620775702443, 'global_pooling': 'max', 'learning_rate': 0.00027092619829593935, 'weight_decay': 0.00047198127867928446, 'beta_0': 0.8723099222557296, 'beta_1': 0.9806534795905361, 'epsilon': 4.181551769896334e-05, 'balanced_loss': False, 'epochs': 111, 'early_stopping_patience': 23, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 15:04:25,722] Trial 272 finished with value: 0.9584124364912656 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9519663128259429, 'batch_size': 104, 'attention_heads': 15, 'hidden_dimension': 176, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3371536408411242, 'global_pooling': 'max', 'learning_rate': 0.0004430805069728874, 'weight_decay': 0.0008248710090326484, 'beta_0': 0.8749269940389175, 'beta_1': 0.9826939591908624, 'epsilon': 8.017627115703626e-05, 'balanced_loss': False, 'epochs': 125, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 15:17:23,552] Trial 273 finished with value: 0.9695989456607996 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.972168303851912, 'batch_size': 114, 'attention_heads': 16, 'hidden_dimension': 134, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3584800755790127, 'global_pooling': 'max', 'learning_rate': 0.0002107519513765675, 'weight_decay': 0.0006460370210137755, 'beta_0': 0.8699924800980365, 'beta_1': 0.9819103841963734, 'epsilon': 6.372971161078741e-05, 'balanced_loss': False, 'epochs': 129, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
CUDA out of memory. Tried to allocate 2.14 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.20 GiB is free. Including non-PyTorch memory, this process has 43.36 GiB memory in use. Of the allocated memory 41.07 GiB is allocated by PyTorch, and 1.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 15:26:07,925] Trial 274 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9419128734314576, 'batch_size': 120, 'attention_heads': 16, 'hidden_dimension': 135, 'number_of_hidden_layers': 2, 'dropout_rate': 0.35781623070383684, 'global_pooling': 'max', 'learning_rate': 0.00019142768740957288, 'weight_decay': 0.0006519179189752063, 'beta_0': 0.8692615844294782, 'beta_1': 0.9819234594218686, 'epsilon': 6.450653901607506e-05, 'balanced_loss': False, 'epochs': 130, 'early_stopping_patience': 25, 'plateau_patience': 24, 'plateau_divider': 6}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 15:39:56,660] Trial 275 finished with value: 0.963351945797144 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9655409846037414, 'batch_size': 113, 'attention_heads': 16, 'hidden_dimension': 144, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3631656537681095, 'global_pooling': 'max', 'learning_rate': 0.00016492489928729217, 'weight_decay': 0.0007418242830550737, 'beta_0': 0.8707147122915155, 'beta_1': 0.9821564676931888, 'epsilon': 8.215337026596504e-05, 'balanced_loss': False, 'epochs': 128, 'early_stopping_patience': 25, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 15:51:32,191] Trial 276 finished with value: 0.9469072179754142 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9862702959562242, 'batch_size': 117, 'attention_heads': 16, 'hidden_dimension': 135, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3539587051490224, 'global_pooling': 'max', 'learning_rate': 0.00021508256572037624, 'weight_decay': 0.0005373920534957141, 'beta_0': 0.8667510750619223, 'beta_1': 0.9826800699032067, 'epsilon': 6.088025354149657e-05, 'balanced_loss': False, 'epochs': 136, 'early_stopping_patience': 25, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
CUDA out of memory. Tried to allocate 3.84 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.52 GiB is free. Including non-PyTorch memory, this process has 41.03 GiB memory in use. Of the allocated memory 38.07 GiB is allocated by PyTorch, and 1.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 16:00:31,971] Trial 277 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9328040302442768, 'batch_size': 145, 'attention_heads': 16, 'hidden_dimension': 151, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34883324532251536, 'global_pooling': 'max', 'learning_rate': 0.00021882152765984421, 'weight_decay': 0.0006488762747271955, 'beta_0': 0.877030934433785, 'beta_1': 0.9815379438625701, 'epsilon': 2.6483462379066086e-06, 'balanced_loss': False, 'epochs': 132, 'early_stopping_patience': 18, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 16:12:09,616] Trial 278 finished with value: 0.9388164007349362 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9755175261578671, 'batch_size': 130, 'attention_heads': 16, 'hidden_dimension': 161, 'number_of_hidden_layers': 0, 'dropout_rate': 0.36001215789176233, 'global_pooling': 'sum', 'learning_rate': 0.0001709280805689488, 'weight_decay': 0.0005627213793320546, 'beta_0': 0.8393013856583281, 'beta_1': 0.9823538865076575, 'epsilon': 7.258634098317514e-05, 'balanced_loss': False, 'epochs': 137, 'early_stopping_patience': 14, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 16:25:41,685] Trial 279 finished with value: 0.9690913770568368 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.958904192585201, 'batch_size': 109, 'attention_heads': 15, 'hidden_dimension': 154, 'number_of_hidden_layers': 0, 'dropout_rate': 0.36700128927530673, 'global_pooling': 'max', 'learning_rate': 0.0002607495530805065, 'weight_decay': 0.00017788608354253843, 'beta_0': 0.8733470037981317, 'beta_1': 0.9820932349096118, 'epsilon': 9.911348616739398e-05, 'balanced_loss': False, 'epochs': 128, 'early_stopping_patience': 19, 'plateau_patience': 10, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 16:43:09,997] Trial 280 finished with value: 0.9536986079791031 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.948370791079187, 'batch_size': 110, 'attention_heads': 15, 'hidden_dimension': 154, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37053394830265757, 'global_pooling': 'max', 'learning_rate': 0.0001364344918545257, 'weight_decay': 0.00019725973944184042, 'beta_0': 0.8735542526450348, 'beta_1': 0.9818787302734079, 'epsilon': 9.712932349334376e-05, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 19, 'plateau_patience': 10, 'plateau_divider': 8}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 16:56:53,582] Trial 281 finished with value: 0.9590547494950796 and parameters: {'left_stride': 32, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9602606879023081, 'batch_size': 107, 'attention_heads': 15, 'hidden_dimension': 157, 'number_of_hidden_layers': 0, 'dropout_rate': 0.36996492058192837, 'global_pooling': 'max', 'learning_rate': 0.0002454375766936623, 'weight_decay': 0.00017717580570600746, 'beta_0': 0.8709730061402404, 'beta_1': 0.9827497097639111, 'epsilon': 4.7642856002483864e-05, 'balanced_loss': False, 'epochs': 124, 'early_stopping_patience': 22, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 17:11:26,082] Trial 282 finished with value: 0.9630343721541659 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9558929768675156, 'batch_size': 99, 'attention_heads': 14, 'hidden_dimension': 151, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3603900872771985, 'global_pooling': 'max', 'learning_rate': 0.00019504569912801413, 'weight_decay': 0.0004854378114263364, 'beta_0': 0.8737235248536727, 'beta_1': 0.9822650367303881, 'epsilon': 9.887827811628616e-05, 'balanced_loss': False, 'epochs': 129, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 17:25:05,250] Trial 283 finished with value: 0.9685543986143841 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9626515576471886, 'batch_size': 111, 'attention_heads': 15, 'hidden_dimension': 128, 'number_of_hidden_layers': 0, 'dropout_rate': 0.353171251807997, 'global_pooling': 'max', 'learning_rate': 0.0001498896774744033, 'weight_decay': 0.0007066262635061581, 'beta_0': 0.8790900135016686, 'beta_1': 0.9829808168107316, 'epsilon': 3.791190244829344e-05, 'balanced_loss': False, 'epochs': 131, 'early_stopping_patience': 25, 'plateau_patience': 10, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 17:36:25,562] Trial 284 finished with value: 0.9398862926222591 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.951304756846823, 'batch_size': 112, 'attention_heads': 16, 'hidden_dimension': 127, 'number_of_hidden_layers': 0, 'dropout_rate': 0.36581265419023845, 'global_pooling': 'max', 'learning_rate': 0.040770296098192195, 'weight_decay': 0.0009952136478222717, 'beta_0': 0.8798586360668117, 'beta_1': 0.9833840113669579, 'epsilon': 3.329789788622528e-05, 'balanced_loss': False, 'epochs': 133, 'early_stopping_patience': 19, 'plateau_patience': 11, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
CUDA out of memory. Tried to allocate 478.00 MiB. GPU 0 has a total capacity of 44.56 GiB of which 188.69 MiB is free. Including non-PyTorch memory, this process has 44.37 GiB memory in use. Of the allocated memory 42.43 GiB is allocated by PyTorch, and 811.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 17:41:10,785] Trial 285 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.6536941901394503, 'batch_size': 107, 'attention_heads': 15, 'hidden_dimension': 139, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37834616177002217, 'global_pooling': 'max', 'learning_rate': 1.5302351530815115e-05, 'weight_decay': 0.0007359745384883357, 'beta_0': 0.8785353424366129, 'beta_1': 0.9829073209734024, 'epsilon': 5.563757954925857e-05, 'balanced_loss': False, 'epochs': 129, 'early_stopping_patience': 17, 'plateau_patience': 10, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
CUDA out of memory. Tried to allocate 3.89 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.26 GiB is free. Including non-PyTorch memory, this process has 42.29 GiB memory in use. Of the allocated memory 37.35 GiB is allocated by PyTorch, and 3.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 17:57:45,860] Trial 286 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9378598372194282, 'batch_size': 120, 'attention_heads': 14, 'hidden_dimension': 128, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35546331192898856, 'global_pooling': 'max', 'learning_rate': 0.00014512224600617498, 'weight_decay': 0.0007924362929333026, 'beta_0': 0.8765708313452413, 'beta_1': 0.9828456612568782, 'epsilon': 6.714522243804541e-05, 'balanced_loss': False, 'epochs': 124, 'early_stopping_patience': 25, 'plateau_patience': 10, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 18:11:04,507] Trial 287 finished with value: 0.9514888218243773 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9593366305412743, 'batch_size': 112, 'attention_heads': 15, 'hidden_dimension': 121, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3627322587139413, 'global_pooling': 'max', 'learning_rate': 0.00012211795514096443, 'weight_decay': 0.0006389954443580321, 'beta_0': 0.8249087970835699, 'beta_1': 0.9837861115527983, 'epsilon': 2.516456151166596e-05, 'balanced_loss': False, 'epochs': 132, 'early_stopping_patience': 20, 'plateau_patience': 10, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 18:24:07,977] Trial 288 finished with value: 0.9622577332683642 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9709300855189693, 'batch_size': 123, 'attention_heads': 15, 'hidden_dimension': 126, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3520398587879077, 'global_pooling': 'max', 'learning_rate': 0.00016257869113169758, 'weight_decay': 0.0008718738077901152, 'beta_0': 0.872281135633867, 'beta_1': 0.981143416604665, 'epsilon': 8.280909516824744e-05, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 16, 'plateau_patience': 11, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 18:38:40,546] Trial 289 finished with value: 0.954656607644857 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9454154643626236, 'batch_size': 105, 'attention_heads': 16, 'hidden_dimension': 146, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3257658332590937, 'global_pooling': 'max', 'learning_rate': 0.00027074885575899434, 'weight_decay': 0.0005958076451866846, 'beta_0': 0.8813298936653435, 'beta_1': 0.9819211305497495, 'epsilon': 3.729206467111564e-05, 'balanced_loss': False, 'epochs': 130, 'early_stopping_patience': 25, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 18:50:13,863] Trial 290 finished with value: 0.9409656757128775 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.979311923276391, 'batch_size': 117, 'attention_heads': 15, 'hidden_dimension': 161, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3448057652787271, 'global_pooling': 'sum', 'learning_rate': 0.000613951504373843, 'weight_decay': 0.000693363172608718, 'beta_0': 0.8754233106157494, 'beta_1': 0.9824957873014334, 'epsilon': 4.70738551342326e-05, 'balanced_loss': True, 'epochs': 96, 'early_stopping_patience': 21, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 19:04:11,404] Trial 291 finished with value: 0.9559392679032391 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9631292289633671, 'batch_size': 179, 'attention_heads': 15, 'hidden_dimension': 133, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3567412641589916, 'global_pooling': 'max', 'learning_rate': 0.00016572478268893627, 'weight_decay': 0.0005348959822744112, 'beta_0': 0.8697715065869029, 'beta_1': 0.9831801497952312, 'epsilon': 3.936559323153102e-06, 'balanced_loss': False, 'epochs': 121, 'early_stopping_patience': 25, 'plateau_patience': 10, 'plateau_divider': 4}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 19:16:40,222] Trial 292 finished with value: 0.9574913231143193 and parameters: {'left_stride': 32, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9560163884275109, 'batch_size': 109, 'attention_heads': 12, 'hidden_dimension': 132, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33305332382774955, 'global_pooling': 'max', 'learning_rate': 0.00034061866567687164, 'weight_decay': 0.0001290327687443111, 'beta_0': 0.8788414789197656, 'beta_1': 0.9817919665345626, 'epsilon': 5.683950040286939e-05, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 20, 'plateau_patience': 10, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 19:33:48,293] Trial 293 finished with value: 0.9576906088138868 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9722821275560293, 'batch_size': 115, 'attention_heads': 15, 'hidden_dimension': 154, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3423279496706586, 'global_pooling': 'max', 'learning_rate': 0.00011405570732823818, 'weight_decay': 0.000443048532382783, 'beta_0': 0.8744424622528814, 'beta_1': 0.9812595979589166, 'epsilon': 2.812680847662983e-05, 'balanced_loss': False, 'epochs': 135, 'early_stopping_patience': 22, 'plateau_patience': 11, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 19:44:26,900] Trial 294 finished with value: 0.9385452626206209 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9926065345382846, 'batch_size': 142, 'attention_heads': 15, 'hidden_dimension': 142, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37431761384345796, 'global_pooling': 'max', 'learning_rate': 0.00023936429083465816, 'weight_decay': 0.000617342562322469, 'beta_0': 0.8712035762826104, 'beta_1': 0.9824226651073441, 'epsilon': 6.799175688880713e-05, 'balanced_loss': False, 'epochs': 126, 'early_stopping_patience': 25, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
CUDA out of memory. Tried to allocate 4.55 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.91 GiB is free. Including non-PyTorch memory, this process has 42.64 GiB memory in use. Of the allocated memory 38.84 GiB is allocated by PyTorch, and 2.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 19:53:08,373] Trial 295 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.8755475157662794, 'batch_size': 100, 'attention_heads': 14, 'hidden_dimension': 158, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5321874814448335, 'global_pooling': 'mean', 'learning_rate': 0.0001958976305706083, 'weight_decay': 0.00016619261302618123, 'beta_0': 0.8842480211528035, 'beta_1': 0.9835873235453799, 'epsilon': 4.447430376513099e-05, 'balanced_loss': False, 'epochs': 119, 'early_stopping_patience': 23, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
[I 2024-12-21 20:08:05,728] Trial 296 finished with value: 0.958455598241666 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9664418642844709, 'batch_size': 104, 'attention_heads': 15, 'hidden_dimension': 147, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35180124195986606, 'global_pooling': 'max', 'learning_rate': 0.0001314363985362543, 'weight_decay': 0.000508366668145095, 'beta_0': 0.8774699937558988, 'beta_1': 0.9820891224693984, 'epsilon': 5.330904115819515e-05, 'balanced_loss': False, 'epochs': 131, 'early_stopping_patience': 25, 'plateau_patience': 10, 'plateau_divider': 3}. Best is trial 240 with value: 0.9721836830431988.
slurmstepd: error: *** JOB 14130636 ON gpu003 CANCELLED AT 2024-12-21T20:09:26 DUE TO TIME LIMIT ***
