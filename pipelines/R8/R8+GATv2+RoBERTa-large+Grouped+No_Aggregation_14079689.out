Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2024-12-11 04:08:16,515] Using an existing study with name 'R8-GATv2-FacebookAI-roberta-large-Grouped-No_Aggregation' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors
[I 2024-12-11 04:16:54,263] Trial 212 finished with value: 0.9493036547975857 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8411119037602293, 'batch_size': 134, 'attention_heads': 5, 'hidden_dimension': 215, 'number_of_hidden_layers': 0, 'dropout_rate': 0.533886370454857, 'global_pooling': 'mean', 'learning_rate': 0.0010120392562747499, 'weight_decay': 2.4380003254969343e-05, 'beta_0': 0.8631722604168575, 'beta_1': 0.9916788716842597, 'epsilon': 2.8049111581289134e-06, 'balanced_loss': False, 'epochs': 189, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 04:25:27,623] Trial 213 finished with value: 0.9628644728276767 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8208705958601604, 'batch_size': 146, 'attention_heads': 5, 'hidden_dimension': 226, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5998087315924654, 'global_pooling': 'mean', 'learning_rate': 0.0008769178250557448, 'weight_decay': 3.857228960423926e-05, 'beta_0': 0.850238181789966, 'beta_1': 0.9902647209769553, 'epsilon': 2.521476778039595e-08, 'balanced_loss': False, 'epochs': 196, 'early_stopping_patience': 10, 'plateau_patience': 15, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 04:33:59,639] Trial 214 finished with value: 0.9517016765454042 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8223671211048146, 'batch_size': 146, 'attention_heads': 5, 'hidden_dimension': 227, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5691903947223881, 'global_pooling': 'mean', 'learning_rate': 0.0011732143468579882, 'weight_decay': 2.3670953792253516e-05, 'beta_0': 0.8599420558439946, 'beta_1': 0.9901655333086219, 'epsilon': 2.630310686831717e-08, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 10, 'plateau_patience': 15, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 04:42:56,010] Trial 215 finished with value: 0.9585462012876103 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8124557806791345, 'batch_size': 139, 'attention_heads': 5, 'hidden_dimension': 220, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5845811804541343, 'global_pooling': 'mean', 'learning_rate': 0.0008563039152604519, 'weight_decay': 3.48153312432644e-05, 'beta_0': 0.8449391388770224, 'beta_1': 0.9911817386490505, 'epsilon': 2.3940196737000523e-08, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 04:51:14,688] Trial 216 finished with value: 0.9414860590808574 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8319045957661587, 'batch_size': 143, 'attention_heads': 5, 'hidden_dimension': 225, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5147160774397008, 'global_pooling': 'mean', 'learning_rate': 0.0017115628547905107, 'weight_decay': 3.9814009329237966e-05, 'beta_0': 0.8505187124777637, 'beta_1': 0.9909403763345964, 'epsilon': 2.9506254545453693e-08, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 11, 'plateau_patience': 14, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 04:59:42,621] Trial 217 finished with value: 0.9592256693427577 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.820759309656237, 'batch_size': 147, 'attention_heads': 5, 'hidden_dimension': 221, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5250367755683549, 'global_pooling': 'mean', 'learning_rate': 0.000890851957298742, 'weight_decay': 1.4338884774974103e-05, 'beta_0': 0.8643397376493781, 'beta_1': 0.992125271991441, 'epsilon': 1.4440086316783604e-08, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 05:08:27,636] Trial 218 finished with value: 0.9473396063558257 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.802174099989393, 'batch_size': 132, 'attention_heads': 5, 'hidden_dimension': 212, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5992650166339437, 'global_pooling': 'mean', 'learning_rate': 0.0013846464493499303, 'weight_decay': 3.056057926466638e-05, 'beta_0': 0.8477122254065715, 'beta_1': 0.9905421240276486, 'epsilon': 2.1173222666817137e-08, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 05:16:58,170] Trial 219 finished with value: 0.9631237027704405 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8264419189074926, 'batch_size': 151, 'attention_heads': 4, 'hidden_dimension': 230, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5122396775346159, 'global_pooling': 'mean', 'learning_rate': 0.0007091760529201409, 'weight_decay': 2.0921065740773317e-05, 'beta_0': 0.8494589221251688, 'beta_1': 0.992845859789972, 'epsilon': 3.168495957046385e-08, 'balanced_loss': False, 'epochs': 189, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 05:25:17,624] Trial 220 finished with value: 0.9637593262387554 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8408709864152262, 'batch_size': 150, 'attention_heads': 4, 'hidden_dimension': 228, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5105889467336564, 'global_pooling': 'mean', 'learning_rate': 0.00048088451840596936, 'weight_decay': 2.336107405862116e-05, 'beta_0': 0.8540839338381649, 'beta_1': 0.9927504818219833, 'epsilon': 3.703873304793477e-08, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 05:33:46,011] Trial 221 finished with value: 0.9562350615825841 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.82801855500619, 'batch_size': 149, 'attention_heads': 4, 'hidden_dimension': 229, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5129851166150694, 'global_pooling': 'mean', 'learning_rate': 0.0004813692684196577, 'weight_decay': 2.3138556620375803e-05, 'beta_0': 0.8513459277460449, 'beta_1': 0.9928501043112167, 'epsilon': 4.234851326874258e-08, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 05:42:13,567] Trial 222 finished with value: 0.9587937944098142 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8342541943753018, 'batch_size': 142, 'attention_heads': 4, 'hidden_dimension': 218, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5818046806339354, 'global_pooling': 'mean', 'learning_rate': 0.0004304245330270456, 'weight_decay': 1.6152080567752337e-05, 'beta_0': 0.8541232833511154, 'beta_1': 0.9932705720644888, 'epsilon': 4.003693625258248e-08, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 05:50:33,060] Trial 223 finished with value: 0.9545190340477563 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.844211162559142, 'batch_size': 152, 'attention_heads': 4, 'hidden_dimension': 232, 'number_of_hidden_layers': 0, 'dropout_rate': 0.509634582627352, 'global_pooling': 'mean', 'learning_rate': 0.0006631596387985531, 'weight_decay': 2.0779339559522497e-05, 'beta_0': 0.8463395193905408, 'beta_1': 0.9923638146368047, 'epsilon': 3.610500150693789e-08, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 05:59:15,515] Trial 224 finished with value: 0.950172587204885 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8246601782092174, 'batch_size': 137, 'attention_heads': 4, 'hidden_dimension': 206, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5177544922147532, 'global_pooling': 'mean', 'learning_rate': 0.000515767999439901, 'weight_decay': 2.6919553275800125e-05, 'beta_0': 0.852162765282861, 'beta_1': 0.9935586700623233, 'epsilon': 3.163711031102083e-08, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 06:07:33,730] Trial 225 finished with value: 0.9596115638227141 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8398099219027243, 'batch_size': 145, 'attention_heads': 4, 'hidden_dimension': 229, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5261817914708564, 'global_pooling': 'mean', 'learning_rate': 0.0007295840706302154, 'weight_decay': 4.780383505739318e-05, 'beta_0': 0.8501112993965324, 'beta_1': 0.9925633275551993, 'epsilon': 2.5257503325700914e-08, 'balanced_loss': False, 'epochs': 118, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 06:16:28,523] Trial 226 finished with value: 0.956708382836694 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8295763724927268, 'batch_size': 52, 'attention_heads': 5, 'hidden_dimension': 213, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5115520333133294, 'global_pooling': 'mean', 'learning_rate': 0.000366397836741227, 'weight_decay': 2.2992533117238278e-05, 'beta_0': 0.8418242036273678, 'beta_1': 0.9902289218554555, 'epsilon': 4.711753480995767e-08, 'balanced_loss': False, 'epochs': 196, 'early_stopping_patience': 11, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 06:25:05,780] Trial 227 finished with value: 0.9470646095556909 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8220764463743725, 'batch_size': 153, 'attention_heads': 4, 'hidden_dimension': 224, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5297702494641787, 'global_pooling': 'mean', 'learning_rate': 0.0005255270202580598, 'weight_decay': 1.8657863023307496e-05, 'beta_0': 0.8518149565474709, 'beta_1': 0.9906782482253756, 'epsilon': 3.385719441000124e-08, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 06:33:49,697] Trial 228 finished with value: 0.9613862784787114 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8118444804976602, 'batch_size': 149, 'attention_heads': 4, 'hidden_dimension': 219, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5211529308935327, 'global_pooling': 'mean', 'learning_rate': 0.0007206314086878614, 'weight_decay': 2.660661879830438e-05, 'beta_0': 0.8485434223574966, 'beta_1': 0.9930242580783804, 'epsilon': 2.405485874119539e-05, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 10, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 06:52:39,913] Trial 229 finished with value: 0.929098236129684 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8106825220927842, 'batch_size': 148, 'attention_heads': 5, 'hidden_dimension': 219, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5199249256033136, 'global_pooling': 'mean', 'learning_rate': 2.677729565995597e-05, 'weight_decay': 2.1074139730245158e-05, 'beta_0': 0.8479633061381124, 'beta_1': 0.9942428393078292, 'epsilon': 3.2127982600617116e-05, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 07:01:15,493] Trial 230 finished with value: 0.9542978885881099 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8068145406589547, 'batch_size': 140, 'attention_heads': 4, 'hidden_dimension': 210, 'number_of_hidden_layers': 0, 'dropout_rate': 0.44434699224245405, 'global_pooling': 'mean', 'learning_rate': 0.0006616057901365653, 'weight_decay': 2.617453616530441e-05, 'beta_0': 0.8494535080251383, 'beta_1': 0.9931062397377495, 'epsilon': 2.716725067216207e-08, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 10, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 07:10:25,702] Trial 231 finished with value: 0.9589660961531616 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8149725085587473, 'batch_size': 150, 'attention_heads': 4, 'hidden_dimension': 224, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5118670952885184, 'global_pooling': 'mean', 'learning_rate': 0.00043280554645474173, 'weight_decay': 3.2313446837972345e-05, 'beta_0': 0.8556512194843904, 'beta_1': 0.992933561978463, 'epsilon': 3.3338191055742254e-08, 'balanced_loss': False, 'epochs': 126, 'early_stopping_patience': 10, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 07:19:03,281] Trial 232 finished with value: 0.9496477879217246 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8197266241739113, 'batch_size': 143, 'attention_heads': 5, 'hidden_dimension': 217, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5207893714173958, 'global_pooling': 'mean', 'learning_rate': 0.0005618407947879309, 'weight_decay': 1.60562100911162e-05, 'beta_0': 0.8480862708074928, 'beta_1': 0.9938900675431127, 'epsilon': 2.1881044304203383e-08, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 07:29:26,097] Trial 233 finished with value: 0.9626026225359301 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8377260103361149, 'batch_size': 154, 'attention_heads': 10, 'hidden_dimension': 227, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5274542369623132, 'global_pooling': 'mean', 'learning_rate': 0.0010419461771135263, 'weight_decay': 1.2254120622208541e-05, 'beta_0': 0.851164827261696, 'beta_1': 0.993409525341239, 'epsilon': 7.86031101449287e-06, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 12, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 07:39:39,295] Trial 234 finished with value: 0.9637316557047133 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.834253062109217, 'batch_size': 154, 'attention_heads': 10, 'hidden_dimension': 227, 'number_of_hidden_layers': 0, 'dropout_rate': 0.532369312426825, 'global_pooling': 'mean', 'learning_rate': 0.000756644687893657, 'weight_decay': 2.9217647671964442e-05, 'beta_0': 0.8520555497510647, 'beta_1': 0.993135846855054, 'epsilon': 9.819790704352507e-06, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 07:50:01,723] Trial 235 finished with value: 0.9616201905963249 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8350561162845229, 'batch_size': 156, 'attention_heads': 10, 'hidden_dimension': 232, 'number_of_hidden_layers': 0, 'dropout_rate': 0.536784482161286, 'global_pooling': 'mean', 'learning_rate': 0.0007468257635643206, 'weight_decay': 2.8638342512306233e-05, 'beta_0': 0.8528638114035452, 'beta_1': 0.9935683081579367, 'epsilon': 1.0378013429063798e-05, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 12, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 08:00:08,909] Trial 236 finished with value: 0.9519731508933902 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8471780405978737, 'batch_size': 154, 'attention_heads': 10, 'hidden_dimension': 231, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5401228482178796, 'global_pooling': 'mean', 'learning_rate': 0.0007646048343980331, 'weight_decay': 2.8992719151840674e-05, 'beta_0': 0.8503299707409145, 'beta_1': 0.9928408178634957, 'epsilon': 5.534632231942274e-06, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 12, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
CUDA out of memory. Tried to allocate 3.21 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.00 GiB is free. Including non-PyTorch memory, this process has 41.55 GiB memory in use. Of the allocated memory 35.98 GiB is allocated by PyTorch, and 4.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 08:08:06,590] Trial 237 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8367253398472476, 'batch_size': 155, 'attention_heads': 11, 'hidden_dimension': 226, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5370340312903947, 'global_pooling': 'mean', 'learning_rate': 0.0011488117393874122, 'weight_decay': 3.664435112593797e-05, 'beta_0': 0.8532028840059074, 'beta_1': 0.9932231989345782, 'epsilon': 9.88450963623801e-06, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 12, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 08:17:22,323] Trial 238 finished with value: 0.9583721477146095 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8338019361804022, 'batch_size': 151, 'attention_heads': 9, 'hidden_dimension': 232, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5524875768414697, 'global_pooling': 'mean', 'learning_rate': 0.000738962335088521, 'weight_decay': 1.3442493898991647e-05, 'beta_0': 0.8523437583807807, 'beta_1': 0.9937163477377491, 'epsilon': 1.3532104319622378e-05, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.44 GiB is free. Including non-PyTorch memory, this process has 42.11 GiB memory in use. Of the allocated memory 35.80 GiB is allocated by PyTorch, and 5.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 08:24:46,012] Trial 239 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8232452667481405, 'batch_size': 162, 'attention_heads': 10, 'hidden_dimension': 227, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5342743823677748, 'global_pooling': 'mean', 'learning_rate': 0.0010338286345845152, 'weight_decay': 2.9449299115778884e-05, 'beta_0': 0.849467204670335, 'beta_1': 0.9933097161496726, 'epsilon': 1.1036174947235173e-05, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 12, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 08:34:52,159] Trial 240 finished with value: 0.9551914191136996 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8289072104720154, 'batch_size': 147, 'attention_heads': 10, 'hidden_dimension': 222, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5226459042719561, 'global_pooling': 'mean', 'learning_rate': 0.00063885663759721, 'weight_decay': 2.5816651428262358e-05, 'beta_0': 0.8459589506617833, 'beta_1': 0.9924570280047401, 'epsilon': 9.077436304328554e-06, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 08:50:40,594] Trial 241 finished with value: 0.9306663897023479 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8471320305807314, 'batch_size': 155, 'attention_heads': 10, 'hidden_dimension': 233, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5310735771495854, 'global_pooling': 'sum', 'learning_rate': 0.0008185198700040251, 'weight_decay': 1.015354616720312e-05, 'beta_0': 0.8548496612360736, 'beta_1': 0.9934664603488147, 'epsilon': 1.4189000691468037e-05, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 12, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
CUDA out of memory. Tried to allocate 3.04 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.04 GiB is free. Including non-PyTorch memory, this process has 41.51 GiB memory in use. Of the allocated memory 36.80 GiB is allocated by PyTorch, and 3.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 08:58:35,998] Trial 242 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8184139679945827, 'batch_size': 149, 'attention_heads': 10, 'hidden_dimension': 228, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5436304648332941, 'global_pooling': 'mean', 'learning_rate': 0.0005244069673062707, 'weight_decay': 2.2026744318657373e-05, 'beta_0': 0.8517838963314988, 'beta_1': 0.9925033352577639, 'epsilon': 6.279121935351294e-06, 'balanced_loss': False, 'epochs': 193, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
CUDA out of memory. Tried to allocate 2.90 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.42 GiB is free. Including non-PyTorch memory, this process has 42.13 GiB memory in use. Of the allocated memory 35.11 GiB is allocated by PyTorch, and 5.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 09:06:00,414] Trial 243 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8280707417486224, 'batch_size': 143, 'attention_heads': 11, 'hidden_dimension': 221, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5264528727407322, 'global_pooling': 'mean', 'learning_rate': 0.0007251336830863542, 'weight_decay': 3.4327981166378123e-05, 'beta_0': 0.8480896057369678, 'beta_1': 0.9940896720009958, 'epsilon': 7.3931663929251834e-06, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 10, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 09:16:05,623] Trial 244 finished with value: 0.9576410721881274 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8361744656281075, 'batch_size': 152, 'attention_heads': 10, 'hidden_dimension': 216, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5314969541617115, 'global_pooling': 'mean', 'learning_rate': 0.0010275521034677413, 'weight_decay': 2.1067552200116352e-05, 'beta_0': 0.8439557845449286, 'beta_1': 0.9929752923891951, 'epsilon': 8.261098619082274e-06, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 12, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 09:26:26,988] Trial 245 finished with value: 0.9509594258893869 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8119027695852435, 'batch_size': 157, 'attention_heads': 13, 'hidden_dimension': 97, 'number_of_hidden_layers': 0, 'dropout_rate': 0.516505386699265, 'global_pooling': 'mean', 'learning_rate': 0.0004424989571792761, 'weight_decay': 4.3569168399706705e-05, 'beta_0': 0.8538480347048932, 'beta_1': 0.9920093479171298, 'epsilon': 2.3985127533700365e-05, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
CUDA out of memory. Tried to allocate 3.20 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.17 GiB is free. Including non-PyTorch memory, this process has 41.38 GiB memory in use. Of the allocated memory 36.90 GiB is allocated by PyTorch, and 3.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 09:33:58,654] Trial 246 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8245161870791639, 'batch_size': 146, 'attention_heads': 15, 'hidden_dimension': 233, 'number_of_hidden_layers': 0, 'dropout_rate': 0.523821110569792, 'global_pooling': 'mean', 'learning_rate': 0.0006078046370777617, 'weight_decay': 2.5253149693710712e-05, 'beta_0': 0.8506794308854757, 'beta_1': 0.9935013182141837, 'epsilon': 4.7072689291266554e-05, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 10, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 09:44:02,422] Trial 247 finished with value: 0.9409749692075149 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8326135102417689, 'batch_size': 151, 'attention_heads': 9, 'hidden_dimension': 108, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5297867321596061, 'global_pooling': 'mean', 'learning_rate': 0.0003613332896428751, 'weight_decay': 1.8600183703796168e-05, 'beta_0': 0.8548021468753987, 'beta_1': 0.9945284720282995, 'epsilon': 6.788694269908015e-05, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 11, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 09:54:49,916] Trial 248 finished with value: 0.954768883648151 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8408435650272622, 'batch_size': 141, 'attention_heads': 12, 'hidden_dimension': 226, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5388457256306721, 'global_pooling': 'mean', 'learning_rate': 0.0005109537809761092, 'weight_decay': 5.841784067393838e-05, 'beta_0': 0.856335881246305, 'beta_1': 0.9914421941218194, 'epsilon': 1.3278842594312999e-05, 'balanced_loss': False, 'epochs': 196, 'early_stopping_patience': 12, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
CUDA out of memory. Tried to allocate 5.78 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.16 GiB is free. Including non-PyTorch memory, this process has 42.39 GiB memory in use. Of the allocated memory 38.42 GiB is allocated by PyTorch, and 2.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 10:02:10,585] Trial 249 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.697830228005001, 'batch_size': 162, 'attention_heads': 16, 'hidden_dimension': 236, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5089323694852446, 'global_pooling': 'mean', 'learning_rate': 0.0008729829920302043, 'weight_decay': 2.763887035561737e-05, 'beta_0': 0.8528216732943027, 'beta_1': 0.9919454689228614, 'epsilon': 3.823425608702999e-06, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 10:12:03,724] Trial 250 finished with value: 0.9513664961425929 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8186589042930109, 'batch_size': 147, 'attention_heads': 10, 'hidden_dimension': 213, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4526369489599726, 'global_pooling': 'mean', 'learning_rate': 0.0007061672565021039, 'weight_decay': 1.2610363473658843e-05, 'beta_0': 0.8575411728783574, 'beta_1': 0.9927816735629096, 'epsilon': 2.2997948666366136e-05, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 11, 'plateau_patience': 14, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 10:22:28,262] Trial 251 finished with value: 0.9572721574270736 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8274921036047634, 'batch_size': 156, 'attention_heads': 10, 'hidden_dimension': 219, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5160180644143609, 'global_pooling': 'mean', 'learning_rate': 0.0012045204614767177, 'weight_decay': 2.9741305707191822e-05, 'beta_0': 0.8490256409052332, 'beta_1': 0.9876578600817761, 'epsilon': 1.9641882488832194e-05, 'balanced_loss': False, 'epochs': 97, 'early_stopping_patience': 12, 'plateau_patience': 15, 'plateau_divider': 9}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 10:31:38,996] Trial 252 finished with value: 0.9661686872140454 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8110509300375904, 'batch_size': 137, 'attention_heads': 4, 'hidden_dimension': 223, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5239377762965862, 'global_pooling': 'mean', 'learning_rate': 0.0005892648848959856, 'weight_decay': 2.2533741421467172e-05, 'beta_0': 0.8006453265052721, 'beta_1': 0.9922754835212381, 'epsilon': 1.0932864944608952e-05, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 10, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 10:42:05,766] Trial 253 finished with value: 0.9503797978770562 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8047757377770316, 'batch_size': 144, 'attention_heads': 4, 'hidden_dimension': 223, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5232866505032313, 'global_pooling': 'mean', 'learning_rate': 0.0005922636413790024, 'weight_decay': 2.1707139395126783e-05, 'beta_0': 0.8313035170962151, 'beta_1': 0.9926282639925593, 'epsilon': 5.159145003156855e-06, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 10, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 10:50:44,176] Trial 254 finished with value: 0.957778753978195 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.7980133970628003, 'batch_size': 152, 'attention_heads': 4, 'hidden_dimension': 229, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5202932012186428, 'global_pooling': 'mean', 'learning_rate': 0.0009582725280293416, 'weight_decay': 1.819017620383664e-05, 'beta_0': 0.8466947199562105, 'beta_1': 0.992214907379129, 'epsilon': 1.121121679494505e-05, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 10, 'plateau_patience': 25, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 10:59:16,845] Trial 255 finished with value: 0.963103227641068 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8137195065381313, 'batch_size': 138, 'attention_heads': 4, 'hidden_dimension': 226, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5891994959937706, 'global_pooling': 'mean', 'learning_rate': 0.00076967219453828, 'weight_decay': 2.3652901167068543e-05, 'beta_0': 0.8503887959833104, 'beta_1': 0.9913615541982544, 'epsilon': 7.068345177118445e-06, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 10, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 11:07:41,781] Trial 256 finished with value: 0.9571227431404354 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8194462418960585, 'batch_size': 140, 'attention_heads': 4, 'hidden_dimension': 236, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5938091348135718, 'global_pooling': 'mean', 'learning_rate': 0.0007899486085459321, 'weight_decay': 2.3013143392593767e-05, 'beta_0': 0.8100446473303126, 'beta_1': 0.9913610515111141, 'epsilon': 8.130759773480087e-06, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 11, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 11:15:55,403] Trial 257 finished with value: 0.9507892850614004 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8114621521128285, 'batch_size': 137, 'attention_heads': 4, 'hidden_dimension': 225, 'number_of_hidden_layers': 0, 'dropout_rate': 0.589620566319181, 'global_pooling': 'mean', 'learning_rate': 0.0005877313724076597, 'weight_decay': 2.021140765595159e-05, 'beta_0': 0.8513449517605629, 'beta_1': 0.9917342223276407, 'epsilon': 6.238790365038249e-06, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 10, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 11:24:36,473] Trial 258 finished with value: 0.9611977762553823 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8248267701980156, 'batch_size': 160, 'attention_heads': 4, 'hidden_dimension': 229, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5896745295247579, 'global_pooling': 'mean', 'learning_rate': 0.0004690767392294057, 'weight_decay': 1.542877842981892e-05, 'beta_0': 0.8071205908808688, 'beta_1': 0.9911729094386648, 'epsilon': 1.0774394153325156e-05, 'balanced_loss': False, 'epochs': 193, 'early_stopping_patience': 10, 'plateau_patience': 15, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 11:32:51,491] Trial 259 finished with value: 0.9527295808979914 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.837037418988373, 'batch_size': 135, 'attention_heads': 4, 'hidden_dimension': 223, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5950435077071053, 'global_pooling': 'mean', 'learning_rate': 0.00099444453093371, 'weight_decay': 3.36650166657323e-05, 'beta_0': 0.8575333157710789, 'beta_1': 0.9921028042402217, 'epsilon': 6.620427950318142e-06, 'balanced_loss': False, 'epochs': 131, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 11:40:53,781] Trial 260 finished with value: 0.9585097578485228 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8160181467912254, 'batch_size': 144, 'attention_heads': 4, 'hidden_dimension': 231, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5345949312775478, 'global_pooling': 'mean', 'learning_rate': 0.0013265325957516703, 'weight_decay': 0.0003032450545135842, 'beta_0': 0.8535220064215752, 'beta_1': 0.9902117864799072, 'epsilon': 9.089789160237806e-06, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 12, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 11:48:52,221] Trial 261 finished with value: 0.9486485127264055 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8497427785042929, 'batch_size': 79, 'attention_heads': 4, 'hidden_dimension': 234, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5123695356575668, 'global_pooling': 'mean', 'learning_rate': 0.0006339160134224526, 'weight_decay': 0.00036254083550309196, 'beta_0': 0.8589445711557249, 'beta_1': 0.9917321894265652, 'epsilon': 8.001318155460604e-06, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 11:56:47,858] Trial 262 finished with value: 0.9509864777925541 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8303178159614005, 'batch_size': 155, 'attention_heads': 4, 'hidden_dimension': 227, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5269813625831514, 'global_pooling': 'mean', 'learning_rate': 0.0008348491340112188, 'weight_decay': 2.4232673307711e-05, 'beta_0': 0.8264385088691609, 'beta_1': 0.9909865507662157, 'epsilon': 1.601781058363294e-05, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 10, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 12:05:45,533] Trial 263 finished with value: 0.9568634941201897 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8038787037560227, 'batch_size': 139, 'attention_heads': 4, 'hidden_dimension': 216, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5476086387964296, 'global_pooling': 'mean', 'learning_rate': 0.0004148301016814549, 'weight_decay': 3.733778336328957e-05, 'beta_0': 0.8512415980827994, 'beta_1': 0.9923728914148461, 'epsilon': 1.0839961174308752e-05, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 13, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 12:13:38,866] Trial 264 finished with value: 0.9531288222930991 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8233494385849781, 'batch_size': 147, 'attention_heads': 4, 'hidden_dimension': 223, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5390928598145983, 'global_pooling': 'mean', 'learning_rate': 0.0005322079047182783, 'weight_decay': 1.7037139784819133e-05, 'beta_0': 0.8544573085815336, 'beta_1': 0.9906839280703392, 'epsilon': 4.359435004544837e-06, 'balanced_loss': False, 'epochs': 154, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 12:21:54,066] Trial 265 finished with value: 0.9481292969217829 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.8420578310612203, 'batch_size': 165, 'attention_heads': 10, 'hidden_dimension': 144, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5156455069349551, 'global_pooling': 'mean', 'learning_rate': 0.002069507197952484, 'weight_decay': 0.00032209498098205805, 'beta_0': 0.86079524042538, 'beta_1': 0.9915207592113038, 'epsilon': 1.1751393737752899e-08, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 12:29:34,455] Trial 266 finished with value: 0.9393561051595669 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.832778536865488, 'batch_size': 133, 'attention_heads': 4, 'hidden_dimension': 164, 'number_of_hidden_layers': 0, 'dropout_rate': 0.558219556194587, 'global_pooling': 'mean', 'learning_rate': 0.0154033431805622, 'weight_decay': 2.3733205527101053e-05, 'beta_0': 0.8620380825905702, 'beta_1': 0.991301622401571, 'epsilon': 1.4853999962061136e-08, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 12, 'plateau_patience': 15, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
The selected strides are greater or equal to the total chunk size.
[I 2024-12-11 12:29:36,201] Trial 267 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8170894951411893, 'batch_size': 157, 'attention_heads': 11, 'hidden_dimension': 208, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5829947805973427, 'global_pooling': 'sum', 'learning_rate': 0.0010929596897241226, 'weight_decay': 9.258466235295282e-06, 'beta_0': 0.8499539302610435, 'beta_1': 0.989839721308376, 'epsilon': 9.404286849702801e-06, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 24, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 12:38:38,932] Trial 268 finished with value: 0.9437895407674549 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8105997503997658, 'batch_size': 151, 'attention_heads': 4, 'hidden_dimension': 236, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5997829620376143, 'global_pooling': 'mean', 'learning_rate': 0.000719862382202176, 'weight_decay': 0.00027682415320747183, 'beta_0': 0.8174850937100129, 'beta_1': 0.9922116593613174, 'epsilon': 1.298682317609665e-05, 'balanced_loss': True, 'epochs': 194, 'early_stopping_patience': 13, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 12:46:29,889] Trial 269 finished with value: 0.9532027986348024 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8233695271969439, 'batch_size': 144, 'attention_heads': 4, 'hidden_dimension': 230, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5309711594318093, 'global_pooling': 'mean', 'learning_rate': 0.0008541821796189394, 'weight_decay': 2.8747190398155566e-05, 'beta_0': 0.8763142550202473, 'beta_1': 0.991842735552588, 'epsilon': 3.7726365120518154e-07, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 10, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
CUDA out of memory. Tried to allocate 3.15 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.11 GiB is free. Including non-PyTorch memory, this process has 41.44 GiB memory in use. Of the allocated memory 35.64 GiB is allocated by PyTorch, and 4.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 12:53:49,686] Trial 270 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8392867114709281, 'batch_size': 256, 'attention_heads': 9, 'hidden_dimension': 219, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5082816669101116, 'global_pooling': 'mean', 'learning_rate': 0.0004750461992617736, 'weight_decay': 2.0915162660735283e-05, 'beta_0': 0.874734525059764, 'beta_1': 0.9932566990278022, 'epsilon': 2.1341094560122694e-08, 'balanced_loss': False, 'epochs': 188, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 2}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 13:01:40,799] Trial 271 finished with value: 0.9542825584384087 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.8316254539474791, 'batch_size': 160, 'attention_heads': 4, 'hidden_dimension': 129, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5239828831757882, 'global_pooling': 'mean', 'learning_rate': 0.0014739933777475726, 'weight_decay': 0.0003848613149148304, 'beta_0': 0.8563091790311739, 'beta_1': 0.9926147316490743, 'epsilon': 6.819660795103185e-06, 'balanced_loss': False, 'epochs': 193, 'early_stopping_patience': 10, 'plateau_patience': 15, 'plateau_divider': 9}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 13:09:46,049] Trial 272 finished with value: 0.9553444416273921 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8487967501211472, 'batch_size': 138, 'attention_heads': 4, 'hidden_dimension': 226, 'number_of_hidden_layers': 0, 'dropout_rate': 0.46348724906176, 'global_pooling': 'mean', 'learning_rate': 0.0006184421666813807, 'weight_decay': 0.0002340252074118573, 'beta_0': 0.8532869809847683, 'beta_1': 0.9903912824614367, 'epsilon': 1.4598878895954288e-08, 'balanced_loss': False, 'epochs': 145, 'early_stopping_patience': 12, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 13:17:53,552] Trial 273 finished with value: 0.9560122603607155 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8202081201870028, 'batch_size': 149, 'attention_heads': 4, 'hidden_dimension': 214, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4310077620774092, 'global_pooling': 'mean', 'learning_rate': 0.0003869461542305049, 'weight_decay': 1.792600862520386e-05, 'beta_0': 0.8498522343999201, 'beta_1': 0.9908818424054413, 'epsilon': 1.0247090473245802e-08, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 13, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 13:26:22,978] Trial 274 finished with value: 0.9468557168685265 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.7999625635132073, 'batch_size': 154, 'attention_heads': 4, 'hidden_dimension': 222, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5177938764796907, 'global_pooling': 'mean', 'learning_rate': 0.0009339798351274034, 'weight_decay': 1.1794049672116668e-05, 'beta_0': 0.8580255723121286, 'beta_1': 0.993907987819584, 'epsilon': 1.9231981193223446e-08, 'balanced_loss': False, 'epochs': 196, 'early_stopping_patience': 15, 'plateau_patience': 16, 'plateau_divider': 6}. Best is trial 176 with value: 0.9700233141517449.
CUDA out of memory. Tried to allocate 3.31 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.23 GiB is free. Including non-PyTorch memory, this process has 41.32 GiB memory in use. Of the allocated memory 35.63 GiB is allocated by PyTorch, and 4.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 13:34:47,809] Trial 275 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.8104562581414789, 'batch_size': 144, 'attention_heads': 11, 'hidden_dimension': 232, 'number_of_hidden_layers': 0, 'dropout_rate': 0.533133124485123, 'global_pooling': 'mean', 'learning_rate': 0.0005358021833123762, 'weight_decay': 2.5805259951563128e-05, 'beta_0': 0.8601371036524879, 'beta_1': 0.9915068096656158, 'epsilon': 2.6929480684087816e-08, 'balanced_loss': False, 'epochs': 192, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 13:42:34,841] Trial 276 finished with value: 0.946111201454779 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8263857821394228, 'batch_size': 148, 'attention_heads': 4, 'hidden_dimension': 152, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5279749205180575, 'global_pooling': 'mean', 'learning_rate': 0.0006894929189709525, 'weight_decay': 0.0002727082731199545, 'beta_0': 0.8009312234678304, 'beta_1': 0.9936086544493442, 'epsilon': 1.6406465442058575e-08, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 15, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 176 with value: 0.9700233141517449.
The selected strides are greater or equal to the total chunk size.
[I 2024-12-11 13:42:36,719] Trial 277 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8364653217939977, 'batch_size': 141, 'attention_heads': 4, 'hidden_dimension': 206, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5142782021565236, 'global_pooling': 'mean', 'learning_rate': 0.0011959316378705844, 'weight_decay': 3.1036159078513273e-05, 'beta_0': 0.8651648961921838, 'beta_1': 0.9871492296960995, 'epsilon': 7.900423975135328e-06, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 10, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 13:50:57,779] Trial 278 finished with value: 0.9565609597566527 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8167255904588099, 'batch_size': 154, 'attention_heads': 4, 'hidden_dimension': 212, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5361730927712729, 'global_pooling': 'mean', 'learning_rate': 0.00047198716842579804, 'weight_decay': 0.00034036603497902894, 'beta_0': 0.8713902641172844, 'beta_1': 0.988130004923811, 'epsilon': 1.209823746015233e-08, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 10, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 13:59:18,384] Trial 279 finished with value: 0.9576854551325824 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8269148464484557, 'batch_size': 163, 'attention_heads': 5, 'hidden_dimension': 228, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5231915895210326, 'global_pooling': 'mean', 'learning_rate': 0.0007854215141144183, 'weight_decay': 0.00020978545688313347, 'beta_0': 0.8620166986967907, 'beta_1': 0.9900631411564145, 'epsilon': 2.2252894536828455e-08, 'balanced_loss': False, 'epochs': 187, 'early_stopping_patience': 15, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 14:07:13,536] Trial 280 finished with value: 0.9553811247931684 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8433698908129585, 'batch_size': 158, 'attention_heads': 4, 'hidden_dimension': 236, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5073864507861456, 'global_pooling': 'mean', 'learning_rate': 0.0006077043304016365, 'weight_decay': 2.1281637063107923e-05, 'beta_0': 0.8885535231930015, 'beta_1': 0.9921202634203762, 'epsilon': 2.748574729731531e-08, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 11, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 14:17:30,386] Trial 281 finished with value: 0.9596392090059882 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.8051922682276456, 'batch_size': 130, 'attention_heads': 10, 'hidden_dimension': 218, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5451139059024497, 'global_pooling': 'mean', 'learning_rate': 0.0003166045287652944, 'weight_decay': 0.00041928541036533225, 'beta_0': 0.842348203278988, 'beta_1': 0.9928147404913081, 'epsilon': 1.1868528660608907e-05, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 12, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 14:26:21,468] Trial 282 finished with value: 0.968364726843591 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8328795154792151, 'batch_size': 151, 'attention_heads': 5, 'hidden_dimension': 224, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5264535758776044, 'global_pooling': 'mean', 'learning_rate': 0.001023361086347886, 'weight_decay': 0.00022989937429519593, 'beta_0': 0.85254120860706, 'beta_1': 0.9906971471498361, 'epsilon': 1.5217974145747642e-08, 'balanced_loss': False, 'epochs': 182, 'early_stopping_patience': 15, 'plateau_patience': 14, 'plateau_divider': 9}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 14:35:37,095] Trial 283 finished with value: 0.9542940067829511 and parameters: {'left_stride': 256, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8206472797039286, 'batch_size': 137, 'attention_heads': 5, 'hidden_dimension': 221, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5258799130356925, 'global_pooling': 'mean', 'learning_rate': 0.0010100948300858408, 'weight_decay': 0.00018516957252009473, 'beta_0': 0.8556103491014116, 'beta_1': 0.9906221145062042, 'epsilon': 1.4128883576372866e-08, 'balanced_loss': False, 'epochs': 185, 'early_stopping_patience': 15, 'plateau_patience': 14, 'plateau_divider': 8}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 14:44:05,704] Trial 284 finished with value: 0.9497374154309306 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8140152751467442, 'batch_size': 146, 'attention_heads': 5, 'hidden_dimension': 214, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5199220119835299, 'global_pooling': 'mean', 'learning_rate': 0.0016399076783923724, 'weight_decay': 0.00022985563321823002, 'beta_0': 0.8476983189640791, 'beta_1': 0.9911833628458833, 'epsilon': 1.7300270563499302e-08, 'balanced_loss': False, 'epochs': 181, 'early_stopping_patience': 15, 'plateau_patience': 14, 'plateau_divider': 9}. Best is trial 176 with value: 0.9700233141517449.
CUDA out of memory. Tried to allocate 3.50 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.38 GiB is free. Including non-PyTorch memory, this process has 41.17 GiB memory in use. Of the allocated memory 37.84 GiB is allocated by PyTorch, and 2.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 14:51:14,302] Trial 285 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.8305297480629694, 'batch_size': 151, 'attention_heads': 14, 'hidden_dimension': 210, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5135674497981474, 'global_pooling': 'mean', 'learning_rate': 0.0011868828584608584, 'weight_decay': 0.000252776565716872, 'beta_0': 0.8740251608306122, 'beta_1': 0.9909107430961804, 'epsilon': 1.2198399493846188e-08, 'balanced_loss': False, 'epochs': 177, 'early_stopping_patience': 15, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 176 with value: 0.9700233141517449.
[I 2024-12-11 15:01:27,642] Trial 286 finished with value: 0.9418127614600491 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.853410842934616, 'batch_size': 142, 'attention_heads': 5, 'hidden_dimension': 225, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5282700762211052, 'global_pooling': 'mean', 'learning_rate': 0.00040511061338246985, 'weight_decay': 0.0002973937093687418, 'beta_0': 0.8638729265477267, 'beta_1': 0.9903249122946881, 'epsilon': 1.950010207977097e-08, 'balanced_loss': True, 'epochs': 183, 'early_stopping_patience': 15, 'plateau_patience': 17, 'plateau_divider': 9}. Best is trial 176 with value: 0.9700233141517449.

[TRIAL] 176 [VALIDATION PERFORMANCE] 0.9700233141517449 [TRAINING LOSS] 0.017480957514510072 [VALIDATION LOSS] 0.14646670315414667 

number                                     176
value                                 0.970023
params_threshold                      0.837045
params_attention_heads                       4
params_balanced_loss                     False
params_embedding_pooling_operation         max
params_attention_pooling_operation         max
params_batch_size                          156
params_dropout_rate                   0.527537
params_early_stopping_patience              16
params_epochs                              198
params_global_pooling                     mean
params_hidden_dimension                    248
params_learning_rate                  0.000936
params_number_of_hidden_layers               0
params_plateau_divider                       6
params_plateau_patience                     15
params_weight_decay                   0.000186
params_beta_0                         0.865683
params_beta_1                         0.991509
params_epsilon                             0.0
user_attrs_epoch                          26.0
user_attrs_training_loss              0.017481
user_attrs_validation_loss            0.146467
params_left_stride                         256
params_right_stride                        128
Name: 176, dtype: object
37 Val: 0.9592675606335959 Test: 0.9298076350447635
38 Val: 0.9586854892220537 Test: 0.9251975379218521
39 Val: 0.9583476415361928 Test: 0.9371584956176439
40 Val: 0.9499045798768715 Test: 0.9311559215712077
41 Val: 0.9680936603718437 Test: 0.9326719149324854
42 Val: 0.9700233141517449 Test: 0.9353995076992707
43 Val: 0.9473718042761113 Test: 0.9388245414816554
44 Val: 0.9585145847228236 Test: 0.9417733540670128
45 Val: 0.9493594564373897 Test: 0.9415072309489975
46 Val: 0.9509561502851873 Test: 0.9439357063047145
Validation performance: 94.74 & 95.71  0.78 & 97.0
Testing performance: 92.52 & 93.57  0.6 & 94.39

[TRIAL] 282 [VALIDATION PERFORMANCE] 0.968364726843591 [TRAINING LOSS] 0.015378082334063948 [VALIDATION LOSS] 0.08390104374848306 

number                                     282
value                                 0.968365
params_threshold                       0.83288
params_attention_heads                       5
params_balanced_loss                     False
params_embedding_pooling_operation         max
params_attention_pooling_operation         max
params_batch_size                          151
params_dropout_rate                   0.526454
params_early_stopping_patience              15
params_epochs                              182
params_global_pooling                     mean
params_hidden_dimension                    224
params_learning_rate                  0.001023
params_number_of_hidden_layers               0
params_plateau_divider                       9
params_plateau_patience                     14
params_weight_decay                    0.00023
params_beta_0                         0.852541
params_beta_1                         0.990697
params_epsilon                             0.0
user_attrs_epoch                          27.0
user_attrs_training_loss              0.015378
user_attrs_validation_loss            0.083901
params_left_stride                         128
params_right_stride                        256
Name: 282, dtype: object
37 Val: 0.9545907264698761 Test: 0.9298442819459372
38 Val: 0.9444372993603923 Test: 0.9360385636880699
39 Val: 0.9620767069029639 Test: 0.9327596541832969
40 Val: 0.9595571144646073 Test: 0.9381569659370099
41 Val: 0.9571682422951364 Test: 0.9432047601823133
42 Val: 0.9658937367873306 Test: 0.9455400938716163
43 Val: 0.949540448765346 Test: 0.9320437653771462
44 Val: 0.9580147106460573 Test: 0.929795060426847
45 Val: 0.9560623260445167 Test: 0.9441146286568272
46 Val: 0.9549223858211509 Test: 0.9433843971887694
Validation performance: 94.44 & 95.62  0.61 & 96.59
Testing performance: 92.98 & 93.75  0.62 & 94.55

[TRIAL] 203 [VALIDATION PERFORMANCE] 0.9680285518954118 [TRAINING LOSS] 0.016695953985868858 [VALIDATION LOSS] 0.061668121750699356 

number                                     203
value                                 0.968029
params_threshold                      0.824086
params_attention_heads                       5
params_balanced_loss                     False
params_embedding_pooling_operation         max
params_attention_pooling_operation         max
params_batch_size                          152
params_dropout_rate                   0.524441
params_early_stopping_patience              11
params_epochs                              200
params_global_pooling                     mean
params_hidden_dimension                    208
params_learning_rate                   0.00054
params_number_of_hidden_layers               0
params_plateau_divider                       7
params_plateau_patience                     15
params_weight_decay                   0.000023
params_beta_0                         0.860175
params_beta_1                         0.992234
params_epsilon                             0.0
user_attrs_epoch                          31.0
user_attrs_training_loss              0.016696
user_attrs_validation_loss            0.061668
params_left_stride                         128
params_right_stride                        128
Name: 203, dtype: object
37 Val: 0.96183115888353 Test: 0.949820757981749
38 Val: 0.9588795159029062 Test: 0.9321428812380972
39 Val: 0.9639284888693093 Test: 0.9425281692662122
40 Val: 0.9566849549931912 Test: 0.9419944866793264
41 Val: 0.9501799475626335 Test: 0.9429306660217689
42 Val: 0.9677252977979087 Test: 0.9390737862122925
43 Val: 0.9520994129650703 Test: 0.9430423749366215
44 Val: 0.9636175502137063 Test: 0.9378929408696424
45 Val: 0.9554934334099747 Test: 0.9342168971548395
46 Val: 0.9600714566927974 Test: 0.9324583751061064
Validation performance: 95.02 & 95.91  0.55 & 96.77
Testing performance: 93.21 & 93.96  0.56 & 94.98

[TRIAL] 194 [VALIDATION PERFORMANCE] 0.9675793853364614 [TRAINING LOSS] 0.018185605897150677 [VALIDATION LOSS] 0.055000690641463734 

number                                     194
value                                 0.967579
params_threshold                      0.813108
params_attention_heads                       4
params_balanced_loss                     False
params_embedding_pooling_operation         max
params_attention_pooling_operation         max
params_batch_size                          156
params_dropout_rate                   0.523942
params_early_stopping_patience              15
params_epochs                              195
params_global_pooling                     mean
params_hidden_dimension                    213
params_learning_rate                  0.000558
params_number_of_hidden_layers               0
params_plateau_divider                       8
params_plateau_patience                     15
params_weight_decay                   0.000274
params_beta_0                         0.864579
params_beta_1                         0.991912
params_epsilon                             0.0
user_attrs_epoch                          31.0
user_attrs_training_loss              0.018186
user_attrs_validation_loss            0.055001
params_left_stride                         128
params_right_stride                        128
Name: 194, dtype: object
37 Val: 0.9581915099376732 Test: 0.9333259546824995
38 Val: 0.9636288719674299 Test: 0.94247156924541
39 Val: 0.9610442976171631 Test: 0.9519390044409662
40 Val: 0.9526367790669105 Test: 0.9404558134401476
41 Val: 0.9567375168453713 Test: 0.9424922706589852
slurmstepd: error: *** JOB 14079689 ON gpu027 CANCELLED AT 2024-12-11T20:08:12 DUE TO TIME LIMIT ***
