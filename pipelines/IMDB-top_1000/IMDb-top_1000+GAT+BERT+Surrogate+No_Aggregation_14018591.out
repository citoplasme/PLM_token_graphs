[I 2024-11-27 04:43:43,852] Using an existing study with name 'IMDb-top_1000-GAT-google-bert-bert-base-uncased-Surrogate-No_Aggregation' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 512). Running this sequence through the model will result in indexing errors
[I 2024-11-27 04:55:32,650] Trial 294 finished with value: 0.9151515151515152 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9780522996676335, 'batch_size': 60, 'attention_heads': 4, 'hidden_dimension': 109, 'number_of_hidden_layers': 4, 'dropout_rate': 0.42351060617772124, 'global_pooling': 'mean', 'learning_rate': 0.0007643014450127017, 'weight_decay': 8.268731048567056e-05, 'beta_0': 0.8162366093132454, 'beta_1': 0.9967720215834959, 'epsilon': 6.872132782423338e-08, 'balanced_loss': False, 'epochs': 180, 'early_stopping_patience': 22, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 05:11:39,441] Trial 295 finished with value: 0.9090909090909091 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.97658781390596, 'batch_size': 59, 'attention_heads': 4, 'hidden_dimension': 81, 'number_of_hidden_layers': 4, 'dropout_rate': 0.41188264234946015, 'global_pooling': 'mean', 'learning_rate': 0.0009283864707102933, 'weight_decay': 2.2584967348618406e-06, 'beta_0': 0.8690494858170321, 'beta_1': 0.9821094518512538, 'epsilon': 9.285911195368361e-08, 'balanced_loss': False, 'epochs': 185, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 05:28:33,487] Trial 296 finished with value: 0.9212121212121213 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9807166804233554, 'batch_size': 61, 'attention_heads': 4, 'hidden_dimension': 100, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5485056013407421, 'global_pooling': 'mean', 'learning_rate': 0.001756640230468072, 'weight_decay': 1.7579881559582501e-06, 'beta_0': 0.8775830132529113, 'beta_1': 0.9971857540391478, 'epsilon': 4.158120608425374e-08, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 24, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 05:46:09,385] Trial 297 finished with value: 0.9030303030303031 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9702830544418072, 'batch_size': 63, 'attention_heads': 4, 'hidden_dimension': 93, 'number_of_hidden_layers': 4, 'dropout_rate': 0.55258941975626, 'global_pooling': 'mean', 'learning_rate': 0.0016198182934751635, 'weight_decay': 2.9278400338051914e-05, 'beta_0': 0.8750347183451396, 'beta_1': 0.9969972202040568, 'epsilon': 5.862714476346575e-08, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 24, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 06:03:21,315] Trial 298 finished with value: 0.8848484848484849 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9805899157781313, 'batch_size': 61, 'attention_heads': 4, 'hidden_dimension': 98, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5519949557039898, 'global_pooling': 'mean', 'learning_rate': 0.002214135942104532, 'weight_decay': 2.7850901775472884e-06, 'beta_0': 0.8859048594347487, 'beta_1': 0.9961035664881057, 'epsilon': 4.815637501534974e-08, 'balanced_loss': True, 'epochs': 189, 'early_stopping_patience': 24, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 06:25:17,009] Trial 299 finished with value: 0.8666666666666667 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9757060633806635, 'batch_size': 37, 'attention_heads': 4, 'hidden_dimension': 101, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5080459067280787, 'global_pooling': 'max', 'learning_rate': 0.00240439098794187, 'weight_decay': 1.7146445195762997e-06, 'beta_0': 0.8826034213958812, 'beta_1': 0.9967398103453268, 'epsilon': 3.952727319037837e-06, 'balanced_loss': False, 'epochs': 193, 'early_stopping_patience': 24, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 06:42:41,267] Trial 300 finished with value: 0.9090909090909091 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9795569976632634, 'batch_size': 60, 'attention_heads': 4, 'hidden_dimension': 87, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5937546123665083, 'global_pooling': 'mean', 'learning_rate': 0.001609568011629312, 'weight_decay': 1.5672116404665842e-06, 'beta_0': 0.8695188196582279, 'beta_1': 0.9974086844484471, 'epsilon': 4.1626352810085646e-08, 'balanced_loss': False, 'epochs': 198, 'early_stopping_patience': 24, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 07:00:03,898] Trial 301 finished with value: 0.9151515151515152 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9819485973420372, 'batch_size': 63, 'attention_heads': 4, 'hidden_dimension': 104, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5481487189181725, 'global_pooling': 'mean', 'learning_rate': 0.0012148324328292942, 'weight_decay': 1.763296072923318e-05, 'beta_0': 0.8755024565877508, 'beta_1': 0.9971146546928253, 'epsilon': 3.5246106190412905e-08, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 22, 'plateau_patience': 18, 'plateau_divider': 2}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 07:11:59,356] Trial 302 finished with value: 0.9030303030303031 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9863580283642729, 'batch_size': 64, 'attention_heads': 4, 'hidden_dimension': 94, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5583667166436254, 'global_pooling': 'mean', 'learning_rate': 0.0019224338958952242, 'weight_decay': 2.0545622720307487e-06, 'beta_0': 0.8906540551379536, 'beta_1': 0.9966272465180722, 'epsilon': 7.869719697746937e-08, 'balanced_loss': False, 'epochs': 186, 'early_stopping_patience': 25, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 07:32:09,760] Trial 303 finished with value: 0.896969696969697 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9779924329060414, 'batch_size': 61, 'attention_heads': 4, 'hidden_dimension': 99, 'number_of_hidden_layers': 4, 'dropout_rate': 0.444627300379802, 'global_pooling': 'mean', 'learning_rate': 0.0002762628692332118, 'weight_decay': 3.448827800783155e-05, 'beta_0': 0.8132222795846638, 'beta_1': 0.9975369565670339, 'epsilon': 9.854524839581189e-08, 'balanced_loss': False, 'epochs': 140, 'early_stopping_patience': 21, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.42 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.54 GiB is free. Including non-PyTorch memory, this process has 40.02 GiB memory in use. Of the allocated memory 32.79 GiB is allocated by PyTorch, and 6.08 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-27 07:41:46,780] Trial 304 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9732109939157253, 'batch_size': 58, 'attention_heads': 14, 'hidden_dimension': 105, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4983691528427562, 'global_pooling': 'mean', 'learning_rate': 0.0004179350228478003, 'weight_decay': 1.1705654654535686e-06, 'beta_0': 0.8820558668368089, 'beta_1': 0.9971958362319804, 'epsilon': 2.1557230138771213e-07, 'balanced_loss': False, 'epochs': 194, 'early_stopping_patience': 24, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 08:01:24,720] Trial 305 finished with value: 0.8909090909090909 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9799500044711206, 'batch_size': 62, 'attention_heads': 4, 'hidden_dimension': 109, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5161740687930947, 'global_pooling': 'mean', 'learning_rate': 0.000579762219568829, 'weight_decay': 2.4487582931667253e-06, 'beta_0': 0.808615025466867, 'beta_1': 0.9956427471657764, 'epsilon': 1.4921870363059376e-07, 'balanced_loss': False, 'epochs': 159, 'early_stopping_patience': 22, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 08:20:15,149] Trial 306 finished with value: 0.9212121212121213 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9813152517591687, 'batch_size': 64, 'attention_heads': 4, 'hidden_dimension': 103, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5616372717451735, 'global_pooling': 'mean', 'learning_rate': 0.0007099797381210962, 'weight_decay': 1.7562589484474987e-06, 'beta_0': 0.880359577392255, 'beta_1': 0.9977299997494227, 'epsilon': 1.1142212310032152e-07, 'balanced_loss': False, 'epochs': 183, 'early_stopping_patience': 22, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 08:37:24,263] Trial 307 finished with value: 0.9090909090909091 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9820898507318231, 'batch_size': 64, 'attention_heads': 4, 'hidden_dimension': 101, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5681721352370732, 'global_pooling': 'mean', 'learning_rate': 0.0004887915748809615, 'weight_decay': 1.7361029396875923e-06, 'beta_0': 0.8786516477678189, 'beta_1': 0.9977288741371059, 'epsilon': 1.1053270789523317e-07, 'balanced_loss': False, 'epochs': 184, 'early_stopping_patience': 21, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 175 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 2.06 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.41 GiB is free. Including non-PyTorch memory, this process has 43.14 GiB memory in use. Of the allocated memory 38.76 GiB is allocated by PyTorch, and 3.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-27 08:50:35,904] Trial 308 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9866788930463556, 'batch_size': 63, 'attention_heads': 4, 'hidden_dimension': 250, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5018228292925784, 'global_pooling': 'mean', 'learning_rate': 0.0006814705120254222, 'weight_decay': 1.416890499901873e-06, 'beta_0': 0.8498921631733914, 'beta_1': 0.9975748643171707, 'epsilon': 8.942750009290138e-08, 'balanced_loss': False, 'epochs': 181, 'early_stopping_patience': 22, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 09:05:14,164] Trial 309 finished with value: 0.8909090909090909 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.98399312307423, 'batch_size': 64, 'attention_heads': 4, 'hidden_dimension': 105, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5825675195025107, 'global_pooling': 'mean', 'learning_rate': 0.0006949600992719611, 'weight_decay': 1.964527558357153e-06, 'beta_0': 0.8963755691475884, 'beta_1': 0.9970966012165687, 'epsilon': 1.6916239060817013e-07, 'balanced_loss': True, 'epochs': 188, 'early_stopping_patience': 10, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 09:19:27,017] Trial 310 finished with value: 0.8484848484848485 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9937924185674287, 'batch_size': 62, 'attention_heads': 4, 'hidden_dimension': 97, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5402294105536571, 'global_pooling': 'sum', 'learning_rate': 0.0010155013144542227, 'weight_decay': 1.6258710876294865e-06, 'beta_0': 0.8430154557433817, 'beta_1': 0.9885347168008545, 'epsilon': 1.192697964853731e-07, 'balanced_loss': False, 'epochs': 183, 'early_stopping_patience': 22, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 09:34:55,825] Trial 311 finished with value: 0.8909090909090909 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9911502403587905, 'batch_size': 63, 'attention_heads': 4, 'hidden_dimension': 108, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5718252510198417, 'global_pooling': 'mean', 'learning_rate': 0.0005398931244458411, 'weight_decay': 2.3175318506037888e-06, 'beta_0': 0.8813114887276342, 'beta_1': 0.9979621252342044, 'epsilon': 6.696447974992225e-08, 'balanced_loss': False, 'epochs': 179, 'early_stopping_patience': 21, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 09:51:11,405] Trial 312 finished with value: 0.9151515151515152 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.981959811831703, 'batch_size': 62, 'attention_heads': 4, 'hidden_dimension': 103, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5567084879114326, 'global_pooling': 'mean', 'learning_rate': 0.000793743531416325, 'weight_decay': 1.3552346859770302e-06, 'beta_0': 0.8799135601333158, 'beta_1': 0.9974150446791848, 'epsilon': 1.4143934986950528e-07, 'balanced_loss': False, 'epochs': 99, 'early_stopping_patience': 22, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 10:06:07,377] Trial 313 finished with value: 0.9090909090909091 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9853204493315708, 'batch_size': 64, 'attention_heads': 4, 'hidden_dimension': 111, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5432785802080428, 'global_pooling': 'mean', 'learning_rate': 0.001357695124482358, 'weight_decay': 1.811718791534422e-06, 'beta_0': 0.8836959998912282, 'beta_1': 0.9980950363785647, 'epsilon': 8.065741823587847e-08, 'balanced_loss': False, 'epochs': 197, 'early_stopping_patience': 22, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 10:22:43,287] Trial 314 finished with value: 0.9151515151515152 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9881536388040526, 'batch_size': 60, 'attention_heads': 4, 'hidden_dimension': 116, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5778693289456123, 'global_pooling': 'mean', 'learning_rate': 0.0006468987819072005, 'weight_decay': 2.0612331565717174e-06, 'beta_0': 0.8764594597251848, 'beta_1': 0.9977160455751443, 'epsilon': 5.315871136244621e-08, 'balanced_loss': False, 'epochs': 186, 'early_stopping_patience': 22, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 6.11 GiB. GPU 0 has a total capacity of 44.56 GiB of which 5.14 GiB is free. Including non-PyTorch memory, this process has 39.41 GiB memory in use. Of the allocated memory 35.48 GiB is allocated by PyTorch, and 2.79 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-27 10:35:52,256] Trial 315 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.917470197352656, 'batch_size': 61, 'attention_heads': 4, 'hidden_dimension': 128, 'number_of_hidden_layers': 4, 'dropout_rate': 0.566083096151042, 'global_pooling': 'mean', 'learning_rate': 0.0004731082974309452, 'weight_decay': 1.5168974287508678e-06, 'beta_0': 0.8784805702833025, 'beta_1': 0.9968108982704583, 'epsilon': 1.1158236389936479e-07, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 21, 'plateau_patience': 16, 'plateau_divider': 6}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 10:49:41,181] Trial 316 finished with value: 0.8484848484848485 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9989986461791637, 'batch_size': 63, 'attention_heads': 5, 'hidden_dimension': 95, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5107626875398127, 'global_pooling': 'mean', 'learning_rate': 0.0010280522115114024, 'weight_decay': 0.00018182898402034452, 'beta_0': 0.8107586254703358, 'beta_1': 0.9982225515957781, 'epsilon': 1.8607696716718304e-07, 'balanced_loss': False, 'epochs': 178, 'early_stopping_patience': 25, 'plateau_patience': 17, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 11:04:24,533] Trial 317 finished with value: 0.8909090909090909 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9770248139119113, 'batch_size': 26, 'attention_heads': 4, 'hidden_dimension': 101, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5211357033222995, 'global_pooling': 'mean', 'learning_rate': 0.0007645530127290415, 'weight_decay': 1.7485548965948134e-06, 'beta_0': 0.89986087646536, 'beta_1': 0.9972669706241791, 'epsilon': 9.612629673566587e-08, 'balanced_loss': False, 'epochs': 82, 'early_stopping_patience': 24, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.22 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 41.70 GiB memory in use. Of the allocated memory 37.49 GiB is allocated by PyTorch, and 3.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-27 11:21:12,136] Trial 318 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9798391644224409, 'batch_size': 59, 'attention_heads': 13, 'hidden_dimension': 107, 'number_of_hidden_layers': 4, 'dropout_rate': 0.45557343631743374, 'global_pooling': 'mean', 'learning_rate': 0.0005849617745124912, 'weight_decay': 2.875196709201429e-06, 'beta_0': 0.8137600763455144, 'beta_1': 0.9977359884432663, 'epsilon': 1.270248047497951e-07, 'balanced_loss': False, 'epochs': 182, 'early_stopping_patience': 23, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 11:38:12,144] Trial 319 finished with value: 0.9030303030303031 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9839167221108506, 'batch_size': 62, 'attention_heads': 5, 'hidden_dimension': 123, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5627828182812189, 'global_pooling': 'mean', 'learning_rate': 0.0008633168012341483, 'weight_decay': 1.28628202733889e-06, 'beta_0': 0.8806966147802151, 'beta_1': 0.9964382705215686, 'epsilon': 1.541131944155545e-07, 'balanced_loss': False, 'epochs': 167, 'early_stopping_patience': 22, 'plateau_patience': 19, 'plateau_divider': 2}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 11:55:46,413] Trial 320 finished with value: 0.896969696969697 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9812853368729472, 'batch_size': 63, 'attention_heads': 5, 'hidden_dimension': 112, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4316514398941671, 'global_pooling': 'mean', 'learning_rate': 0.0003858721446108756, 'weight_decay': 2.1198194293129453e-06, 'beta_0': 0.809047115455748, 'beta_1': 0.9981446771859995, 'epsilon': 7.04256793862357e-08, 'balanced_loss': True, 'epochs': 189, 'early_stopping_patience': 22, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 12:11:31,903] Trial 321 finished with value: 0.9151515151515152 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.97859659326795, 'batch_size': 64, 'attention_heads': 4, 'hidden_dimension': 117, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4952103242710187, 'global_pooling': 'mean', 'learning_rate': 0.0012693659995583946, 'weight_decay': 1.5700995965615829e-06, 'beta_0': 0.8724683442464038, 'beta_1': 0.9969626405300774, 'epsilon': 8.561557364029701e-08, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 23, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 12:28:00,997] Trial 322 finished with value: 0.9090909090909091 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9852368167747295, 'batch_size': 61, 'attention_heads': 5, 'hidden_dimension': 131, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4614713963947409, 'global_pooling': 'mean', 'learning_rate': 0.0018453421663306333, 'weight_decay': 3.3149584524899616e-06, 'beta_0': 0.812162157033151, 'beta_1': 0.9974579227255523, 'epsilon': 1.005833038390223e-07, 'balanced_loss': False, 'epochs': 184, 'early_stopping_patience': 22, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 12:43:31,778] Trial 323 finished with value: 0.8545454545454545 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9832149827596314, 'batch_size': 63, 'attention_heads': 4, 'hidden_dimension': 107, 'number_of_hidden_layers': 4, 'dropout_rate': 0.50823837631057, 'global_pooling': 'max', 'learning_rate': 0.000664700019951829, 'weight_decay': 1.9084903819122534e-06, 'beta_0': 0.8198555423024743, 'beta_1': 0.9977977636715903, 'epsilon': 1.3511931413746668e-07, 'balanced_loss': False, 'epochs': 177, 'early_stopping_patience': 25, 'plateau_patience': 14, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 12:58:01,269] Trial 324 finished with value: 0.8787878787878788 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9869955908332605, 'batch_size': 62, 'attention_heads': 4, 'hidden_dimension': 98, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5259882760302146, 'global_pooling': 'mean', 'learning_rate': 0.0010478351522134211, 'weight_decay': 2.6355397995873666e-06, 'beta_0': 0.8740979300385454, 'beta_1': 0.9982789597178703, 'epsilon': 2.466286693595684e-07, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 175 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 1.98 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 42.60 GiB memory in use. Of the allocated memory 40.08 GiB is allocated by PyTorch, and 1.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-27 13:13:02,520] Trial 325 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9755714531531143, 'batch_size': 61, 'attention_heads': 5, 'hidden_dimension': 103, 'number_of_hidden_layers': 4, 'dropout_rate': 0.44903910490132154, 'global_pooling': 'mean', 'learning_rate': 0.0008556273364163687, 'weight_decay': 1.182936331817442e-06, 'beta_0': 0.8642227043850166, 'beta_1': 0.9972486126648208, 'epsilon': 1.1625213284801785e-07, 'balanced_loss': False, 'epochs': 186, 'early_stopping_patience': 18, 'plateau_patience': 17, 'plateau_divider': 7}. Best is trial 175 with value: 0.9333333333333333.
[I 2024-11-27 13:27:16,479] Trial 326 finished with value: 0.8606060606060606 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9961765404322552, 'batch_size': 64, 'attention_heads': 4, 'hidden_dimension': 112, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5037955645103246, 'global_pooling': 'mean', 'learning_rate': 0.000502938149234608, 'weight_decay': 4.145237252594533e-06, 'beta_0': 0.8078771111622628, 'beta_1': 0.9979554765997963, 'epsilon': 1.665599901772696e-07, 'balanced_loss': False, 'epochs': 170, 'early_stopping_patience': 21, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 175 with value: 0.9333333333333333.

[TRIAL] 175 [VALIDATION PERFORMANCE] 0.9333333333333333 [TRAINING LOSS] 0.11042248550802469 [VALIDATION LOSS] 0.2618548596898715 

number                                     175
value                                 0.933333
params_threshold                      0.983794
params_attention_heads                       5
params_balanced_loss                     False
params_embedding_pooling_operation         max
params_attention_pooling_operation        mean
params_batch_size                           63
params_dropout_rate                   0.505874
params_early_stopping_patience              22
params_epochs                              189
params_global_pooling                     mean
params_hidden_dimension                    105
params_learning_rate                  0.000713
params_number_of_hidden_layers               4
params_plateau_divider                       7
params_plateau_patience                     16
params_weight_decay                   0.000002
params_beta_0                         0.810369
params_beta_1                         0.997473
params_epsilon                             0.0
user_attrs_epoch                          24.0
user_attrs_training_loss              0.110422
user_attrs_validation_loss            0.261855
params_left_stride                           0
params_right_stride                         64
Name: 175, dtype: object
37 Val: 0.9151515151515152 Test: 0.9194029850746268
38 Val: 0.9090909090909091 Test: 0.9253731343283582
39 Val: 0.9090909090909091 Test: 0.9134328358208955
40 Val: 0.9212121212121213 Test: 0.9283582089552239
41 Val: 0.9151515151515152 Test: 0.9283582089552239
42 Val: 0.9333333333333333 Test: 0.9134328358208955
43 Val: 0.9272727272727272 Test: 0.9223880597014925
44 Val: 0.9212121212121213 Test: 0.9283582089552239
45 Val: 0.9030303030303031 Test: 0.9253731343283582
46 Val: 0.9393939393939394 Test: 0.9343283582089552
Validation performance: 90.3 & 91.94 ± 1.14 & 93.94
Testing performance: 91.34 & 92.39 ± 0.68 & 93.43

[TRIAL] 194 [VALIDATION PERFORMANCE] 0.9272727272727272 [TRAINING LOSS] 0.025543327352756426 [VALIDATION LOSS] 0.23380364974339804 

number                                     194
value                                 0.927273
params_threshold                      0.977746
params_attention_heads                       5
params_balanced_loss                     False
params_embedding_pooling_operation         max
params_attention_pooling_operation        mean
params_batch_size                           61
params_dropout_rate                   0.470491
params_early_stopping_patience              21
params_epochs                              196
params_global_pooling                     mean
params_hidden_dimension                    103
params_learning_rate                  0.000898
params_number_of_hidden_layers               4
params_plateau_divider                       7
params_plateau_patience                     17
params_weight_decay                   0.000002
params_beta_0                         0.812537
params_beta_1                         0.997444
params_epsilon                             0.0
user_attrs_epoch                          34.0
user_attrs_training_loss              0.025543
user_attrs_validation_loss            0.233804
params_left_stride                           0
params_right_stride                         64
Name: 194, dtype: object
37 Val: 0.9090909090909091 Test: 0.9194029850746268
38 Val: 0.9090909090909091 Test: 0.9343283582089552
39 Val: 0.9030303030303031 Test: 0.9343283582089552
40 Val: 0.9151515151515152 Test: 0.9343283582089552
41 Val: 0.9212121212121213 Test: 0.9164179104477612
42 Val: 0.9212121212121213 Test: 0.9223880597014925
43 Val: 0.9212121212121213 Test: 0.9343283582089552
44 Val: 0.9030303030303031 Test: 0.9253731343283582
45 Val: 0.896969696969697 Test: 0.9373134328358209
46 Val: 0.9030303030303031 Test: 0.9194029850746268
Validation performance: 89.7 & 91.03 ± 0.89 & 92.12
Testing performance: 91.64 & 92.78 ± 0.79 & 93.73

[TRIAL] 170 [VALIDATION PERFORMANCE] 0.9272727272727272 [TRAINING LOSS] 0.037434700527228415 [VALIDATION LOSS] 0.2622981245319049 

number                                     170
value                                 0.927273
params_threshold                      0.982942
params_attention_heads                       5
params_balanced_loss                     False
params_embedding_pooling_operation         max
params_attention_pooling_operation        mean
params_batch_size                           63
params_dropout_rate                   0.490556
params_early_stopping_patience              23
params_epochs                              187
params_global_pooling                     mean
params_hidden_dimension                    108
params_learning_rate                  0.000694
params_number_of_hidden_layers               4
params_plateau_divider                       7
params_plateau_patience                     16
params_weight_decay                   0.000001
params_beta_0                         0.807806
params_beta_1                         0.997502
params_epsilon                             0.0
user_attrs_epoch                          39.0
user_attrs_training_loss              0.037435
user_attrs_validation_loss            0.262298
params_left_stride                           0
params_right_stride                         64
Name: 170, dtype: object
37 Val: 0.9090909090909091 Test: 0.9283582089552239
38 Val: 0.9030303030303031 Test: 0.9223880597014925
39 Val: 0.9212121212121213 Test: 0.9283582089552239
40 Val: 0.9030303030303031 Test: 0.9283582089552239
41 Val: 0.9030303030303031 Test: 0.9194029850746268
42 Val: 0.9272727272727272 Test: 0.9253731343283582
43 Val: 0.9272727272727272 Test: 0.9343283582089552
44 Val: 0.9393939393939394 Test: 0.9283582089552239
45 Val: 0.896969696969697 Test: 0.9283582089552239
46 Val: 0.896969696969697 Test: 0.9223880597014925
Validation performance: 89.7 & 91.27 ± 1.49 & 93.94
Testing performance: 91.94 & 92.66 ± 0.43 & 93.43

[TRIAL] 210 [VALIDATION PERFORMANCE] 0.9272727272727272 [TRAINING LOSS] 0.10834544814295238 [VALIDATION LOSS] 0.2712324857711792 

number                                     210
value                                 0.927273
params_threshold                      0.981614
params_attention_heads                       4
params_balanced_loss                     False
params_embedding_pooling_operation         max
params_attention_pooling_operation        mean
params_batch_size                           61
params_dropout_rate                   0.464936
params_early_stopping_patience              23
params_epochs                              122
params_global_pooling                     mean
params_hidden_dimension                    117
params_learning_rate                  0.000952
params_number_of_hidden_layers               4
params_plateau_divider                       6
params_plateau_patience                     15
params_weight_decay                   0.000001
params_beta_0                         0.806309
params_beta_1                          0.99895
params_epsilon                             0.0
user_attrs_epoch                          21.0
user_attrs_training_loss              0.108345
user_attrs_validation_loss            0.271232
params_left_stride                           0
params_right_stride                         64
Name: 210, dtype: object
37 Val: 0.9030303030303031 Test: 0.9134328358208955
38 Val: 0.9212121212121213 Test: 0.9313432835820895
39 Val: 0.9151515151515152 Test: 0.9313432835820895
40 Val: 0.9151515151515152 Test: 0.9283582089552239
41 Val: 0.9151515151515152 Test: 0.9343283582089552
42 Val: 0.9212121212121213 Test: 0.9074626865671642
43 Val: 0.9151515151515152 Test: 0.9313432835820895
44 Val: 0.9151515151515152 Test: 0.9283582089552239
45 Val: 0.9030303030303031 Test: 0.9044776119402985
46 Val: 0.9030303030303031 Test: 0.9283582089552239
Validation performance: 90.3 & 91.27 ± 0.71 & 92.12
Testing performance: 90.45 & 92.39 ± 1.1 & 93.43

[TRIAL] 174 [VALIDATION PERFORMANCE] 0.9272727272727272 [TRAINING LOSS] 0.10288691334426403 [VALIDATION LOSS] 0.2845950424671173 

number                                     174
value                                 0.927273
params_threshold                      0.983297
params_attention_heads                       5
params_balanced_loss                     False
params_embedding_pooling_operation         max
params_attention_pooling_operation        mean
params_batch_size                           63
params_dropout_rate                   0.504308
params_early_stopping_patience              22
params_epochs                              188
params_global_pooling                     mean
params_hidden_dimension                    109
params_learning_rate                  0.000689
params_number_of_hidden_layers               4
params_plateau_divider                       7
params_plateau_patience                     16
params_weight_decay                   0.000002
params_beta_0                         0.809093
params_beta_1                         0.997524
params_epsilon                             0.0
user_attrs_epoch                          26.0
user_attrs_training_loss              0.102887
user_attrs_validation_loss            0.284595
params_left_stride                           0
params_right_stride                         64
Name: 174, dtype: object
37 Val: 0.9090909090909091 Test: 0.9253731343283582
38 Val: 0.9151515151515152 Test: 0.9253731343283582
39 Val: 0.9090909090909091 Test: 0.9253731343283582
40 Val: 0.9151515151515152 Test: 0.9253731343283582
41 Val: 0.9212121212121213 Test: 0.9164179104477612
42 Val: 0.9151515151515152 Test: 0.9134328358208955
43 Val: 0.9090909090909091 Test: 0.9194029850746268
44 Val: 0.9030303030303031 Test: 0.9253731343283582
45 Val: 0.8909090909090909 Test: 0.9223880597014925
46 Val: 0.9151515151515152 Test: 0.9283582089552239
Validation performance: 89.09 & 91.03 ± 0.85 & 92.12
Testing performance: 91.34 & 92.27 ± 0.48 & 92.84

[IMDb-top_1000] Elapsed time: 1342.8277762850125 minutes.
