[I 2024-12-11 04:08:37,509] Using an existing study with name 'IMDb-top_1000-GATv2-facebook-bart-large-Grouped-No_Aggregation' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 1024). Running this sequence through the model will result in indexing errors
CUDA out of memory. Tried to allocate 2.75 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.31 GiB is free. Including non-PyTorch memory, this process has 42.24 GiB memory in use. Of the allocated memory 34.63 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 04:16:14,176] Trial 212 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9595238204045079, 'batch_size': 57, 'attention_heads': 16, 'hidden_dimension': 83, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5104481200641404, 'global_pooling': 'mean', 'learning_rate': 0.0007905659062659199, 'weight_decay': 2.3719498163424135e-05, 'beta_0': 0.881566510757618, 'beta_1': 0.9839933995735881, 'epsilon': 8.722722517864948e-08, 'balanced_loss': False, 'epochs': 111, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 04:26:04,852] Trial 213 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9643661880254489, 'batch_size': 61, 'attention_heads': 16, 'hidden_dimension': 78, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5274132010550485, 'global_pooling': 'mean', 'learning_rate': 0.000672605827295215, 'weight_decay': 0.0003986503370915924, 'beta_0': 0.8708081804240217, 'beta_1': 0.9804862645169218, 'epsilon': 6.366431997352735e-08, 'balanced_loss': False, 'epochs': 119, 'early_stopping_patience': 20, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 04:35:58,787] Trial 214 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9632924765385099, 'batch_size': 62, 'attention_heads': 16, 'hidden_dimension': 74, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5260278035166372, 'global_pooling': 'mean', 'learning_rate': 0.0008913698296164244, 'weight_decay': 0.00040736154682181387, 'beta_0': 0.8718667772348129, 'beta_1': 0.9805372660029762, 'epsilon': 6.740929887157301e-08, 'balanced_loss': False, 'epochs': 115, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 04:45:52,882] Trial 215 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9656403968043108, 'batch_size': 64, 'attention_heads': 16, 'hidden_dimension': 78, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5685553325613628, 'global_pooling': 'mean', 'learning_rate': 0.00045199335527111855, 'weight_decay': 0.00045731357633269635, 'beta_0': 0.8749945649118419, 'beta_1': 0.9810254517626147, 'epsilon': 7.844942394077934e-08, 'balanced_loss': False, 'epochs': 124, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 4.14 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.23 GiB is free. Including non-PyTorch memory, this process has 41.32 GiB memory in use. Of the allocated memory 36.21 GiB is allocated by PyTorch, and 3.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 04:53:31,765] Trial 216 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9700259652771251, 'batch_size': 61, 'attention_heads': 16, 'hidden_dimension': 157, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5184014115045295, 'global_pooling': 'mean', 'learning_rate': 0.000650246404570007, 'weight_decay': 0.0005870035343923921, 'beta_0': 0.8776907128677652, 'beta_1': 0.9818795155813367, 'epsilon': 2.9553488911755016e-08, 'balanced_loss': False, 'epochs': 117, 'early_stopping_patience': 21, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 05:03:06,002] Trial 217 finished with value: 0.9454545454545454 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9614668003645309, 'batch_size': 59, 'attention_heads': 15, 'hidden_dimension': 68, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5314822008316396, 'global_pooling': 'mean', 'learning_rate': 0.0009501576786373489, 'weight_decay': 0.00025591455514090047, 'beta_0': 0.8743730363215904, 'beta_1': 0.9804768235572681, 'epsilon': 4.378516510594298e-08, 'balanced_loss': False, 'epochs': 121, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 4}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.98 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.03 GiB is free. Including non-PyTorch memory, this process has 42.53 GiB memory in use. Of the allocated memory 37.73 GiB is allocated by PyTorch, and 3.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 05:10:41,188] Trial 218 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9533482139338268, 'batch_size': 60, 'attention_heads': 16, 'hidden_dimension': 74, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5478082349324089, 'global_pooling': 'sum', 'learning_rate': 0.0014959217562830322, 'weight_decay': 0.0003028014732585558, 'beta_0': 0.8785677033074953, 'beta_1': 0.9824178476266208, 'epsilon': 2.1899574306341768e-08, 'balanced_loss': False, 'epochs': 108, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 05:19:12,824] Trial 219 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9674269060928371, 'batch_size': 59, 'attention_heads': 15, 'hidden_dimension': 40, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5271613631932953, 'global_pooling': 'mean', 'learning_rate': 0.0007330047329049429, 'weight_decay': 0.00034618380835292357, 'beta_0': 0.8841491547908092, 'beta_1': 0.9813578717665962, 'epsilon': 1.5574483490923845e-08, 'balanced_loss': False, 'epochs': 112, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.16 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.15 GiB is free. Including non-PyTorch memory, this process has 42.40 GiB memory in use. Of the allocated memory 36.93 GiB is allocated by PyTorch, and 4.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 05:26:39,188] Trial 220 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9570112995630066, 'batch_size': 58, 'attention_heads': 16, 'hidden_dimension': 58, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5217648985895834, 'global_pooling': 'mean', 'learning_rate': 0.0011144890836759897, 'weight_decay': 0.000482513879626307, 'beta_0': 0.8804200697305182, 'beta_1': 0.9808239561087251, 'epsilon': 3.7303100256149757e-08, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 19, 'plateau_patience': 12, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 05:36:03,183] Trial 221 finished with value: 0.9454545454545454 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9637375731449547, 'batch_size': 61, 'attention_heads': 15, 'hidden_dimension': 64, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5356731723490409, 'global_pooling': 'mean', 'learning_rate': 0.0017865187171488101, 'weight_decay': 4.900970546154203e-06, 'beta_0': 0.8686360238243833, 'beta_1': 0.9827494073800556, 'epsilon': 1.0455558424786696e-07, 'balanced_loss': False, 'epochs': 132, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.80 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.56 GiB is free. Including non-PyTorch memory, this process has 41.99 GiB memory in use. Of the allocated memory 34.16 GiB is allocated by PyTorch, and 6.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 05:43:46,766] Trial 222 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9654029909546452, 'batch_size': 63, 'attention_heads': 16, 'hidden_dimension': 82, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5592948734203834, 'global_pooling': 'mean', 'learning_rate': 0.09285939748894982, 'weight_decay': 0.0006906558928207316, 'beta_0': 0.8766304002259616, 'beta_1': 0.9815589848004623, 'epsilon': 2.3856029412303275e-05, 'balanced_loss': False, 'epochs': 119, 'early_stopping_patience': 21, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 05:53:04,079] Trial 223 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9610642290575254, 'batch_size': 55, 'attention_heads': 15, 'hidden_dimension': 61, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5406505278349786, 'global_pooling': 'mean', 'learning_rate': 0.0007540547511409401, 'weight_decay': 0.000596878780369717, 'beta_0': 0.8815845150870076, 'beta_1': 0.9826321823151208, 'epsilon': 6.038802862386324e-08, 'balanced_loss': False, 'epochs': 126, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 06:02:13,843] Trial 224 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9601695488285488, 'batch_size': 56, 'attention_heads': 15, 'hidden_dimension': 53, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5449507061845076, 'global_pooling': 'mean', 'learning_rate': 0.000550845438623507, 'weight_decay': 0.0005359198738674148, 'beta_0': 0.8802355663211061, 'beta_1': 0.9834797868588412, 'epsilon': 4.311532809815805e-08, 'balanced_loss': False, 'epochs': 129, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 06:11:04,339] Trial 225 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9623887682698145, 'batch_size': 34, 'attention_heads': 14, 'hidden_dimension': 59, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5525258477566442, 'global_pooling': 'mean', 'learning_rate': 0.0008405136036030292, 'weight_decay': 0.0008204213439114805, 'beta_0': 0.8784268413597002, 'beta_1': 0.9821697450617198, 'epsilon': 6.898092203255712e-08, 'balanced_loss': False, 'epochs': 123, 'early_stopping_patience': 17, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 06:20:16,508] Trial 226 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9677490804365446, 'batch_size': 54, 'attention_heads': 15, 'hidden_dimension': 70, 'number_of_hidden_layers': 1, 'dropout_rate': 0.542017776162608, 'global_pooling': 'mean', 'learning_rate': 0.0010130259726743673, 'weight_decay': 0.0005371803437301516, 'beta_0': 0.8826460185666446, 'beta_1': 0.9825781163859427, 'epsilon': 4.995261374575529e-08, 'balanced_loss': False, 'epochs': 127, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.31 GiB. GPU 0 has a total capacity of 44.56 GiB of which 656.69 MiB is free. Including non-PyTorch memory, this process has 43.91 GiB memory in use. Of the allocated memory 37.42 GiB is allocated by PyTorch, and 5.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 06:27:45,817] Trial 227 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9506567359987721, 'batch_size': 58, 'attention_heads': 12, 'hidden_dimension': 77, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5314425868530133, 'global_pooling': 'mean', 'learning_rate': 0.0006693214079483737, 'weight_decay': 0.0004252138035137438, 'beta_0': 0.8748637680086367, 'beta_1': 0.9829954926848213, 'epsilon': 2.5598195766636423e-08, 'balanced_loss': False, 'epochs': 122, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 06:36:51,563] Trial 228 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9642071851746647, 'batch_size': 25, 'attention_heads': 15, 'hidden_dimension': 66, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5161831922225372, 'global_pooling': 'mean', 'learning_rate': 0.0008279286126660223, 'weight_decay': 3.356534119689505e-05, 'beta_0': 0.8729260089776444, 'beta_1': 0.9800887270898019, 'epsilon': 1.9389991700221267e-08, 'balanced_loss': False, 'epochs': 117, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.84 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.60 GiB is free. Including non-PyTorch memory, this process has 41.95 GiB memory in use. Of the allocated memory 35.13 GiB is allocated by PyTorch, and 5.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 06:46:56,060] Trial 229 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9614058796017246, 'batch_size': 53, 'attention_heads': 16, 'hidden_dimension': 87, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5388807225175871, 'global_pooling': 'mean', 'learning_rate': 0.0012422416883490957, 'weight_decay': 0.0003726021809777484, 'beta_0': 0.8773006823733078, 'beta_1': 0.9819388712387401, 'epsilon': 5.1417924459191324e-08, 'balanced_loss': False, 'epochs': 125, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 06:55:47,635] Trial 230 finished with value: 0.9393939393939394 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9727879549134466, 'batch_size': 62, 'attention_heads': 16, 'hidden_dimension': 49, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5235446360432651, 'global_pooling': 'mean', 'learning_rate': 0.00040176030259826104, 'weight_decay': 0.00048763683220135, 'beta_0': 0.8813628216905748, 'beta_1': 0.981040244290613, 'epsilon': 3.2969475118012467e-08, 'balanced_loss': False, 'epochs': 120, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 07:05:57,636] Trial 231 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9582489846425546, 'batch_size': 53, 'attention_heads': 16, 'hidden_dimension': 73, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5323253557161086, 'global_pooling': 'mean', 'learning_rate': 0.0005555513932253871, 'weight_decay': 0.0002852351389467018, 'beta_0': 0.8712792542633957, 'beta_1': 0.9807331249460409, 'epsilon': 4.3240026664218366e-08, 'balanced_loss': False, 'epochs': 133, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 07:15:38,700] Trial 232 finished with value: 0.9454545454545454 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9656680007919125, 'batch_size': 57, 'attention_heads': 15, 'hidden_dimension': 63, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5778693289456123, 'global_pooling': 'mean', 'learning_rate': 0.001019517238340347, 'weight_decay': 0.0006710241682789308, 'beta_0': 0.887072942971786, 'beta_1': 0.989503259861639, 'epsilon': 5.08636552754972e-05, 'balanced_loss': False, 'epochs': 115, 'early_stopping_patience': 17, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 07:25:35,789] Trial 233 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9712183110011404, 'batch_size': 63, 'attention_heads': 15, 'hidden_dimension': 98, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5495120461691267, 'global_pooling': 'mean', 'learning_rate': 0.0018617170860832607, 'weight_decay': 0.00040756984342523345, 'beta_0': 0.8778234740073907, 'beta_1': 0.981637283256797, 'epsilon': 2.9772975457727952e-08, 'balanced_loss': False, 'epochs': 110, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 07:35:20,108] Trial 234 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9699689958832275, 'batch_size': 62, 'attention_heads': 15, 'hidden_dimension': 69, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5538297369567352, 'global_pooling': 'mean', 'learning_rate': 0.0024324248537146314, 'weight_decay': 4.655374601839933e-05, 'beta_0': 0.8759636660654787, 'beta_1': 0.9816637146859231, 'epsilon': 2.5422796146669585e-08, 'balanced_loss': False, 'epochs': 106, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 07:45:19,730] Trial 235 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9685548668327595, 'batch_size': 60, 'attention_heads': 15, 'hidden_dimension': 93, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5647097865791494, 'global_pooling': 'mean', 'learning_rate': 0.0015965920470719373, 'weight_decay': 0.00042051965971780047, 'beta_0': 0.8795635416340499, 'beta_1': 0.9849145985574246, 'epsilon': 2.096165323922487e-08, 'balanced_loss': False, 'epochs': 128, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 3.03 GiB. GPU 0 has a total capacity of 44.56 GiB of which 986.69 MiB is free. Including non-PyTorch memory, this process has 43.59 GiB memory in use. Of the allocated memory 35.88 GiB is allocated by PyTorch, and 6.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 07:52:59,453] Trial 236 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9665426004384261, 'batch_size': 63, 'attention_heads': 15, 'hidden_dimension': 99, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5481249132850271, 'global_pooling': 'mean', 'learning_rate': 0.0013224052926392176, 'weight_decay': 0.00032279955201218935, 'beta_0': 0.8760675025296848, 'beta_1': 0.9811990521295989, 'epsilon': 2.7108528259794914e-08, 'balanced_loss': False, 'epochs': 112, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 08:02:53,970] Trial 237 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9632334393302641, 'batch_size': 61, 'attention_heads': 14, 'hidden_dimension': 91, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5417828606045679, 'global_pooling': 'mean', 'learning_rate': 0.001789554483228507, 'weight_decay': 5.7922253182633205e-06, 'beta_0': 0.8774988253924269, 'beta_1': 0.9822774560809474, 'epsilon': 1.6417366627324223e-08, 'balanced_loss': False, 'epochs': 123, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 08:13:01,796] Trial 238 finished with value: 0.9151515151515152 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9643718988269235, 'batch_size': 59, 'attention_heads': 16, 'hidden_dimension': 84, 'number_of_hidden_layers': 1, 'dropout_rate': 0.535242527304624, 'global_pooling': 'max', 'learning_rate': 0.0008376533257156276, 'weight_decay': 0.0005612679195414303, 'beta_0': 0.8841301159513387, 'beta_1': 0.9814782196995894, 'epsilon': 8.36962417462814e-08, 'balanced_loss': False, 'epochs': 105, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 08:22:33,966] Trial 239 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9710406900158262, 'batch_size': 64, 'attention_heads': 16, 'hidden_dimension': 76, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5716633578690405, 'global_pooling': 'mean', 'learning_rate': 0.001498458108086722, 'weight_decay': 0.0003749378718374058, 'beta_0': 0.8801430685582462, 'beta_1': 0.9832746846757643, 'epsilon': 4.0110067620678756e-08, 'balanced_loss': False, 'epochs': 101, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 08:31:10,859] Trial 240 finished with value: 0.9393939393939394 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.968593627754419, 'batch_size': 60, 'attention_heads': 15, 'hidden_dimension': 58, 'number_of_hidden_layers': 1, 'dropout_rate': 0.527143206267825, 'global_pooling': 'mean', 'learning_rate': 0.0011826772533681095, 'weight_decay': 0.00024533006488790547, 'beta_0': 0.8738308167533814, 'beta_1': 0.9806967483171618, 'epsilon': 2.300341094003988e-08, 'balanced_loss': False, 'epochs': 107, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 4.93 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.62 GiB is free. Including non-PyTorch memory, this process has 42.93 GiB memory in use. Of the allocated memory 36.96 GiB is allocated by PyTorch, and 4.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 08:38:40,742] Trial 241 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9598214404515418, 'batch_size': 57, 'attention_heads': 15, 'hidden_dimension': 164, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5593463564116712, 'global_pooling': 'mean', 'learning_rate': 0.003287316144174488, 'weight_decay': 0.00045477462835252644, 'beta_0': 0.8814394979751982, 'beta_1': 0.9819055865311986, 'epsilon': 2.948331341000904e-08, 'balanced_loss': False, 'epochs': 180, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 08:47:45,243] Trial 242 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9767239325927864, 'batch_size': 56, 'attention_heads': 16, 'hidden_dimension': 67, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5212781397089875, 'global_pooling': 'mean', 'learning_rate': 0.0006943918682246144, 'weight_decay': 4.688649437985157e-06, 'beta_0': 0.8784884891280287, 'beta_1': 0.9811418981993032, 'epsilon': 5.4009483294507535e-08, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 08:57:35,342] Trial 243 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9635838897996913, 'batch_size': 60, 'attention_heads': 15, 'hidden_dimension': 76, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5655965637314951, 'global_pooling': 'mean', 'learning_rate': 0.0011925425233324225, 'weight_decay': 0.0003410870955878911, 'beta_0': 0.8732652784031129, 'beta_1': 0.982362308764509, 'epsilon': 7.444162521551744e-08, 'balanced_loss': False, 'epochs': 109, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 09:07:25,110] Trial 244 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9661250260886851, 'batch_size': 59, 'attention_heads': 15, 'hidden_dimension': 80, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5595789649710243, 'global_pooling': 'mean', 'learning_rate': 0.0009653184350325463, 'weight_decay': 0.0002981988937950921, 'beta_0': 0.8748196260431688, 'beta_1': 0.9828785243363584, 'epsilon': 7.35082542889959e-08, 'balanced_loss': False, 'epochs': 117, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 09:17:14,132] Trial 245 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9620361073645192, 'batch_size': 58, 'attention_heads': 15, 'hidden_dimension': 73, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5468912707295128, 'global_pooling': 'mean', 'learning_rate': 0.0014700471808761827, 'weight_decay': 9.232950685494453e-05, 'beta_0': 0.8764523239371412, 'beta_1': 0.9824343203101145, 'epsilon': 1.0076704951912215e-07, 'balanced_loss': False, 'epochs': 113, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.74 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.11 GiB is free. Including non-PyTorch memory, this process has 42.44 GiB memory in use. Of the allocated memory 33.81 GiB is allocated by PyTorch, and 7.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 09:25:00,214] Trial 246 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.964468888110894, 'batch_size': 61, 'attention_heads': 15, 'hidden_dimension': 85, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5518564546930637, 'global_pooling': 'mean', 'learning_rate': 0.0011332646303468432, 'weight_decay': 0.0003373045548515629, 'beta_0': 0.8718396962575841, 'beta_1': 0.9817078791276613, 'epsilon': 8.170578950050565e-08, 'balanced_loss': False, 'epochs': 124, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 4}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 09:34:33,810] Trial 247 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9671075934419378, 'batch_size': 59, 'attention_heads': 16, 'hidden_dimension': 76, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5297928989358435, 'global_pooling': 'mean', 'learning_rate': 0.002168983416507246, 'weight_decay': 0.0002235050456771021, 'beta_0': 0.8736805386725246, 'beta_1': 0.9813622113113099, 'epsilon': 1.8197620224204668e-08, 'balanced_loss': False, 'epochs': 121, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 09:44:32,385] Trial 248 finished with value: 0.9454545454545454 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9642601179421088, 'batch_size': 58, 'attention_heads': 16, 'hidden_dimension': 71, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3788756712891915, 'global_pooling': 'mean', 'learning_rate': 0.0008220841020900664, 'weight_decay': 0.0003896246930045752, 'beta_0': 0.8788124932824071, 'beta_1': 0.9808634333866825, 'epsilon': 5.945814255157786e-08, 'balanced_loss': False, 'epochs': 97, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 4.23 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.66 GiB is free. Including non-PyTorch memory, this process has 42.90 GiB memory in use. Of the allocated memory 33.74 GiB is allocated by PyTorch, and 8.01 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 09:52:11,830] Trial 249 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.913664803275008, 'batch_size': 62, 'attention_heads': 14, 'hidden_dimension': 63, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5140450706648577, 'global_pooling': 'mean', 'learning_rate': 0.0006466124557307002, 'weight_decay': 0.0002932326282265823, 'beta_0': 0.8695497027496061, 'beta_1': 0.9803645191798989, 'epsilon': 1.1872022686836766e-07, 'balanced_loss': False, 'epochs': 110, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.96 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.66 GiB is free. Including non-PyTorch memory, this process has 42.89 GiB memory in use. Of the allocated memory 36.17 GiB is allocated by PyTorch, and 5.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 10:02:23,623] Trial 250 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9609657468101126, 'batch_size': 59, 'attention_heads': 15, 'hidden_dimension': 96, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5870044742590134, 'global_pooling': 'mean', 'learning_rate': 0.0009562626695047199, 'weight_decay': 0.0004933692838707788, 'beta_0': 0.876120792734674, 'beta_1': 0.9820414077509326, 'epsilon': 1.4570951820822212e-08, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 20, 'plateau_patience': 11, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 10:11:52,820] Trial 251 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9665080393954875, 'batch_size': 60, 'attention_heads': 15, 'hidden_dimension': 80, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5354500734216787, 'global_pooling': 'mean', 'learning_rate': 0.001775173863827589, 'weight_decay': 6.282459843356561e-06, 'beta_0': 0.8818985473358536, 'beta_1': 0.9891005511826327, 'epsilon': 3.337217285252151e-08, 'balanced_loss': False, 'epochs': 151, 'early_stopping_patience': 20, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 10:21:20,662] Trial 252 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9627070568810442, 'batch_size': 23, 'attention_heads': 16, 'hidden_dimension': 68, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5596145950450753, 'global_pooling': 'mean', 'learning_rate': 0.0014394764694722617, 'weight_decay': 0.00033441366998258697, 'beta_0': 0.8777217288490392, 'beta_1': 0.9942870832838394, 'epsilon': 7.23926841051565e-08, 'balanced_loss': False, 'epochs': 119, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 4.16 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.86 GiB is free. Including non-PyTorch memory, this process has 42.69 GiB memory in use. Of the allocated memory 36.97 GiB is allocated by PyTorch, and 4.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 10:29:04,978] Trial 253 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9654217257081606, 'batch_size': 57, 'attention_heads': 15, 'hidden_dimension': 156, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5415655865700167, 'global_pooling': 'mean', 'learning_rate': 0.0012124368763457394, 'weight_decay': 0.000583395803586148, 'beta_0': 0.8799211629491, 'beta_1': 0.9827210742785549, 'epsilon': 9.130635409335482e-08, 'balanced_loss': False, 'epochs': 116, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 10:39:27,890] Trial 254 finished with value: 0.9333333333333333 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9690976816368989, 'batch_size': 63, 'attention_heads': 16, 'hidden_dimension': 73, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5724294582379996, 'global_pooling': 'sum', 'learning_rate': 0.0007649255135188406, 'weight_decay': 0.0004302943499308998, 'beta_0': 0.8749510227458127, 'beta_1': 0.983157114319312, 'epsilon': 6.825188752659235e-05, 'balanced_loss': False, 'epochs': 130, 'early_stopping_patience': 21, 'plateau_patience': 12, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 10:49:05,340] Trial 255 finished with value: 0.9454545454545454 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9629629487788851, 'batch_size': 61, 'attention_heads': 15, 'hidden_dimension': 55, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5258068787589611, 'global_pooling': 'mean', 'learning_rate': 0.0005198393866620247, 'weight_decay': 0.00048543888121264955, 'beta_0': 0.8833721108981013, 'beta_1': 0.982438180015549, 'epsilon': 2.1684349497962447e-08, 'balanced_loss': False, 'epochs': 126, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 10:58:27,041] Trial 256 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9552311596740746, 'batch_size': 56, 'attention_heads': 16, 'hidden_dimension': 61, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5551387691266038, 'global_pooling': 'mean', 'learning_rate': 0.0009468155925167009, 'weight_decay': 0.0002622526900825462, 'beta_0': 0.8732869519965659, 'beta_1': 0.9841643612332848, 'epsilon': 1.809303953335357e-07, 'balanced_loss': False, 'epochs': 113, 'early_stopping_patience': 15, 'plateau_patience': 21, 'plateau_divider': 4}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 11:08:26,177] Trial 257 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9595927341812869, 'batch_size': 59, 'attention_heads': 15, 'hidden_dimension': 77, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5655986467566352, 'global_pooling': 'mean', 'learning_rate': 0.0005910336111323427, 'weight_decay': 0.00018517868757974396, 'beta_0': 0.8854166212999833, 'beta_1': 0.9804563803699238, 'epsilon': 2.6025759854866804e-08, 'balanced_loss': False, 'epochs': 121, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 11:18:38,412] Trial 258 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9673466462743725, 'batch_size': 58, 'attention_heads': 16, 'hidden_dimension': 88, 'number_of_hidden_layers': 1, 'dropout_rate': 0.538079021482299, 'global_pooling': 'mean', 'learning_rate': 0.0010926001289007113, 'weight_decay': 5.3150511049825165e-06, 'beta_0': 0.8770162543552948, 'beta_1': 0.9811727755137282, 'epsilon': 6.272998805502927e-08, 'balanced_loss': False, 'epochs': 138, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 11:29:12,426] Trial 259 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9642841121629969, 'batch_size': 62, 'attention_heads': 14, 'hidden_dimension': 67, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5199260921733495, 'global_pooling': 'mean', 'learning_rate': 0.0007608569287642544, 'weight_decay': 3.6575080803320583e-06, 'beta_0': 0.8798038678751474, 'beta_1': 0.9899014835471796, 'epsilon': 4.6183398177371053e-08, 'balanced_loss': False, 'epochs': 107, 'early_stopping_patience': 19, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 11:39:17,489] Trial 260 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9732173624535331, 'batch_size': 55, 'attention_heads': 16, 'hidden_dimension': 83, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5309563558764226, 'global_pooling': 'mean', 'learning_rate': 0.0013476299343169946, 'weight_decay': 0.0003665060342123243, 'beta_0': 0.8714093802290795, 'beta_1': 0.9818560976027584, 'epsilon': 8.646813370981739e-06, 'balanced_loss': False, 'epochs': 160, 'early_stopping_patience': 21, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 11:48:47,741] Trial 261 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9619424792231037, 'batch_size': 16, 'attention_heads': 15, 'hidden_dimension': 72, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5456695579866532, 'global_pooling': 'mean', 'learning_rate': 0.0019918201456854273, 'weight_decay': 7.358171314226086e-06, 'beta_0': 0.8761594758362978, 'beta_1': 0.9835560311474925, 'epsilon': 1.7616621508491553e-08, 'balanced_loss': False, 'epochs': 118, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 3.97 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.52 GiB is free. Including non-PyTorch memory, this process has 41.04 GiB memory in use. Of the allocated memory 35.15 GiB is allocated by PyTorch, and 4.73 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 11:58:51,635] Trial 262 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.969718155179833, 'batch_size': 61, 'attention_heads': 16, 'hidden_dimension': 150, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5092395092306228, 'global_pooling': 'mean', 'learning_rate': 0.0024875503628784415, 'weight_decay': 0.00030875573115741025, 'beta_0': 0.8823525426748454, 'beta_1': 0.980840771124756, 'epsilon': 3.4198462919725515e-08, 'balanced_loss': False, 'epochs': 126, 'early_stopping_patience': 19, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 12:08:01,946] Trial 263 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9663276836329051, 'batch_size': 60, 'attention_heads': 15, 'hidden_dimension': 63, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5786936532216309, 'global_pooling': 'mean', 'learning_rate': 0.0008354485378337706, 'weight_decay': 0.00042535585357590867, 'beta_0': 0.8786619577041997, 'beta_1': 0.9888354884911599, 'epsilon': 1.2828951295455608e-08, 'balanced_loss': False, 'epochs': 131, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.98 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.90 GiB is free. Including non-PyTorch memory, this process has 42.65 GiB memory in use. Of the allocated memory 37.16 GiB is allocated by PyTorch, and 4.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 12:15:40,198] Trial 264 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9567897744183728, 'batch_size': 57, 'attention_heads': 16, 'hidden_dimension': 80, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5260393429373652, 'global_pooling': 'mean', 'learning_rate': 0.0006697699104113456, 'weight_decay': 0.0005390464607474784, 'beta_0': 0.8742944119408012, 'beta_1': 0.9815942803622485, 'epsilon': 3.847678370571536e-08, 'balanced_loss': False, 'epochs': 124, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 12:28:57,342] Trial 265 finished with value: 0.9454545454545454 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9646141961755995, 'batch_size': 42, 'attention_heads': 15, 'hidden_dimension': 51, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5523720054303715, 'global_pooling': 'max', 'learning_rate': 0.0016736023579122152, 'weight_decay': 0.0006767273017230208, 'beta_0': 0.8928993488969537, 'beta_1': 0.9821281053611826, 'epsilon': 2.0852538107503334e-08, 'balanced_loss': False, 'epochs': 111, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 4}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 12:37:28,048] Trial 266 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9604116883705186, 'batch_size': 59, 'attention_heads': 14, 'hidden_dimension': 32, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5357100777772261, 'global_pooling': 'mean', 'learning_rate': 0.001028228590561756, 'weight_decay': 4.53472015623308e-06, 'beta_0': 0.8810152826402158, 'beta_1': 0.9800508849375442, 'epsilon': 5.178402781427017e-08, 'balanced_loss': False, 'epochs': 120, 'early_stopping_patience': 18, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 12:47:12,054] Trial 267 finished with value: 0.9454545454545454 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9681892587104506, 'batch_size': 61, 'attention_heads': 16, 'hidden_dimension': 69, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5153638983449741, 'global_pooling': 'mean', 'learning_rate': 0.0012870677825052754, 'weight_decay': 0.0003730874702560695, 'beta_0': 0.8704507845169867, 'beta_1': 0.9828894397073148, 'epsilon': 2.667075515539738e-08, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 19, 'plateau_patience': 12, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 12:56:59,155] Trial 268 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9626611952470056, 'batch_size': 63, 'attention_heads': 15, 'hidden_dimension': 75, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5417589493356673, 'global_pooling': 'mean', 'learning_rate': 0.0005015126779939918, 'weight_decay': 0.0002561868411590284, 'beta_0': 0.8777214949487245, 'beta_1': 0.9811126838936841, 'epsilon': 9.346180115529233e-08, 'balanced_loss': False, 'epochs': 100, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 13:07:07,844] Trial 269 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9301563021959678, 'batch_size': 18, 'attention_heads': 16, 'hidden_dimension': 58, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5305651766556478, 'global_pooling': 'mean', 'learning_rate': 0.0008712338158960662, 'weight_decay': 5.9732339695299494e-05, 'beta_0': 0.8896033820381037, 'beta_1': 0.9824456571175911, 'epsilon': 1.5030552264700453e-08, 'balanced_loss': False, 'epochs': 116, 'early_stopping_patience': 21, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 13:16:09,130] Trial 270 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9711063836307564, 'batch_size': 58, 'attention_heads': 9, 'hidden_dimension': 105, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5484392046294526, 'global_pooling': 'mean', 'learning_rate': 0.0006415949064729093, 'weight_decay': 0.00045124522092443263, 'beta_0': 0.8838819059304891, 'beta_1': 0.9813767867966632, 'epsilon': 6.746180331061828e-08, 'balanced_loss': False, 'epochs': 128, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 5.85 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.89 GiB is free. Including non-PyTorch memory, this process has 41.66 GiB memory in use. Of the allocated memory 36.33 GiB is allocated by PyTorch, and 4.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 13:23:47,047] Trial 271 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9586755244018486, 'batch_size': 62, 'attention_heads': 15, 'hidden_dimension': 170, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5241276945375696, 'global_pooling': 'mean', 'learning_rate': 0.0011110844861383295, 'weight_decay': 0.0003243490404170447, 'beta_0': 0.8727381619155821, 'beta_1': 0.980553275952344, 'epsilon': 2.310470537660364e-08, 'balanced_loss': False, 'epochs': 120, 'early_stopping_patience': 17, 'plateau_patience': 10, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 13:32:56,202] Trial 272 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9653099651218733, 'batch_size': 56, 'attention_heads': 11, 'hidden_dimension': 90, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5593010825865923, 'global_pooling': 'mean', 'learning_rate': 0.001437448390129377, 'weight_decay': 5.766062567368587e-06, 'beta_0': 0.8468405559921984, 'beta_1': 0.9903124446318885, 'epsilon': 1.7991099785536146e-08, 'balanced_loss': False, 'epochs': 123, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 13:42:13,630] Trial 273 finished with value: 0.9636363636363636 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9612156373341098, 'batch_size': 60, 'attention_heads': 16, 'hidden_dimension': 66, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5347763109585301, 'global_pooling': 'mean', 'learning_rate': 0.0018599424362658345, 'weight_decay': 0.0006074090182220919, 'beta_0': 0.8749817730764461, 'beta_1': 0.9880879592151858, 'epsilon': 1.1885978766581352e-07, 'balanced_loss': False, 'epochs': 184, 'early_stopping_patience': 16, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.33 GiB is free. Including non-PyTorch memory, this process has 43.22 GiB memory in use. Of the allocated memory 36.41 GiB is allocated by PyTorch, and 5.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 13:52:15,583] Trial 274 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9605511091870805, 'batch_size': 60, 'attention_heads': 16, 'hidden_dimension': 64, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5353820004626143, 'global_pooling': 'mean', 'learning_rate': 0.0027331333203799795, 'weight_decay': 0.0006695560322878008, 'beta_0': 0.8800353398462777, 'beta_1': 0.9878460548697675, 'epsilon': 1.17746316022943e-07, 'balanced_loss': False, 'epochs': 129, 'early_stopping_patience': 17, 'plateau_patience': 21, 'plateau_divider': 4}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 14:01:35,099] Trial 275 finished with value: 0.9454545454545454 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9580185109202991, 'batch_size': 64, 'attention_heads': 16, 'hidden_dimension': 66, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5197468835252452, 'global_pooling': 'mean', 'learning_rate': 0.0021767703109418736, 'weight_decay': 0.0005248946804409388, 'beta_0': 0.8768307243859489, 'beta_1': 0.9882327350315386, 'epsilon': 2.8288035499663723e-08, 'balanced_loss': False, 'epochs': 176, 'early_stopping_patience': 14, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 4.31 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.67 GiB is free. Including non-PyTorch memory, this process has 42.89 GiB memory in use. Of the allocated memory 39.39 GiB is allocated by PyTorch, and 2.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 14:09:01,530] Trial 276 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9543980043650179, 'batch_size': 41, 'attention_heads': 16, 'hidden_dimension': 160, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5298061365038531, 'global_pooling': 'mean', 'learning_rate': 0.001751485283281995, 'weight_decay': 0.0008652141403965347, 'beta_0': 0.8752130392470846, 'beta_1': 0.9886524202479077, 'epsilon': 1.5618698853039512e-07, 'balanced_loss': False, 'epochs': 133, 'early_stopping_patience': 16, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 14:18:15,642] Trial 277 finished with value: 0.9333333333333333 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9613880969889866, 'batch_size': 62, 'attention_heads': 16, 'hidden_dimension': 59, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5392311321909217, 'global_pooling': 'mean', 'learning_rate': 0.0007617321228842246, 'weight_decay': 0.0006164928125659904, 'beta_0': 0.8854159164226957, 'beta_1': 0.988428473623261, 'epsilon': 1.3285184758582663e-07, 'balanced_loss': False, 'epochs': 183, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 14:26:55,835] Trial 278 finished with value: 0.9515151515151515 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9745868132884566, 'batch_size': 36, 'attention_heads': 16, 'hidden_dimension': 70, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5439093073367247, 'global_pooling': 'mean', 'learning_rate': 0.0018902764792967763, 'weight_decay': 0.0004968830742784941, 'beta_0': 0.8983784218972862, 'beta_1': 0.9892359777338847, 'epsilon': 3.828096531417017e-08, 'balanced_loss': False, 'epochs': 126, 'early_stopping_patience': 18, 'plateau_patience': 21, 'plateau_divider': 10}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 14:36:45,295] Trial 279 finished with value: 0.9515151515151515 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9680075179723856, 'batch_size': 61, 'attention_heads': 16, 'hidden_dimension': 85, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5240521551924607, 'global_pooling': 'mean', 'learning_rate': 0.0005705998916758356, 'weight_decay': 4.088534009442635e-06, 'beta_0': 0.8790456153334298, 'beta_1': 0.9874899683393366, 'epsilon': 2.0861034799094878e-08, 'balanced_loss': False, 'epochs': 200, 'early_stopping_patience': 15, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 14:46:14,367] Trial 280 finished with value: 0.9393939393939394 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9624056014329017, 'batch_size': 58, 'attention_heads': 16, 'hidden_dimension': 54, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5335084273493, 'global_pooling': 'sum', 'learning_rate': 0.0009469906079830787, 'weight_decay': 0.00011976226616964246, 'beta_0': 0.8810655150626117, 'beta_1': 0.9896354782158518, 'epsilon': 4.6402158759510904e-08, 'balanced_loss': False, 'epochs': 166, 'early_stopping_patience': 16, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 15:09:31,067] Trial 281 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9656078738769367, 'batch_size': 32, 'attention_heads': 14, 'hidden_dimension': 95, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5136264740595249, 'global_pooling': 'mean', 'learning_rate': 1.127356562825626e-05, 'weight_decay': 0.000721049916494086, 'beta_0': 0.8873860815833404, 'beta_1': 0.9808646851253288, 'epsilon': 2.9415020631821235e-05, 'balanced_loss': False, 'epochs': 187, 'early_stopping_patience': 19, 'plateau_patience': 24, 'plateau_divider': 8}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.79 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.69 GiB is free. Including non-PyTorch memory, this process has 41.86 GiB memory in use. Of the allocated memory 33.67 GiB is allocated by PyTorch, and 7.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 15:17:09,485] Trial 282 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9493076919734531, 'batch_size': 29, 'attention_heads': 13, 'hidden_dimension': 154, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5391452899638076, 'global_pooling': 'mean', 'learning_rate': 0.03046465578557558, 'weight_decay': 5.269400175257813e-06, 'beta_0': 0.882812066638067, 'beta_1': 0.9870376216455388, 'epsilon': 3.001617296329176e-08, 'balanced_loss': False, 'epochs': 173, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.40 GiB is free. Including non-PyTorch memory, this process has 42.16 GiB memory in use. Of the allocated memory 34.71 GiB is allocated by PyTorch, and 6.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 15:24:46,021] Trial 283 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9522372317948172, 'batch_size': 57, 'attention_heads': 15, 'hidden_dimension': 71, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5272840608281166, 'global_pooling': 'mean', 'learning_rate': 0.000465518482638023, 'weight_decay': 0.0005839674477819414, 'beta_0': 0.8773062558017022, 'beta_1': 0.9817263239006919, 'epsilon': 1.0459279542797315e-07, 'balanced_loss': False, 'epochs': 122, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 15:33:44,762] Trial 284 finished with value: 0.9515151515151515 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9639779788017254, 'batch_size': 59, 'attention_heads': 16, 'hidden_dimension': 43, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5207033812481312, 'global_pooling': 'mean', 'learning_rate': 0.001565839901361469, 'weight_decay': 6.710862475522477e-06, 'beta_0': 0.8751083826747227, 'beta_1': 0.9855993729705197, 'epsilon': 1.6357996117147292e-08, 'balanced_loss': False, 'epochs': 118, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 9}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 15:43:44,241] Trial 285 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.966436058315843, 'batch_size': 42, 'attention_heads': 16, 'hidden_dimension': 102, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5472976323157412, 'global_pooling': 'mean', 'learning_rate': 0.0007371069962603297, 'weight_decay': 0.0004057070674188251, 'beta_0': 0.8675627674970001, 'beta_1': 0.9804279393423772, 'epsilon': 1.2489951669205771e-05, 'balanced_loss': False, 'epochs': 195, 'early_stopping_patience': 13, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 15:53:16,923] Trial 286 finished with value: 0.9454545454545454 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.960224074395148, 'batch_size': 52, 'attention_heads': 15, 'hidden_dimension': 66, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5324638912192543, 'global_pooling': 'mean', 'learning_rate': 0.002284848331860055, 'weight_decay': 2.6265504654801926e-05, 'beta_0': 0.8784580463512429, 'beta_1': 0.9812730516898868, 'epsilon': 5.7511976106536394e-08, 'balanced_loss': False, 'epochs': 184, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 16:03:59,657] Trial 287 finished with value: 0.9272727272727272 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9691834258235573, 'batch_size': 60, 'attention_heads': 4, 'hidden_dimension': 80, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5527486994609555, 'global_pooling': 'max', 'learning_rate': 0.0012691667220698854, 'weight_decay': 0.0004601339612981208, 'beta_0': 0.8806460034701117, 'beta_1': 0.9880417217072079, 'epsilon': 2.6258107631355883e-08, 'balanced_loss': False, 'epochs': 190, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 16:12:46,373] Trial 288 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9627496164488271, 'batch_size': 55, 'attention_heads': 10, 'hidden_dimension': 63, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5277007612835183, 'global_pooling': 'mean', 'learning_rate': 0.0009248856798468415, 'weight_decay': 0.0005752790206178003, 'beta_0': 0.8724960685381616, 'beta_1': 0.9913170210311907, 'epsilon': 3.4927055679148105e-08, 'balanced_loss': False, 'epochs': 96, 'early_stopping_patience': 19, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.97 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.96 GiB is free. Including non-PyTorch memory, this process has 42.59 GiB memory in use. Of the allocated memory 37.22 GiB is allocated by PyTorch, and 4.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 16:20:25,823] Trial 289 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9562620436167864, 'batch_size': 60, 'attention_heads': 16, 'hidden_dimension': 74, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5406267242235816, 'global_pooling': 'mean', 'learning_rate': 0.0006487652063370209, 'weight_decay': 0.0002255266253727596, 'beta_0': 0.876067654447617, 'beta_1': 0.9865294872327484, 'epsilon': 1.7783563816729452e-08, 'balanced_loss': False, 'epochs': 91, 'early_stopping_patience': 17, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 16:28:56,520] Trial 290 finished with value: 0.9393939393939394 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9709901414560437, 'batch_size': 61, 'attention_heads': 15, 'hidden_dimension': 61, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5190138359848534, 'global_pooling': 'mean', 'learning_rate': 0.0029263692358105532, 'weight_decay': 0.0007736830093279634, 'beta_0': 0.8827549881037097, 'beta_1': 0.9807373433704086, 'epsilon': 2.478703996277671e-07, 'balanced_loss': False, 'epochs': 123, 'early_stopping_patience': 16, 'plateau_patience': 13, 'plateau_divider': 4}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 16:38:34,710] Trial 291 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9657539696978165, 'batch_size': 56, 'attention_heads': 16, 'hidden_dimension': 69, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5332648772771252, 'global_pooling': 'mean', 'learning_rate': 0.0015332321549422522, 'weight_decay': 0.00027874024207110836, 'beta_0': 0.87880808717496, 'beta_1': 0.9844454031845618, 'epsilon': 8.506700227960969e-08, 'balanced_loss': False, 'epochs': 104, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.47 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.67 GiB is free. Including non-PyTorch memory, this process has 42.88 GiB memory in use. Of the allocated memory 37.66 GiB is allocated by PyTorch, and 4.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 16:46:05,733] Trial 292 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9586898708884848, 'batch_size': 54, 'attention_heads': 16, 'hidden_dimension': 78, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5087571698324604, 'global_pooling': 'mean', 'learning_rate': 0.0011306018239045982, 'weight_decay': 4.453467303088652e-06, 'beta_0': 0.8696956727778475, 'beta_1': 0.9833907398721742, 'epsilon': 1.2742611446876285e-08, 'balanced_loss': False, 'epochs': 126, 'early_stopping_patience': 19, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 16:54:41,280] Trial 293 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9677607867336586, 'batch_size': 63, 'attention_heads': 14, 'hidden_dimension': 38, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5688301402828587, 'global_pooling': 'mean', 'learning_rate': 0.001886177237995648, 'weight_decay': 0.00040603717939082564, 'beta_0': 0.8751714028049283, 'beta_1': 0.9889211909571888, 'epsilon': 4.045676038850663e-05, 'balanced_loss': False, 'epochs': 76, 'early_stopping_patience': 18, 'plateau_patience': 11, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 17:03:48,866] Trial 294 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9636816730108216, 'batch_size': 58, 'attention_heads': 15, 'hidden_dimension': 49, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5435347140794116, 'global_pooling': 'mean', 'learning_rate': 0.000850414331887503, 'weight_decay': 0.0005168726234869464, 'beta_0': 0.8948436510123366, 'beta_1': 0.9819275692045389, 'epsilon': 2.211242739473488e-08, 'balanced_loss': False, 'epochs': 134, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 17:13:26,971] Trial 295 finished with value: 0.9454545454545454 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9611728772166995, 'batch_size': 43, 'attention_heads': 16, 'hidden_dimension': 87, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5244502876232581, 'global_pooling': 'mean', 'learning_rate': 0.0005886260787827768, 'weight_decay': 0.0003595321776517496, 'beta_0': 0.8772841283060622, 'beta_1': 0.9928864759121181, 'epsilon': 4.193930772688646e-08, 'balanced_loss': False, 'epochs': 116, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 17:23:40,817] Trial 296 finished with value: 0.9515151515151515 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9667770488335947, 'batch_size': 40, 'attention_heads': 15, 'hidden_dimension': 82, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5908742994413217, 'global_pooling': 'mean', 'learning_rate': 0.00042598872825955507, 'weight_decay': 6.142116354371966e-06, 'beta_0': 0.8805110837696158, 'beta_1': 0.981439702043526, 'epsilon': 5.147622419503654e-08, 'balanced_loss': False, 'epochs': 129, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 4}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 17:32:45,505] Trial 297 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9648047628849684, 'batch_size': 62, 'attention_heads': 15, 'hidden_dimension': 56, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5827929955176473, 'global_pooling': 'mean', 'learning_rate': 0.0010599469952319621, 'weight_decay': 0.0006171476621262257, 'beta_0': 0.873826255798911, 'beta_1': 0.981012318175634, 'epsilon': 6.991110811272196e-08, 'balanced_loss': False, 'epochs': 119, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 17:46:04,942] Trial 298 finished with value: 0.9151515151515152 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9792686294721609, 'batch_size': 60, 'attention_heads': 16, 'hidden_dimension': 166, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5357693075067899, 'global_pooling': 'sum', 'learning_rate': 0.0007180872641920843, 'weight_decay': 3.3670067852294532e-06, 'beta_0': 0.8844935666209114, 'beta_1': 0.9958798856201191, 'epsilon': 2.352313644236326e-08, 'balanced_loss': False, 'epochs': 82, 'early_stopping_patience': 18, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 17:55:49,004] Trial 299 finished with value: 0.9454545454545454 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9618595176085665, 'batch_size': 57, 'attention_heads': 15, 'hidden_dimension': 71, 'number_of_hidden_layers': 1, 'dropout_rate': 0.548449984037078, 'global_pooling': 'mean', 'learning_rate': 0.0013364983622084622, 'weight_decay': 5.0387773281109425e-06, 'beta_0': 0.878221002131328, 'beta_1': 0.983812614216529, 'epsilon': 3.3377718819174397e-08, 'balanced_loss': False, 'epochs': 122, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 5}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 18:07:29,075] Trial 300 finished with value: 0.9454545454545454 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9591454532102666, 'batch_size': 59, 'attention_heads': 16, 'hidden_dimension': 66, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5549815143262508, 'global_pooling': 'mean', 'learning_rate': 0.0009235800271415553, 'weight_decay': 0.0004669381616098983, 'beta_0': 0.8715320690932861, 'beta_1': 0.9937217559143788, 'epsilon': 8.606333981968494e-05, 'balanced_loss': False, 'epochs': 57, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 18:16:21,577] Trial 301 finished with value: 0.9393939393939394 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9727926698361277, 'batch_size': 61, 'attention_heads': 15, 'hidden_dimension': 76, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5160821521768942, 'global_pooling': 'mean', 'learning_rate': 0.0016000889572185316, 'weight_decay': 0.0003974065374644, 'beta_0': 0.8761752052394223, 'beta_1': 0.9970037704142313, 'epsilon': 5.423835393540786e-07, 'balanced_loss': False, 'epochs': 141, 'early_stopping_patience': 12, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.47 GiB is free. Including non-PyTorch memory, this process has 42.09 GiB memory in use. Of the allocated memory 32.75 GiB is allocated by PyTorch, and 8.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 18:24:00,907] Trial 302 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9688607848619053, 'batch_size': 62, 'attention_heads': 16, 'hidden_dimension': 91, 'number_of_hidden_layers': 1, 'dropout_rate': 0.531984934350008, 'global_pooling': 'mean', 'learning_rate': 0.0007995285463313146, 'weight_decay': 0.00029978092827536806, 'beta_0': 0.8907169087657676, 'beta_1': 0.9946635657371442, 'epsilon': 1.4408881767762818e-08, 'balanced_loss': False, 'epochs': 146, 'early_stopping_patience': 20, 'plateau_patience': 20, 'plateau_divider': 8}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 18:32:19,862] Trial 303 finished with value: 0.9575757575757575 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.962979008356923, 'batch_size': 21, 'attention_heads': 8, 'hidden_dimension': 59, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5395634530613479, 'global_pooling': 'mean', 'learning_rate': 0.0010785615239003298, 'weight_decay': 0.0009370736859101751, 'beta_0': 0.8820094133022212, 'beta_1': 0.9802621694731961, 'epsilon': 1.927855500966977e-08, 'balanced_loss': True, 'epochs': 87, 'early_stopping_patience': 18, 'plateau_patience': 12, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.33 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.04 GiB is free. Including non-PyTorch memory, this process has 42.52 GiB memory in use. Of the allocated memory 37.47 GiB is allocated by PyTorch, and 3.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 18:41:13,845] Trial 304 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9649373697713092, 'batch_size': 58, 'attention_heads': 16, 'hidden_dimension': 74, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5275301152489287, 'global_pooling': 'mean', 'learning_rate': 0.0019662248762093715, 'weight_decay': 2.0579814362942827e-05, 'beta_0': 0.8863152695268528, 'beta_1': 0.9827188822803344, 'epsilon': 9.768779083739792e-08, 'balanced_loss': False, 'epochs': 125, 'early_stopping_patience': 20, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 4.35 GiB. GPU 0 has a total capacity of 44.56 GiB of which 748.69 MiB is free. Including non-PyTorch memory, this process has 43.82 GiB memory in use. Of the allocated memory 37.86 GiB is allocated by PyTorch, and 4.81 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 18:48:50,681] Trial 305 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9674665274623082, 'batch_size': 63, 'attention_heads': 16, 'hidden_dimension': 148, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5225259714706604, 'global_pooling': 'mean', 'learning_rate': 0.0005641443166273447, 'weight_decay': 8.071095036018142e-06, 'beta_0': 0.8796986338273899, 'beta_1': 0.9819990038758056, 'epsilon': 1.3018804817110266e-07, 'balanced_loss': False, 'epochs': 114, 'early_stopping_patience': 17, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 2.60 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.40 GiB is free. Including non-PyTorch memory, this process has 42.16 GiB memory in use. Of the allocated memory 35.57 GiB is allocated by PyTorch, and 5.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 18:56:17,798] Trial 306 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9465179577615332, 'batch_size': 59, 'attention_heads': 15, 'hidden_dimension': 63, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5633865840812217, 'global_pooling': 'mean', 'learning_rate': 0.0013254019024094418, 'weight_decay': 0.00014929767439245622, 'beta_0': 0.8743852475532946, 'beta_1': 0.9906773373221157, 'epsilon': 6.02241909165255e-08, 'balanced_loss': False, 'epochs': 107, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 19:05:41,361] Trial 307 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.97022235766256, 'batch_size': 57, 'attention_heads': 15, 'hidden_dimension': 69, 'number_of_hidden_layers': 1, 'dropout_rate': 0.573708209974656, 'global_pooling': 'mean', 'learning_rate': 0.0006676844306719098, 'weight_decay': 0.0005114667881466698, 'beta_0': 0.8776210605171931, 'beta_1': 0.9815434011454905, 'epsilon': 1.735373880108164e-05, 'balanced_loss': False, 'epochs': 130, 'early_stopping_patience': 21, 'plateau_patience': 24, 'plateau_divider': 4}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 3.04 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.99 GiB is free. Including non-PyTorch memory, this process has 42.56 GiB memory in use. Of the allocated memory 37.04 GiB is allocated by PyTorch, and 4.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 19:13:19,310] Trial 308 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9601606811614933, 'batch_size': 60, 'attention_heads': 16, 'hidden_dimension': 83, 'number_of_hidden_layers': 1, 'dropout_rate': 0.548242465261629, 'global_pooling': 'mean', 'learning_rate': 0.0003652593745564817, 'weight_decay': 3.869299259231073e-06, 'beta_0': 0.8818332397326073, 'beta_1': 0.9831676070206901, 'epsilon': 3.022570365244258e-08, 'balanced_loss': True, 'epochs': 65, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.17 GiB is free. Including non-PyTorch memory, this process has 43.39 GiB memory in use. Of the allocated memory 39.34 GiB is allocated by PyTorch, and 2.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 19:20:48,879] Trial 309 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.956728233472543, 'batch_size': 43, 'attention_heads': 14, 'hidden_dimension': 78, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5109475170660023, 'global_pooling': 'mean', 'learning_rate': 0.0024432405991640614, 'weight_decay': 0.00035028096684077434, 'beta_0': 0.8797041557065758, 'beta_1': 0.9922364468215904, 'epsilon': 1.1694926719314736e-06, 'balanced_loss': False, 'epochs': 120, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 4.45 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1000.69 MiB is free. Including non-PyTorch memory, this process has 43.58 GiB memory in use. Of the allocated memory 39.12 GiB is allocated by PyTorch, and 3.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 19:28:31,565] Trial 310 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9634440980078717, 'batch_size': 56, 'attention_heads': 15, 'hidden_dimension': 160, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5362597796104132, 'global_pooling': 'max', 'learning_rate': 0.0008991718044677278, 'weight_decay': 0.000431370231088034, 'beta_0': 0.852615091983392, 'beta_1': 0.9809970646470884, 'epsilon': 1.114882693518476e-08, 'balanced_loss': False, 'epochs': 169, 'early_stopping_patience': 18, 'plateau_patience': 22, 'plateau_divider': 5}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 19:37:59,240] Trial 311 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9660855313364742, 'batch_size': 61, 'attention_heads': 16, 'hidden_dimension': 66, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5294047464027272, 'global_pooling': 'mean', 'learning_rate': 0.0015985496897477289, 'weight_decay': 7.538396623869639e-05, 'beta_0': 0.8726453056756608, 'beta_1': 0.9806421563466577, 'epsilon': 4.5886656571852055e-08, 'balanced_loss': False, 'epochs': 101, 'early_stopping_patience': 20, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 19:49:58,456] Trial 312 finished with value: 0.9454545454545454 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9616724115674755, 'batch_size': 64, 'attention_heads': 15, 'hidden_dimension': 71, 'number_of_hidden_layers': 1, 'dropout_rate': 0.541824439388982, 'global_pooling': 'mean', 'learning_rate': 0.001098959969885561, 'weight_decay': 0.00027111729499944493, 'beta_0': 0.8762465462697501, 'beta_1': 0.9893610536348041, 'epsilon': 2.526304751726786e-08, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 21, 'plateau_patience': 21, 'plateau_divider': 2}. Best is trial 155 with value: 0.9636363636363636.
[I 2024-12-11 19:58:58,846] Trial 313 finished with value: 0.9515151515151515 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9637207894050108, 'batch_size': 59, 'attention_heads': 14, 'hidden_dimension': 53, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5558895589936873, 'global_pooling': 'mean', 'learning_rate': 0.000757086393029672, 'weight_decay': 0.0006355120713887163, 'beta_0': 0.8636895700816702, 'beta_1': 0.9884163364071098, 'epsilon': 8.296672519703797e-08, 'balanced_loss': False, 'epochs': 111, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 155 with value: 0.9636363636363636.
CUDA out of memory. Tried to allocate 3.78 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.17 GiB is free. Including non-PyTorch memory, this process has 43.38 GiB memory in use. Of the allocated memory 37.84 GiB is allocated by PyTorch, and 4.40 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-11 20:06:22,853] Trial 314 finished with value: -1.0 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9674605175521888, 'batch_size': 55, 'attention_heads': 16, 'hidden_dimension': 152, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5205551996807111, 'global_pooling': 'mean', 'learning_rate': 0.001296150893748821, 'weight_decay': 0.0005295303788513352, 'beta_0': 0.8836984179944622, 'beta_1': 0.9878331614540173, 'epsilon': 2.0869092550047403e-08, 'balanced_loss': False, 'epochs': 71, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 4}. Best is trial 155 with value: 0.9636363636363636.
slurmstepd: error: *** JOB 14079690 ON gpu049 CANCELLED AT 2024-12-11T20:08:40 DUE TO TIME LIMIT ***
