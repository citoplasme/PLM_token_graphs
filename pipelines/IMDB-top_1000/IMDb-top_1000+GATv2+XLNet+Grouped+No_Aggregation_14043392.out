[I 2024-12-02 10:49:53,881] A new study created in RDB with name: IMDb-top_1000-GATv2-xlnet-xlnet-base-cased-Grouped-No_Aggregation
CUDA out of memory. Tried to allocate 5.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.68 GiB is free. Including non-PyTorch memory, this process has 40.87 GiB memory in use. Of the allocated memory 35.18 GiB is allocated by PyTorch, and 4.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 10:57:35,530] Trial 0 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9058077803806983, 'batch_size': 58, 'attention_heads': 11, 'hidden_dimension': 191, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5909729556485983, 'global_pooling': 'mean', 'learning_rate': 5.415244119402538e-05, 'weight_decay': 8.179499475211674e-06, 'beta_0': 0.8510059609290175, 'beta_1': 0.9881622148267181, 'epsilon': 1.4618962793704927e-07, 'balanced_loss': True, 'epochs': 94, 'early_stopping_patience': 15, 'plateau_patience': 17, 'plateau_divider': 9}. Best is trial 0 with value: -1.0.
CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.85 GiB is free. Including non-PyTorch memory, this process has 39.70 GiB memory in use. Of the allocated memory 26.91 GiB is allocated by PyTorch, and 11.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 11:05:46,758] Trial 1 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9065045087825981, 'batch_size': 62, 'attention_heads': 16, 'hidden_dimension': 213, 'number_of_hidden_layers': 1, 'dropout_rate': 0.32930163420191516, 'global_pooling': 'mean', 'learning_rate': 0.0009565499215943821, 'weight_decay': 1.2681352169084602e-06, 'beta_0': 0.8904386843107996, 'beta_1': 0.9848818831861611, 'epsilon': 4.467752817973898e-06, 'balanced_loss': False, 'epochs': 132, 'early_stopping_patience': 12, 'plateau_patience': 25, 'plateau_divider': 8}. Best is trial 0 with value: -1.0.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.52 GiB is free. Including non-PyTorch memory, this process has 40.03 GiB memory in use. Of the allocated memory 33.11 GiB is allocated by PyTorch, and 5.78 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 11:13:57,502] Trial 2 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9045222766181648, 'batch_size': 31, 'attention_heads': 9, 'hidden_dimension': 93, 'number_of_hidden_layers': 4, 'dropout_rate': 0.40702599800807676, 'global_pooling': 'sum', 'learning_rate': 0.016172900811143146, 'weight_decay': 1.6736010167825795e-06, 'beta_0': 0.8986110261361376, 'beta_1': 0.9946405101730994, 'epsilon': 6.235377135673148e-08, 'balanced_loss': False, 'epochs': 156, 'early_stopping_patience': 21, 'plateau_patience': 22, 'plateau_divider': 2}. Best is trial 0 with value: -1.0.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 596.69 MiB is free. Including non-PyTorch memory, this process has 43.97 GiB memory in use. Of the allocated memory 29.63 GiB is allocated by PyTorch, and 13.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 11:22:09,287] Trial 3 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9310951223483491, 'batch_size': 31, 'attention_heads': 13, 'hidden_dimension': 175, 'number_of_hidden_layers': 4, 'dropout_rate': 0.44166447754858473, 'global_pooling': 'max', 'learning_rate': 0.0017583640270008513, 'weight_decay': 0.00020554245520150764, 'beta_0': 0.8479082820660899, 'beta_1': 0.9898864065152503, 'epsilon': 5.130551760589827e-07, 'balanced_loss': False, 'epochs': 54, 'early_stopping_patience': 20, 'plateau_patience': 15, 'plateau_divider': 6}. Best is trial 0 with value: -1.0.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.94 GiB is free. Including non-PyTorch memory, this process has 41.62 GiB memory in use. Of the allocated memory 29.85 GiB is allocated by PyTorch, and 10.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 11:30:21,242] Trial 4 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9289722477768477, 'batch_size': 23, 'attention_heads': 16, 'hidden_dimension': 213, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5614381770563153, 'global_pooling': 'max', 'learning_rate': 0.0014367095138664223, 'weight_decay': 0.00026443593078398644, 'beta_0': 0.889052315352582, 'beta_1': 0.9860025494147586, 'epsilon': 2.755546207779655e-08, 'balanced_loss': False, 'epochs': 173, 'early_stopping_patience': 23, 'plateau_patience': 10, 'plateau_divider': 6}. Best is trial 0 with value: -1.0.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.64 GiB is free. Including non-PyTorch memory, this process has 41.92 GiB memory in use. Of the allocated memory 26.77 GiB is allocated by PyTorch, and 14.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 11:38:32,858] Trial 5 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9518738742681192, 'batch_size': 50, 'attention_heads': 8, 'hidden_dimension': 250, 'number_of_hidden_layers': 4, 'dropout_rate': 0.3755346887476092, 'global_pooling': 'mean', 'learning_rate': 1.4045842344024695e-05, 'weight_decay': 6.740513796374044e-05, 'beta_0': 0.8487959271998592, 'beta_1': 0.9809692144821089, 'epsilon': 1.3019246714361555e-07, 'balanced_loss': True, 'epochs': 71, 'early_stopping_patience': 17, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 0 with value: -1.0.
CUDA out of memory. Tried to allocate 5.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.64 GiB is free. Including non-PyTorch memory, this process has 41.92 GiB memory in use. Of the allocated memory 22.06 GiB is allocated by PyTorch, and 18.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 11:46:12,371] Trial 6 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9633466357789819, 'batch_size': 42, 'attention_heads': 5, 'hidden_dimension': 219, 'number_of_hidden_layers': 1, 'dropout_rate': 0.35595555311995625, 'global_pooling': 'max', 'learning_rate': 1.1650681118986128e-05, 'weight_decay': 3.4377886617795816e-05, 'beta_0': 0.8216291089982651, 'beta_1': 0.9922164838130152, 'epsilon': 4.9827112000811335e-08, 'balanced_loss': True, 'epochs': 191, 'early_stopping_patience': 12, 'plateau_patience': 15, 'plateau_divider': 3}. Best is trial 0 with value: -1.0.
CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 44.56 GiB of which 384.69 MiB is free. Including non-PyTorch memory, this process has 44.18 GiB memory in use. Of the allocated memory 29.82 GiB is allocated by PyTorch, and 13.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 11:55:12,819] Trial 7 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9529597613298171, 'batch_size': 27, 'attention_heads': 5, 'hidden_dimension': 233, 'number_of_hidden_layers': 4, 'dropout_rate': 0.48993043718198037, 'global_pooling': 'max', 'learning_rate': 0.0387651117091163, 'weight_decay': 0.00045841547801363794, 'beta_0': 0.8769656613172253, 'beta_1': 0.9921566381933148, 'epsilon': 2.1705003488711103e-08, 'balanced_loss': False, 'epochs': 141, 'early_stopping_patience': 10, 'plateau_patience': 11, 'plateau_divider': 7}. Best is trial 0 with value: -1.0.
[I 2024-12-02 12:09:19,967] Trial 8 finished with value: 0.9090909090909091 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9712108003425401, 'batch_size': 27, 'attention_heads': 8, 'hidden_dimension': 199, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5547670231482533, 'global_pooling': 'mean', 'learning_rate': 0.0002957080941494348, 'weight_decay': 6.24607368131809e-06, 'beta_0': 0.8233238054292655, 'beta_1': 0.9984823954805346, 'epsilon': 3.7358626308127487e-07, 'balanced_loss': True, 'epochs': 170, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 6}. Best is trial 8 with value: 0.9090909090909091.
CUDA out of memory. Tried to allocate 5.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 310.69 MiB is free. Including non-PyTorch memory, this process has 44.25 GiB memory in use. Of the allocated memory 25.98 GiB is allocated by PyTorch, and 17.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 12:17:00,400] Trial 9 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9940364538494479, 'batch_size': 62, 'attention_heads': 15, 'hidden_dimension': 115, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5784955687763176, 'global_pooling': 'sum', 'learning_rate': 0.025824850844906145, 'weight_decay': 7.644457600399742e-06, 'beta_0': 0.8371219067759552, 'beta_1': 0.9961484316107455, 'epsilon': 1.8522006003174358e-07, 'balanced_loss': False, 'epochs': 191, 'early_stopping_patience': 21, 'plateau_patience': 19, 'plateau_divider': 2}. Best is trial 8 with value: 0.9090909090909091.
[I 2024-12-02 12:27:01,716] Trial 10 finished with value: 0.8484848484848485 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9851710804155442, 'batch_size': 16, 'attention_heads': 7, 'hidden_dimension': 40, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5069924419974332, 'global_pooling': 'mean', 'learning_rate': 0.00011015753215781712, 'weight_decay': 6.954771451368797e-06, 'beta_0': 0.8011183479951905, 'beta_1': 0.997553073267282, 'epsilon': 6.646086576758891e-05, 'balanced_loss': True, 'epochs': 108, 'early_stopping_patience': 25, 'plateau_patience': 20, 'plateau_divider': 5}. Best is trial 8 with value: 0.9090909090909091.
CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.86 GiB is free. Including non-PyTorch memory, this process has 41.69 GiB memory in use. Of the allocated memory 16.25 GiB is allocated by PyTorch, and 24.29 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 12:35:12,285] Trial 11 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9862974001101031, 'batch_size': 16, 'attention_heads': 7, 'hidden_dimension': 38, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5084585346377367, 'global_pooling': 'mean', 'learning_rate': 0.00013857943411927569, 'weight_decay': 7.679738601475693e-06, 'beta_0': 0.8001766262431174, 'beta_1': 0.9984899547570018, 'epsilon': 4.710988347881894e-05, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 25, 'plateau_patience': 21, 'plateau_divider': 5}. Best is trial 8 with value: 0.9090909090909091.
[I 2024-12-02 12:48:14,881] Trial 12 finished with value: 0.8727272727272727 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9777633832346591, 'batch_size': 16, 'attention_heads': 11, 'hidden_dimension': 146, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5207556792136036, 'global_pooling': 'mean', 'learning_rate': 0.00024356157517181777, 'weight_decay': 3.431767241750914e-06, 'beta_0': 0.8007804741287059, 'beta_1': 0.9987114194139771, 'epsilon': 5.060911509050166e-06, 'balanced_loss': True, 'epochs': 106, 'early_stopping_patience': 25, 'plateau_patience': 20, 'plateau_divider': 10}. Best is trial 8 with value: 0.9090909090909091.
CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.41 GiB is free. Including non-PyTorch memory, this process has 43.15 GiB memory in use. Of the allocated memory 34.54 GiB is allocated by PyTorch, and 7.46 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 12:57:19,278] Trial 13 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9723547319186756, 'batch_size': 40, 'attention_heads': 11, 'hidden_dimension': 155, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5418473188867232, 'global_pooling': 'mean', 'learning_rate': 0.00040612506883825727, 'weight_decay': 2.792058480411356e-06, 'beta_0': 0.8186869001425181, 'beta_1': 0.9942537412396695, 'epsilon': 3.3390500650132797e-06, 'balanced_loss': True, 'epochs': 159, 'early_stopping_patience': 18, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 8 with value: 0.9090909090909091.
[I 2024-12-02 13:10:28,341] Trial 14 finished with value: 0.6666666666666666 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9725470412065579, 'batch_size': 22, 'attention_heads': 13, 'hidden_dimension': 124, 'number_of_hidden_layers': 3, 'dropout_rate': 0.4643119547121601, 'global_pooling': 'mean', 'learning_rate': 0.005819012745924347, 'weight_decay': 2.182559164603337e-05, 'beta_0': 0.8157251761306415, 'beta_1': 0.9989858000852625, 'epsilon': 3.426215439185116e-06, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 16, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 8 with value: 0.9090909090909091.
[I 2024-12-02 13:20:37,174] Trial 15 finished with value: 0.7515151515151515 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9981214955449618, 'batch_size': 37, 'attention_heads': 10, 'hidden_dimension': 173, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5384051614323463, 'global_pooling': 'sum', 'learning_rate': 0.00034453498599641046, 'weight_decay': 3.1579488167215517e-06, 'beta_0': 0.8311631958808916, 'beta_1': 0.9955874848849253, 'epsilon': 7.294568719823208e-07, 'balanced_loss': True, 'epochs': 89, 'early_stopping_patience': 19, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 8 with value: 0.9090909090909091.
[I 2024-12-02 13:35:33,631] Trial 16 finished with value: 0.9090909090909091 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9691759632269894, 'batch_size': 22, 'attention_heads': 13, 'hidden_dimension': 138, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4398157646545306, 'global_pooling': 'mean', 'learning_rate': 4.131098050701256e-05, 'weight_decay': 1.7892179812052506e-05, 'beta_0': 0.8101761635869574, 'beta_1': 0.9923856631952251, 'epsilon': 1.498080961015864e-05, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 23, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 8 with value: 0.9090909090909091.
CUDA out of memory. Tried to allocate 2.73 GiB. GPU 0 has a total capacity of 44.56 GiB of which 34.69 MiB is free. Including non-PyTorch memory, this process has 44.52 GiB memory in use. Of the allocated memory 32.23 GiB is allocated by PyTorch, and 11.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 13:44:50,957] Trial 17 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9337347661980276, 'batch_size': 34, 'attention_heads': 13, 'hidden_dimension': 81, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4278526465455581, 'global_pooling': 'mean', 'learning_rate': 3.2496313436217765e-05, 'weight_decay': 2.8264170018299033e-05, 'beta_0': 0.8289790791957933, 'beta_1': 0.9925014229565521, 'epsilon': 2.0593758867690195e-05, 'balanced_loss': True, 'epochs': 148, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 8 with value: 0.9090909090909091.
[I 2024-12-02 13:55:17,592] Trial 18 finished with value: 0.696969696969697 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9625945026250644, 'batch_size': 24, 'attention_heads': 4, 'hidden_dimension': 188, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4673866545692256, 'global_pooling': 'mean', 'learning_rate': 4.2766265346261324e-05, 'weight_decay': 1.4668025747827192e-05, 'beta_0': 0.8125224678334142, 'beta_1': 0.9893124514535948, 'epsilon': 1.5904166800174762e-05, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 14, 'plateau_patience': 23, 'plateau_divider': 7}. Best is trial 8 with value: 0.9090909090909091.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.53 GiB is free. Including non-PyTorch memory, this process has 42.03 GiB memory in use. Of the allocated memory 32.55 GiB is allocated by PyTorch, and 8.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 14:05:20,046] Trial 19 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9619594971215485, 'batch_size': 45, 'attention_heads': 9, 'hidden_dimension': 119, 'number_of_hidden_layers': 3, 'dropout_rate': 0.4014292460884948, 'global_pooling': 'sum', 'learning_rate': 0.00010607291244493705, 'weight_decay': 5.9882089015385226e-05, 'beta_0': 0.8383949962158139, 'beta_1': 0.9826763331531471, 'epsilon': 1.7859440651664174e-06, 'balanced_loss': True, 'epochs': 177, 'early_stopping_patience': 23, 'plateau_patience': 13, 'plateau_divider': 5}. Best is trial 8 with value: 0.9090909090909091.
[I 2024-12-02 14:15:56,004] Trial 20 finished with value: 0.9333333333333333 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9435877279861572, 'batch_size': 28, 'attention_heads': 14, 'hidden_dimension': 67, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30183467789246166, 'global_pooling': 'mean', 'learning_rate': 0.0069653930138241504, 'weight_decay': 9.474782135262343e-05, 'beta_0': 0.8666213275077617, 'beta_1': 0.9910821608078008, 'epsilon': 3.8692941423321504e-07, 'balanced_loss': True, 'epochs': 170, 'early_stopping_patience': 18, 'plateau_patience': 18, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 14:26:10,087] Trial 21 finished with value: 0.9272727272727272 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9421598835985358, 'batch_size': 28, 'attention_heads': 14, 'hidden_dimension': 73, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31990588005286436, 'global_pooling': 'mean', 'learning_rate': 0.0041597201590134235, 'weight_decay': 0.00010813148985076637, 'beta_0': 0.8680735514401137, 'beta_1': 0.9907669850146774, 'epsilon': 3.570565784092295e-07, 'balanced_loss': True, 'epochs': 175, 'early_stopping_patience': 18, 'plateau_patience': 18, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 5.86 GiB is free. Including non-PyTorch memory, this process has 38.69 GiB memory in use. Of the allocated memory 27.89 GiB is allocated by PyTorch, and 9.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 14:34:22,897] Trial 22 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9441439324273019, 'batch_size': 28, 'attention_heads': 14, 'hidden_dimension': 70, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30178028043574195, 'global_pooling': 'mean', 'learning_rate': 0.005412694718291956, 'weight_decay': 0.0001473526860648239, 'beta_0': 0.8685671412926684, 'beta_1': 0.9878867370404925, 'epsilon': 4.2191725653226535e-07, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 18, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 14:44:56,779] Trial 23 finished with value: 0.9272727272727272 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9395847474465431, 'batch_size': 35, 'attention_heads': 15, 'hidden_dimension': 59, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30783488305008394, 'global_pooling': 'mean', 'learning_rate': 0.0866438695660128, 'weight_decay': 8.48747179847868e-05, 'beta_0': 0.8635773926855573, 'beta_1': 0.9904084243732059, 'epsilon': 1.0355251154243386e-08, 'balanced_loss': True, 'epochs': 172, 'early_stopping_patience': 16, 'plateau_patience': 18, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.79 GiB is free. Including non-PyTorch memory, this process has 39.77 GiB memory in use. Of the allocated memory 30.90 GiB is allocated by PyTorch, and 7.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 14:53:08,530] Trial 24 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9218095792760395, 'batch_size': 38, 'attention_heads': 15, 'hidden_dimension': 68, 'number_of_hidden_layers': 0, 'dropout_rate': 0.300769790888574, 'global_pooling': 'mean', 'learning_rate': 0.0799882531160043, 'weight_decay': 9.653641495694455e-05, 'beta_0': 0.866213568964, 'beta_1': 0.9904827039162708, 'epsilon': 1.614717111490225e-08, 'balanced_loss': True, 'epochs': 181, 'early_stopping_patience': 16, 'plateau_patience': 18, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.86 GiB is free. Including non-PyTorch memory, this process has 39.69 GiB memory in use. Of the allocated memory 28.42 GiB is allocated by PyTorch, and 10.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 15:01:20,285] Trial 25 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9401080781180903, 'batch_size': 33, 'attention_heads': 14, 'hidden_dimension': 56, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33458640040728066, 'global_pooling': 'mean', 'learning_rate': 0.006948999028514531, 'weight_decay': 0.000705351335655913, 'beta_0': 0.8632436234040772, 'beta_1': 0.9869549809113541, 'epsilon': 6.113320001349732e-08, 'balanced_loss': True, 'epochs': 160, 'early_stopping_patience': 14, 'plateau_patience': 16, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.77 GiB is free. Including non-PyTorch memory, this process has 39.79 GiB memory in use. Of the allocated memory 31.45 GiB is allocated by PyTorch, and 7.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 15:09:31,464] Trial 26 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9177730812170232, 'batch_size': 47, 'attention_heads': 12, 'hidden_dimension': 97, 'number_of_hidden_layers': 0, 'dropout_rate': 0.32903427782700667, 'global_pooling': 'mean', 'learning_rate': 0.08343198420935174, 'weight_decay': 0.00011572141857448745, 'beta_0': 0.8762311788484167, 'beta_1': 0.9908889068323644, 'epsilon': 1.2329175692375946e-06, 'balanced_loss': True, 'epochs': 145, 'early_stopping_patience': 20, 'plateau_patience': 13, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 15:19:40,054] Trial 27 finished with value: 0.9272727272727272 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9431129568415159, 'batch_size': 36, 'attention_heads': 15, 'hidden_dimension': 54, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3629385895894966, 'global_pooling': 'mean', 'learning_rate': 0.0032649196348338246, 'weight_decay': 5.511219797330901e-05, 'beta_0': 0.85968456160547, 'beta_1': 0.9887964346674735, 'epsilon': 2.450993537119925e-07, 'balanced_loss': True, 'epochs': 167, 'early_stopping_patience': 16, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 72.69 MiB is free. Including non-PyTorch memory, this process has 44.48 GiB memory in use. Of the allocated memory 33.39 GiB is allocated by PyTorch, and 9.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 15:27:22,628] Trial 28 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9234069464094683, 'batch_size': 53, 'attention_heads': 14, 'hidden_dimension': 100, 'number_of_hidden_layers': 1, 'dropout_rate': 0.31395752283758116, 'global_pooling': 'sum', 'learning_rate': 0.01759448072701687, 'weight_decay': 0.0003682138035557881, 'beta_0': 0.8750248451074656, 'beta_1': 0.9938475371229625, 'epsilon': 1.5129020687819063e-06, 'balanced_loss': True, 'epochs': 188, 'early_stopping_patience': 14, 'plateau_patience': 20, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 15:37:12,093] Trial 29 finished with value: 0.9090909090909091 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9372420953370018, 'batch_size': 30, 'attention_heads': 16, 'hidden_dimension': 33, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3540754039766213, 'global_pooling': 'max', 'learning_rate': 0.013689121151739104, 'weight_decay': 0.0009537686638812364, 'beta_0': 0.8568632221071039, 'beta_1': 0.991061536086367, 'epsilon': 1.230312878735322e-08, 'balanced_loss': True, 'epochs': 198, 'early_stopping_patience': 17, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.50 GiB is free. Including non-PyTorch memory, this process has 41.05 GiB memory in use. Of the allocated memory 30.86 GiB is allocated by PyTorch, and 9.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 15:44:56,509] Trial 30 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.947636806296473, 'batch_size': 20, 'attention_heads': 12, 'hidden_dimension': 78, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3841586435687818, 'global_pooling': 'mean', 'learning_rate': 0.042443875608914314, 'weight_decay': 4.274988948295524e-05, 'beta_0': 0.8535997271281148, 'beta_1': 0.9873529000211195, 'epsilon': 1.5460753684919528e-07, 'balanced_loss': True, 'epochs': 179, 'early_stopping_patience': 15, 'plateau_patience': 18, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 15:54:46,909] Trial 31 finished with value: 0.9212121212121213 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9544510545513429, 'batch_size': 35, 'attention_heads': 15, 'hidden_dimension': 57, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3507584515574218, 'global_pooling': 'mean', 'learning_rate': 0.003244546118849293, 'weight_decay': 7.391387494873439e-05, 'beta_0': 0.8611291632715787, 'beta_1': 0.9888774443523317, 'epsilon': 2.444471552936711e-07, 'balanced_loss': True, 'epochs': 156, 'early_stopping_patience': 16, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 16:05:05,796] Trial 32 finished with value: 0.9272727272727272 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9430867529160939, 'batch_size': 42, 'attention_heads': 15, 'hidden_dimension': 52, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3294666863899077, 'global_pooling': 'mean', 'learning_rate': 0.0029148862214817277, 'weight_decay': 0.00018664045473362891, 'beta_0': 0.8828804868799902, 'beta_1': 0.985565333721121, 'epsilon': 9.205667462739165e-08, 'balanced_loss': True, 'epochs': 165, 'early_stopping_patience': 19, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.69 GiB is free. Including non-PyTorch memory, this process has 39.87 GiB memory in use. Of the allocated memory 26.21 GiB is allocated by PyTorch, and 12.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 16:13:18,020] Trial 33 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9566369340411407, 'batch_size': 36, 'attention_heads': 16, 'hidden_dimension': 51, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3181441924158905, 'global_pooling': 'mean', 'learning_rate': 0.000863125180457001, 'weight_decay': 0.0001054751729690666, 'beta_0': 0.8440224529471811, 'beta_1': 0.9836170911400609, 'epsilon': 8.859490765443182e-07, 'balanced_loss': True, 'epochs': 168, 'early_stopping_patience': 15, 'plateau_patience': 15, 'plateau_divider': 7}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.76 GiB is free. Including non-PyTorch memory, this process has 39.80 GiB memory in use. Of the allocated memory 31.88 GiB is allocated by PyTorch, and 6.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 16:21:27,388] Trial 34 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9143415729036601, 'batch_size': 31, 'attention_heads': 14, 'hidden_dimension': 84, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37734230305162964, 'global_pooling': 'mean', 'learning_rate': 0.009799451408239686, 'weight_decay': 4.5849394208688093e-05, 'beta_0': 0.85751377250638, 'beta_1': 0.9885122735873335, 'epsilon': 2.694135403642761e-07, 'balanced_loss': False, 'epochs': 140, 'early_stopping_patience': 12, 'plateau_patience': 19, 'plateau_divider': 10}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 5.83 GiB is free. Including non-PyTorch memory, this process has 38.72 GiB memory in use. Of the allocated memory 28.99 GiB is allocated by PyTorch, and 8.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 16:29:38,570] Trial 35 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9359397377451523, 'batch_size': 27, 'attention_heads': 12, 'hidden_dimension': 67, 'number_of_hidden_layers': 1, 'dropout_rate': 0.34539190481030124, 'global_pooling': 'mean', 'learning_rate': 0.0007729335591808943, 'weight_decay': 0.00028020220741171737, 'beta_0': 0.8707389837717275, 'beta_1': 0.9897817408550601, 'epsilon': 3.756830532002227e-08, 'balanced_loss': False, 'epochs': 148, 'early_stopping_patience': 19, 'plateau_patience': 23, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 3.05 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.78 GiB is free. Including non-PyTorch memory, this process has 41.77 GiB memory in use. Of the allocated memory 25.87 GiB is allocated by PyTorch, and 14.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 16:38:39,707] Trial 36 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9470926557886955, 'batch_size': 33, 'attention_heads': 15, 'hidden_dimension': 103, 'number_of_hidden_layers': 0, 'dropout_rate': 0.316920763673689, 'global_pooling': 'mean', 'learning_rate': 0.002349399108678778, 'weight_decay': 6.064067749220502e-05, 'beta_0': 0.896129262321413, 'beta_1': 0.993179346049934, 'epsilon': 9.903077470737059e-08, 'balanced_loss': True, 'epochs': 186, 'early_stopping_patience': 17, 'plateau_patience': 14, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 44.56 GiB of which 5.14 GiB is free. Including non-PyTorch memory, this process has 39.41 GiB memory in use. Of the allocated memory 24.00 GiB is allocated by PyTorch, and 14.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 16:46:48,921] Trial 37 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9282981562130505, 'batch_size': 39, 'attention_heads': 16, 'hidden_dimension': 89, 'number_of_hidden_layers': 0, 'dropout_rate': 0.39975569609983014, 'global_pooling': 'max', 'learning_rate': 0.00387930100220154, 'weight_decay': 0.00014949949399755005, 'beta_0': 0.8816835461902878, 'beta_1': 0.9911468578646654, 'epsilon': 5.762813085581642e-07, 'balanced_loss': True, 'epochs': 172, 'early_stopping_patience': 13, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.51 GiB is free. Including non-PyTorch memory, this process has 40.05 GiB memory in use. Of the allocated memory 32.34 GiB is allocated by PyTorch, and 6.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 16:54:59,916] Trial 38 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9109778770123201, 'batch_size': 25, 'attention_heads': 14, 'hidden_dimension': 43, 'number_of_hidden_layers': 1, 'dropout_rate': 0.36212293733982265, 'global_pooling': 'sum', 'learning_rate': 0.0013056509078337988, 'weight_decay': 1.1963330572673158e-05, 'beta_0': 0.8519920957640856, 'beta_1': 0.986426936363804, 'epsilon': 2.987245402476689e-07, 'balanced_loss': False, 'epochs': 155, 'early_stopping_patience': 16, 'plateau_patience': 21, 'plateau_divider': 7}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 4.02 GiB. GPU 0 has a total capacity of 44.56 GiB of which 648.69 MiB is free. Including non-PyTorch memory, this process has 43.92 GiB memory in use. Of the allocated memory 30.17 GiB is allocated by PyTorch, and 12.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 17:04:03,091] Trial 39 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9265279305745152, 'batch_size': 58, 'attention_heads': 15, 'hidden_dimension': 65, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33870869230563194, 'global_pooling': 'mean', 'learning_rate': 0.026501040707976254, 'weight_decay': 8.336472381950449e-05, 'beta_0': 0.8866529048477376, 'beta_1': 0.9901064381016526, 'epsilon': 2.5162059567822462e-08, 'balanced_loss': True, 'epochs': 136, 'early_stopping_patience': 20, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 392.69 MiB is free. Including non-PyTorch memory, this process has 44.17 GiB memory in use. Of the allocated memory 29.55 GiB is allocated by PyTorch, and 13.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 17:12:15,023] Trial 40 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9318526522348879, 'batch_size': 30, 'attention_heads': 16, 'hidden_dimension': 108, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3686682046936157, 'global_pooling': 'max', 'learning_rate': 0.008852033292517224, 'weight_decay': 2.8593864119391238e-05, 'beta_0': 0.8464149469624599, 'beta_1': 0.9847424729431352, 'epsilon': 2.215871158333956e-06, 'balanced_loss': False, 'epochs': 164, 'early_stopping_patience': 21, 'plateau_patience': 14, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 17:22:29,683] Trial 41 finished with value: 0.9151515151515152 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9420321133895034, 'batch_size': 42, 'attention_heads': 15, 'hidden_dimension': 52, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3263474606167122, 'global_pooling': 'mean', 'learning_rate': 0.0020372751597011567, 'weight_decay': 0.000206866502393057, 'beta_0': 0.8825904530649732, 'beta_1': 0.9851906037467233, 'epsilon': 9.679734724846878e-08, 'balanced_loss': True, 'epochs': 165, 'early_stopping_patience': 19, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 17:32:42,996] Trial 42 finished with value: 0.9212121212121213 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.948806758637657, 'batch_size': 45, 'attention_heads': 14, 'hidden_dimension': 75, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30711351707775875, 'global_pooling': 'mean', 'learning_rate': 0.0034673005707863956, 'weight_decay': 0.0001495051261761502, 'beta_0': 0.8719398404879659, 'beta_1': 0.9810428328198362, 'epsilon': 7.973177568376002e-08, 'balanced_loss': True, 'epochs': 179, 'early_stopping_patience': 17, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.63 GiB is free. Including non-PyTorch memory, this process has 39.92 GiB memory in use. Of the allocated memory 27.97 GiB is allocated by PyTorch, and 10.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 17:40:55,116] Trial 43 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9433911761500086, 'batch_size': 42, 'attention_heads': 13, 'hidden_dimension': 48, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3261260000454018, 'global_pooling': 'mean', 'learning_rate': 0.0015180048902458897, 'weight_decay': 0.0004243297903231477, 'beta_0': 0.863175874251667, 'beta_1': 0.9880720208447372, 'epsilon': 4.24087794574307e-08, 'balanced_loss': True, 'epochs': 50, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 6}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 17:51:02,910] Trial 44 finished with value: 0.9030303030303031 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9378008372789418, 'batch_size': 40, 'attention_heads': 15, 'hidden_dimension': 32, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3877426692057587, 'global_pooling': 'mean', 'learning_rate': 0.0005709920759309558, 'weight_decay': 0.0002134592555460361, 'beta_0': 0.8950614258376183, 'beta_1': 0.9917894562748112, 'epsilon': 1.68505473440132e-07, 'balanced_loss': True, 'epochs': 151, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 18:04:48,053] Trial 45 finished with value: 0.9272727272727272 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9578436493525345, 'batch_size': 32, 'attention_heads': 16, 'hidden_dimension': 62, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3454944492416744, 'global_pooling': 'mean', 'learning_rate': 0.01338673574711661, 'weight_decay': 4.555250315560743e-05, 'beta_0': 0.8794654143987408, 'beta_1': 0.9857779230546466, 'epsilon': 1.0478400602842515e-08, 'balanced_loss': True, 'epochs': 173, 'early_stopping_patience': 19, 'plateau_patience': 15, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 18:14:15,122] Trial 46 finished with value: 0.896969696969697 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.951547520253638, 'batch_size': 28, 'attention_heads': 12, 'hidden_dimension': 45, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30008472268865877, 'global_pooling': 'mean', 'learning_rate': 0.0514856238263475, 'weight_decay': 0.00013293104939169766, 'beta_0': 0.8876173771267567, 'beta_1': 0.9891162981360894, 'epsilon': 6.6520291360561e-07, 'balanced_loss': True, 'epochs': 194, 'early_stopping_patience': 10, 'plateau_patience': 20, 'plateau_divider': 10}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.96 GiB is free. Including non-PyTorch memory, this process has 41.59 GiB memory in use. Of the allocated memory 23.14 GiB is allocated by PyTorch, and 17.30 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 18:23:18,121] Trial 47 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9448605958099441, 'batch_size': 50, 'attention_heads': 11, 'hidden_dimension': 90, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4185005071292985, 'global_pooling': 'mean', 'learning_rate': 0.02371207311954595, 'weight_decay': 0.00031585305463703426, 'beta_0': 0.8599816645208213, 'beta_1': 0.993426994920347, 'epsilon': 4.3100690827573585e-07, 'balanced_loss': True, 'epochs': 185, 'early_stopping_patience': 22, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 18:33:53,515] Trial 48 finished with value: 0.9333333333333333 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9321314280451016, 'batch_size': 36, 'attention_heads': 14, 'hidden_dimension': 60, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3168730720302968, 'global_pooling': 'max', 'learning_rate': 0.0027072053550659986, 'weight_decay': 0.00019991899452015098, 'beta_0': 0.8665668117042115, 'beta_1': 0.9950078854846914, 'epsilon': 2.1584600740903603e-07, 'balanced_loss': True, 'epochs': 65, 'early_stopping_patience': 17, 'plateau_patience': 17, 'plateau_divider': 4}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 2.36 GiB. GPU 0 has a total capacity of 44.56 GiB of which 716.69 MiB is free. Including non-PyTorch memory, this process has 43.85 GiB memory in use. Of the allocated memory 31.86 GiB is allocated by PyTorch, and 10.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 18:42:57,313] Trial 49 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9319364154701221, 'batch_size': 20, 'attention_heads': 13, 'hidden_dimension': 132, 'number_of_hidden_layers': 1, 'dropout_rate': 0.31514709649975753, 'global_pooling': 'max', 'learning_rate': 0.004646149025101562, 'weight_decay': 8.388305675890409e-05, 'beta_0': 0.8664868414755187, 'beta_1': 0.9952568112381072, 'epsilon': 8.09220543191936e-06, 'balanced_loss': False, 'epochs': 123, 'early_stopping_patience': 17, 'plateau_patience': 21, 'plateau_divider': 4}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.71 GiB is free. Including non-PyTorch memory, this process has 40.85 GiB memory in use. Of the allocated memory 30.67 GiB is allocated by PyTorch, and 9.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 18:51:10,240] Trial 50 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.923503650531764, 'batch_size': 36, 'attention_heads': 14, 'hidden_dimension': 73, 'number_of_hidden_layers': 4, 'dropout_rate': 0.33917500212676244, 'global_pooling': 'max', 'learning_rate': 0.009403994353864404, 'weight_decay': 1.0668744210321953e-06, 'beta_0': 0.8544121608256141, 'beta_1': 0.99778096952418, 'epsilon': 1.0512290449210267e-06, 'balanced_loss': True, 'epochs': 74, 'early_stopping_patience': 15, 'plateau_patience': 11, 'plateau_divider': 2}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.61 GiB is free. Including non-PyTorch memory, this process has 39.94 GiB memory in use. Of the allocated memory 28.63 GiB is allocated by PyTorch, and 10.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 18:59:23,193] Trial 51 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9385648733442576, 'batch_size': 38, 'attention_heads': 15, 'hidden_dimension': 57, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3259202734665533, 'global_pooling': 'max', 'learning_rate': 0.0025141453717247774, 'weight_decay': 0.00018760753641501208, 'beta_0': 0.8703319988845838, 'beta_1': 0.9966035145995772, 'epsilon': 2.3506457837153824e-07, 'balanced_loss': True, 'epochs': 60, 'early_stopping_patience': 18, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.65 GiB is free. Including non-PyTorch memory, this process has 42.90 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 19.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 19:07:36,004] Trial 52 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9407145678391973, 'batch_size': 45, 'attention_heads': 14, 'hidden_dimension': 41, 'number_of_hidden_layers': 0, 'dropout_rate': 0.36492100861166504, 'global_pooling': 'max', 'learning_rate': 0.0012074656639316248, 'weight_decay': 5.875502211257305e-05, 'beta_0': 0.8645270950371903, 'beta_1': 0.991480763054296, 'epsilon': 1.415985548223184e-07, 'balanced_loss': True, 'epochs': 90, 'early_stopping_patience': 16, 'plateau_patience': 17, 'plateau_divider': 4}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 402.69 MiB is free. Including non-PyTorch memory, this process has 44.16 GiB memory in use. Of the allocated memory 29.21 GiB is allocated by PyTorch, and 13.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 19:15:48,000] Trial 53 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9342658545114363, 'batch_size': 35, 'attention_heads': 13, 'hidden_dimension': 85, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3138762109612915, 'global_pooling': 'max', 'learning_rate': 0.0025132810423045947, 'weight_decay': 0.0005003618767200846, 'beta_0': 0.8741922273691969, 'beta_1': 0.9925487053350184, 'epsilon': 3.109306910826764e-07, 'balanced_loss': True, 'epochs': 164, 'early_stopping_patience': 19, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.37 GiB is free. Including non-PyTorch memory, this process has 43.19 GiB memory in use. Of the allocated memory 27.02 GiB is allocated by PyTorch, and 15.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 19:24:00,916] Trial 54 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9504260461713412, 'batch_size': 43, 'attention_heads': 15, 'hidden_dimension': 255, 'number_of_hidden_layers': 0, 'dropout_rate': 0.33583119104299747, 'global_pooling': 'sum', 'learning_rate': 0.006162342057048507, 'weight_decay': 0.0002316559580756312, 'beta_0': 0.849235630337492, 'beta_1': 0.9841671804418495, 'epsilon': 5.030456573532623e-07, 'balanced_loss': True, 'epochs': 78, 'early_stopping_patience': 17, 'plateau_patience': 19, 'plateau_divider': 6}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 19:35:18,088] Trial 55 finished with value: 0.9272727272727272 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9583469248088327, 'batch_size': 26, 'attention_heads': 16, 'hidden_dimension': 58, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3570909348029379, 'global_pooling': 'mean', 'learning_rate': 0.0016905046595424075, 'weight_decay': 0.00017009929245966328, 'beta_0': 0.8914437431022826, 'beta_1': 0.9904742646510074, 'epsilon': 1.1672806958793302e-07, 'balanced_loss': True, 'epochs': 173, 'early_stopping_patience': 18, 'plateau_patience': 15, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 44.56 GiB of which 5.14 GiB is free. Including non-PyTorch memory, this process has 39.41 GiB memory in use. Of the allocated memory 23.98 GiB is allocated by PyTorch, and 14.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 19:43:29,559] Trial 56 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9286567578882484, 'batch_size': 29, 'attention_heads': 15, 'hidden_dimension': 77, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31105516025202457, 'global_pooling': 'mean', 'learning_rate': 0.0005055989552538837, 'weight_decay': 3.6236717649250644e-05, 'beta_0': 0.8585964193781116, 'beta_1': 0.9944539131716189, 'epsilon': 6.268662217432272e-08, 'balanced_loss': True, 'epochs': 183, 'early_stopping_patience': 15, 'plateau_patience': 20, 'plateau_divider': 5}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.79 GiB is free. Including non-PyTorch memory, this process has 41.76 GiB memory in use. Of the allocated memory 27.65 GiB is allocated by PyTorch, and 12.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 19:53:28,176] Trial 57 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9457838702757535, 'batch_size': 33, 'attention_heads': 14, 'hidden_dimension': 160, 'number_of_hidden_layers': 2, 'dropout_rate': 0.32283739787449284, 'global_pooling': 'mean', 'learning_rate': 0.004149672696264454, 'weight_decay': 0.00011324599407821485, 'beta_0': 0.8843145863934653, 'beta_1': 0.9826355087581999, 'epsilon': 4.1403286246459685e-07, 'balanced_loss': True, 'epochs': 63, 'early_stopping_patience': 16, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 20:03:26,479] Trial 58 finished with value: 0.9333333333333333 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9420883505779709, 'batch_size': 39, 'attention_heads': 13, 'hidden_dimension': 48, 'number_of_hidden_layers': 0, 'dropout_rate': 0.34486575273473385, 'global_pooling': 'mean', 'learning_rate': 0.007725233936821973, 'weight_decay': 2.2608770709848288e-05, 'beta_0': 0.879714225604061, 'beta_1': 0.9876720515081362, 'epsilon': 2.020216341655336e-07, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 18, 'plateau_patience': 18, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 44.56 GiB of which 5.50 GiB is free. Including non-PyTorch memory, this process has 39.06 GiB memory in use. Of the allocated memory 16.95 GiB is allocated by PyTorch, and 20.95 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 20:11:38,350] Trial 59 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9350321303182181, 'batch_size': 38, 'attention_heads': 13, 'hidden_dimension': 36, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3446512405336218, 'global_pooling': 'max', 'learning_rate': 0.007305695427072494, 'weight_decay': 2.1792604906123266e-05, 'beta_0': 0.8682513600876892, 'beta_1': 0.9873961017942465, 'epsilon': 2.0742753120803705e-07, 'balanced_loss': True, 'epochs': 104, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 10}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.40 GiB is free. Including non-PyTorch memory, this process has 42.16 GiB memory in use. Of the allocated memory 33.38 GiB is allocated by PyTorch, and 7.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 20:19:48,811] Trial 60 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9029682511556215, 'batch_size': 40, 'attention_heads': 10, 'hidden_dimension': 65, 'number_of_hidden_layers': 0, 'dropout_rate': 0.30707026369398677, 'global_pooling': 'sum', 'learning_rate': 1.7711601745251386e-05, 'weight_decay': 1.1065146501683455e-05, 'beta_0': 0.8786023850194549, 'beta_1': 0.9895669195019342, 'epsilon': 8.242052721554529e-07, 'balanced_loss': True, 'epochs': 132, 'early_stopping_patience': 20, 'plateau_patience': 18, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 20:29:46,830] Trial 61 finished with value: 0.9151515151515152 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.940292826699109, 'batch_size': 43, 'attention_heads': 14, 'hidden_dimension': 49, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3308130308841324, 'global_pooling': 'mean', 'learning_rate': 0.0030843557905072196, 'weight_decay': 8.924325267745243e-05, 'beta_0': 0.8736897008211568, 'beta_1': 0.9860793160186629, 'epsilon': 1.884916478055354e-07, 'balanced_loss': True, 'epochs': 116, 'early_stopping_patience': 17, 'plateau_patience': 17, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 20:39:40,893] Trial 62 finished with value: 0.9333333333333333 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9434734835276772, 'batch_size': 37, 'attention_heads': 12, 'hidden_dimension': 45, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37385445836199627, 'global_pooling': 'mean', 'learning_rate': 0.01924456409406355, 'weight_decay': 5.215880609027194e-05, 'beta_0': 0.8773920122392571, 'beta_1': 0.9883871854793908, 'epsilon': 3.116968780921683e-08, 'balanced_loss': True, 'epochs': 95, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.24 GiB. GPU 0 has a total capacity of 44.56 GiB of which 306.69 MiB is free. Including non-PyTorch memory, this process has 44.25 GiB memory in use. Of the allocated memory 31.61 GiB is allocated by PyTorch, and 11.50 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 20:48:43,705] Trial 63 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9488652011727885, 'batch_size': 35, 'attention_heads': 12, 'hidden_dimension': 235, 'number_of_hidden_layers': 0, 'dropout_rate': 0.39319230755608114, 'global_pooling': 'mean', 'learning_rate': 0.060444269707854145, 'weight_decay': 2.1388968543937996e-05, 'beta_0': 0.8622148073065014, 'beta_1': 0.988451496002969, 'epsilon': 1.7939707636413225e-08, 'balanced_loss': True, 'epochs': 97, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 20:58:26,971] Trial 64 finished with value: 0.9272727272727272 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9538783426145471, 'batch_size': 37, 'attention_heads': 13, 'hidden_dimension': 40, 'number_of_hidden_layers': 0, 'dropout_rate': 0.37453647929243233, 'global_pooling': 'mean', 'learning_rate': 0.02158746367262588, 'weight_decay': 5.28088851649853e-05, 'beta_0': 0.8675590085193433, 'beta_1': 0.9874011120560524, 'epsilon': 3.6706820108145495e-08, 'balanced_loss': True, 'epochs': 120, 'early_stopping_patience': 16, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 392.69 MiB is free. Including non-PyTorch memory, this process has 44.17 GiB memory in use. Of the allocated memory 29.60 GiB is allocated by PyTorch, and 13.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 21:06:38,739] Trial 65 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9314702939951978, 'batch_size': 31, 'attention_heads': 12, 'hidden_dimension': 61, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3531659017295972, 'global_pooling': 'mean', 'learning_rate': 0.03066267251255246, 'weight_decay': 3.496895082799721e-05, 'beta_0': 0.8782188155771606, 'beta_1': 0.9901385570723354, 'epsilon': 1.4098232289192618e-08, 'balanced_loss': True, 'epochs': 82, 'early_stopping_patience': 17, 'plateau_patience': 20, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 21:16:51,997] Trial 66 finished with value: 0.9151515151515152 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9192449733653911, 'batch_size': 34, 'attention_heads': 9, 'hidden_dimension': 72, 'number_of_hidden_layers': 0, 'dropout_rate': 0.46329945718657833, 'global_pooling': 'mean', 'learning_rate': 0.012641275385434247, 'weight_decay': 6.572983115573432e-05, 'beta_0': 0.8554126275552837, 'beta_1': 0.9892193852915573, 'epsilon': 2.1613822089480637e-08, 'balanced_loss': True, 'epochs': 99, 'early_stopping_patience': 15, 'plateau_patience': 21, 'plateau_divider': 7}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 21:27:34,697] Trial 67 finished with value: 0.9272727272727272 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.937535574375194, 'batch_size': 24, 'attention_heads': 11, 'hidden_dimension': 81, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5944571682991443, 'global_pooling': 'mean', 'learning_rate': 0.005384461164969361, 'weight_decay': 5.014966963983882e-06, 'beta_0': 0.8725148107571923, 'beta_1': 0.9867311230836692, 'epsilon': 3.203266682708821e-07, 'balanced_loss': True, 'epochs': 114, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 10}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 5.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.34 GiB is free. Including non-PyTorch memory, this process has 40.22 GiB memory in use. Of the allocated memory 31.20 GiB is allocated by PyTorch, and 7.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 21:35:18,098] Trial 68 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9443894990180007, 'batch_size': 37, 'attention_heads': 13, 'hidden_dimension': 46, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4165587579517379, 'global_pooling': 'mean', 'learning_rate': 0.01776469380573772, 'weight_decay': 7.302063407223402e-05, 'beta_0': 0.8655764398886596, 'beta_1': 0.987837488670894, 'epsilon': 6.749694320285001e-08, 'balanced_loss': False, 'epochs': 108, 'early_stopping_patience': 14, 'plateau_patience': 16, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 3.30 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.12 GiB is free. Including non-PyTorch memory, this process has 41.43 GiB memory in use. Of the allocated memory 24.00 GiB is allocated by PyTorch, and 16.28 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 21:44:21,245] Trial 69 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9249980672263424, 'batch_size': 32, 'attention_heads': 14, 'hidden_dimension': 96, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3008044378082169, 'global_pooling': 'mean', 'learning_rate': 0.03875078251248322, 'weight_decay': 2.678881051310892e-05, 'beta_0': 0.8765798285194334, 'beta_1': 0.9887375526969591, 'epsilon': 4.985767322016744e-08, 'balanced_loss': True, 'epochs': 85, 'early_stopping_patience': 16, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 21:53:47,995] Trial 70 finished with value: 0.9212121212121213 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9663233378482912, 'batch_size': 64, 'attention_heads': 6, 'hidden_dimension': 55, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3204475742547746, 'global_pooling': 'mean', 'learning_rate': 0.009074990034650033, 'weight_decay': 0.0001238879603713906, 'beta_0': 0.8410461380663551, 'beta_1': 0.9929515112086378, 'epsilon': 3.268886674000317e-08, 'balanced_loss': True, 'epochs': 70, 'early_stopping_patience': 20, 'plateau_patience': 22, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 22:04:12,273] Trial 71 finished with value: 0.9212121212121213 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9419938968429411, 'batch_size': 40, 'attention_heads': 15, 'hidden_dimension': 67, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3341829585500893, 'global_pooling': 'mean', 'learning_rate': 0.005122202861240521, 'weight_decay': 0.00010202089076241218, 'beta_0': 0.8825219207811014, 'beta_1': 0.9855938926226351, 'epsilon': 1.2900447776886932e-07, 'balanced_loss': True, 'epochs': 158, 'early_stopping_patience': 19, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 44.56 GiB of which 5.22 GiB is free. Including non-PyTorch memory, this process has 39.34 GiB memory in use. Of the allocated memory 21.56 GiB is allocated by PyTorch, and 16.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 22:12:27,506] Trial 72 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9464900292600267, 'batch_size': 49, 'attention_heads': 14, 'hidden_dimension': 50, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3451698179242946, 'global_pooling': 'mean', 'learning_rate': 0.007183290176746365, 'weight_decay': 5.118199655749922e-05, 'beta_0': 0.8899455385378519, 'beta_1': 0.9904883812689049, 'epsilon': 9.126519977224286e-08, 'balanced_loss': True, 'epochs': 177, 'early_stopping_patience': 18, 'plateau_patience': 18, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 22:23:31,214] Trial 73 finished with value: 0.896969696969697 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9394200623908233, 'batch_size': 41, 'attention_heads': 15, 'hidden_dimension': 39, 'number_of_hidden_layers': 0, 'dropout_rate': 0.36241521339608385, 'global_pooling': 'mean', 'learning_rate': 0.09779616826694827, 'weight_decay': 0.00025156068044684856, 'beta_0': 0.8693527442059318, 'beta_1': 0.9919032171312449, 'epsilon': 5.375326803629764e-07, 'balanced_loss': True, 'epochs': 162, 'early_stopping_patience': 21, 'plateau_patience': 17, 'plateau_divider': 9}. Best is trial 20 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 3.22 GiB. GPU 0 has a total capacity of 44.56 GiB of which 40.69 MiB is free. Including non-PyTorch memory, this process has 44.51 GiB memory in use. Of the allocated memory 25.75 GiB is allocated by PyTorch, and 17.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 22:32:42,172] Trial 74 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9342444388876356, 'batch_size': 44, 'attention_heads': 16, 'hidden_dimension': 59, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3078028128810706, 'global_pooling': 'mean', 'learning_rate': 0.002969906489213371, 'weight_decay': 4.122615180023566e-05, 'beta_0': 0.8853435220599531, 'beta_1': 0.9897091932827251, 'epsilon': 2.7695104943049592e-08, 'balanced_loss': True, 'epochs': 190, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 22:42:38,670] Trial 75 finished with value: 0.9212121212121213 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9513196343574373, 'batch_size': 39, 'attention_heads': 13, 'hidden_dimension': 52, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3216886460216989, 'global_pooling': 'mean', 'learning_rate': 0.012155897276340815, 'weight_decay': 0.00016720726936925168, 'beta_0': 0.860472683956711, 'beta_1': 0.9878612952128158, 'epsilon': 1.1746390106973209e-07, 'balanced_loss': True, 'epochs': 167, 'early_stopping_patience': 17, 'plateau_patience': 15, 'plateau_divider': 8}. Best is trial 20 with value: 0.9333333333333333.
[I 2024-12-02 22:53:33,537] Trial 76 finished with value: 0.9454545454545454 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9428352518235366, 'batch_size': 36, 'attention_heads': 14, 'hidden_dimension': 32, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5793842599734286, 'global_pooling': 'mean', 'learning_rate': 0.0010178472910452397, 'weight_decay': 1.784267128614988e-05, 'beta_0': 0.8805174906838046, 'beta_1': 0.9867368225734552, 'epsilon': 2.0865708114145153e-07, 'balanced_loss': True, 'epochs': 170, 'early_stopping_patience': 18, 'plateau_patience': 18, 'plateau_divider': 9}. Best is trial 76 with value: 0.9454545454545454.
[I 2024-12-02 23:04:44,099] Trial 77 finished with value: 0.8909090909090909 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9557530391190421, 'batch_size': 34, 'attention_heads': 13, 'hidden_dimension': 35, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3783516102207564, 'global_pooling': 'sum', 'learning_rate': 0.0010767786394868036, 'weight_decay': 1.4241808030468238e-05, 'beta_0': 0.8792273380714272, 'beta_1': 0.9868008668748119, 'epsilon': 3.838990867385714e-07, 'balanced_loss': True, 'epochs': 175, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 10}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.53 GiB is free. Including non-PyTorch memory, this process has 42.02 GiB memory in use. Of the allocated memory 28.86 GiB is allocated by PyTorch, and 12.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 23:13:00,477] Trial 78 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9364096474441348, 'batch_size': 36, 'attention_heads': 14, 'hidden_dimension': 45, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5226432288093578, 'global_pooling': 'max', 'learning_rate': 0.0008576845138823247, 'weight_decay': 1.693857036590321e-05, 'beta_0': 0.875304888263204, 'beta_1': 0.9883544600589663, 'epsilon': 2.0317663971217586e-07, 'balanced_loss': True, 'epochs': 128, 'early_stopping_patience': 17, 'plateau_patience': 20, 'plateau_divider': 9}. Best is trial 76 with value: 0.9454545454545454.
[I 2024-12-02 23:24:19,497] Trial 79 finished with value: 0.9151515151515152 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.928878422161694, 'batch_size': 29, 'attention_heads': 12, 'hidden_dimension': 64, 'number_of_hidden_layers': 1, 'dropout_rate': 0.5833996953764744, 'global_pooling': 'mean', 'learning_rate': 0.001876507054947176, 'weight_decay': 2.9629345291792226e-05, 'beta_0': 0.8711809513189848, 'beta_1': 0.9910173852668624, 'epsilon': 1.0039324903191494e-08, 'balanced_loss': False, 'epochs': 170, 'early_stopping_patience': 13, 'plateau_patience': 18, 'plateau_divider': 9}. Best is trial 76 with value: 0.9454545454545454.
[I 2024-12-02 23:34:39,791] Trial 80 finished with value: 0.9454545454545454 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9605932061739486, 'batch_size': 38, 'attention_heads': 14, 'hidden_dimension': 70, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5604962439425343, 'global_pooling': 'mean', 'learning_rate': 0.016975228339310124, 'weight_decay': 1.0320654511533209e-05, 'beta_0': 0.851595456160874, 'beta_1': 0.9952373769398456, 'epsilon': 1.3046104023342964e-06, 'balanced_loss': True, 'epochs': 150, 'early_stopping_patience': 18, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 76 with value: 0.9454545454545454.
[I 2024-12-02 23:46:18,762] Trial 81 finished with value: 0.8848484848484849 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9424453262964797, 'batch_size': 39, 'attention_heads': 14, 'hidden_dimension': 73, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5637913541630858, 'global_pooling': 'mean', 'learning_rate': 0.00018894337994197045, 'weight_decay': 4.476764415788337e-06, 'beta_0': 0.8516404327265775, 'beta_1': 0.9963957793561745, 'epsilon': 2.103526833464557e-06, 'balanced_loss': True, 'epochs': 154, 'early_stopping_patience': 18, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 5.61 GiB is free. Including non-PyTorch memory, this process has 38.94 GiB memory in use. Of the allocated memory 23.61 GiB is allocated by PyTorch, and 14.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-02 23:54:33,965] Trial 82 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.976124794422155, 'batch_size': 32, 'attention_heads': 10, 'hidden_dimension': 43, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5723188637405382, 'global_pooling': 'mean', 'learning_rate': 0.015291546412590106, 'weight_decay': 1.1400954462495487e-05, 'beta_0': 0.8568764528067382, 'beta_1': 0.9891934055186988, 'epsilon': 2.666774617562388e-07, 'balanced_loss': True, 'epochs': 182, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 10}. Best is trial 76 with value: 0.9454545454545454.
[I 2024-12-03 00:04:16,921] Trial 83 finished with value: 0.9272727272727272 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9484150827059589, 'batch_size': 37, 'attention_heads': 13, 'hidden_dimension': 34, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5511075266607969, 'global_pooling': 'mean', 'learning_rate': 0.033522487702936005, 'weight_decay': 8.974580827846867e-06, 'beta_0': 0.8634672578995322, 'beta_1': 0.9951341091489093, 'epsilon': 1.4277586641565572e-06, 'balanced_loss': True, 'epochs': 140, 'early_stopping_patience': 17, 'plateau_patience': 16, 'plateau_divider': 9}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 44.56 GiB of which 5.27 GiB is free. Including non-PyTorch memory, this process has 39.28 GiB memory in use. Of the allocated memory 19.71 GiB is allocated by PyTorch, and 18.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-03 00:12:31,657] Trial 84 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9603418090715787, 'batch_size': 36, 'attention_heads': 14, 'hidden_dimension': 87, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5852857012271468, 'global_pooling': 'mean', 'learning_rate': 0.020116308226372087, 'weight_decay': 8.69801982326116e-06, 'beta_0': 0.8485673969377832, 'beta_1': 0.9973106199079084, 'epsilon': 6.846064085946305e-07, 'balanced_loss': True, 'epochs': 146, 'early_stopping_patience': 16, 'plateau_patience': 18, 'plateau_divider': 5}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.56 GiB is free. Including non-PyTorch memory, this process has 40.99 GiB memory in use. Of the allocated memory 27.65 GiB is allocated by PyTorch, and 12.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-03 00:20:46,711] Trial 85 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9458438200473632, 'batch_size': 34, 'attention_heads': 15, 'hidden_dimension': 79, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5991365320298793, 'global_pooling': 'mean', 'learning_rate': 0.0037869134467686232, 'weight_decay': 1.7211328961017291e-06, 'beta_0': 0.860532279110693, 'beta_1': 0.9935786251815742, 'epsilon': 3.2925880363887426e-06, 'balanced_loss': True, 'epochs': 151, 'early_stopping_patience': 18, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 5.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.84 GiB is free. Including non-PyTorch memory, this process has 42.71 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 11.23 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-03 00:28:32,950] Trial 86 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9530325496797668, 'batch_size': 38, 'attention_heads': 14, 'hidden_dimension': 70, 'number_of_hidden_layers': 0, 'dropout_rate': 0.473388222359301, 'global_pooling': 'mean', 'learning_rate': 0.0107787093064563, 'weight_decay': 2.4313317618219132e-05, 'beta_0': 0.8444019899922838, 'beta_1': 0.98726452341402, 'epsilon': 1.2023720223595209e-06, 'balanced_loss': True, 'epochs': 169, 'early_stopping_patience': 17, 'plateau_patience': 25, 'plateau_divider': 7}. Best is trial 76 with value: 0.9454545454545454.
[I 2024-12-03 00:38:43,801] Trial 87 finished with value: 0.9272727272727272 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9401868118688695, 'batch_size': 22, 'attention_heads': 15, 'hidden_dimension': 55, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5378365560520404, 'global_pooling': 'max', 'learning_rate': 0.007331682243284406, 'weight_decay': 1.7547753022219185e-05, 'beta_0': 0.8809528229489914, 'beta_1': 0.9956470104230094, 'epsilon': 1.567131970681158e-07, 'balanced_loss': True, 'epochs': 161, 'early_stopping_patience': 18, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.43 GiB is free. Including non-PyTorch memory, this process has 43.12 GiB memory in use. Of the allocated memory 24.98 GiB is allocated by PyTorch, and 17.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-03 00:46:58,447] Trial 88 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9653971571907191, 'batch_size': 41, 'attention_heads': 13, 'hidden_dimension': 61, 'number_of_hidden_layers': 2, 'dropout_rate': 0.307626175447355, 'global_pooling': 'mean', 'learning_rate': 0.052973159272251075, 'weight_decay': 7.774947461789233e-05, 'beta_0': 0.8663395606708708, 'beta_1': 0.9914550860935833, 'epsilon': 9.425961433649074e-07, 'balanced_loss': True, 'epochs': 92, 'early_stopping_patience': 20, 'plateau_patience': 19, 'plateau_divider': 9}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.90 GiB is free. Including non-PyTorch memory, this process has 39.65 GiB memory in use. Of the allocated memory 27.05 GiB is allocated by PyTorch, and 11.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-03 00:55:13,209] Trial 89 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9504205296262782, 'batch_size': 30, 'attention_heads': 15, 'hidden_dimension': 107, 'number_of_hidden_layers': 0, 'dropout_rate': 0.44943542245026824, 'global_pooling': 'mean', 'learning_rate': 0.002178662270982876, 'weight_decay': 3.9907873364894276e-05, 'beta_0': 0.8583425793389885, 'beta_1': 0.9942342911902939, 'epsilon': 3.3173586931437715e-07, 'balanced_loss': True, 'epochs': 196, 'early_stopping_patience': 16, 'plateau_patience': 19, 'plateau_divider': 8}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 5.23 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.24 GiB is free. Including non-PyTorch memory, this process has 40.32 GiB memory in use. Of the allocated memory 28.96 GiB is allocated by PyTorch, and 10.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-03 01:04:18,687] Trial 90 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9309947087284696, 'batch_size': 27, 'attention_heads': 14, 'hidden_dimension': 195, 'number_of_hidden_layers': 1, 'dropout_rate': 0.33889446782582344, 'global_pooling': 'mean', 'learning_rate': 0.0007024644623559729, 'weight_decay': 6.437878615789644e-06, 'beta_0': 0.8532672844593568, 'beta_1': 0.9862687250787657, 'epsilon': 4.942152895607823e-07, 'balanced_loss': False, 'epochs': 176, 'early_stopping_patience': 15, 'plateau_patience': 20, 'plateau_divider': 6}. Best is trial 76 with value: 0.9454545454545454.
[I 2024-12-03 01:14:34,388] Trial 91 finished with value: 0.9272727272727272 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9439227955970521, 'batch_size': 41, 'attention_heads': 15, 'hidden_dimension': 50, 'number_of_hidden_layers': 0, 'dropout_rate': 0.490302230143808, 'global_pooling': 'mean', 'learning_rate': 0.004500032423364718, 'weight_decay': 0.00012770036190870387, 'beta_0': 0.8766043249895911, 'beta_1': 0.9852355100389614, 'epsilon': 2.3133751946737495e-07, 'balanced_loss': True, 'epochs': 166, 'early_stopping_patience': 19, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 76 with value: 0.9454545454545454.
[I 2024-12-03 01:24:57,614] Trial 92 finished with value: 0.9212121212121213 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9423870207728497, 'batch_size': 47, 'attention_heads': 16, 'hidden_dimension': 53, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3298317672274852, 'global_pooling': 'mean', 'learning_rate': 0.002906961992258913, 'weight_decay': 1.3523739151107577e-05, 'beta_0': 0.8847869715447665, 'beta_1': 0.9844117636533807, 'epsilon': 7.700830994922822e-08, 'balanced_loss': True, 'epochs': 158, 'early_stopping_patience': 19, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 76 with value: 0.9454545454545454.
[I 2024-12-03 01:34:58,384] Trial 93 finished with value: 0.9151515151515152 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9470973539933151, 'batch_size': 39, 'attention_heads': 14, 'hidden_dimension': 39, 'number_of_hidden_layers': 0, 'dropout_rate': 0.5724342526617078, 'global_pooling': 'mean', 'learning_rate': 0.001382692844092787, 'weight_decay': 0.0001794319849605948, 'beta_0': 0.8044476809640742, 'beta_1': 0.9889064448035791, 'epsilon': 1.1250502849451804e-07, 'balanced_loss': True, 'epochs': 171, 'early_stopping_patience': 18, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 76 with value: 0.9454545454545454.
[I 2024-12-03 01:45:23,406] Trial 94 finished with value: 0.9272727272727272 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9373140468369093, 'batch_size': 35, 'attention_heads': 15, 'hidden_dimension': 68, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3710299295344648, 'global_pooling': 'mean', 'learning_rate': 0.0082350553463534, 'weight_decay': 9.702232549770276e-05, 'beta_0': 0.8922105608570573, 'beta_1': 0.9901647286454414, 'epsilon': 4.8184670475456645e-08, 'balanced_loss': True, 'epochs': 179, 'early_stopping_patience': 17, 'plateau_patience': 18, 'plateau_divider': 9}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 398.69 MiB is free. Including non-PyTorch memory, this process has 44.16 GiB memory in use. Of the allocated memory 29.34 GiB is allocated by PyTorch, and 13.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-03 01:53:37,891] Trial 95 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9335390377509021, 'batch_size': 42, 'attention_heads': 14, 'hidden_dimension': 47, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3157661875304768, 'global_pooling': 'sum', 'learning_rate': 0.006005417583167681, 'weight_decay': 0.0002790103166641617, 'beta_0': 0.8993194651698941, 'beta_1': 0.9878744279838465, 'epsilon': 1.4855437985913993e-07, 'balanced_loss': True, 'epochs': 135, 'early_stopping_patience': 20, 'plateau_patience': 16, 'plateau_divider': 8}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 5.06 GiB is free. Including non-PyTorch memory, this process has 39.49 GiB memory in use. Of the allocated memory 28.44 GiB is allocated by PyTorch, and 9.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-03 02:01:53,803] Trial 96 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9396679090962956, 'batch_size': 33, 'attention_heads': 16, 'hidden_dimension': 63, 'number_of_hidden_layers': 0, 'dropout_rate': 0.35948027752365164, 'global_pooling': 'max', 'learning_rate': 0.003600215064862651, 'weight_decay': 5.30540131687716e-05, 'beta_0': 0.8882371618243972, 'beta_1': 0.9947855701289444, 'epsilon': 1.8392989226486162e-08, 'balanced_loss': True, 'epochs': 186, 'early_stopping_patience': 22, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 5.85 GiB is free. Including non-PyTorch memory, this process has 38.70 GiB memory in use. Of the allocated memory 28.16 GiB is allocated by PyTorch, and 9.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-03 02:10:08,633] Trial 97 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9420959494841193, 'batch_size': 37, 'attention_heads': 15, 'hidden_dimension': 58, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3491176886539088, 'global_pooling': 'mean', 'learning_rate': 0.06759075015987935, 'weight_decay': 6.656718697757123e-05, 'beta_0': 0.873183099164908, 'beta_1': 0.9907190945935386, 'epsilon': 1.7223721261296827e-07, 'balanced_loss': True, 'epochs': 58, 'early_stopping_patience': 18, 'plateau_patience': 18, 'plateau_divider': 5}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 406.69 MiB is free. Including non-PyTorch memory, this process has 44.16 GiB memory in use. Of the allocated memory 28.98 GiB is allocated by PyTorch, and 14.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-03 02:18:23,437] Trial 98 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9360426040882645, 'batch_size': 35, 'attention_heads': 13, 'hidden_dimension': 32, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3404560629487529, 'global_pooling': 'mean', 'learning_rate': 0.002326616363486209, 'weight_decay': 0.0003397190830111145, 'beta_0': 0.8698377399426486, 'beta_1': 0.9970581818144151, 'epsilon': 2.487797266331569e-07, 'balanced_loss': True, 'epochs': 68, 'early_stopping_patience': 11, 'plateau_patience': 17, 'plateau_divider': 9}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 2.68 GiB. GPU 0 has a total capacity of 44.56 GiB of which 174.69 MiB is free. Including non-PyTorch memory, this process has 44.38 GiB memory in use. Of the allocated memory 32.33 GiB is allocated by PyTorch, and 10.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-03 02:29:27,625] Trial 99 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9490335556683658, 'batch_size': 43, 'attention_heads': 14, 'hidden_dimension': 76, 'number_of_hidden_layers': 1, 'dropout_rate': 0.32354769446694837, 'global_pooling': 'mean', 'learning_rate': 0.01594440523526265, 'weight_decay': 0.00014883774271316034, 'beta_0': 0.8650975194228303, 'beta_1': 0.9982236475220317, 'epsilon': 3.780869973916113e-07, 'balanced_loss': True, 'epochs': 152, 'early_stopping_patience': 19, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 76 with value: 0.9454545454545454.
[I 2024-12-03 02:40:00,368] Trial 100 finished with value: 0.9333333333333333 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.984212305913395, 'batch_size': 31, 'attention_heads': 13, 'hidden_dimension': 210, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3127956381487411, 'global_pooling': 'mean', 'learning_rate': 0.010573043617167044, 'weight_decay': 3.339875026875211e-05, 'beta_0': 0.8802315621019587, 'beta_1': 0.9833113287803278, 'epsilon': 6.461846148262491e-07, 'balanced_loss': True, 'epochs': 173, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 9}. Best is trial 76 with value: 0.9454545454545454.
CUDA out of memory. Tried to allocate 5.99 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.63 GiB is free. Including non-PyTorch memory, this process has 41.92 GiB memory in use. Of the allocated memory 21.69 GiB is allocated by PyTorch, and 19.09 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-03 02:48:14,961] Trial 101 finished with value: -1.0 and parameters: {'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9907296352978173, 'batch_size': 28, 'attention_heads': 13, 'hidden_dimension': 232, 'number_of_hidden_layers': 0, 'dropout_rate': 0.31088206308377764, 'global_pooling': 'mean', 'learning_rate': 0.011759038401584598, 'weight_decay': 1.9981071571469197e-05, 'beta_0': 0.8842375644831796, 'beta_1': 0.9800557390062659, 'epsilon': 5.806655218664776e-07, 'balanced_loss': True, 'epochs': 173, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 9}. Best is trial 76 with value: 0.9454545454545454.
slurmstepd: error: *** JOB 14043392 ON gpu032 CANCELLED AT 2024-12-03T02:49:49 DUE TO TIME LIMIT ***
