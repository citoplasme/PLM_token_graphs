Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2024-12-21 04:10:24,925] Using an existing study with name 'IMDb-top_1000-GATv2-FacebookAI-roberta-large-Surrogate-No_Aggregation' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 512). Running this sequence through the model will result in indexing errors
[I 2024-12-21 04:30:58,333] Trial 135 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9968803518238317, 'batch_size': 46, 'attention_heads': 8, 'hidden_dimension': 165, 'number_of_hidden_layers': 2, 'dropout_rate': 0.43487740231074257, 'global_pooling': 'mean', 'learning_rate': 0.001818405363084864, 'weight_decay': 2.1925155971100392e-05, 'beta_0': 0.8495814641368146, 'beta_1': 0.9861164984000526, 'epsilon': 1.4166070669946932e-08, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 14, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 04:51:26,613] Trial 136 finished with value: 0.9151515151515152 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9979004649815592, 'batch_size': 43, 'attention_heads': 7, 'hidden_dimension': 237, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4107962006186849, 'global_pooling': 'mean', 'learning_rate': 0.0009835204788589465, 'weight_decay': 2.681858513334698e-05, 'beta_0': 0.8440000966498598, 'beta_1': 0.9968894858712878, 'epsilon': 1.9103069540225687e-08, 'balanced_loss': True, 'epochs': 175, 'early_stopping_patience': 13, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 05:11:09,832] Trial 137 finished with value: 0.9212121212121213 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9959322984826684, 'batch_size': 41, 'attention_heads': 8, 'hidden_dimension': 247, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4000934087638159, 'global_pooling': 'mean', 'learning_rate': 0.0012021706113758768, 'weight_decay': 1.2298487746894066e-05, 'beta_0': 0.8474962810868947, 'beta_1': 0.9888773067260098, 'epsilon': 3.869428976898032e-08, 'balanced_loss': True, 'epochs': 179, 'early_stopping_patience': 15, 'plateau_patience': 17, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 05:36:56,594] Trial 138 finished with value: 0.9454545454545454 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9918596295920717, 'batch_size': 46, 'attention_heads': 6, 'hidden_dimension': 222, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3880905849872322, 'global_pooling': 'mean', 'learning_rate': 0.0015214990632329034, 'weight_decay': 4.135143047594919e-05, 'beta_0': 0.8556986034233345, 'beta_1': 0.9883669453887188, 'epsilon': 1.0394798761085472e-08, 'balanced_loss': True, 'epochs': 184, 'early_stopping_patience': 12, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 06:01:25,816] Trial 139 finished with value: 0.8242424242424242 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9922915128936592, 'batch_size': 47, 'attention_heads': 6, 'hidden_dimension': 237, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3678576692240983, 'global_pooling': 'sum', 'learning_rate': 0.04111834324236489, 'weight_decay': 1.4786275433693728e-06, 'beta_0': 0.8510884060837002, 'beta_1': 0.987881836172107, 'epsilon': 1.0018686959441902e-08, 'balanced_loss': True, 'epochs': 183, 'early_stopping_patience': 12, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 2.17 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.61 GiB is free. Including non-PyTorch memory, this process has 42.94 GiB memory in use. Of the allocated memory 35.65 GiB is allocated by PyTorch, and 6.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 06:23:11,277] Trial 140 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9875584382880518, 'batch_size': 45, 'attention_heads': 6, 'hidden_dimension': 215, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3851992792990921, 'global_pooling': 'mean', 'learning_rate': 0.0015624130952708786, 'weight_decay': 4.266260550344405e-05, 'beta_0': 0.8553231764644671, 'beta_1': 0.9884611964923485, 'epsilon': 2.3803817563436722e-08, 'balanced_loss': True, 'epochs': 179, 'early_stopping_patience': 12, 'plateau_patience': 10, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 06:46:57,468] Trial 141 finished with value: 0.9333333333333333 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9937481156181766, 'batch_size': 51, 'attention_heads': 6, 'hidden_dimension': 225, 'number_of_hidden_layers': 1, 'dropout_rate': 0.31684630782457424, 'global_pooling': 'mean', 'learning_rate': 0.002264961880805715, 'weight_decay': 2.332409303547475e-06, 'beta_0': 0.8523913273995795, 'beta_1': 0.9870323287570968, 'epsilon': 1.2461641172178638e-08, 'balanced_loss': True, 'epochs': 168, 'early_stopping_patience': 13, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 3.30 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.28 GiB is free. Including non-PyTorch memory, this process has 42.27 GiB memory in use. Of the allocated memory 35.39 GiB is allocated by PyTorch, and 5.74 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 07:06:41,452] Trial 142 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9825092596658492, 'batch_size': 42, 'attention_heads': 5, 'hidden_dimension': 224, 'number_of_hidden_layers': 0, 'dropout_rate': 0.3947570064901177, 'global_pooling': 'mean', 'learning_rate': 0.001395740917663702, 'weight_decay': 1.844684234141378e-05, 'beta_0': 0.8555548740814611, 'beta_1': 0.989227338450361, 'epsilon': 2.2481836585915218e-05, 'balanced_loss': True, 'epochs': 186, 'early_stopping_patience': 19, 'plateau_patience': 19, 'plateau_divider': 2}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 3.51 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.41 GiB is free. Including non-PyTorch memory, this process has 43.14 GiB memory in use. Of the allocated memory 37.11 GiB is allocated by PyTorch, and 4.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 07:24:56,469] Trial 143 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9893077347322854, 'batch_size': 44, 'attention_heads': 14, 'hidden_dimension': 208, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3816928629125475, 'global_pooling': 'mean', 'learning_rate': 0.0027572602931896823, 'weight_decay': 2.6514086790610283e-06, 'beta_0': 0.8467923269258156, 'beta_1': 0.9875475177721917, 'epsilon': 1.7530943529894648e-08, 'balanced_loss': True, 'epochs': 173, 'early_stopping_patience': 14, 'plateau_patience': 16, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 07:45:08,602] Trial 144 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9961335963098038, 'batch_size': 39, 'attention_heads': 7, 'hidden_dimension': 148, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4063191613946128, 'global_pooling': 'mean', 'learning_rate': 0.0007191343738683622, 'weight_decay': 3.268696945570247e-05, 'beta_0': 0.8600310448044656, 'beta_1': 0.9963429111419329, 'epsilon': 1.5876707770079134e-08, 'balanced_loss': True, 'epochs': 189, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 08:07:14,232] Trial 145 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9914801109064054, 'batch_size': 39, 'attention_heads': 7, 'hidden_dimension': 150, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40614893078755315, 'global_pooling': 'mean', 'learning_rate': 0.0009691541261424232, 'weight_decay': 3.124887484191118e-05, 'beta_0': 0.849462375172603, 'beta_1': 0.9887089723349661, 'epsilon': 2.9971540339796794e-08, 'balanced_loss': True, 'epochs': 190, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 2.15 GiB. GPU 0 has a total capacity of 44.56 GiB of which 312.69 MiB is free. Including non-PyTorch memory, this process has 44.25 GiB memory in use. Of the allocated memory 39.67 GiB is allocated by PyTorch, and 3.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 08:26:05,730] Trial 146 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9913559315553948, 'batch_size': 61, 'attention_heads': 7, 'hidden_dimension': 219, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40269450582180155, 'global_pooling': 'mean', 'learning_rate': 0.0009662691932557359, 'weight_decay': 3.2792938912357124e-05, 'beta_0': 0.8613438578921054, 'beta_1': 0.9882715584276371, 'epsilon': 3.007924344098547e-08, 'balanced_loss': True, 'epochs': 184, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 08:46:46,413] Trial 147 finished with value: 0.9454545454545454 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9934869817271004, 'batch_size': 46, 'attention_heads': 7, 'hidden_dimension': 148, 'number_of_hidden_layers': 2, 'dropout_rate': 0.38573786926528897, 'global_pooling': 'mean', 'learning_rate': 0.0017534346776964921, 'weight_decay': 2.7579985437609766e-05, 'beta_0': 0.8416547447022241, 'beta_1': 0.9897530313134206, 'epsilon': 4.197787724807509e-08, 'balanced_loss': True, 'epochs': 192, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 2.71 GiB. GPU 0 has a total capacity of 44.56 GiB of which 2.11 GiB is free. Including non-PyTorch memory, this process has 42.44 GiB memory in use. Of the allocated memory 37.57 GiB is allocated by PyTorch, and 3.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 09:00:00,365] Trial 148 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9637493352360469, 'batch_size': 46, 'attention_heads': 7, 'hidden_dimension': 147, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3867085696575415, 'global_pooling': 'mean', 'learning_rate': 0.0011461663125706212, 'weight_decay': 2.6743621831845474e-05, 'beta_0': 0.8579023281636246, 'beta_1': 0.990192032003419, 'epsilon': 3.6944752668895954e-08, 'balanced_loss': True, 'epochs': 191, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 5.36 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.26 GiB is free. Including non-PyTorch memory, this process has 40.29 GiB memory in use. Of the allocated memory 30.05 GiB is allocated by PyTorch, and 9.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 09:33:40,996] Trial 149 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9934889570281855, 'batch_size': 48, 'attention_heads': 7, 'hidden_dimension': 139, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40711518993879203, 'global_pooling': 'mean', 'learning_rate': 0.0017438310926221198, 'weight_decay': 4.033983776134957e-05, 'beta_0': 0.8594137314279422, 'beta_1': 0.9895945352760027, 'epsilon': 4.7145250730680965e-08, 'balanced_loss': True, 'epochs': 189, 'early_stopping_patience': 12, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.64 GiB. GPU 0 has a total capacity of 44.56 GiB of which 44.69 MiB is free. Including non-PyTorch memory, this process has 44.51 GiB memory in use. Of the allocated memory 39.71 GiB is allocated by PyTorch, and 3.65 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 09:52:34,057] Trial 150 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9852229051584431, 'batch_size': 40, 'attention_heads': 7, 'hidden_dimension': 149, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3971941828242161, 'global_pooling': 'mean', 'learning_rate': 0.000852461508823423, 'weight_decay': 4.926569649204101e-05, 'beta_0': 0.8419746918761912, 'beta_1': 0.9971368049244697, 'epsilon': 2.603729016531566e-08, 'balanced_loss': True, 'epochs': 187, 'early_stopping_patience': 12, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.42 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.03 GiB is free. Including non-PyTorch memory, this process has 43.52 GiB memory in use. Of the allocated memory 36.65 GiB is allocated by PyTorch, and 5.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 10:12:04,251] Trial 151 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9873474883632435, 'batch_size': 39, 'attention_heads': 7, 'hidden_dimension': 143, 'number_of_hidden_layers': 2, 'dropout_rate': 0.379620518596593, 'global_pooling': 'mean', 'learning_rate': 0.0014251747233428333, 'weight_decay': 3.232613129015821e-05, 'beta_0': 0.8370817536019289, 'beta_1': 0.9963497229410755, 'epsilon': 1.5607868492557356e-08, 'balanced_loss': True, 'epochs': 192, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 10:32:59,625] Trial 152 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9911809106025645, 'batch_size': 42, 'attention_heads': 6, 'hidden_dimension': 154, 'number_of_hidden_layers': 2, 'dropout_rate': 0.38876663125690347, 'global_pooling': 'mean', 'learning_rate': 0.0004290020361337994, 'weight_decay': 2.3702577501233057e-05, 'beta_0': 0.8400217574070197, 'beta_1': 0.9888187347137437, 'epsilon': 2.0518729317420385e-08, 'balanced_loss': True, 'epochs': 194, 'early_stopping_patience': 13, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 10:54:30,431] Trial 153 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9905551521039231, 'batch_size': 54, 'attention_heads': 6, 'hidden_dimension': 161, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3916611603522887, 'global_pooling': 'mean', 'learning_rate': 0.0004319571782978117, 'weight_decay': 2.2085478261589795e-05, 'beta_0': 0.8405127101092973, 'beta_1': 0.9887977972584874, 'epsilon': 1.9549633427363785e-08, 'balanced_loss': True, 'epochs': 194, 'early_stopping_patience': 14, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 11:16:21,406] Trial 154 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9903164433622106, 'batch_size': 41, 'attention_heads': 6, 'hidden_dimension': 158, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3881085105528411, 'global_pooling': 'mean', 'learning_rate': 0.0003394747385495372, 'weight_decay': 2.244242640852992e-05, 'beta_0': 0.8399463388295587, 'beta_1': 0.9889400513194249, 'epsilon': 2.0368871924381366e-08, 'balanced_loss': True, 'epochs': 195, 'early_stopping_patience': 14, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 11:37:01,502] Trial 155 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9918724574568765, 'batch_size': 42, 'attention_heads': 5, 'hidden_dimension': 153, 'number_of_hidden_layers': 2, 'dropout_rate': 0.392336606554448, 'global_pooling': 'mean', 'learning_rate': 0.00043095571146851047, 'weight_decay': 1.94928026775311e-05, 'beta_0': 0.8349042705470724, 'beta_1': 0.9888268252894026, 'epsilon': 2.8978331912150924e-08, 'balanced_loss': True, 'epochs': 193, 'early_stopping_patience': 13, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 11:58:29,108] Trial 156 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9946048237816993, 'batch_size': 53, 'attention_heads': 6, 'hidden_dimension': 161, 'number_of_hidden_layers': 2, 'dropout_rate': 0.37397957789435254, 'global_pooling': 'mean', 'learning_rate': 0.0005222691578222293, 'weight_decay': 2.541635747673515e-05, 'beta_0': 0.8437124725354702, 'beta_1': 0.9896748108405831, 'epsilon': 1.2041707179065497e-08, 'balanced_loss': True, 'epochs': 185, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.51 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.26 GiB is free. Including non-PyTorch memory, this process has 43.30 GiB memory in use. Of the allocated memory 36.30 GiB is allocated by PyTorch, and 5.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 12:17:42,077] Trial 157 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9890506042523793, 'batch_size': 55, 'attention_heads': 6, 'hidden_dimension': 148, 'number_of_hidden_layers': 2, 'dropout_rate': 0.39909884956070474, 'global_pooling': 'mean', 'learning_rate': 0.0002688946896511387, 'weight_decay': 2.6888513152447422e-05, 'beta_0': 0.8414531043005057, 'beta_1': 0.9887053988688033, 'epsilon': 1.754757955544993e-08, 'balanced_loss': True, 'epochs': 189, 'early_stopping_patience': 12, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 12:38:41,985] Trial 158 finished with value: 0.6787878787878788 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9918456938997736, 'batch_size': 57, 'attention_heads': 7, 'hidden_dimension': 172, 'number_of_hidden_layers': 2, 'dropout_rate': 0.36299978478482386, 'global_pooling': 'mean', 'learning_rate': 0.0007284204340617654, 'weight_decay': 3.018260778802893e-05, 'beta_0': 0.89986087646536, 'beta_1': 0.9877760294777964, 'epsilon': 3.27943372643999e-08, 'balanced_loss': True, 'epochs': 183, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 2}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.51 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.03 GiB is free. Including non-PyTorch memory, this process has 43.53 GiB memory in use. Of the allocated memory 37.78 GiB is allocated by PyTorch, and 4.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 12:58:06,957] Trial 159 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9874142064057735, 'batch_size': 43, 'attention_heads': 6, 'hidden_dimension': 156, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40706573693605574, 'global_pooling': 'mean', 'learning_rate': 0.00036735893009376527, 'weight_decay': 3.724621299328775e-05, 'beta_0': 0.85386881245967, 'beta_1': 0.9900181287519181, 'epsilon': 2.1609778438770023e-08, 'balanced_loss': True, 'epochs': 196, 'early_stopping_patience': 14, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 13:18:11,746] Trial 160 finished with value: 0.9212121212121213 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9941201848195336, 'batch_size': 45, 'attention_heads': 7, 'hidden_dimension': 161, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4222598261934426, 'global_pooling': 'mean', 'learning_rate': 0.0004386519370145548, 'weight_decay': 2.3451979127609123e-05, 'beta_0': 0.8370642734254918, 'beta_1': 0.9873834887980782, 'epsilon': 4.39953856668485e-08, 'balanced_loss': True, 'epochs': 179, 'early_stopping_patience': 13, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 13:40:09,747] Trial 161 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9901512956117973, 'batch_size': 41, 'attention_heads': 6, 'hidden_dimension': 169, 'number_of_hidden_layers': 2, 'dropout_rate': 0.38704705185951943, 'global_pooling': 'mean', 'learning_rate': 0.0006138809637315451, 'weight_decay': 1.398512852838258e-05, 'beta_0': 0.8391788592366073, 'beta_1': 0.9881113690185923, 'epsilon': 1.4095131265966349e-08, 'balanced_loss': True, 'epochs': 191, 'early_stopping_patience': 12, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 14:00:53,392] Trial 162 finished with value: 0.7696969696969697 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9952521466900648, 'batch_size': 50, 'attention_heads': 13, 'hidden_dimension': 151, 'number_of_hidden_layers': 2, 'dropout_rate': 0.377768607743118, 'global_pooling': 'sum', 'learning_rate': 0.000690937116579928, 'weight_decay': 4.8909160480396945e-05, 'beta_0': 0.8335371072161588, 'beta_1': 0.9975282477455184, 'epsilon': 2.55456933131826e-08, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 15, 'plateau_patience': 25, 'plateau_divider': 2}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 14:20:30,288] Trial 163 finished with value: 0.8848484848484849 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9989888947742154, 'batch_size': 44, 'attention_heads': 7, 'hidden_dimension': 146, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3942121540209826, 'global_pooling': 'mean', 'learning_rate': 0.001167082535715564, 'weight_decay': 1.9420576466882503e-05, 'beta_0': 0.8487939227335851, 'beta_1': 0.9893357764978896, 'epsilon': 1.8764627184842034e-08, 'balanced_loss': True, 'epochs': 144, 'early_stopping_patience': 12, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 14:41:12,062] Trial 164 finished with value: 0.9515151515151515 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.996059751891042, 'batch_size': 47, 'attention_heads': 8, 'hidden_dimension': 142, 'number_of_hidden_layers': 2, 'dropout_rate': 0.401979377783578, 'global_pooling': 'mean', 'learning_rate': 0.0009738766811462496, 'weight_decay': 3.392887377474798e-05, 'beta_0': 0.843945191856476, 'beta_1': 0.9885259698838007, 'epsilon': 2.3271793302691315e-08, 'balanced_loss': True, 'epochs': 188, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 15:04:04,345] Trial 165 finished with value: 0.9454545454545454 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9924845124241864, 'batch_size': 48, 'attention_heads': 8, 'hidden_dimension': 142, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40348104981163413, 'global_pooling': 'mean', 'learning_rate': 0.0008729654963762231, 'weight_decay': 3.342915497433915e-05, 'beta_0': 0.8450594943167008, 'beta_1': 0.9883475257539842, 'epsilon': 3.297883421240919e-08, 'balanced_loss': True, 'epochs': 194, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 15:26:07,012] Trial 166 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9927135376358919, 'batch_size': 47, 'attention_heads': 8, 'hidden_dimension': 141, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40194808675039745, 'global_pooling': 'mean', 'learning_rate': 0.0008650798926203756, 'weight_decay': 3.520022798987857e-05, 'beta_0': 0.8449841114283378, 'beta_1': 0.9885144114066898, 'epsilon': 3.545781823241793e-08, 'balanced_loss': True, 'epochs': 194, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 15:46:28,159] Trial 167 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.996146552348319, 'batch_size': 48, 'attention_heads': 8, 'hidden_dimension': 133, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40805588262600967, 'global_pooling': 'mean', 'learning_rate': 0.0005348363467597542, 'weight_decay': 4.368470910897087e-05, 'beta_0': 0.8429295013449877, 'beta_1': 0.9879563134909014, 'epsilon': 2.816186352222507e-08, 'balanced_loss': True, 'epochs': 188, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 16:06:49,101] Trial 168 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9961891833376737, 'batch_size': 48, 'attention_heads': 8, 'hidden_dimension': 131, 'number_of_hidden_layers': 2, 'dropout_rate': 0.409436890469807, 'global_pooling': 'mean', 'learning_rate': 0.00047116001374099986, 'weight_decay': 4.3569168399706705e-05, 'beta_0': 0.8425648296456856, 'beta_1': 0.98787841973671, 'epsilon': 2.332433930180402e-08, 'balanced_loss': True, 'epochs': 188, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 16:29:59,787] Trial 169 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9912349592673132, 'batch_size': 52, 'attention_heads': 8, 'hidden_dimension': 124, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4168772974987989, 'global_pooling': 'mean', 'learning_rate': 0.0005269959213589071, 'weight_decay': 2.979641809055452e-05, 'beta_0': 0.8409999427415963, 'beta_1': 0.9871958174429539, 'epsilon': 2.763905217224279e-08, 'balanced_loss': True, 'epochs': 182, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 16:49:38,249] Trial 170 finished with value: 0.806060606060606 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9999129339671647, 'batch_size': 46, 'attention_heads': 9, 'hidden_dimension': 136, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3905466637449591, 'global_pooling': 'mean', 'learning_rate': 0.0007546898504119477, 'weight_decay': 5.079963229529152e-05, 'beta_0': 0.8457476491362876, 'beta_1': 0.9867793785848795, 'epsilon': 1.689437620780339e-08, 'balanced_loss': True, 'epochs': 186, 'early_stopping_patience': 13, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 17:11:37,196] Trial 171 finished with value: 0.9212121212121213 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9930508094136072, 'batch_size': 50, 'attention_heads': 8, 'hidden_dimension': 140, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3989814431001688, 'global_pooling': 'mean', 'learning_rate': 0.00031373687569625147, 'weight_decay': 4.012597693746782e-05, 'beta_0': 0.8392194613180686, 'beta_1': 0.9881860195669665, 'epsilon': 1.165423616612311e-08, 'balanced_loss': True, 'epochs': 191, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 17:32:09,100] Trial 172 finished with value: 0.9151515151515152 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.998045838734506, 'batch_size': 48, 'attention_heads': 8, 'hidden_dimension': 153, 'number_of_hidden_layers': 2, 'dropout_rate': 0.406502979981161, 'global_pooling': 'mean', 'learning_rate': 0.0006562298241325319, 'weight_decay': 3.3424048021296565e-05, 'beta_0': 0.8437553475574252, 'beta_1': 0.9875924753544456, 'epsilon': 5.2301233800530505e-08, 'balanced_loss': True, 'epochs': 193, 'early_stopping_patience': 12, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.65 GiB. GPU 0 has a total capacity of 44.56 GiB of which 932.69 MiB is free. Including non-PyTorch memory, this process has 43.64 GiB memory in use. Of the allocated memory 39.37 GiB is allocated by PyTorch, and 3.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-21 17:54:32,488] Trial 173 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9889906932764024, 'batch_size': 49, 'attention_heads': 8, 'hidden_dimension': 127, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3837894501069728, 'global_pooling': 'mean', 'learning_rate': 0.0009988334702713368, 'weight_decay': 2.801442457083132e-05, 'beta_0': 0.8475566577273301, 'beta_1': 0.9886632624613504, 'epsilon': 2.0913078410486432e-08, 'balanced_loss': True, 'epochs': 189, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 18:15:35,265] Trial 174 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9960574593194043, 'batch_size': 48, 'attention_heads': 8, 'hidden_dimension': 130, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4106726102925183, 'global_pooling': 'mean', 'learning_rate': 0.0004930003745948606, 'weight_decay': 4.5956228201830654e-05, 'beta_0': 0.8431283693783868, 'beta_1': 0.9880127936953896, 'epsilon': 2.447243853895547e-08, 'balanced_loss': True, 'epochs': 188, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 18:36:39,739] Trial 175 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9956127230289153, 'batch_size': 45, 'attention_heads': 8, 'hidden_dimension': 145, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40373646261478396, 'global_pooling': 'mean', 'learning_rate': 0.0004175933120101802, 'weight_decay': 4.047651750303517e-05, 'beta_0': 0.8417444171430348, 'beta_1': 0.9878692662905547, 'epsilon': 2.3120562254033415e-08, 'balanced_loss': True, 'epochs': 185, 'early_stopping_patience': 13, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 18:57:39,964] Trial 176 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9967733410139009, 'batch_size': 47, 'attention_heads': 9, 'hidden_dimension': 135, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4116071101155097, 'global_pooling': 'mean', 'learning_rate': 0.0005964950447579573, 'weight_decay': 7.289992229691727e-05, 'beta_0': 0.838360404145856, 'beta_1': 0.9968536485113091, 'epsilon': 2.9265193739850506e-08, 'balanced_loss': True, 'epochs': 181, 'early_stopping_patience': 12, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 19:19:29,865] Trial 177 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9931886909476826, 'batch_size': 46, 'attention_heads': 8, 'hidden_dimension': 131, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3965520421752129, 'global_pooling': 'mean', 'learning_rate': 0.000458138869086416, 'weight_decay': 3.5821555030626014e-05, 'beta_0': 0.8446130386627241, 'beta_1': 0.9883826249016079, 'epsilon': 1.5574692653014826e-08, 'balanced_loss': True, 'epochs': 195, 'early_stopping_patience': 12, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 19:42:08,672] Trial 178 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9909303773167965, 'batch_size': 43, 'attention_heads': 7, 'hidden_dimension': 150, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4186814620920489, 'global_pooling': 'mean', 'learning_rate': 0.0008022817338438288, 'weight_decay': 2.3029111416548692e-05, 'beta_0': 0.8410558513578055, 'beta_1': 0.987657886801636, 'epsilon': 4.051927992031232e-08, 'balanced_loss': True, 'epochs': 177, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-21 20:02:19,217] Trial 179 finished with value: 0.9030303030303031 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9979554214498967, 'batch_size': 47, 'attention_heads': 7, 'hidden_dimension': 115, 'number_of_hidden_layers': 2, 'dropout_rate': 0.39374380032297274, 'global_pooling': 'mean', 'learning_rate': 0.00036740081079735643, 'weight_decay': 5.529964735429536e-05, 'beta_0': 0.8465524775365869, 'beta_1': 0.9958933243627542, 'epsilon': 3.217973813503303e-08, 'balanced_loss': True, 'epochs': 188, 'early_stopping_patience': 11, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
slurmstepd: error: *** JOB 14130651 ON gpu007 CANCELLED AT 2024-12-21T20:10:26 DUE TO TIME LIMIT ***
