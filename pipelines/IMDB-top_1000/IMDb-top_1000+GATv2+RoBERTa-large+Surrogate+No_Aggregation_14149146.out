Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2024-12-25 04:05:14,720] Using an existing study with name 'IMDb-top_1000-GATv2-FacebookAI-roberta-large-Surrogate-No_Aggregation' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 512). Running this sequence through the model will result in indexing errors
[I 2024-12-25 04:26:28,875] Trial 318 finished with value: 0.9212121212121213 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9944170961104987, 'batch_size': 42, 'attention_heads': 7, 'hidden_dimension': 181, 'number_of_hidden_layers': 2, 'dropout_rate': 0.38274117315201533, 'global_pooling': 'max', 'learning_rate': 0.0013535267707727257, 'weight_decay': 2.3704818993800663e-05, 'beta_0': 0.8392295307428861, 'beta_1': 0.9957580185282243, 'epsilon': 1.5637974723312813e-08, 'balanced_loss': True, 'epochs': 176, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 04:48:53,682] Trial 319 finished with value: 0.9454545454545454 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9923664560735981, 'batch_size': 39, 'attention_heads': 8, 'hidden_dimension': 191, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3767939255619298, 'global_pooling': 'mean', 'learning_rate': 0.0005590643584318072, 'weight_decay': 1.717205596242174e-05, 'beta_0': 0.8589647926788745, 'beta_1': 0.9929852133403209, 'epsilon': 2.968004493314309e-08, 'balanced_loss': True, 'epochs': 193, 'early_stopping_patience': 12, 'plateau_patience': 24, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.23 GiB is free. Including non-PyTorch memory, this process has 43.32 GiB memory in use. Of the allocated memory 38.00 GiB is allocated by PyTorch, and 4.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 05:07:39,566] Trial 320 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9858109060199364, 'batch_size': 39, 'attention_heads': 6, 'hidden_dimension': 192, 'number_of_hidden_layers': 2, 'dropout_rate': 0.37912163220027006, 'global_pooling': 'max', 'learning_rate': 0.0006363182069024733, 'weight_decay': 1.4772143137277342e-05, 'beta_0': 0.858764927888309, 'beta_1': 0.990188444626678, 'epsilon': 1.229587012022507e-08, 'balanced_loss': True, 'epochs': 196, 'early_stopping_patience': 12, 'plateau_patience': 24, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.85 GiB. GPU 0 has a total capacity of 44.56 GiB of which 532.69 MiB is free. Including non-PyTorch memory, this process has 44.03 GiB memory in use. Of the allocated memory 38.97 GiB is allocated by PyTorch, and 3.91 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 05:31:34,190] Trial 321 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9904228393046466, 'batch_size': 40, 'attention_heads': 8, 'hidden_dimension': 190, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3705319108175045, 'global_pooling': 'mean', 'learning_rate': 0.0025339632012937804, 'weight_decay': 1.6944413704362027e-05, 'beta_0': 0.861811658074363, 'beta_1': 0.9915835921894399, 'epsilon': 2.0317223311716268e-08, 'balanced_loss': True, 'epochs': 73, 'early_stopping_patience': 11, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.01 GiB is free. Including non-PyTorch memory, this process has 43.54 GiB memory in use. Of the allocated memory 37.14 GiB is allocated by PyTorch, and 5.26 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 05:50:20,156] Trial 322 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9876983599096271, 'batch_size': 37, 'attention_heads': 8, 'hidden_dimension': 185, 'number_of_hidden_layers': 2, 'dropout_rate': 0.37436019050910646, 'global_pooling': 'mean', 'learning_rate': 0.001904837519494519, 'weight_decay': 1.818359417373412e-05, 'beta_0': 0.8594711529746574, 'beta_1': 0.9926183304615285, 'epsilon': 1.6744762287506202e-08, 'balanced_loss': True, 'epochs': 194, 'early_stopping_patience': 15, 'plateau_patience': 24, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 06:09:42,862] Trial 323 finished with value: 0.8909090909090909 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9920493356035475, 'batch_size': 38, 'attention_heads': 8, 'hidden_dimension': 182, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3858529768620649, 'global_pooling': 'max', 'learning_rate': 0.0011318784612024708, 'weight_decay': 2.0381322074630688e-05, 'beta_0': 0.8601773985188698, 'beta_1': 0.9908057750094477, 'epsilon': 3.0613315949798626e-08, 'balanced_loss': True, 'epochs': 198, 'early_stopping_patience': 12, 'plateau_patience': 23, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 06:31:01,874] Trial 324 finished with value: 0.7575757575757576 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9924792781033734, 'batch_size': 40, 'attention_heads': 9, 'hidden_dimension': 201, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3669543963454663, 'global_pooling': 'mean', 'learning_rate': 0.0009040342118346723, 'weight_decay': 2.249421375419646e-05, 'beta_0': 0.8563947778335498, 'beta_1': 0.9951497443720599, 'epsilon': 2.4499872723657996e-08, 'balanced_loss': True, 'epochs': 193, 'early_stopping_patience': 12, 'plateau_patience': 19, 'plateau_divider': 6}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 7.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 670.69 MiB is free. Including non-PyTorch memory, this process has 43.90 GiB memory in use. Of the allocated memory 32.27 GiB is allocated by PyTorch, and 10.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 06:59:04,946] Trial 325 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.993949695088433, 'batch_size': 35, 'attention_heads': 6, 'hidden_dimension': 194, 'number_of_hidden_layers': 2, 'dropout_rate': 0.37679943834861124, 'global_pooling': 'mean', 'learning_rate': 0.0016184751528401783, 'weight_decay': 2.629185220507562e-05, 'beta_0': 0.8582649723493603, 'beta_1': 0.993968134201741, 'epsilon': 4.023401347188348e-08, 'balanced_loss': True, 'epochs': 100, 'early_stopping_patience': 11, 'plateau_patience': 24, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.86 GiB. GPU 0 has a total capacity of 44.56 GiB of which 220.69 MiB is free. Including non-PyTorch memory, this process has 44.34 GiB memory in use. Of the allocated memory 40.08 GiB is allocated by PyTorch, and 3.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 07:17:50,866] Trial 326 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9891475386175522, 'batch_size': 43, 'attention_heads': 8, 'hidden_dimension': 187, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4362665054703549, 'global_pooling': 'mean', 'learning_rate': 0.0007185096670484013, 'weight_decay': 1.2087930298394608e-05, 'beta_0': 0.8631206647862205, 'beta_1': 0.9931069181655213, 'epsilon': 1.837501444764095e-08, 'balanced_loss': True, 'epochs': 161, 'early_stopping_patience': 12, 'plateau_patience': 23, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 07:39:31,233] Trial 327 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9954915949192662, 'batch_size': 39, 'attention_heads': 7, 'hidden_dimension': 206, 'number_of_hidden_layers': 2, 'dropout_rate': 0.39059398477676466, 'global_pooling': 'mean', 'learning_rate': 0.0005595652710880207, 'weight_decay': 3.1081106109394935e-05, 'beta_0': 0.8502342500312584, 'beta_1': 0.9970149010525529, 'epsilon': 2.7503138940689108e-08, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 12, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 07:59:19,209] Trial 328 finished with value: 0.9333333333333333 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9907758250865845, 'batch_size': 41, 'attention_heads': 7, 'hidden_dimension': 197, 'number_of_hidden_layers': 2, 'dropout_rate': 0.39796418590839666, 'global_pooling': 'mean', 'learning_rate': 0.0010029847588998708, 'weight_decay': 1.895000368248662e-05, 'beta_0': 0.845757090935498, 'beta_1': 0.9965196288860629, 'epsilon': 1.4194165184844198e-08, 'balanced_loss': True, 'epochs': 191, 'early_stopping_patience': 14, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 08:21:10,241] Trial 329 finished with value: 0.9454545454545454 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9929887334975307, 'batch_size': 44, 'attention_heads': 8, 'hidden_dimension': 239, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3842955884596959, 'global_pooling': 'mean', 'learning_rate': 0.0012838803586973206, 'weight_decay': 3.3599043134711516e-05, 'beta_0': 0.8341281472538508, 'beta_1': 0.9898785492524689, 'epsilon': 2.3194745386229145e-08, 'balanced_loss': True, 'epochs': 169, 'early_stopping_patience': 10, 'plateau_patience': 20, 'plateau_divider': 5}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.27 GiB. GPU 0 has a total capacity of 44.56 GiB of which 538.69 MiB is free. Including non-PyTorch memory, this process has 44.03 GiB memory in use. Of the allocated memory 37.89 GiB is allocated by PyTorch, and 4.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 08:34:10,537] Trial 330 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9584457900238124, 'batch_size': 44, 'attention_heads': 8, 'hidden_dimension': 236, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3797480525400798, 'global_pooling': 'mean', 'learning_rate': 0.0013486680821395809, 'weight_decay': 3.300384549320514e-05, 'beta_0': 0.8336985885292916, 'beta_1': 0.9896726774153507, 'epsilon': 5.443091998292696e-08, 'balanced_loss': True, 'epochs': 168, 'early_stopping_patience': 10, 'plateau_patience': 20, 'plateau_divider': 5}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.66 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.50 GiB is free. Including non-PyTorch memory, this process has 43.05 GiB memory in use. Of the allocated memory 35.59 GiB is allocated by PyTorch, and 6.31 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 08:54:23,261] Trial 331 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9929416731225638, 'batch_size': 44, 'attention_heads': 8, 'hidden_dimension': 230, 'number_of_hidden_layers': 2, 'dropout_rate': 0.38608535132510746, 'global_pooling': 'mean', 'learning_rate': 0.0012244133704540426, 'weight_decay': 0.00019374705324116704, 'beta_0': 0.8325099089855932, 'beta_1': 0.9957685949607475, 'epsilon': 3.3130856886658566e-08, 'balanced_loss': True, 'epochs': 173, 'early_stopping_patience': 10, 'plateau_patience': 20, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 09:16:02,974] Trial 332 finished with value: 0.9212121212121213 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9970828603758003, 'batch_size': 43, 'attention_heads': 8, 'hidden_dimension': 240, 'number_of_hidden_layers': 1, 'dropout_rate': 0.37360646185201546, 'global_pooling': 'mean', 'learning_rate': 0.0015350570103110715, 'weight_decay': 3.51973904874885e-05, 'beta_0': 0.8361212475321784, 'beta_1': 0.9900666066771298, 'epsilon': 2.3886884578092205e-08, 'balanced_loss': True, 'epochs': 165, 'early_stopping_patience': 10, 'plateau_patience': 20, 'plateau_divider': 5}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 09:34:44,854] Trial 333 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9947831191715383, 'batch_size': 42, 'attention_heads': 8, 'hidden_dimension': 112, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3574557056079937, 'global_pooling': 'mean', 'learning_rate': 0.0009147661804825053, 'weight_decay': 0.0002849242968665377, 'beta_0': 0.8532084108814978, 'beta_1': 0.9974853027586954, 'epsilon': 2.174163963657059e-08, 'balanced_loss': True, 'epochs': 169, 'early_stopping_patience': 10, 'plateau_patience': 20, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 09:54:12,546] Trial 334 finished with value: 0.8909090909090909 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9984781297569184, 'batch_size': 32, 'attention_heads': 8, 'hidden_dimension': 239, 'number_of_hidden_layers': 2, 'dropout_rate': 0.39520009542242657, 'global_pooling': 'mean', 'learning_rate': 0.0011801129808049395, 'weight_decay': 3.004902678811567e-05, 'beta_0': 0.8550441856220173, 'beta_1': 0.9967921723381263, 'epsilon': 3.0226959168650546e-08, 'balanced_loss': True, 'epochs': 171, 'early_stopping_patience': 19, 'plateau_patience': 21, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.07 GiB. GPU 0 has a total capacity of 44.56 GiB of which 876.69 MiB is free. Including non-PyTorch memory, this process has 43.70 GiB memory in use. Of the allocated memory 38.72 GiB is allocated by PyTorch, and 3.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 10:09:44,288] Trial 335 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9633010694749309, 'batch_size': 44, 'attention_heads': 9, 'hidden_dimension': 249, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3858951041093735, 'global_pooling': 'mean', 'learning_rate': 0.0008021455297535568, 'weight_decay': 3.8050241045598924e-05, 'beta_0': 0.8305558863485127, 'beta_1': 0.9922032000272765, 'epsilon': 3.7782993526819423e-08, 'balanced_loss': True, 'epochs': 176, 'early_stopping_patience': 11, 'plateau_patience': 20, 'plateau_divider': 5}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 10:36:37,010] Trial 336 finished with value: 0.9151515151515152 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9929374328493275, 'batch_size': 45, 'attention_heads': 8, 'hidden_dimension': 144, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40227341440857733, 'global_pooling': 'mean', 'learning_rate': 0.0018204372897382382, 'weight_decay': 2.7961532478357585e-05, 'beta_0': 0.8495950656357772, 'beta_1': 0.9966888437274211, 'epsilon': 2.6039429634472395e-08, 'balanced_loss': True, 'epochs': 180, 'early_stopping_patience': 11, 'plateau_patience': 19, 'plateau_divider': 5}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 10:57:37,488] Trial 337 finished with value: 0.7636363636363637 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.99576893770607, 'batch_size': 42, 'attention_heads': 8, 'hidden_dimension': 242, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3808341879577141, 'global_pooling': 'sum', 'learning_rate': 0.001030191904103761, 'weight_decay': 0.00012850698169407186, 'beta_0': 0.8468190353123292, 'beta_1': 0.9961506453391705, 'epsilon': 1.1692234844008411e-08, 'balanced_loss': True, 'epochs': 156, 'early_stopping_patience': 10, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 11:21:43,889] Trial 338 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.991422165479017, 'batch_size': 39, 'attention_heads': 7, 'hidden_dimension': 246, 'number_of_hidden_layers': 2, 'dropout_rate': 0.36704197260493554, 'global_pooling': 'mean', 'learning_rate': 0.0013428096048242733, 'weight_decay': 2.4804493222435663e-05, 'beta_0': 0.857030024098663, 'beta_1': 0.9899597200501866, 'epsilon': 1.6944824615019285e-08, 'balanced_loss': True, 'epochs': 163, 'early_stopping_patience': 12, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 11:45:49,229] Trial 339 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9946168631264293, 'batch_size': 38, 'attention_heads': 9, 'hidden_dimension': 220, 'number_of_hidden_layers': 2, 'dropout_rate': 0.39133264098558995, 'global_pooling': 'mean', 'learning_rate': 0.0007832761350701073, 'weight_decay': 3.35159733054764e-05, 'beta_0': 0.8371363460093343, 'beta_1': 0.9894483131865186, 'epsilon': 2.180796319580876e-08, 'balanced_loss': True, 'epochs': 152, 'early_stopping_patience': 13, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 12:10:00,381] Trial 340 finished with value: 0.8606060606060606 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9997889106290748, 'batch_size': 43, 'attention_heads': 8, 'hidden_dimension': 214, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4066122763002441, 'global_pooling': 'max', 'learning_rate': 0.0009661396607567851, 'weight_decay': 3.8026368885185424e-05, 'beta_0': 0.8661524414748617, 'beta_1': 0.9979001909527225, 'epsilon': 1.3837289854399331e-08, 'balanced_loss': True, 'epochs': 174, 'early_stopping_patience': 12, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 12:29:55,648] Trial 341 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.997223982004368, 'batch_size': 30, 'attention_heads': 8, 'hidden_dimension': 176, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4217726038233515, 'global_pooling': 'mean', 'learning_rate': 0.001157034528137993, 'weight_decay': 9.474097135596211e-05, 'beta_0': 0.844753779183686, 'beta_1': 0.9928592671956016, 'epsilon': 6.398353058122808e-08, 'balanced_loss': True, 'epochs': 82, 'early_stopping_patience': 13, 'plateau_patience': 21, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.90 GiB. GPU 0 has a total capacity of 44.56 GiB of which 786.69 MiB is free. Including non-PyTorch memory, this process has 43.79 GiB memory in use. Of the allocated memory 37.17 GiB is allocated by PyTorch, and 5.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 12:48:48,249] Trial 342 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9931585456323796, 'batch_size': 41, 'attention_heads': 10, 'hidden_dimension': 255, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3976637196835356, 'global_pooling': 'mean', 'learning_rate': 0.002129860202747696, 'weight_decay': 4.153359586029957e-06, 'beta_0': 0.8614078412650716, 'beta_1': 0.9962331970415017, 'epsilon': 1.838361935144362e-08, 'balanced_loss': True, 'epochs': 185, 'early_stopping_patience': 17, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 13:09:45,969] Trial 343 finished with value: 0.9090909090909091 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9890191741651699, 'batch_size': 34, 'attention_heads': 7, 'hidden_dimension': 186, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3764729812946227, 'global_pooling': 'mean', 'learning_rate': 0.0006360353835067705, 'weight_decay': 2.7481146357725093e-05, 'beta_0': 0.8287320841926368, 'beta_1': 0.9988174353751474, 'epsilon': 2.940275235712165e-08, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 10, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 3.40 GiB. GPU 0 has a total capacity of 44.56 GiB of which 262.69 MiB is free. Including non-PyTorch memory, this process has 44.30 GiB memory in use. Of the allocated memory 37.26 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 13:26:34,492] Trial 344 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9807050983793435, 'batch_size': 46, 'attention_heads': 7, 'hidden_dimension': 191, 'number_of_hidden_layers': 2, 'dropout_rate': 0.41346206791255347, 'global_pooling': 'mean', 'learning_rate': 0.0015110459607221127, 'weight_decay': 1.417332208477074e-05, 'beta_0': 0.8339756095826207, 'beta_1': 0.9970770702219952, 'epsilon': 2.4843401695811998e-08, 'balanced_loss': True, 'epochs': 178, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 13:50:17,774] Trial 345 finished with value: 0.9272727272727272 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9955422991650293, 'batch_size': 45, 'attention_heads': 8, 'hidden_dimension': 150, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3845516561697053, 'global_pooling': 'mean', 'learning_rate': 0.0008801253749724031, 'weight_decay': 3.1696858770826806e-05, 'beta_0': 0.8517164719463735, 'beta_1': 0.9955584533753069, 'epsilon': 3.333594694681378e-08, 'balanced_loss': True, 'epochs': 183, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 5}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 14:11:36,151] Trial 346 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9922294873243669, 'batch_size': 40, 'attention_heads': 8, 'hidden_dimension': 145, 'number_of_hidden_layers': 2, 'dropout_rate': 0.42769130753743634, 'global_pooling': 'mean', 'learning_rate': 0.0006841742193662854, 'weight_decay': 4.026141259990806e-05, 'beta_0': 0.8479349762465107, 'beta_1': 0.9891174754253906, 'epsilon': 2.0558952797143514e-08, 'balanced_loss': True, 'epochs': 168, 'early_stopping_patience': 10, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 14:34:34,787] Trial 347 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9969654188319114, 'batch_size': 36, 'attention_heads': 10, 'hidden_dimension': 226, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4034612463709633, 'global_pooling': 'mean', 'learning_rate': 0.0011166495214651657, 'weight_decay': 2.3345296621355968e-05, 'beta_0': 0.8455365962745307, 'beta_1': 0.9966342718823896, 'epsilon': 4.375677509492428e-08, 'balanced_loss': True, 'epochs': 190, 'early_stopping_patience': 11, 'plateau_patience': 25, 'plateau_divider': 2}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 15:00:58,508] Trial 348 finished with value: 0.7878787878787878 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9941205136798135, 'batch_size': 42, 'attention_heads': 7, 'hidden_dimension': 137, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3913788166582225, 'global_pooling': 'mean', 'learning_rate': 0.039348461092948, 'weight_decay': 2.9364371781299996e-05, 'beta_0': 0.8413588885950385, 'beta_1': 0.9903992270718307, 'epsilon': 1.5264848733315997e-08, 'balanced_loss': True, 'epochs': 185, 'early_stopping_patience': 12, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.91 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.36 GiB is free. Including non-PyTorch memory, this process has 43.19 GiB memory in use. Of the allocated memory 36.22 GiB is allocated by PyTorch, and 5.82 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 15:33:17,726] Trial 349 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.990052734633237, 'batch_size': 44, 'attention_heads': 8, 'hidden_dimension': 205, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4106236922141743, 'global_pooling': 'mean', 'learning_rate': 0.0015853608071777837, 'weight_decay': 5.131211985437051e-05, 'beta_0': 0.8377421936283982, 'beta_1': 0.9960147144009728, 'epsilon': 1.7490161021195476e-06, 'balanced_loss': True, 'epochs': 171, 'early_stopping_patience': 13, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.62 GiB. GPU 0 has a total capacity of 44.56 GiB of which 16.69 MiB is free. Including non-PyTorch memory, this process has 44.54 GiB memory in use. Of the allocated memory 38.69 GiB is allocated by PyTorch, and 4.69 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 15:50:56,006] Trial 350 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9867506155268154, 'batch_size': 43, 'attention_heads': 9, 'hidden_dimension': 128, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3987921487835271, 'global_pooling': 'mean', 'learning_rate': 0.000575677277568143, 'weight_decay': 7.292908521376468e-05, 'beta_0': 0.835200883261201, 'beta_1': 0.9945572624463409, 'epsilon': 2.538735523497055e-06, 'balanced_loss': True, 'epochs': 188, 'early_stopping_patience': 12, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 16:10:47,246] Trial 351 finished with value: 0.9151515151515152 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9976654339779149, 'batch_size': 41, 'attention_heads': 8, 'hidden_dimension': 212, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4546366822688626, 'global_pooling': 'mean', 'learning_rate': 0.0007834044094355395, 'weight_decay': 3.50929529014957e-05, 'beta_0': 0.8499532681829832, 'beta_1': 0.9919220916746102, 'epsilon': 2.479320100399777e-08, 'balanced_loss': True, 'epochs': 192, 'early_stopping_patience': 11, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.64 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.07 GiB is free. Including non-PyTorch memory, this process has 43.48 GiB memory in use. Of the allocated memory 37.12 GiB is allocated by PyTorch, and 5.21 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 16:34:49,252] Trial 352 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9915322718510801, 'batch_size': 45, 'attention_heads': 9, 'hidden_dimension': 140, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3888525480637019, 'global_pooling': 'mean', 'learning_rate': 0.0013431662735604781, 'weight_decay': 2.577166404371279e-05, 'beta_0': 0.8440523776319164, 'beta_1': 0.9884345408187531, 'epsilon': 1.7461421673473886e-08, 'balanced_loss': True, 'epochs': 181, 'early_stopping_patience': 13, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 16:56:04,261] Trial 353 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9952701278169502, 'batch_size': 63, 'attention_heads': 7, 'hidden_dimension': 199, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3789317760291004, 'global_pooling': 'mean', 'learning_rate': 0.0010214915404993636, 'weight_decay': 4.4428350431086996e-05, 'beta_0': 0.8403040743712055, 'beta_1': 0.9932664878473019, 'epsilon': 1.0110364934872515e-08, 'balanced_loss': True, 'epochs': 196, 'early_stopping_patience': 12, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 17:14:03,938] Trial 354 finished with value: 0.9212121212121213 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9999075072052503, 'batch_size': 46, 'attention_heads': 8, 'hidden_dimension': 120, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4201731051509313, 'global_pooling': 'mean', 'learning_rate': 0.0008826146211299555, 'weight_decay': 1.6175321968959655e-05, 'beta_0': 0.8472969933091683, 'beta_1': 0.9973411789552972, 'epsilon': 2.2424771016850513e-08, 'balanced_loss': True, 'epochs': 176, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 4.43 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.06 GiB is free. Including non-PyTorch memory, this process has 40.49 GiB memory in use. Of the allocated memory 33.34 GiB is allocated by PyTorch, and 6.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 17:19:48,804] Trial 355 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.913664803275008, 'batch_size': 40, 'attention_heads': 8, 'hidden_dimension': 154, 'number_of_hidden_layers': 2, 'dropout_rate': 0.37235494005700426, 'global_pooling': 'max', 'learning_rate': 0.0018828321306408801, 'weight_decay': 3.1452332013795014e-05, 'beta_0': 0.8424668578017322, 'beta_1': 0.996348944766014, 'epsilon': 2.8392850937076838e-08, 'balanced_loss': True, 'epochs': 192, 'early_stopping_patience': 13, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.94 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.31 GiB is free. Including non-PyTorch memory, this process has 43.25 GiB memory in use. Of the allocated memory 37.57 GiB is allocated by PyTorch, and 4.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 17:38:41,402] Trial 356 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9843107698167017, 'batch_size': 39, 'attention_heads': 7, 'hidden_dimension': 171, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3947393893656878, 'global_pooling': 'mean', 'learning_rate': 0.0006876060294474013, 'weight_decay': 2.1668631240611848e-05, 'beta_0': 0.8487443475670787, 'beta_1': 0.9953204217101784, 'epsilon': 1.1163748299752787e-07, 'balanced_loss': True, 'epochs': 187, 'early_stopping_patience': 13, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 18:00:22,224] Trial 357 finished with value: 0.6909090909090909 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9937043053178983, 'batch_size': 42, 'attention_heads': 8, 'hidden_dimension': 180, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4075204842143257, 'global_pooling': 'mean', 'learning_rate': 0.0011800575313109006, 'weight_decay': 3.851091332181891e-05, 'beta_0': 0.8446694903130497, 'beta_1': 0.9891493298158403, 'epsilon': 8.170684125433397e-07, 'balanced_loss': True, 'epochs': 65, 'early_stopping_patience': 11, 'plateau_patience': 16, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.48 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 43.34 GiB memory in use. Of the allocated memory 36.70 GiB is allocated by PyTorch, and 5.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 18:07:42,303] Trial 358 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9262275737698105, 'batch_size': 38, 'attention_heads': 5, 'hidden_dimension': 218, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4000290026174495, 'global_pooling': 'mean', 'learning_rate': 0.0005522896976586468, 'weight_decay': 2.828238264673e-05, 'beta_0': 0.8515534895411879, 'beta_1': 0.9937755594090426, 'epsilon': 1.3135379871167761e-08, 'balanced_loss': True, 'epochs': 184, 'early_stopping_patience': 12, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 18:28:28,891] Trial 359 finished with value: 0.9272727272727272 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9891746068293567, 'batch_size': 44, 'attention_heads': 8, 'hidden_dimension': 193, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3840172562763384, 'global_pooling': 'mean', 'learning_rate': 0.0014081730553286743, 'weight_decay': 2.447951171950933e-05, 'beta_0': 0.8400690990951832, 'beta_1': 0.9887968900115627, 'epsilon': 3.492782144917339e-08, 'balanced_loss': True, 'epochs': 190, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 18:53:07,788] Trial 360 finished with value: 0.8424242424242424 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9969536098835411, 'batch_size': 41, 'attention_heads': 4, 'hidden_dimension': 137, 'number_of_hidden_layers': 2, 'dropout_rate': 0.41488677842710814, 'global_pooling': 'sum', 'learning_rate': 0.0009080184219532298, 'weight_decay': 3.464113492505006e-05, 'beta_0': 0.8461674326126797, 'beta_1': 0.9907139510681677, 'epsilon': 1.880170334640399e-08, 'balanced_loss': True, 'epochs': 157, 'early_stopping_patience': 12, 'plateau_patience': 21, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 19:13:28,767] Trial 361 finished with value: 0.9212121212121213 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9920030048117112, 'batch_size': 45, 'attention_heads': 7, 'hidden_dimension': 134, 'number_of_hidden_layers': 2, 'dropout_rate': 0.36365116704030936, 'global_pooling': 'mean', 'learning_rate': 0.0007632562453440794, 'weight_decay': 4.752029366910284e-05, 'beta_0': 0.8426507578280575, 'beta_1': 0.9836257101242306, 'epsilon': 1.5263731329436568e-08, 'balanced_loss': True, 'epochs': 195, 'early_stopping_patience': 10, 'plateau_patience': 12, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 19:38:42,370] Trial 362 finished with value: 0.9212121212121213 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9952920440007191, 'batch_size': 47, 'attention_heads': 8, 'hidden_dimension': 202, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4025997564484032, 'global_pooling': 'mean', 'learning_rate': 0.0010847013836598304, 'weight_decay': 1.9557251201075277e-05, 'beta_0': 0.8683476101807202, 'beta_1': 0.9882092774203414, 'epsilon': 2.213693896045259e-08, 'balanced_loss': True, 'epochs': 167, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 20:01:56,309] Trial 363 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9934543780469693, 'batch_size': 43, 'attention_heads': 9, 'hidden_dimension': 232, 'number_of_hidden_layers': 2, 'dropout_rate': 0.39351126778299617, 'global_pooling': 'mean', 'learning_rate': 0.0006479586777014603, 'weight_decay': 5.692285716855374e-05, 'beta_0': 0.8550814631396277, 'beta_1': 0.9956992705502901, 'epsilon': 2.0059986523630985e-07, 'balanced_loss': True, 'epochs': 132, 'early_stopping_patience': 12, 'plateau_patience': 24, 'plateau_divider': 6}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 20:21:33,229] Trial 364 finished with value: 0.9090909090909091 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9982765133702214, 'batch_size': 43, 'attention_heads': 8, 'hidden_dimension': 146, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3882694894510276, 'global_pooling': 'mean', 'learning_rate': 0.0024676141357682616, 'weight_decay': 2.8667376825400837e-05, 'beta_0': 0.8379550646986713, 'beta_1': 0.9969749719774035, 'epsilon': 2.8347303415139976e-08, 'balanced_loss': True, 'epochs': 193, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 20:44:38,018] Trial 365 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9907443181409332, 'batch_size': 41, 'attention_heads': 7, 'hidden_dimension': 157, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40785402806075083, 'global_pooling': 'mean', 'learning_rate': 0.0012677851135095544, 'weight_decay': 3.351039973537335e-05, 'beta_0': 0.8594664705756517, 'beta_1': 0.9964658699649093, 'epsilon': 1.8924179296182545e-08, 'balanced_loss': True, 'epochs': 173, 'early_stopping_patience': 13, 'plateau_patience': 17, 'plateau_divider': 2}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.37 GiB. GPU 0 has a total capacity of 44.56 GiB of which 808.69 MiB is free. Including non-PyTorch memory, this process has 43.76 GiB memory in use. Of the allocated memory 37.92 GiB is allocated by PyTorch, and 4.70 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 21:08:30,782] Trial 366 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9880727829738669, 'batch_size': 47, 'attention_heads': 6, 'hidden_dimension': 128, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3797196422936319, 'global_pooling': 'max', 'learning_rate': 0.0016051274726904753, 'weight_decay': 4.2472391998262466e-05, 'beta_0': 0.847474092864795, 'beta_1': 0.9894369855826199, 'epsilon': 4.0040614443916194e-08, 'balanced_loss': True, 'epochs': 178, 'early_stopping_patience': 10, 'plateau_patience': 24, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 21:28:00,339] Trial 367 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9958535791204165, 'batch_size': 46, 'attention_heads': 8, 'hidden_dimension': 151, 'number_of_hidden_layers': 0, 'dropout_rate': 0.4372055324587733, 'global_pooling': 'mean', 'learning_rate': 0.000522435534975397, 'weight_decay': 2.471707187183548e-05, 'beta_0': 0.8636649744935408, 'beta_1': 0.9976921353855639, 'epsilon': 1.1990004248031908e-08, 'balanced_loss': True, 'epochs': 163, 'early_stopping_patience': 14, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 21:47:55,322] Trial 368 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9932245698988627, 'batch_size': 44, 'attention_heads': 6, 'hidden_dimension': 140, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3975973622948005, 'global_pooling': 'mean', 'learning_rate': 0.000944602140647541, 'weight_decay': 3.8574201035973994e-05, 'beta_0': 0.8437702257274717, 'beta_1': 0.9854448385792717, 'epsilon': 2.590890880429182e-08, 'balanced_loss': True, 'epochs': 198, 'early_stopping_patience': 12, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 22:10:13,941] Trial 369 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9911848855866765, 'batch_size': 40, 'attention_heads': 7, 'hidden_dimension': 210, 'number_of_hidden_layers': 2, 'dropout_rate': 0.41826490815054007, 'global_pooling': 'mean', 'learning_rate': 0.0007370215973586964, 'weight_decay': 0.00010987593203627182, 'beta_0': 0.8414235732136899, 'beta_1': 0.9873842196233026, 'epsilon': 1.681377224388997e-08, 'balanced_loss': True, 'epochs': 187, 'early_stopping_patience': 13, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 7.76 GiB. GPU 0 has a total capacity of 44.56 GiB of which 686.69 MiB is free. Including non-PyTorch memory, this process has 43.88 GiB memory in use. Of the allocated memory 32.14 GiB is allocated by PyTorch, and 10.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-25 22:46:37,023] Trial 370 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9965446197037016, 'batch_size': 42, 'attention_heads': 8, 'hidden_dimension': 116, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3856089590718503, 'global_pooling': 'mean', 'learning_rate': 0.0010547360720605733, 'weight_decay': 2.986732623578839e-05, 'beta_0': 0.8570527880198862, 'beta_1': 0.9897824040966059, 'epsilon': 3.381402547565135e-08, 'balanced_loss': True, 'epochs': 182, 'early_stopping_patience': 13, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 23:06:02,191] Trial 371 finished with value: 0.9030303030303031 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9984852563231353, 'batch_size': 32, 'attention_heads': 8, 'hidden_dimension': 123, 'number_of_hidden_layers': 2, 'dropout_rate': 0.37236603431790066, 'global_pooling': 'mean', 'learning_rate': 0.0008441687471319753, 'weight_decay': 8.015353846342664e-05, 'beta_0': 0.8948458802248084, 'beta_1': 0.9948478473862542, 'epsilon': 2.2179234185400763e-08, 'balanced_loss': True, 'epochs': 191, 'early_stopping_patience': 11, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 23:25:43,964] Trial 372 finished with value: 0.9454545454545454 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9943603337318822, 'batch_size': 39, 'attention_heads': 9, 'hidden_dimension': 32, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4011611402560647, 'global_pooling': 'mean', 'learning_rate': 0.0013641563721131047, 'weight_decay': 2.2182199576572386e-05, 'beta_0': 0.8493462940530558, 'beta_1': 0.9887488770982168, 'epsilon': 4.99517296465867e-08, 'balanced_loss': True, 'epochs': 142, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 6}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-25 23:46:35,264] Trial 373 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9948771510393857, 'batch_size': 37, 'attention_heads': 9, 'hidden_dimension': 186, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4111036995223363, 'global_pooling': 'mean', 'learning_rate': 0.0019340718149455656, 'weight_decay': 2.1566775745280655e-05, 'beta_0': 0.8496630789628974, 'beta_1': 0.9960364296284715, 'epsilon': 5.289054203452984e-08, 'balanced_loss': True, 'epochs': 160, 'early_stopping_patience': 15, 'plateau_patience': 25, 'plateau_divider': 7}. Best is trial 110 with value: 0.9515151515151515.
The selected strides are greater or equal to the total chunk size.
[I 2024-12-25 23:46:36,227] Trial 374 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9965020339361533, 'batch_size': 39, 'attention_heads': 9, 'hidden_dimension': 71, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4037296052701581, 'global_pooling': 'mean', 'learning_rate': 0.001648807341316771, 'weight_decay': 3.3290465640633603e-05, 'beta_0': 0.8504553057330833, 'beta_1': 0.9912517524458667, 'epsilon': 3.800821288501121e-08, 'balanced_loss': False, 'epochs': 145, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 5}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-26 00:10:14,194] Trial 375 finished with value: 0.9515151515151515 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9937594222905622, 'batch_size': 38, 'attention_heads': 9, 'hidden_dimension': 177, 'number_of_hidden_layers': 2, 'dropout_rate': 0.42434180025873247, 'global_pooling': 'mean', 'learning_rate': 0.001288098668416941, 'weight_decay': 2.7148090324439112e-05, 'beta_0': 0.8530510663846415, 'beta_1': 0.9882551987396335, 'epsilon': 3.1185749414248406e-08, 'balanced_loss': True, 'epochs': 140, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-26 00:32:36,261] Trial 376 finished with value: 0.9212121212121213 and parameters: {'left_stride': 128, 'right_stride': 0, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'mean', 'threshold': 0.9944079658595466, 'batch_size': 38, 'attention_heads': 9, 'hidden_dimension': 186, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4266784593313387, 'global_pooling': 'mean', 'learning_rate': 0.0015207370684197014, 'weight_decay': 2.0928479987117523e-05, 'beta_0': 0.8529887956937465, 'beta_1': 0.987898292474503, 'epsilon': 7.199459769757141e-08, 'balanced_loss': True, 'epochs': 128, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-26 00:50:47,090] Trial 377 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9979203016828201, 'batch_size': 37, 'attention_heads': 9, 'hidden_dimension': 61, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4270455367029793, 'global_pooling': 'mean', 'learning_rate': 0.0013078969926992282, 'weight_decay': 1.748128637085706e-05, 'beta_0': 0.8517988416081163, 'beta_1': 0.98818677475538, 'epsilon': 4.4641160888791295e-08, 'balanced_loss': True, 'epochs': 139, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 3.32 GiB. GPU 0 has a total capacity of 44.56 GiB of which 3.21 GiB is free. Including non-PyTorch memory, this process has 41.34 GiB memory in use. Of the allocated memory 38.12 GiB is allocated by PyTorch, and 2.07 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-26 01:09:50,249] Trial 378 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9769818940554004, 'batch_size': 34, 'attention_heads': 9, 'hidden_dimension': 175, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4455099441066711, 'global_pooling': 'max', 'learning_rate': 0.0013012565883587371, 'weight_decay': 6.314888540253543e-05, 'beta_0': 0.8542059314677893, 'beta_1': 0.987732190548224, 'epsilon': 4.418143831332423e-08, 'balanced_loss': True, 'epochs': 136, 'early_stopping_patience': 15, 'plateau_patience': 22, 'plateau_divider': 5}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-26 01:35:32,794] Trial 379 finished with value: 0.9212121212121213 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.993979863054427, 'batch_size': 38, 'attention_heads': 9, 'hidden_dimension': 84, 'number_of_hidden_layers': 2, 'dropout_rate': 0.43320923960202595, 'global_pooling': 'mean', 'learning_rate': 0.0021822427513815447, 'weight_decay': 2.6700548303028328e-05, 'beta_0': 0.8573077510839834, 'beta_1': 0.9969449695996783, 'epsilon': 3.287232208312986e-08, 'balanced_loss': True, 'epochs': 152, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 6}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-26 01:58:30,969] Trial 380 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9960431832889871, 'batch_size': 40, 'attention_heads': 10, 'hidden_dimension': 178, 'number_of_hidden_layers': 2, 'dropout_rate': 0.41715826663035493, 'global_pooling': 'mean', 'learning_rate': 0.0016639542571163647, 'weight_decay': 5.28436411475681e-05, 'beta_0': 0.8532660033201137, 'beta_1': 0.9885586465264102, 'epsilon': 5.169549712710948e-08, 'balanced_loss': True, 'epochs': 152, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 8}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.18 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 43.54 GiB memory in use. Of the allocated memory 38.86 GiB is allocated by PyTorch, and 3.52 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-26 02:09:21,477] Trial 381 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9461790123634772, 'batch_size': 36, 'attention_heads': 9, 'hidden_dimension': 181, 'number_of_hidden_layers': 2, 'dropout_rate': 0.422577483495669, 'global_pooling': 'mean', 'learning_rate': 0.0011829013656459353, 'weight_decay': 2.509334091479027e-05, 'beta_0': 0.8474063676297668, 'beta_1': 0.9955060135903042, 'epsilon': 2.8658056714860496e-08, 'balanced_loss': True, 'epochs': 133, 'early_stopping_patience': 15, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.71 GiB is free. Including non-PyTorch memory, this process has 42.84 GiB memory in use. Of the allocated memory 36.86 GiB is allocated by PyTorch, and 4.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-26 02:30:26,934] Trial 382 finished with value: -1.0 and parameters: {'left_stride': 32, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9924012462538495, 'batch_size': 46, 'attention_heads': 10, 'hidden_dimension': 173, 'number_of_hidden_layers': 2, 'dropout_rate': 0.43033583026824196, 'global_pooling': 'mean', 'learning_rate': 0.001381507446314441, 'weight_decay': 1.7146659662651284e-05, 'beta_0': 0.8558211299177668, 'beta_1': 0.9974604404264811, 'epsilon': 1.5017240302653132e-08, 'balanced_loss': True, 'epochs': 150, 'early_stopping_patience': 16, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-26 02:49:32,397] Trial 383 finished with value: 0.8121212121212121 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9999318898860747, 'batch_size': 39, 'attention_heads': 9, 'hidden_dimension': 93, 'number_of_hidden_layers': 1, 'dropout_rate': 0.39800035383268717, 'global_pooling': 'sum', 'learning_rate': 0.001111822455345729, 'weight_decay': 0.00024147717942100703, 'beta_0': 0.8492726188596472, 'beta_1': 0.9963417054647917, 'epsilon': 2.3466562882373644e-08, 'balanced_loss': True, 'epochs': 156, 'early_stopping_patience': 14, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-26 03:11:45,934] Trial 384 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9976914774036153, 'batch_size': 35, 'attention_heads': 9, 'hidden_dimension': 190, 'number_of_hidden_layers': 2, 'dropout_rate': 0.41004202680350993, 'global_pooling': 'mean', 'learning_rate': 0.0017481362905133952, 'weight_decay': 3.374923863199941e-06, 'beta_0': 0.846063260839244, 'beta_1': 0.9942106362938604, 'epsilon': 1.181269105688005e-08, 'balanced_loss': True, 'epochs': 164, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.

[TRIAL] 375 [VALIDATION PERFORMANCE] 0.9515151515151515 [TRAINING LOSS] 0.05782594358814614 [VALIDATION LOSS] 0.22678509801626207 

number                                     375
value                                 0.951515
params_threshold                      0.993759
params_attention_heads                       9
params_balanced_loss                      True
params_embedding_pooling_operation        mean
params_attention_pooling_operation         min
params_batch_size                           38
params_dropout_rate                   0.424342
params_early_stopping_patience              14
params_epochs                              140
params_global_pooling                     mean
params_hidden_dimension                    177
params_learning_rate                  0.001288
params_number_of_hidden_layers               2
params_plateau_divider                       4
params_plateau_patience                     25
params_weight_decay                   0.000027
params_beta_0                         0.853051
params_beta_1                         0.988255
params_epsilon                             0.0
user_attrs_epoch                          30.0
user_attrs_training_loss              0.057826
user_attrs_validation_loss            0.226785
params_left_stride                         128
params_right_stride                         64
Name: 375, dtype: object
37 Val: 0.9393939393939394 Test: 0.9432835820895522
38 Val: 0.9333333333333333 Test: 0.9402985074626866
39 Val: 0.9333333333333333 Test: 0.9462686567164179
40 Val: 0.9454545454545454 Test: 0.9373134328358209
41 Val: 0.9333333333333333 Test: 0.9552238805970149
42 Val: 0.9515151515151515 Test: 0.9611940298507463
43 Val: 0.9454545454545454 Test: 0.9432835820895522
44 Val: 0.9393939393939394 Test: 0.9373134328358209
45 Val: 0.9333333333333333 Test: 0.9402985074626866
46 Val: 0.9393939393939394 Test: 0.9522388059701492
Validation performance: 93.33 & 93.94 ± 0.64 & 95.15
Testing performance: 93.73 & 94.57 ± 0.81 & 96.12

[TRIAL] 110 [VALIDATION PERFORMANCE] 0.9515151515151515 [TRAINING LOSS] 0.03352659079246223 [VALIDATION LOSS] 0.25892964005470276 

number                                     110
value                                 0.951515
params_threshold                      0.991849
params_attention_heads                       7
params_balanced_loss                      True
params_embedding_pooling_operation        mean
params_attention_pooling_operation         min
params_batch_size                           42
params_dropout_rate                   0.378333
params_early_stopping_patience              12
params_epochs                              186
params_global_pooling                     mean
params_hidden_dimension                    181
params_learning_rate                  0.000582
params_number_of_hidden_layers               2
params_plateau_divider                       3
params_plateau_patience                     20
params_weight_decay                   0.000052
params_beta_0                         0.839704
params_beta_1                         0.996495
params_epsilon                             0.0
user_attrs_epoch                          25.0
user_attrs_training_loss              0.033527
user_attrs_validation_loss             0.25893
params_left_stride                         128
params_right_stride                        256
Name: 110, dtype: object
37 Val: 0.9333333333333333 Test: 0.9313432835820895
38 Val: 0.9393939393939394 Test: 0.9492537313432836
CUDA out of memory. Tried to allocate 1.52 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.28 GiB is free. Including non-PyTorch memory, this process has 43.28 GiB memory in use. Of the allocated memory 35.30 GiB is allocated by PyTorch, and 6.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
39 Exception...
40 Val: 0.9333333333333333 Test: 0.9641791044776119
41 Val: 0.8727272727272727 Test: 0.9074626865671642
42 Val: 0.9393939393939394 Test: 0.9402985074626866
43 Val: 0.9454545454545454 Test: 0.9522388059701492
44 Val: 0.9333333333333333 Test: 0.9313432835820895
45 Val: 0.9333333333333333 Test: 0.9522388059701492
46 Val: 0.9393939393939394 Test: 0.9582089552238806
Validation performance: 87.27 & 93.0 ± 2.19 & 94.55
Testing performance: 90.75 & 94.3 ± 1.74 & 96.42

[TRIAL] 164 [VALIDATION PERFORMANCE] 0.9515151515151515 [TRAINING LOSS] 0.020754642176060854 [VALIDATION LOSS] 0.3023087829351425 

number                                     164
value                                 0.951515
params_threshold                       0.99606
params_attention_heads                       8
params_balanced_loss                      True
params_embedding_pooling_operation         max
params_attention_pooling_operation         min
params_batch_size                           47
params_dropout_rate                   0.401979
params_early_stopping_patience              13
params_epochs                              188
params_global_pooling                     mean
params_hidden_dimension                    142
params_learning_rate                  0.000974
params_number_of_hidden_layers               2
params_plateau_divider                       4
params_plateau_patience                     25
params_weight_decay                   0.000034
params_beta_0                         0.843945
params_beta_1                         0.988526
params_epsilon                             0.0
user_attrs_epoch                          25.0
user_attrs_training_loss              0.020755
user_attrs_validation_loss            0.302309
params_left_stride                         128
params_right_stride                         64
Name: 164, dtype: object
37 Val: 0.9393939393939394 Test: 0.9402985074626866
38 Val: 0.9393939393939394 Test: 0.9552238805970149
39 Val: 0.9393939393939394 Test: 0.9343283582089552
40 Val: 0.9333333333333333 Test: 0.9343283582089552
41 Val: 0.9393939393939394 Test: 0.9373134328358209
42 Val: 0.9454545454545454 Test: 0.9283582089552239
43 Val: 0.9454545454545454 Test: 0.9373134328358209
44 Val: 0.9454545454545454 Test: 0.9522388059701492
45 Val: 0.9333333333333333 Test: 0.9492537313432836
46 Val: 0.9454545454545454 Test: 0.9402985074626866
Validation performance: 93.33 & 94.06 ± 0.48 & 94.55
Testing performance: 92.84 & 94.09 ± 0.87 & 95.52

[TRIAL] 267 [VALIDATION PERFORMANCE] 0.9454545454545454 [TRAINING LOSS] 0.21704281777298698 [VALIDATION LOSS] 0.18962627090513706 

number                                     267
value                                 0.945455
params_threshold                      0.995999
params_attention_heads                       8
params_balanced_loss                      True
params_embedding_pooling_operation        mean
params_attention_pooling_operation         min
params_batch_size                           43
params_dropout_rate                   0.366498
params_early_stopping_patience              12
params_epochs                              189
params_global_pooling                     mean
params_hidden_dimension                    199
params_learning_rate                  0.000763
params_number_of_hidden_layers               2
params_plateau_divider                       3
params_plateau_patience                     25
params_weight_decay                   0.000082
params_beta_0                         0.845731
params_beta_1                           0.9895
params_epsilon                             0.0
user_attrs_epoch                          17.0
user_attrs_training_loss              0.217043
user_attrs_validation_loss            0.189626
params_left_stride                         128
params_right_stride                        256
Name: 267, dtype: object
37 Val: 0.9212121212121213 Test: 0.9492537313432836
38 Val: 0.9272727272727272 Test: 0.9373134328358209
39 Val: 0.9272727272727272 Test: 0.9432835820895522
40 Val: 0.9454545454545454 Test: 0.9402985074626866
41 Val: 0.9333333333333333 Test: 0.9552238805970149
42 Val: 0.9393939393939394 Test: 0.9462686567164179
43 Val: 0.9333333333333333 Test: 0.9462686567164179
44 Val: 0.9333333333333333 Test: 0.9283582089552239
45 Val: 0.9393939393939394 Test: 0.9462686567164179
46 Val: 0.9454545454545454 Test: 0.9343283582089552
Validation performance: 92.12 & 93.45 ± 0.8 & 94.55
Testing performance: 92.84 & 94.27 ± 0.78 & 95.52

[TRIAL] 372 [VALIDATION PERFORMANCE] 0.9454545454545454 [TRAINING LOSS] 0.08513502096040891 [VALIDATION LOSS] 0.20130317211151122 

number                                     372
value                                 0.945455
params_threshold                       0.99436
params_attention_heads                       9
params_balanced_loss                      True
params_embedding_pooling_operation        mean
params_attention_pooling_operation         min
params_batch_size                           39
params_dropout_rate                   0.401161
params_early_stopping_patience              14
params_epochs                              142
params_global_pooling                     mean
params_hidden_dimension                     32
params_learning_rate                  0.001364
params_number_of_hidden_layers               2
params_plateau_divider                       6
params_plateau_patience                     25
params_weight_decay                   0.000022
params_beta_0                         0.849346
params_beta_1                         0.988749
params_epsilon                             0.0
user_attrs_epoch                          22.0
user_attrs_training_loss              0.085135
user_attrs_validation_loss            0.201303
params_left_stride                         128
params_right_stride                         64
Name: 372, dtype: object
37 Val: 0.9393939393939394 Test: 0.9194029850746268
38 Val: 0.9333333333333333 Test: 0.9373134328358209
39 Val: 0.9333333333333333 Test: 0.9313432835820895
40 Val: 0.9393939393939394 Test: 0.9373134328358209
41 Val: 0.9333333333333333 Test: 0.9194029850746268
42 Val: 0.9393939393939394 Test: 0.9462686567164179
43 Val: 0.9393939393939394 Test: 0.9343283582089552
44 Val: 0.9333333333333333 Test: 0.9402985074626866
45 Val: 0.9272727272727272 Test: 0.9522388059701492
46 Val: 0.9393939393939394 Test: 0.9582089552238806
Validation performance: 92.73 & 93.58 ± 0.42 & 93.94
Testing performance: 91.94 & 93.76 ± 1.26 & 95.82

[IMDb-top_1000] Elapsed time: 2590.242218919595 minutes.
