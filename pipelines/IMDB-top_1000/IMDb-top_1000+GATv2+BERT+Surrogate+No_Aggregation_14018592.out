[I 2024-11-27 04:44:07,383] Using an existing study with name 'IMDb-top_1000-GATv2-google-bert-bert-base-uncased-Surrogate-No_Aggregation' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (1147 > 512). Running this sequence through the model will result in indexing errors
CUDA out of memory. Tried to allocate 2.66 GiB. GPU 0 has a total capacity of 44.56 GiB of which 530.69 MiB is free. Including non-PyTorch memory, this process has 44.04 GiB memory in use. Of the allocated memory 41.69 GiB is allocated by PyTorch, and 1.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-27 05:01:39,895] Trial 279 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9809376116396771, 'batch_size': 58, 'attention_heads': 13, 'hidden_dimension': 62, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5568201398879602, 'global_pooling': 'mean', 'learning_rate': 3.669591461834728e-05, 'weight_decay': 0.00020175963608375577, 'beta_0': 0.8200935804006889, 'beta_1': 0.9907765370260591, 'epsilon': 1.42866420832483e-07, 'balanced_loss': True, 'epochs': 200, 'early_stopping_patience': 21, 'plateau_patience': 18, 'plateau_divider': 2}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 05:20:23,879] Trial 280 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9778897082874468, 'batch_size': 18, 'attention_heads': 10, 'hidden_dimension': 47, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5386648386844912, 'global_pooling': 'mean', 'learning_rate': 0.000591895022953619, 'weight_decay': 0.0003075851578746235, 'beta_0': 0.828463079644061, 'beta_1': 0.9880134237839477, 'epsilon': 8.420859898842269e-08, 'balanced_loss': True, 'epochs': 172, 'early_stopping_patience': 25, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 05:42:33,687] Trial 281 finished with value: 0.8666666666666667 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9566035187206854, 'batch_size': 22, 'attention_heads': 4, 'hidden_dimension': 36, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5676802036460566, 'global_pooling': 'max', 'learning_rate': 0.0014570365119980025, 'weight_decay': 4.065692843025568e-06, 'beta_0': 0.825083975813162, 'beta_1': 0.9884214782974001, 'epsilon': 3.1914768556465596e-06, 'balanced_loss': True, 'epochs': 99, 'early_stopping_patience': 24, 'plateau_patience': 17, 'plateau_divider': 7}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 06:00:44,038] Trial 282 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.984012022182555, 'batch_size': 20, 'attention_heads': 12, 'hidden_dimension': 55, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5506519336598675, 'global_pooling': 'mean', 'learning_rate': 0.0009939992774965962, 'weight_decay': 0.0005848885725832627, 'beta_0': 0.8221340421056875, 'beta_1': 0.9985846486601766, 'epsilon': 1.1259518468084248e-07, 'balanced_loss': True, 'epochs': 91, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 06:21:28,824] Trial 283 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9707385550434828, 'batch_size': 17, 'attention_heads': 11, 'hidden_dimension': 50, 'number_of_hidden_layers': 4, 'dropout_rate': 0.590469539501388, 'global_pooling': 'mean', 'learning_rate': 0.0007310101279649994, 'weight_decay': 1.978674131711331e-05, 'beta_0': 0.8310878072100385, 'beta_1': 0.9808810090149644, 'epsilon': 5.6089416355193566e-08, 'balanced_loss': True, 'epochs': 192, 'early_stopping_patience': 25, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 06:48:30,506] Trial 284 finished with value: 0.9090909090909091 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.973977222024524, 'batch_size': 18, 'attention_heads': 13, 'hidden_dimension': 59, 'number_of_hidden_layers': 2, 'dropout_rate': 0.5764520798064284, 'global_pooling': 'mean', 'learning_rate': 0.0012059613416816528, 'weight_decay': 0.00039439099964521236, 'beta_0': 0.8137558214080279, 'beta_1': 0.9815361683922225, 'epsilon': 9.557197179942478e-08, 'balanced_loss': True, 'epochs': 95, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 07:04:08,466] Trial 285 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9759732263419288, 'batch_size': 30, 'attention_heads': 6, 'hidden_dimension': 42, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4982797794181535, 'global_pooling': 'mean', 'learning_rate': 0.0008891621889358503, 'weight_decay': 5.3321098605842045e-06, 'beta_0': 0.8386476879897137, 'beta_1': 0.9973278104901799, 'epsilon': 6.647502139868704e-07, 'balanced_loss': False, 'epochs': 66, 'early_stopping_patience': 25, 'plateau_patience': 17, 'plateau_divider': 6}. Best is trial 136 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 1.11 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.08 GiB is free. Including non-PyTorch memory, this process has 43.47 GiB memory in use. Of the allocated memory 40.66 GiB is allocated by PyTorch, and 1.66 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-27 07:14:59,370] Trial 286 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9407573791769457, 'batch_size': 21, 'attention_heads': 5, 'hidden_dimension': 64, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5621511752628628, 'global_pooling': 'mean', 'learning_rate': 0.0005581524639420727, 'weight_decay': 1.0575394218263366e-05, 'beta_0': 0.8169073700812597, 'beta_1': 0.9874950010845424, 'epsilon': 6.994015145566985e-08, 'balanced_loss': True, 'epochs': 183, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 8}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 07:43:06,108] Trial 287 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9788975412434296, 'batch_size': 17, 'attention_heads': 12, 'hidden_dimension': 73, 'number_of_hidden_layers': 3, 'dropout_rate': 0.542552662010817, 'global_pooling': 'mean', 'learning_rate': 0.00043793488107117984, 'weight_decay': 0.0002787602240267922, 'beta_0': 0.8276042103724689, 'beta_1': 0.9896726474969809, 'epsilon': 8.135199354781162e-08, 'balanced_loss': True, 'epochs': 77, 'early_stopping_patience': 24, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 07:58:09,428] Trial 288 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.981314551142405, 'batch_size': 16, 'attention_heads': 13, 'hidden_dimension': 36, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5566957422279991, 'global_pooling': 'sum', 'learning_rate': 0.0006970896788311777, 'weight_decay': 1.5448354179244108e-05, 'beta_0': 0.8098968484926731, 'beta_1': 0.9805738522023661, 'epsilon': 1.1768799917076343e-07, 'balanced_loss': True, 'epochs': 159, 'early_stopping_patience': 24, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 08:16:20,803] Trial 289 finished with value: 0.9090909090909091 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9876292780268557, 'batch_size': 19, 'attention_heads': 13, 'hidden_dimension': 46, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5722668154804594, 'global_pooling': 'mean', 'learning_rate': 0.0010212291172778712, 'weight_decay': 0.00017433246741886406, 'beta_0': 0.8189396102705927, 'beta_1': 0.9811683151956064, 'epsilon': 5.1603152580027275e-08, 'balanced_loss': True, 'epochs': 137, 'early_stopping_patience': 25, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 08:35:25,590] Trial 290 finished with value: 0.9272727272727272 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.99331140555891, 'batch_size': 35, 'attention_heads': 13, 'hidden_dimension': 53, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4808430681213234, 'global_pooling': 'mean', 'learning_rate': 0.001664749927703621, 'weight_decay': 0.00022731141358680842, 'beta_0': 0.8233292210645002, 'beta_1': 0.9822784594045987, 'epsilon': 1.5952736905959227e-07, 'balanced_loss': True, 'epochs': 133, 'early_stopping_patience': 23, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 08:51:57,815] Trial 291 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9936340769764155, 'batch_size': 27, 'attention_heads': 10, 'hidden_dimension': 51, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5310357425495347, 'global_pooling': 'mean', 'learning_rate': 0.0017048182782623334, 'weight_decay': 0.00022266542869820227, 'beta_0': 0.8231100553255704, 'beta_1': 0.9822993178547119, 'epsilon': 3.825304117346204e-06, 'balanced_loss': True, 'epochs': 133, 'early_stopping_patience': 24, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 09:11:23,914] Trial 292 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9913709244289932, 'batch_size': 34, 'attention_heads': 13, 'hidden_dimension': 82, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5238903202802837, 'global_pooling': 'mean', 'learning_rate': 0.0023478470843840077, 'weight_decay': 0.00025048465927044947, 'beta_0': 0.8212962310980115, 'beta_1': 0.981820159753043, 'epsilon': 1.685770646564855e-07, 'balanced_loss': True, 'epochs': 129, 'early_stopping_patience': 25, 'plateau_patience': 14, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 09:28:49,877] Trial 293 finished with value: 0.9272727272727272 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9924020952100141, 'batch_size': 39, 'attention_heads': 13, 'hidden_dimension': 39, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5465639790786355, 'global_pooling': 'mean', 'learning_rate': 0.0014578082629377212, 'weight_decay': 4.070715175533587e-05, 'beta_0': 0.8191808699616675, 'beta_1': 0.982599720862422, 'epsilon': 1.4570703790287447e-07, 'balanced_loss': True, 'epochs': 140, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 09:44:59,221] Trial 294 finished with value: 0.9090909090909091 and parameters: {'left_stride': 0, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9937215849424036, 'batch_size': 41, 'attention_heads': 13, 'hidden_dimension': 40, 'number_of_hidden_layers': 4, 'dropout_rate': 0.48490371971710416, 'global_pooling': 'mean', 'learning_rate': 0.0019502944908967735, 'weight_decay': 2.5399023460176698e-05, 'beta_0': 0.8159626163053982, 'beta_1': 0.9823953742429065, 'epsilon': 1.3435948585799062e-07, 'balanced_loss': True, 'epochs': 138, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 10:10:14,324] Trial 295 finished with value: 0.8545454545454545 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9981476557577004, 'batch_size': 37, 'attention_heads': 13, 'hidden_dimension': 228, 'number_of_hidden_layers': 3, 'dropout_rate': 0.45179992905688277, 'global_pooling': 'mean', 'learning_rate': 0.0015110325018017567, 'weight_decay': 4.5689280192309935e-05, 'beta_0': 0.8195712668602265, 'beta_1': 0.9820279282327362, 'epsilon': 1.5794612358285483e-07, 'balanced_loss': True, 'epochs': 141, 'early_stopping_patience': 25, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 10:27:12,840] Trial 296 finished with value: 0.9090909090909091 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9904477874547593, 'batch_size': 35, 'attention_heads': 12, 'hidden_dimension': 36, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5459918898533648, 'global_pooling': 'mean', 'learning_rate': 0.0013565339076986357, 'weight_decay': 0.0003336651570968108, 'beta_0': 0.8177456428523204, 'beta_1': 0.9833359246671075, 'epsilon': 9.79514386963155e-08, 'balanced_loss': True, 'epochs': 134, 'early_stopping_patience': 16, 'plateau_patience': 13, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 10:44:01,636] Trial 297 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9931218968658003, 'batch_size': 43, 'attention_heads': 13, 'hidden_dimension': 43, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5360541992105933, 'global_pooling': 'mean', 'learning_rate': 0.0020670528255709595, 'weight_decay': 3.4956191819796404e-05, 'beta_0': 0.8748104757192051, 'beta_1': 0.9828633247553904, 'epsilon': 7.339245583743051e-08, 'balanced_loss': False, 'epochs': 143, 'early_stopping_patience': 25, 'plateau_patience': 18, 'plateau_divider': 5}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 10:59:03,414] Trial 298 finished with value: 0.8787878787878788 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9966990376806719, 'batch_size': 16, 'attention_heads': 14, 'hidden_dimension': 32, 'number_of_hidden_layers': 3, 'dropout_rate': 0.4358663416292139, 'global_pooling': 'mean', 'learning_rate': 0.0015651768777479422, 'weight_decay': 7.689289838666135e-05, 'beta_0': 0.820887756609667, 'beta_1': 0.9823606605084919, 'epsilon': 1.4467832347219448e-07, 'balanced_loss': True, 'epochs': 137, 'early_stopping_patience': 17, 'plateau_patience': 19, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 11:15:20,662] Trial 299 finished with value: 0.9090909090909091 and parameters: {'left_stride': 32, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9902578288052764, 'batch_size': 39, 'attention_heads': 11, 'hidden_dimension': 40, 'number_of_hidden_layers': 4, 'dropout_rate': 0.4799764907116122, 'global_pooling': 'mean', 'learning_rate': 0.0012967486158766597, 'weight_decay': 0.0002939834037803468, 'beta_0': 0.8231390650557132, 'beta_1': 0.9827077854462711, 'epsilon': 8.895208708180868e-08, 'balanced_loss': True, 'epochs': 146, 'early_stopping_patience': 24, 'plateau_patience': 24, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 11:32:33,108] Trial 300 finished with value: 0.9212121212121213 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'max', 'threshold': 0.9925688627407973, 'batch_size': 32, 'attention_heads': 12, 'hidden_dimension': 45, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5425698532047676, 'global_pooling': 'mean', 'learning_rate': 0.001889374838808094, 'weight_decay': 1.3686128809004155e-05, 'beta_0': 0.8148618018073941, 'beta_1': 0.9901160063734763, 'epsilon': 8.145383543037475e-06, 'balanced_loss': True, 'epochs': 140, 'early_stopping_patience': 23, 'plateau_patience': 25, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 11:49:38,153] Trial 301 finished with value: 0.896969696969697 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9880623510352868, 'batch_size': 36, 'attention_heads': 16, 'hidden_dimension': 37, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5521755341556766, 'global_pooling': 'mean', 'learning_rate': 0.0012014101992010354, 'weight_decay': 8.645657006276307e-06, 'beta_0': 0.8183552709104686, 'beta_1': 0.9816678337782729, 'epsilon': 2.090796967155215e-07, 'balanced_loss': True, 'epochs': 121, 'early_stopping_patience': 25, 'plateau_patience': 19, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 12:07:29,147] Trial 302 finished with value: 0.8727272727272727 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9960339583425958, 'batch_size': 33, 'attention_heads': 13, 'hidden_dimension': 48, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5479671114439286, 'global_pooling': 'max', 'learning_rate': 0.0028089266600187907, 'weight_decay': 6.971461375793275e-06, 'beta_0': 0.8204743563911595, 'beta_1': 0.9889904637721805, 'epsilon': 2.467874504629415e-07, 'balanced_loss': True, 'epochs': 82, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 12:24:48,535] Trial 303 finished with value: 0.896969696969697 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9894013668743705, 'batch_size': 35, 'attention_heads': 14, 'hidden_dimension': 39, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5375526985463281, 'global_pooling': 'mean', 'learning_rate': 0.0016502645177004513, 'weight_decay': 6.463922586269847e-05, 'beta_0': 0.8503299707409145, 'beta_1': 0.9830858176695699, 'epsilon': 1.1102303470939298e-07, 'balanced_loss': True, 'epochs': 139, 'early_stopping_patience': 25, 'plateau_patience': 18, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 12:42:08,926] Trial 304 finished with value: 0.896969696969697 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9857412118811331, 'batch_size': 38, 'attention_heads': 13, 'hidden_dimension': 32, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5274702399068328, 'global_pooling': 'mean', 'learning_rate': 0.0010859606604526225, 'weight_decay': 3.4876465472848308e-06, 'beta_0': 0.8241264396668613, 'beta_1': 0.9811992271862071, 'epsilon': 5.494751274480494e-08, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 18, 'plateau_patience': 19, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 2.22 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.60 GiB is free. Including non-PyTorch memory, this process has 42.96 GiB memory in use. Of the allocated memory 38.05 GiB is allocated by PyTorch, and 3.75 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-27 12:56:18,481] Trial 305 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9682702736261547, 'batch_size': 40, 'attention_heads': 10, 'hidden_dimension': 68, 'number_of_hidden_layers': 3, 'dropout_rate': 0.46233971480229724, 'global_pooling': 'mean', 'learning_rate': 0.001400559175987546, 'weight_decay': 0.00037091282218033845, 'beta_0': 0.8218046958770077, 'beta_1': 0.9803008887703251, 'epsilon': 6.786354656752331e-08, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 136 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 3.80 GiB. GPU 0 has a total capacity of 44.56 GiB of which 654.69 MiB is free. Including non-PyTorch memory, this process has 43.91 GiB memory in use. Of the allocated memory 41.77 GiB is allocated by PyTorch, and 1020.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-27 13:06:33,365] Trial 306 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.961009517623411, 'batch_size': 45, 'attention_heads': 12, 'hidden_dimension': 61, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5530706553249439, 'global_pooling': 'mean', 'learning_rate': 0.0010833537896979095, 'weight_decay': 2.126928631863985e-05, 'beta_0': 0.8166456350614111, 'beta_1': 0.9837225394817171, 'epsilon': 1.290090117961357e-07, 'balanced_loss': True, 'epochs': 134, 'early_stopping_patience': 23, 'plateau_patience': 18, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 13:25:28,120] Trial 307 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9829554988968765, 'batch_size': 24, 'attention_heads': 13, 'hidden_dimension': 45, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5410350116314875, 'global_pooling': 'mean', 'learning_rate': 0.0009255649334014516, 'weight_decay': 0.00024504482447145794, 'beta_0': 0.8195921382926747, 'beta_1': 0.9808573139201218, 'epsilon': 9.938959459174789e-08, 'balanced_loss': True, 'epochs': 166, 'early_stopping_patience': 22, 'plateau_patience': 19, 'plateau_divider': 9}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 13:42:08,572] Trial 308 finished with value: 0.6545454545454545 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9952215391086374, 'batch_size': 23, 'attention_heads': 13, 'hidden_dimension': 51, 'number_of_hidden_layers': 3, 'dropout_rate': 0.49119807892656303, 'global_pooling': 'mean', 'learning_rate': 0.02390078730774726, 'weight_decay': 0.00028050286382524784, 'beta_0': 0.8140938489463315, 'beta_1': 0.9819918395476895, 'epsilon': 5.284779928131565e-07, 'balanced_loss': True, 'epochs': 177, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 13:59:47,202] Trial 309 finished with value: 0.896969696969697 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9912723088259217, 'batch_size': 22, 'attention_heads': 12, 'hidden_dimension': 42, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5460286599539516, 'global_pooling': 'sum', 'learning_rate': 0.0013389472119923205, 'weight_decay': 0.0003175338834647409, 'beta_0': 0.822609940075604, 'beta_1': 0.9893997844777936, 'epsilon': 8.21079002723704e-08, 'balanced_loss': False, 'epochs': 87, 'early_stopping_patience': 24, 'plateau_patience': 18, 'plateau_divider': 2}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 14:27:59,215] Trial 310 finished with value: 0.8727272727272727 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9769776676269646, 'batch_size': 31, 'attention_heads': 12, 'hidden_dimension': 36, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5033126405814482, 'global_pooling': 'mean', 'learning_rate': 2.7115959943633915e-05, 'weight_decay': 1.1243389521657609e-05, 'beta_0': 0.8184922916466224, 'beta_1': 0.9814217378198373, 'epsilon': 6.249821578948146e-08, 'balanced_loss': True, 'epochs': 145, 'early_stopping_patience': 25, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.10 GiB is free. Including non-PyTorch memory, this process has 43.46 GiB memory in use. Of the allocated memory 40.28 GiB is allocated by PyTorch, and 2.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-27 14:42:31,082] Trial 311 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9721095971479968, 'batch_size': 28, 'attention_heads': 13, 'hidden_dimension': 58, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5324412957545709, 'global_pooling': 'mean', 'learning_rate': 0.0024272725567792415, 'weight_decay': 1.7650647366841687e-05, 'beta_0': 0.8256369178649989, 'beta_1': 0.9884808576759279, 'epsilon': 1.6055019145684094e-07, 'balanced_loss': True, 'epochs': 105, 'early_stopping_patience': 24, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 14:57:06,143] Trial 312 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9803616854111978, 'batch_size': 16, 'attention_heads': 14, 'hidden_dimension': 53, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5580286570229751, 'global_pooling': 'mean', 'learning_rate': 0.001671783586975556, 'weight_decay': 0.0002609520481409647, 'beta_0': 0.811444296528425, 'beta_1': 0.9808687309064618, 'epsilon': 2.310803080887825e-05, 'balanced_loss': True, 'epochs': 130, 'early_stopping_patience': 25, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 15:16:21,900] Trial 313 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.982221288086279, 'batch_size': 42, 'attention_heads': 13, 'hidden_dimension': 48, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5187701067449698, 'global_pooling': 'mean', 'learning_rate': 0.0007929276290779537, 'weight_decay': 5.419810072597535e-05, 'beta_0': 0.8238429439837824, 'beta_1': 0.9814775149402337, 'epsilon': 9.84283215838388e-08, 'balanced_loss': True, 'epochs': 170, 'early_stopping_patience': 23, 'plateau_patience': 16, 'plateau_divider': 7}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 15:30:40,162] Trial 314 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 128, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'min', 'threshold': 0.9848129545484285, 'batch_size': 37, 'attention_heads': 11, 'hidden_dimension': 65, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5510053225966333, 'global_pooling': 'mean', 'learning_rate': 0.001162980115348793, 'weight_decay': 9.716877860478198e-06, 'beta_0': 0.8215125823908391, 'beta_1': 0.9824775928497821, 'epsilon': 4.560414482255273e-08, 'balanced_loss': True, 'epochs': 180, 'early_stopping_patience': 20, 'plateau_patience': 18, 'plateau_divider': 9}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 15:45:58,549] Trial 315 finished with value: 0.8909090909090909 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9875283872838327, 'batch_size': 24, 'attention_heads': 13, 'hidden_dimension': 42, 'number_of_hidden_layers': 3, 'dropout_rate': 0.511598731266219, 'global_pooling': 'mean', 'learning_rate': 0.0009753740064616626, 'weight_decay': 0.00021411736058655364, 'beta_0': 0.8167393835157687, 'beta_1': 0.9818877383985862, 'epsilon': 1.241826289782401e-07, 'balanced_loss': True, 'epochs': 175, 'early_stopping_patience': 23, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 1.69 GiB. GPU 0 has a total capacity of 44.56 GiB of which 112.69 MiB is free. Including non-PyTorch memory, this process has 44.44 GiB memory in use. Of the allocated memory 40.09 GiB is allocated by PyTorch, and 3.20 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-27 16:00:08,588] Trial 316 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9527416108723059, 'batch_size': 17, 'attention_heads': 14, 'hidden_dimension': 58, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5596005533974717, 'global_pooling': 'mean', 'learning_rate': 0.0008210787800917489, 'weight_decay': 1.4407934380148645e-05, 'beta_0': 0.820153408867729, 'beta_1': 0.9886475484251847, 'epsilon': 8.224797518567006e-08, 'balanced_loss': True, 'epochs': 57, 'early_stopping_patience': 25, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 16:13:23,766] Trial 317 finished with value: 0.9151515151515152 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9925467743054821, 'batch_size': 16, 'attention_heads': 12, 'hidden_dimension': 36, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5395236493457304, 'global_pooling': 'mean', 'learning_rate': 0.0013808912463621067, 'weight_decay': 0.00033179421358017064, 'beta_0': 0.8187067169593176, 'beta_1': 0.9899549525399972, 'epsilon': 7.140861147557282e-08, 'balanced_loss': True, 'epochs': 149, 'early_stopping_patience': 25, 'plateau_patience': 16, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 16:28:24,618] Trial 318 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9737744066881389, 'batch_size': 18, 'attention_heads': 15, 'hidden_dimension': 48, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5460181889319465, 'global_pooling': 'mean', 'learning_rate': 0.0006870134373989999, 'weight_decay': 0.00022686041897546823, 'beta_0': 0.8267196556529671, 'beta_1': 0.9805751052599312, 'epsilon': 1.0483957532037319e-07, 'balanced_loss': True, 'epochs': 142, 'early_stopping_patience': 24, 'plateau_patience': 19, 'plateau_divider': 7}. Best is trial 136 with value: 0.9333333333333333.
CUDA out of memory. Tried to allocate 3.16 GiB. GPU 0 has a total capacity of 44.56 GiB of which 278.69 MiB is free. Including non-PyTorch memory, this process has 44.28 GiB memory in use. Of the allocated memory 40.56 GiB is allocated by PyTorch, and 2.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-11-27 16:44:45,572] Trial 319 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9262275737698105, 'batch_size': 23, 'attention_heads': 5, 'hidden_dimension': 54, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5860596118501008, 'global_pooling': 'mean', 'learning_rate': 0.0010578259422392546, 'weight_decay': 2.846545851340736e-06, 'beta_0': 0.8084572646223637, 'beta_1': 0.9811162545210743, 'epsilon': 5.701706985148366e-08, 'balanced_loss': True, 'epochs': 187, 'early_stopping_patience': 22, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 17:01:49,259] Trial 320 finished with value: 0.9030303030303031 and parameters: {'left_stride': 64, 'right_stride': 32, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9775281089957648, 'batch_size': 25, 'attention_heads': 13, 'hidden_dimension': 62, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5627968734264321, 'global_pooling': 'mean', 'learning_rate': 0.0017714138127997749, 'weight_decay': 0.0002861956638998905, 'beta_0': 0.8241437972902224, 'beta_1': 0.9801734230833238, 'epsilon': 8.727998676883009e-08, 'balanced_loss': False, 'epochs': 182, 'early_stopping_patience': 23, 'plateau_patience': 22, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 17:20:21,219] Trial 321 finished with value: 0.9030303030303031 and parameters: {'left_stride': 0, 'right_stride': 256, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.980119044054749, 'batch_size': 17, 'attention_heads': 4, 'hidden_dimension': 72, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5528643256093467, 'global_pooling': 'mean', 'learning_rate': 0.0011769488498527421, 'weight_decay': 2.0903596071223235e-06, 'beta_0': 0.8150573275484746, 'beta_1': 0.9890874324619098, 'epsilon': 1.2483771567607655e-07, 'balanced_loss': True, 'epochs': 136, 'early_stopping_patience': 25, 'plateau_patience': 18, 'plateau_divider': 7}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 17:35:52,956] Trial 322 finished with value: 0.8909090909090909 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'max', 'threshold': 0.9752983200373316, 'batch_size': 39, 'attention_heads': 13, 'hidden_dimension': 32, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5337906536167452, 'global_pooling': 'mean', 'learning_rate': 0.0009172365983484777, 'weight_decay': 0.0004484937871686314, 'beta_0': 0.8462373609369288, 'beta_1': 0.9816916376814631, 'epsilon': 6.281864640479439e-08, 'balanced_loss': True, 'epochs': 95, 'early_stopping_patience': 24, 'plateau_patience': 19, 'plateau_divider': 6}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 17:52:37,033] Trial 323 finished with value: 0.9090909090909091 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9789035566004743, 'batch_size': 21, 'attention_heads': 13, 'hidden_dimension': 39, 'number_of_hidden_layers': 4, 'dropout_rate': 0.5938768125472261, 'global_pooling': 'mean', 'learning_rate': 0.0021159549955635376, 'weight_decay': 1.6295952838375932e-06, 'beta_0': 0.8218247931817972, 'beta_1': 0.982782313315035, 'epsilon': 1.051111355018287e-06, 'balanced_loss': True, 'epochs': 100, 'early_stopping_patience': 24, 'plateau_patience': 23, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 18:15:18,814] Trial 324 finished with value: 0.9212121212121213 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'min', 'threshold': 0.9696404021444621, 'batch_size': 17, 'attention_heads': 12, 'hidden_dimension': 44, 'number_of_hidden_layers': 4, 'dropout_rate': 0.567087295476768, 'global_pooling': 'mean', 'learning_rate': 0.0005281842762704114, 'weight_decay': 0.0003851548344812935, 'beta_0': 0.8127277825483765, 'beta_1': 0.9821282233364358, 'epsilon': 9.53190613048882e-06, 'balanced_loss': True, 'epochs': 189, 'early_stopping_patience': 25, 'plateau_patience': 17, 'plateau_divider': 10}. Best is trial 136 with value: 0.9333333333333333.
[I 2024-11-27 18:30:53,669] Trial 325 finished with value: 0.8727272727272727 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'max', 'embedding_pooling_operation': 'min', 'threshold': 0.9892707376470176, 'batch_size': 20, 'attention_heads': 13, 'hidden_dimension': 52, 'number_of_hidden_layers': 3, 'dropout_rate': 0.5287084091517643, 'global_pooling': 'max', 'learning_rate': 0.0007053240073345706, 'weight_decay': 1.2826592872313692e-05, 'beta_0': 0.8201010223736871, 'beta_1': 0.9811900370972821, 'epsilon': 7.741265991630141e-08, 'balanced_loss': True, 'epochs': 184, 'early_stopping_patience': 23, 'plateau_patience': 12, 'plateau_divider': 7}. Best is trial 136 with value: 0.9333333333333333.

[TRIAL] 250 [VALIDATION PERFORMANCE] 0.9333333333333333 [TRAINING LOSS] 0.007836842178767256 [VALIDATION LOSS] 0.2719790461872305 

number                                     250
value                                 0.933333
params_threshold                      0.976712
params_attention_heads                       5
params_balanced_loss                     False
params_embedding_pooling_operation         min
params_attention_pooling_operation        mean
params_batch_size                           26
params_dropout_rate                   0.577056
params_early_stopping_patience              23
params_epochs                              136
params_global_pooling                     mean
params_hidden_dimension                     63
params_learning_rate                  0.000728
params_number_of_hidden_layers               4
params_plateau_divider                       7
params_plateau_patience                     17
params_weight_decay                   0.000296
params_beta_0                         0.822301
params_beta_1                         0.997692
params_epsilon                        0.000003
user_attrs_epoch                          45.0
user_attrs_training_loss              0.007837
user_attrs_validation_loss            0.271979
params_left_stride                         128
params_right_stride                        256
Name: 250, dtype: object
37 Val: 0.9090909090909091 Test: 0.9373134328358209
38 Val: 0.9090909090909091 Test: 0.9283582089552239
39 Val: 0.9212121212121213 Test: 0.9223880597014925
40 Val: 0.9151515151515152 Test: 0.9194029850746268
41 Val: 0.9030303030303031 Test: 0.9253731343283582
42 Val: 0.9333333333333333 Test: 0.9313432835820895
43 Val: 0.9151515151515152 Test: 0.9074626865671642
44 Val: 0.9212121212121213 Test: 0.9194029850746268
45 Val: 0.9272727272727272 Test: 0.9343283582089552
46 Val: 0.9090909090909091 Test: 0.9194029850746268
Validation performance: 90.3 & 91.64 ± 0.94 & 93.33
Testing performance: 90.75 & 92.45 ± 0.88 & 93.73

[TRIAL] 136 [VALIDATION PERFORMANCE] 0.9333333333333333 [TRAINING LOSS] 0.011549242047684467 [VALIDATION LOSS] 0.27727113640867174 

number                                     136
value                                 0.933333
params_threshold                      0.980301
params_attention_heads                      13
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation        mean
params_batch_size                           24
params_dropout_rate                   0.569768
params_early_stopping_patience              25
params_epochs                               99
params_global_pooling                     mean
params_hidden_dimension                     32
params_learning_rate                  0.001113
params_number_of_hidden_layers               3
params_plateau_divider                       2
params_plateau_patience                     17
params_weight_decay                   0.000204
params_beta_0                         0.818248
params_beta_1                         0.981414
params_epsilon                             0.0
user_attrs_epoch                          39.0
user_attrs_training_loss              0.011549
user_attrs_validation_loss            0.277271
params_left_stride                          64
params_right_stride                        256
Name: 136, dtype: object
37 Val: 0.896969696969697 Test: 0.9104477611940298
38 Val: 0.9151515151515152 Test: 0.9223880597014925
39 Val: 0.9151515151515152 Test: 0.9164179104477612
40 Val: 0.9151515151515152 Test: 0.9253731343283582
41 Val: 0.9151515151515152 Test: 0.9373134328358209
42 Val: 0.9272727272727272 Test: 0.9313432835820895
43 Val: 0.9090909090909091 Test: 0.9343283582089552
44 Val: 0.896969696969697 Test: 0.9253731343283582
45 Val: 0.9151515151515152 Test: 0.9283582089552239
46 Val: 0.9151515151515152 Test: 0.9313432835820895
Validation performance: 89.7 & 91.21 ± 0.91 & 92.73
Testing performance: 91.04 & 92.63 ± 0.82 & 93.73

[TRIAL] 137 [VALIDATION PERFORMANCE] 0.9333333333333333 [TRAINING LOSS] 0.02519158667200827 [VALIDATION LOSS] 0.3048702422529459 

number                                     137
value                                 0.933333
params_threshold                      0.979356
params_attention_heads                      13
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation        mean
params_batch_size                           23
params_dropout_rate                    0.55922
params_early_stopping_patience              24
params_epochs                               99
params_global_pooling                     mean
params_hidden_dimension                     36
params_learning_rate                  0.001063
params_number_of_hidden_layers               3
params_plateau_divider                       7
params_plateau_patience                     17
params_weight_decay                   0.000016
params_beta_0                         0.818701
params_beta_1                         0.981309
params_epsilon                             0.0
user_attrs_epoch                          38.0
user_attrs_training_loss              0.025192
user_attrs_validation_loss             0.30487
params_left_stride                          64
params_right_stride                        256
Name: 137, dtype: object
37 Val: 0.9090909090909091 Test: 0.9313432835820895
38 Val: 0.9151515151515152 Test: 0.9223880597014925
39 Val: 0.9090909090909091 Test: 0.9313432835820895
40 Val: 0.9030303030303031 Test: 0.9134328358208955
41 Val: 0.9030303030303031 Test: 0.9194029850746268
42 Val: 0.9272727272727272 Test: 0.9194029850746268
43 Val: 0.896969696969697 Test: 0.9253731343283582
44 Val: 0.9151515151515152 Test: 0.9343283582089552
45 Val: 0.9030303030303031 Test: 0.9283582089552239
46 Val: 0.9090909090909091 Test: 0.9223880597014925
Validation performance: 89.7 & 90.91 ± 0.86 & 92.73
Testing performance: 91.34 & 92.48 ± 0.66 & 93.43

[TRIAL] 241 [VALIDATION PERFORMANCE] 0.9333333333333333 [TRAINING LOSS] 0.08965322441971776 [VALIDATION LOSS] 0.3858804451301694 

number                                     241
value                                 0.933333
params_threshold                      0.973373
params_attention_heads                       4
params_balanced_loss                      True
params_embedding_pooling_operation         min
params_attention_pooling_operation        mean
params_batch_size                           23
params_dropout_rate                   0.585884
params_early_stopping_patience              22
params_epochs                              144
params_global_pooling                     mean
params_hidden_dimension                     74
params_learning_rate                  0.000594
params_number_of_hidden_layers               4
params_plateau_divider                       7
params_plateau_patience                     17
params_weight_decay                   0.000304
params_beta_0                         0.826618
params_beta_1                         0.998611
params_epsilon                             0.0
user_attrs_epoch                          47.0
user_attrs_training_loss              0.089653
user_attrs_validation_loss             0.38588
params_left_stride                         128
params_right_stride                        256
Name: 241, dtype: object
37 Val: 0.9151515151515152 Test: 0.9074626865671642
slurmstepd: error: *** JOB 14018592 ON gpu040 CANCELLED AT 2024-11-28T06:11:22 ***
