Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[I 2024-12-23 04:19:45,954] Using an existing study with name 'IMDb-top_1000-GATv2-FacebookAI-roberta-large-Surrogate-No_Aggregation' instead of creating a new one.
Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 512). Running this sequence through the model will result in indexing errors
[I 2024-12-23 04:42:30,033] Trial 227 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9919079215489255, 'batch_size': 39, 'attention_heads': 9, 'hidden_dimension': 122, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3849754910559763, 'global_pooling': 'mean', 'learning_rate': 0.0012103191294026941, 'weight_decay': 2.4380003254969343e-05, 'beta_0': 0.8418817385457886, 'beta_1': 0.9881090821858468, 'epsilon': 2.240625292463991e-08, 'balanced_loss': True, 'epochs': 133, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.26 GiB is free. Including non-PyTorch memory, this process has 43.29 GiB memory in use. Of the allocated memory 37.53 GiB is allocated by PyTorch, and 4.61 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 05:01:48,378] Trial 228 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9869570945957648, 'batch_size': 41, 'attention_heads': 8, 'hidden_dimension': 119, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3803604247490321, 'global_pooling': 'mean', 'learning_rate': 0.0009628293387942764, 'weight_decay': 2.272038165368011e-05, 'beta_0': 0.8909389780599698, 'beta_1': 0.9882514034472484, 'epsilon': 3.2588774832069166e-08, 'balanced_loss': True, 'epochs': 85, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 2.04 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.36 GiB is free. Including non-PyTorch memory, this process has 43.19 GiB memory in use. Of the allocated memory 37.33 GiB is allocated by PyTorch, and 4.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 05:21:18,229] Trial 229 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.985345333390376, 'batch_size': 42, 'attention_heads': 10, 'hidden_dimension': 124, 'number_of_hidden_layers': 2, 'dropout_rate': 0.39516122808775217, 'global_pooling': 'mean', 'learning_rate': 0.0015237111767645777, 'weight_decay': 2.9055050616768832e-05, 'beta_0': 0.8460896134916788, 'beta_1': 0.9874929326436375, 'epsilon': 1.7332153440859028e-08, 'balanced_loss': True, 'epochs': 126, 'early_stopping_patience': 13, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 05:44:32,323] Trial 230 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.993191889097715, 'batch_size': 40, 'attention_heads': 8, 'hidden_dimension': 103, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3880905849872322, 'global_pooling': 'mean', 'learning_rate': 0.0008636729330802475, 'weight_decay': 1.5344916046296764e-05, 'beta_0': 0.8406775691861683, 'beta_1': 0.9886944754952872, 'epsilon': 2.617639758096754e-08, 'balanced_loss': True, 'epochs': 191, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 06:09:52,530] Trial 231 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9905311918248073, 'batch_size': 55, 'attention_heads': 8, 'hidden_dimension': 125, 'number_of_hidden_layers': 2, 'dropout_rate': 0.370655458202025, 'global_pooling': 'mean', 'learning_rate': 0.0011080307940272455, 'weight_decay': 3.286578080638257e-05, 'beta_0': 0.8431341223801299, 'beta_1': 0.9877180306039223, 'epsilon': 2.1463921437143994e-08, 'balanced_loss': True, 'epochs': 96, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.80 GiB. GPU 0 has a total capacity of 44.56 GiB of which 312.69 MiB is free. Including non-PyTorch memory, this process has 44.25 GiB memory in use. Of the allocated memory 38.33 GiB is allocated by PyTorch, and 4.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 06:31:32,747] Trial 232 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9884819837978256, 'batch_size': 42, 'attention_heads': 9, 'hidden_dimension': 155, 'number_of_hidden_layers': 2, 'dropout_rate': 0.39504809645889666, 'global_pooling': 'mean', 'learning_rate': 0.0006950994599834518, 'weight_decay': 2.645988926701741e-05, 'beta_0': 0.845030432450171, 'beta_1': 0.9890894334053798, 'epsilon': 3.956161591606955e-08, 'balanced_loss': True, 'epochs': 188, 'early_stopping_patience': 13, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 06:54:54,652] Trial 233 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9941597260944166, 'batch_size': 39, 'attention_heads': 7, 'hidden_dimension': 128, 'number_of_hidden_layers': 2, 'dropout_rate': 0.41570136075025343, 'global_pooling': 'mean', 'learning_rate': 0.0013411862793538806, 'weight_decay': 2.083829145901733e-05, 'beta_0': 0.8479380723200038, 'beta_1': 0.9883705882628167, 'epsilon': 3.2890543613937874e-08, 'balanced_loss': True, 'epochs': 123, 'early_stopping_patience': 13, 'plateau_patience': 17, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 07:18:16,409] Trial 234 finished with value: 0.9272727272727272 and parameters: {'left_stride': 64, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9916832730013947, 'batch_size': 43, 'attention_heads': 8, 'hidden_dimension': 204, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3837931974332978, 'global_pooling': 'mean', 'learning_rate': 0.001988996938265538, 'weight_decay': 5.1212946428955914e-05, 'beta_0': 0.838565067267005, 'beta_1': 0.9880019326812622, 'epsilon': 1.749667763550945e-08, 'balanced_loss': True, 'epochs': 185, 'early_stopping_patience': 12, 'plateau_patience': 11, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 07:40:48,083] Trial 235 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.996455953435568, 'batch_size': 38, 'attention_heads': 7, 'hidden_dimension': 89, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3979990541576452, 'global_pooling': 'mean', 'learning_rate': 0.0009517330814001243, 'weight_decay': 1.8025793924041226e-05, 'beta_0': 0.843127470396788, 'beta_1': 0.9871507634074909, 'epsilon': 2.5480230101638902e-08, 'balanced_loss': True, 'epochs': 102, 'early_stopping_patience': 11, 'plateau_patience': 18, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 08:03:50,215] Trial 236 finished with value: 0.9454545454545454 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9955742795952066, 'batch_size': 46, 'attention_heads': 8, 'hidden_dimension': 134, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4061001574499232, 'global_pooling': 'mean', 'learning_rate': 0.0005626223438358458, 'weight_decay': 3.585426320025556e-05, 'beta_0': 0.8482742003017525, 'beta_1': 0.9965101997091639, 'epsilon': 1.3257116904708205e-08, 'balanced_loss': True, 'epochs': 194, 'early_stopping_patience': 13, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 08:26:26,515] Trial 237 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9943498942561043, 'batch_size': 49, 'attention_heads': 8, 'hidden_dimension': 130, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4068087406003924, 'global_pooling': 'mean', 'learning_rate': 0.0005690275680020657, 'weight_decay': 3.28148763648282e-05, 'beta_0': 0.8494040078906684, 'beta_1': 0.9958683901388902, 'epsilon': 1.557370935952638e-08, 'balanced_loss': True, 'epochs': 53, 'early_stopping_patience': 13, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 08:50:16,693] Trial 238 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9972273960707214, 'batch_size': 45, 'attention_heads': 8, 'hidden_dimension': 249, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40188630598274944, 'global_pooling': 'mean', 'learning_rate': 0.0007206533031053184, 'weight_decay': 4.592397135605971e-05, 'beta_0': 0.8463475245449236, 'beta_1': 0.9974105210863188, 'epsilon': 2.145298110444861e-08, 'balanced_loss': True, 'epochs': 70, 'early_stopping_patience': 13, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 09:18:24,889] Trial 239 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9926166242369858, 'batch_size': 44, 'attention_heads': 8, 'hidden_dimension': 223, 'number_of_hidden_layers': 2, 'dropout_rate': 0.39152511658016265, 'global_pooling': 'mean', 'learning_rate': 0.0005903662288341436, 'weight_decay': 2.7493034993665954e-05, 'beta_0': 0.8451195293477255, 'beta_1': 0.9963078095384855, 'epsilon': 1.9411417102381463e-08, 'balanced_loss': True, 'epochs': 192, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 09:44:40,255] Trial 240 finished with value: 0.9272727272727272 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9956160348931247, 'batch_size': 47, 'attention_heads': 9, 'hidden_dimension': 107, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4216368688536491, 'global_pooling': 'mean', 'learning_rate': 0.0008354863657374531, 'weight_decay': 3.68676165434264e-05, 'beta_0': 0.8529256596127845, 'beta_1': 0.9966959390789858, 'epsilon': 2.8396135925166305e-08, 'balanced_loss': True, 'epochs': 190, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 10:10:49,489] Trial 241 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9902929074847125, 'batch_size': 40, 'attention_heads': 8, 'hidden_dimension': 149, 'number_of_hidden_layers': 2, 'dropout_rate': 0.41007811593012894, 'global_pooling': 'mean', 'learning_rate': 0.0016104639706355387, 'weight_decay': 2.355089415833571e-05, 'beta_0': 0.8516252980789959, 'beta_1': 0.988342704290369, 'epsilon': 1.179787756050939e-08, 'balanced_loss': True, 'epochs': 140, 'early_stopping_patience': 12, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 10:31:46,144] Trial 242 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9981410981528254, 'batch_size': 42, 'attention_heads': 7, 'hidden_dimension': 139, 'number_of_hidden_layers': 2, 'dropout_rate': 0.37755440299159143, 'global_pooling': 'sum', 'learning_rate': 0.0010087079772905213, 'weight_decay': 4.2707837713914034e-05, 'beta_0': 0.8482685553820586, 'beta_1': 0.9887649130456561, 'epsilon': 1.6166845122723687e-08, 'balanced_loss': True, 'epochs': 194, 'early_stopping_patience': 13, 'plateau_patience': 20, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 10:52:34,746] Trial 243 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9937196935029112, 'batch_size': 46, 'attention_heads': 6, 'hidden_dimension': 168, 'number_of_hidden_layers': 2, 'dropout_rate': 0.41555601115493285, 'global_pooling': 'mean', 'learning_rate': 0.0006870919679174536, 'weight_decay': 3.127451327245018e-05, 'beta_0': 0.8407250702045763, 'beta_1': 0.9971038080614743, 'epsilon': 2.3496138408343346e-08, 'balanced_loss': True, 'epochs': 78, 'early_stopping_patience': 12, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 11:10:15,522] Trial 244 finished with value: 0.9333333333333333 and parameters: {'left_stride': 0, 'right_stride': 0, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9920634908951931, 'batch_size': 41, 'attention_heads': 8, 'hidden_dimension': 139, 'number_of_hidden_layers': 2, 'dropout_rate': 0.388000985217668, 'global_pooling': 'mean', 'learning_rate': 0.0005156827025373277, 'weight_decay': 5.8273483925664145e-05, 'beta_0': 0.858856038468312, 'beta_1': 0.9876616934068546, 'epsilon': 3.155068986646955e-08, 'balanced_loss': True, 'epochs': 187, 'early_stopping_patience': 10, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 11:30:03,415] Trial 245 finished with value: 0.9454545454545454 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9961180429606684, 'batch_size': 45, 'attention_heads': 8, 'hidden_dimension': 127, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3987032339519003, 'global_pooling': 'mean', 'learning_rate': 0.0011879730388363813, 'weight_decay': 2.7318169158941217e-05, 'beta_0': 0.8438313247510958, 'beta_1': 0.9964901172222181, 'epsilon': 1.8491181735014383e-08, 'balanced_loss': True, 'epochs': 155, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 11:50:02,590] Trial 246 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9963814773969478, 'batch_size': 45, 'attention_heads': 8, 'hidden_dimension': 127, 'number_of_hidden_layers': 1, 'dropout_rate': 0.39931679331138414, 'global_pooling': 'mean', 'learning_rate': 0.0011521770547240511, 'weight_decay': 2.7963823450663616e-05, 'beta_0': 0.8428005897817507, 'beta_1': 0.9964534028462219, 'epsilon': 1.911567718153501e-08, 'balanced_loss': True, 'epochs': 166, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 12:10:37,444] Trial 247 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9945007094269706, 'batch_size': 44, 'attention_heads': 8, 'hidden_dimension': 121, 'number_of_hidden_layers': 1, 'dropout_rate': 0.4061098839112529, 'global_pooling': 'mean', 'learning_rate': 0.0014110829485473957, 'weight_decay': 3.477055994046734e-05, 'beta_0': 0.845164476085685, 'beta_1': 0.9978325770505855, 'epsilon': 1.3598621679612566e-08, 'balanced_loss': True, 'epochs': 163, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 12:30:07,292] Trial 248 finished with value: 0.9151515151515152 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9980002877014736, 'batch_size': 48, 'attention_heads': 8, 'hidden_dimension': 116, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3950371099938985, 'global_pooling': 'mean', 'learning_rate': 0.0011352998860616192, 'weight_decay': 2.3895469588714235e-05, 'beta_0': 0.8468745170343335, 'beta_1': 0.9965527041651149, 'epsilon': 2.3126851592892475e-08, 'balanced_loss': True, 'epochs': 172, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 12:50:49,259] Trial 249 finished with value: 0.9454545454545454 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9955806934788082, 'batch_size': 57, 'attention_heads': 8, 'hidden_dimension': 132, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40052132197977125, 'global_pooling': 'mean', 'learning_rate': 0.0008325473037896545, 'weight_decay': 3.045655896402799e-05, 'beta_0': 0.8416428545022451, 'beta_1': 0.9961148025070101, 'epsilon': 2.762762471932343e-08, 'balanced_loss': True, 'epochs': 158, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 4.46 GiB. GPU 0 has a total capacity of 44.56 GiB of which 642.69 MiB is free. Including non-PyTorch memory, this process has 43.93 GiB memory in use. Of the allocated memory 35.06 GiB is allocated by PyTorch, and 7.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 13:09:47,922] Trial 250 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9746286119342231, 'batch_size': 62, 'attention_heads': 8, 'hidden_dimension': 133, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4014432430581626, 'global_pooling': 'mean', 'learning_rate': 0.001800114143141729, 'weight_decay': 3.0355546727714506e-05, 'beta_0': 0.8434982380157674, 'beta_1': 0.9957702581468825, 'epsilon': 2.7712997937607385e-08, 'balanced_loss': True, 'epochs': 192, 'early_stopping_patience': 12, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 13:29:58,565] Trial 251 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.99626027903794, 'batch_size': 47, 'attention_heads': 8, 'hidden_dimension': 129, 'number_of_hidden_layers': 1, 'dropout_rate': 0.3905694904332561, 'global_pooling': 'mean', 'learning_rate': 0.0009424581473990043, 'weight_decay': 4.0597198309792366e-05, 'beta_0': 0.8503299707409145, 'beta_1': 0.996066818112794, 'epsilon': 1.8876265552151024e-08, 'balanced_loss': True, 'epochs': 159, 'early_stopping_patience': 14, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 13:51:18,545] Trial 252 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9949758523107411, 'batch_size': 46, 'attention_heads': 8, 'hidden_dimension': 126, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3984946607149528, 'global_pooling': 'mean', 'learning_rate': 7.975270775105055e-05, 'weight_decay': 3.660894748070067e-05, 'beta_0': 0.8367578779437966, 'beta_1': 0.9962795671966513, 'epsilon': 2.17235254260516e-08, 'balanced_loss': True, 'epochs': 160, 'early_stopping_patience': 13, 'plateau_patience': 23, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 14:10:53,967] Trial 253 finished with value: 0.8242424242424242 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9997623799588826, 'batch_size': 58, 'attention_heads': 9, 'hidden_dimension': 137, 'number_of_hidden_layers': 2, 'dropout_rate': 0.38431995558507104, 'global_pooling': 'mean', 'learning_rate': 0.001246482871008998, 'weight_decay': 2.7057501236373596e-05, 'beta_0': 0.8614894792603739, 'beta_1': 0.9969356517481286, 'epsilon': 1.6233888818039856e-08, 'balanced_loss': True, 'epochs': 110, 'early_stopping_patience': 12, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 14:32:57,540] Trial 254 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9932924803634057, 'batch_size': 53, 'attention_heads': 8, 'hidden_dimension': 131, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4082701294523887, 'global_pooling': 'mean', 'learning_rate': 0.0005961328269796647, 'weight_decay': 4.711261738245862e-05, 'beta_0': 0.8394574440812812, 'beta_1': 0.9957478291531594, 'epsilon': 1.185195669034358e-06, 'balanced_loss': True, 'epochs': 149, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 14:58:58,965] Trial 255 finished with value: 0.9393939393939394 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9964890709955442, 'batch_size': 36, 'attention_heads': 8, 'hidden_dimension': 121, 'number_of_hidden_layers': 2, 'dropout_rate': 0.39339571014459945, 'global_pooling': 'mean', 'learning_rate': 0.00040007593866137054, 'weight_decay': 3.309852528286747e-05, 'beta_0': 0.8419827495115174, 'beta_1': 0.9885043866682057, 'epsilon': 2.5382344022048277e-08, 'balanced_loss': True, 'epochs': 86, 'early_stopping_patience': 13, 'plateau_patience': 19, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 15:32:22,440] Trial 256 finished with value: 0.8787878787878788 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'mean', 'embedding_pooling_operation': 'mean', 'threshold': 0.9975241266943167, 'batch_size': 49, 'attention_heads': 6, 'hidden_dimension': 133, 'number_of_hidden_layers': 2, 'dropout_rate': 0.4034612463709633, 'global_pooling': 'mean', 'learning_rate': 0.0008024700670027413, 'weight_decay': 3.896001207900549e-05, 'beta_0': 0.8448732129332592, 'beta_1': 0.9955079710601253, 'epsilon': 1.1901228890254077e-08, 'balanced_loss': True, 'epochs': 155, 'early_stopping_patience': 11, 'plateau_patience': 18, 'plateau_divider': 2}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 15:54:46,281] Trial 257 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 32, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9944421558443788, 'batch_size': 56, 'attention_heads': 9, 'hidden_dimension': 178, 'number_of_hidden_layers': 2, 'dropout_rate': 0.41028360444472245, 'global_pooling': 'mean', 'learning_rate': 0.0005144092363651809, 'weight_decay': 2.988057809994394e-05, 'beta_0': 0.8485513925547102, 'beta_1': 0.9984002037335474, 'epsilon': 1.9873683327725625e-08, 'balanced_loss': True, 'epochs': 154, 'early_stopping_patience': 17, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.77 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.68 GiB is free. Including non-PyTorch memory, this process has 42.88 GiB memory in use. Of the allocated memory 37.57 GiB is allocated by PyTorch, and 4.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 16:16:29,949] Trial 258 finished with value: -1.0 and parameters: {'left_stride': 256, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9920850733098682, 'batch_size': 59, 'attention_heads': 8, 'hidden_dimension': 143, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3869494965880789, 'global_pooling': 'mean', 'learning_rate': 0.0003174142565396768, 'weight_decay': 5.17294301353061e-05, 'beta_0': 0.8465385427085809, 'beta_1': 0.9952943141382643, 'epsilon': 1.5146401107936572e-08, 'balanced_loss': True, 'epochs': 145, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.09 GiB. GPU 0 has a total capacity of 44.56 GiB of which 714.69 MiB is free. Including non-PyTorch memory, this process has 43.86 GiB memory in use. Of the allocated memory 36.38 GiB is allocated by PyTorch, and 6.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 16:22:22,505] Trial 259 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9049813526707423, 'batch_size': 51, 'attention_heads': 6, 'hidden_dimension': 72, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3980139996234991, 'global_pooling': 'mean', 'learning_rate': 0.0010159985264898911, 'weight_decay': 5.779554195051548e-06, 'beta_0': 0.8664243797500168, 'beta_1': 0.9844765055138394, 'epsilon': 3.143589868291785e-08, 'balanced_loss': True, 'epochs': 167, 'early_stopping_patience': 14, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 16:43:06,393] Trial 260 finished with value: 0.9212121212121213 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9952609859296738, 'batch_size': 64, 'attention_heads': 8, 'hidden_dimension': 126, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40448128092506386, 'global_pooling': 'mean', 'learning_rate': 0.0006944799617393723, 'weight_decay': 2.0537679897261206e-05, 'beta_0': 0.843469784187664, 'beta_1': 0.996987903163949, 'epsilon': 2.457533008472125e-08, 'balanced_loss': True, 'epochs': 189, 'early_stopping_patience': 10, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.38 GiB. GPU 0 has a total capacity of 44.56 GiB of which 1.22 GiB is free. Including non-PyTorch memory, this process has 43.33 GiB memory in use. Of the allocated memory 37.12 GiB is allocated by PyTorch, and 5.06 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 17:07:43,885] Trial 261 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.988898663324054, 'batch_size': 46, 'attention_heads': 6, 'hidden_dimension': 135, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3810657572246839, 'global_pooling': 'mean', 'learning_rate': 0.0014355386518187024, 'weight_decay': 4.4478872918115493e-05, 'beta_0': 0.8408955958811859, 'beta_1': 0.9881370104539872, 'epsilon': 1.4486214815887347e-07, 'balanced_loss': True, 'epochs': 195, 'early_stopping_patience': 12, 'plateau_patience': 17, 'plateau_divider': 2}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 17:29:37,922] Trial 262 finished with value: 0.9212121212121213 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9979959776704835, 'batch_size': 41, 'attention_heads': 8, 'hidden_dimension': 217, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3906287534317476, 'global_pooling': 'mean', 'learning_rate': 0.0004823433743942978, 'weight_decay': 3.426372631999249e-05, 'beta_0': 0.8469462702029992, 'beta_1': 0.9965115897913747, 'epsilon': 1.7713768432279084e-08, 'balanced_loss': True, 'epochs': 185, 'early_stopping_patience': 13, 'plateau_patience': 18, 'plateau_divider': 4}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.25 GiB. GPU 0 has a total capacity of 44.56 GiB of which 590.69 MiB is free. Including non-PyTorch memory, this process has 43.98 GiB memory in use. Of the allocated memory 38.40 GiB is allocated by PyTorch, and 4.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 17:39:41,219] Trial 263 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.942135278733363, 'batch_size': 45, 'attention_heads': 9, 'hidden_dimension': 227, 'number_of_hidden_layers': 2, 'dropout_rate': 0.37506469409018706, 'global_pooling': 'mean', 'learning_rate': 0.0008826146211299555, 'weight_decay': 2.5732514657264167e-05, 'beta_0': 0.8443998635825787, 'beta_1': 0.9891067969251732, 'epsilon': 2.8644019636249868e-08, 'balanced_loss': True, 'epochs': 197, 'early_stopping_patience': 14, 'plateau_patience': 24, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 18:03:05,160] Trial 264 finished with value: 0.9333333333333333 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9929213686856087, 'batch_size': 54, 'attention_heads': 7, 'hidden_dimension': 174, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3976104506091707, 'global_pooling': 'mean', 'learning_rate': 0.0012232220010914283, 'weight_decay': 2.951636985564314e-05, 'beta_0': 0.8421027112660611, 'beta_1': 0.9961232660486153, 'epsilon': 1.3834321809971767e-08, 'balanced_loss': True, 'epochs': 182, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 1.28 GiB. GPU 0 has a total capacity of 44.56 GiB of which 398.69 MiB is free. Including non-PyTorch memory, this process has 44.16 GiB memory in use. Of the allocated memory 37.29 GiB is allocated by PyTorch, and 5.72 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 18:10:36,259] Trial 265 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9236265571089214, 'batch_size': 47, 'attention_heads': 8, 'hidden_dimension': 117, 'number_of_hidden_layers': 2, 'dropout_rate': 0.40994394441801446, 'global_pooling': 'mean', 'learning_rate': 0.0006236227128543162, 'weight_decay': 4.034583926823004e-05, 'beta_0': 0.8387479153123715, 'beta_1': 0.9974881121742308, 'epsilon': 2.2150424817563406e-08, 'balanced_loss': True, 'epochs': 192, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 2.38 GiB. GPU 0 has a total capacity of 44.56 GiB of which 554.69 MiB is free. Including non-PyTorch memory, this process has 44.01 GiB memory in use. Of the allocated memory 40.23 GiB is allocated by PyTorch, and 2.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 18:29:54,109] Trial 266 finished with value: -1.0 and parameters: {'left_stride': 128, 'right_stride': 64, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'max', 'threshold': 0.9908212406422794, 'batch_size': 57, 'attention_heads': 7, 'hidden_dimension': 244, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3931920496428324, 'global_pooling': 'mean', 'learning_rate': 0.0003699373004864493, 'weight_decay': 6.478531963768773e-05, 'beta_0': 0.8489203649853672, 'beta_1': 0.9886291395783938, 'epsilon': 3.591671500764156e-08, 'balanced_loss': True, 'epochs': 151, 'early_stopping_patience': 15, 'plateau_patience': 18, 'plateau_divider': 6}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 18:58:04,502] Trial 267 finished with value: 0.9454545454545454 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9959993577338024, 'batch_size': 43, 'attention_heads': 8, 'hidden_dimension': 199, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3664976063664422, 'global_pooling': 'mean', 'learning_rate': 0.0007634644151072595, 'weight_decay': 8.178621256095379e-05, 'beta_0': 0.8457307290485351, 'beta_1': 0.9895004475472782, 'epsilon': 1.9438025675626867e-08, 'balanced_loss': True, 'epochs': 189, 'early_stopping_patience': 12, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 19:24:08,916] Trial 268 finished with value: 0.8909090909090909 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9987228726479785, 'batch_size': 43, 'attention_heads': 6, 'hidden_dimension': 208, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3511325562566752, 'global_pooling': 'sum', 'learning_rate': 0.0008110868790651174, 'weight_decay': 8.283529452483975e-05, 'beta_0': 0.8520468828444804, 'beta_1': 0.9896945532262345, 'epsilon': 2.6591398091084832e-08, 'balanced_loss': True, 'epochs': 189, 'early_stopping_patience': 13, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
CUDA out of memory. Tried to allocate 5.09 GiB. GPU 0 has a total capacity of 44.56 GiB of which 4.30 GiB is free. Including non-PyTorch memory, this process has 40.25 GiB memory in use. Of the allocated memory 35.30 GiB is allocated by PyTorch, and 3.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[I 2024-12-23 19:39:45,336] Trial 269 finished with value: -1.0 and parameters: {'left_stride': 64, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9695946183542631, 'batch_size': 44, 'attention_heads': 5, 'hidden_dimension': 200, 'number_of_hidden_layers': 2, 'dropout_rate': 0.363299621072331, 'global_pooling': 'mean', 'learning_rate': 0.001058504990258045, 'weight_decay': 0.00014919278161900116, 'beta_0': 0.8471506139886217, 'beta_1': 0.988996935782589, 'epsilon': 2.064390825045872e-08, 'balanced_loss': True, 'epochs': 186, 'early_stopping_patience': 12, 'plateau_patience': 25, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
[I 2024-12-23 20:06:59,857] Trial 270 finished with value: 0.9272727272727272 and parameters: {'left_stride': 128, 'right_stride': 256, 'attention_pooling_operation': 'min', 'embedding_pooling_operation': 'mean', 'threshold': 0.9965381294696755, 'batch_size': 39, 'attention_heads': 8, 'hidden_dimension': 189, 'number_of_hidden_layers': 2, 'dropout_rate': 0.3701830389412739, 'global_pooling': 'mean', 'learning_rate': 0.0007632562453440794, 'weight_decay': 7.715227414110081e-05, 'beta_0': 0.8538947685846614, 'beta_1': 0.9967916376546498, 'epsilon': 3.3695371265749315e-08, 'balanced_loss': True, 'epochs': 183, 'early_stopping_patience': 11, 'plateau_patience': 22, 'plateau_divider': 3}. Best is trial 110 with value: 0.9515151515151515.
slurmstepd: error: *** JOB 14141827 ON gpu052 CANCELLED AT 2024-12-23T20:19:23 DUE TO TIME LIMIT ***
