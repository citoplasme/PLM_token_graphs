[I 2025-05-06 11:05:50,574] Using an existing study with name 'SST-2-google-bert-bert-base-uncased' instead of creating a new one.

[TRIAL] 198 [VALIDATION PERFORMANCE] 0.9323394495412844 [TRAINING LOSS] 0.019480060691216623 [VALIDATION LOSS] 0.30607927707708715 

number                                 198
value                             0.932339
params_balanced_loss                  True
params_batch_size                       13
params_early_stopping_patience           4
params_epochs                            6
params_learning_rate               0.00001
params_plateau_divider                   9
params_plateau_patience                  2
params_weight_decay               0.000513
params_beta_0                     0.824986
params_beta_1                     0.995171
params_epsilon                         0.0
user_attrs_epoch                       6.0
user_attrs_training_loss           0.01948
user_attrs_validation_loss        0.306079
Name: 198, dtype: object
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Count of trainable parameters: 109483778

[SST-2] Elapsed time: 0.09196091095606486 minutes.
